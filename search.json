[{"title":"hysteria2搭建","path":"/2025/12/16/20251216/","content":"官网文档 ： https://v2.hysteria.network/zh/docs/advanced/Full-Server-Config/#_2 安装1bash &lt;(curl -fsSL https://get.hy2.sh/) 当提示 What’s next? 执行下面的命令先将 Hysteria 设置为开机自启 1systemctl enable hysteria-server.service 配置使用以下命令生成自签证书 1openssl req -x509 -nodes -newkey ec:&lt;(openssl ecparam -name prime256v1) -keyout /etc/hysteria/server.key -out /etc/hysteria/server.crt -subj &quot;/CN=bing.com&quot; -days 3650 &amp;&amp; sudo chown hysteria /etc/hysteria/server.key &amp;&amp; sudo chown hysteria /etc/hysteria/server.crt 修改配置文件 1vim /etc/hysteria/config.yaml 将配置文件中的内容全部删除，填入以下配置。根据自己的需要选择使用 CA 证书，还是使用自签证书，将对应的注释取消即可 简版(推荐)12345678910111213141516171819202122listen: :443 #监听端口#有域名，使用CA证书 #acme:# domains:# - test.heybro.bid #你的域名，需要先解析到服务器ip# email: augustdoit@gmail.com#使用自签证书tls: cert: /etc/hysteria/server.crt key: /etc/hysteria/server.keyauth: type: password password: 123456 #设置认证密码masquerade: type: proxy proxy: url: https://bing.com #伪装网址 rewriteHost: true 普版1234567891011121314151617181920212223242526272829303132333435363738394041listen: :443 #默认端口443，可以修改为其他端口#使用CA证书#acme:# domains:# - your.domain.net #已经解析到服务器的域名# email: your@email.com #你的邮箱#使用自签证书#tls:# cert: /etc/hysteria/server.crt # key: /etc/hysteria/server.key auth: type: password password: 123456 #认证密码，使用一个强密码进行替换resolver: type: udp tcp: addr: 8.8.8.8:53 timeout: 4s udp: addr: 8.8.4.4:53 timeout: 4s tls: addr: 1.1.1.1:853 timeout: 10s sni: cloudflare-dns.com insecure: false https: addr: 1.1.1.1:443 timeout: 10s sni: cloudflare-dns.com insecure: falsemasquerade: type: proxy proxy: url: https://cn.bing.com/ #伪装网址 rewriteHost: true 伪装网址推荐使用个人网盘的网址，个人网盘比较符合单节点大流量的特征，可以通过谷歌搜索 intext:登录 cloudreve 来查找别人搭建好的网盘网址 开放 80 和 443 端口 我开放了udp协议443端口和36712端口(36712自行测试关闭) 维护启动 1systemctl start hysteria-server.service 状态 1systemctl status hysteria-server.service 日志 1journalctl --no-pager -e -u hysteria-server.service 重新启动 1systemctl restart hysteria-server.service 如果显示：{“error”: “invalid config: tls: open /etc/hysteria/server.crt: permission denied”} 或者 failed to load server conf 的错误，则说明 Hysteria 没有访问证书文件的权限，需要执行下面的命令将 Hysteria 切换到 root 用户运行 1234sed -i &#x27;/User=/d&#x27; /etc/systemd/system/hysteria-server.servicesed -i &#x27;/User=/d&#x27; /etc/systemd/system/hysteria-server@.servicesystemctl daemon-reloadsystemctl restart hysteria-server.service 客户端我用的clash verge ，建议用最新版，需要支持hysteria2协议 1.订阅页面新增1个本地订阅 2.右键点击刚刚新建的订阅，进入 扩展覆写配置 3.把下面的配置覆盖粘贴进去即可 1234567891011121314151617181920212223242526272829303132# 基础端口设置port: 7890socks-port: 7891allow-lan: truemode: rulelog-level: infoipv6: false# 核心：节点配置 (IP直连 + 自签名证书方案)proxies: - name: &quot;Hysteria2-Oracle&quot; # 节点显示名称 type: hysteria2 # 协议类型 server: xxx # 您的服务器 IP port: 443 # 端口 password: &quot;123456&quot; # 您的密码 sni: bing.com # 伪装域名 skip-cert-verify: true # 跳过证书验证(重要) up: 40 Mbps # 参考您之前设置的上传带宽 down: 100 Mbps # 参考您之前设置的下载带宽# 策略组：决定流量怎么走proxy-groups: - name: &quot;节点选择&quot; # 手动选择节点的组 type: select proxies: - &quot;Hysteria2-Oracle&quot; # 上面定义的节点 - DIRECT # 直连# 规则：简单的分流规则rules: - GEOIP,CN,DIRECT # 国内 IP 直连 - MATCH,节点选择 # 其他所有流量走代理","tags":["笔记"],"categories":["其他"]},{"title":"linux安装neo4j","path":"/2025/11/20/2025112002/","content":"neo4j需要Java环境 下载https://neo4j.com/deployment-center/ 从上面的网址里找到对应版本然后下载 下载1wget --content-disposition &quot;https://neo4j.com/artifact.php?name=neo4j-community-5.26.1-unix.tar.gz&quot; 解压1tar -xzvf neo4j-community-5.26.1-unix.tar.gz 配置12cd neo4j-community-5.26.1/conf/vim neo4j.conf 找个空白地方加入以下配置 123dbms.connector.bolt.listen_address=0.0.0.0:7687dbms.connector.http.listen_address=0.0.0.0:7474dbms.connector.http.advertised_address=服务器ip:7474 启动进入bin目录 1cd ../bin/ 启动 1./neo4j start 修改默认密码进入bin目录 1./cypher-shell -u neo4j -p neo4j 首次登录会提示 12You are required to change your password.Enter new password: 按提示输入新密码即可 退出neo4j 1:exit 验证新密码 1./cypher-shell -u neo4j -p 新密码 其他状态 1./neo4j status 或者jps 以前台控制台方式启动（推荐调试时使用） 1./neo4j console 查看日志（如果启动失败） 12tail -f /data/apps/neo4j/neo4j-community-5.26.1/logs/neo4j.log","tags":["笔记"],"categories":["Linux"]},{"title":"tk获取粉丝数量","path":"/2025/11/20/20251120/","content":"spider_followers123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180import reimport asyncioimport randomimport pandas as pdfrom playwright.async_api import async_playwright# 随机延迟范围（秒）MIN_DELAY = 2MAX_DELAY = 8# 用户代理池USER_AGENTS = [ &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15&quot;]def parse_follower_count(text): &quot;&quot;&quot;解析粉丝数量文本，支持K、M等单位&quot;&quot;&quot; try: text = text.strip().upper() # 移除可能的逗号 text = text.replace(&#x27;,&#x27;, &#x27;&#x27;) # 处理K（千） if &#x27;K&#x27; in text: number = float(text.replace(&#x27;K&#x27;, &#x27;&#x27;)) return int(number * 1000) # 处理M（百万） elif &#x27;M&#x27; in text: number = float(text.replace(&#x27;M&#x27;, &#x27;&#x27;)) return int(number * 1000000) # 处理B（十亿） elif &#x27;B&#x27; in text: number = float(text.replace(&#x27;B&#x27;, &#x27;&#x27;)) return int(number * 1000000000) # 纯数字 else: return int(float(text)) except: return Noneasync def crawl_followers(index, homepage): &quot;&quot;&quot;异步爬取单个主页的粉丝数量&quot;&quot;&quot; result_msg = &quot;未抓取到粉丝数&quot; # 默认状态 try: # 随机延迟 await asyncio.sleep(random.uniform(MIN_DELAY, MAX_DELAY)) async with async_playwright() as p: browser = await p.chromium.launch(headless=True) context = await browser.new_context( user_agent=random.choice(USER_AGENTS) ) page = await context.new_page() try: # 设置超时 await page.goto(homepage, timeout=30000, wait_until=&quot;domcontentloaded&quot;) # 随机滚动 if random.random() &gt; 0.5: await page.evaluate(&quot;window.scrollBy(0, window.innerHeight)&quot;) await asyncio.sleep(random.uniform(0.5, 2)) # 尝试获取粉丝数量信息 try: # 多种选择器尝试 selectors = [ &#x27;[data-e2e=&quot;followers-count&quot;]&#x27;, &#x27;[data-e2e=&quot;followers-number&quot;]&#x27;, &#x27;strong[data-e2e=&quot;followers-count&quot;]&#x27;, &#x27;strong[title*=&quot;Followers&quot;]&#x27;, &#x27;[title*=&quot;Followers&quot;]&#x27; ] follower_text = None for selector in selectors: try: await page.wait_for_selector(selector, timeout=5000) follower_text = await page.locator(selector).first.inner_text() if follower_text: break except: continue # 如果以上选择器都失败，尝试通过文本匹配查找 if not follower_text: try: # 查找包含&quot;Followers&quot;文本的元素 followers_element = page.locator(&#x27;strong:near(:text(&quot;Followers&quot;))&#x27;) follower_text = await followers_element.first.inner_text(timeout=5000) except: pass if follower_text: # 解析粉丝数量 count = parse_follower_count(follower_text) if count is not None: return index, count # 成功抓取粉丝数 else: result_msg = f&quot;解析失败: &#123;follower_text&#125;&quot; else: result_msg = &quot;页面元素未找到&quot; except Exception as e: result_msg = f&quot;页面元素加载失败: &#123;str(e)[:30]&#125;&quot; except Exception as e: result_msg = f&quot;页面加载失败: &#123;str(e)[:30]&#125;&quot; finally: await browser.close() except Exception as e: result_msg = f&quot;浏览器启动失败: &#123;str(e)[:30]&#125;...&quot; # 截取部分错误信息 return index, result_msgasync def main(): file_name = &quot;tiktok_links_table&quot; column_name = &quot;tiktok_url&quot; # 读取Excel文件 file_path = &quot;./target/&quot; + file_name + &quot;.xlsx&quot; df = pd.read_excel(file_path) output_path = &quot;./result/&quot; + file_name + &quot;_followers.xlsx&quot; # 处理粉丝数列数据类型 if &quot;粉丝数&quot; in df.columns: df[&quot;粉丝数&quot;] = df[&quot;粉丝数&quot;].astype(str) # 确保是字符串类型 else: df[&quot;粉丝数&quot;] = &quot;&quot; # 新建列默认就是字符串类型 # 创建任务列表 tasks = [] for i, row in df.iterrows(): homepage = row.get(column_name) if pd.isna(homepage) or not isinstance(homepage, str): df.at[i, &quot;粉丝数&quot;] = &quot;无效链接&quot; continue tasks.append(crawl_followers(i, homepage)) # 并发执行任务 for i in range(0, len(tasks), 5): batch = tasks[i:i + 3] results = await asyncio.gather(*batch) # 更新结果 for index, result in results: df.at[index, &quot;粉丝数&quot;] = result status = &quot;✅&quot; if isinstance(result, int) else &quot;❌&quot; print(f&quot;&#123;status&#125; 索引:&#123;index&#125; &#123;df.at[index,column_name]&#125; -&gt; &#123;result&#125;&quot;) # 保存结果 df.to_excel(output_path, index=False) print(f&quot; 已保存到 &#123;output_path&#125;&quot;) print(f&quot;统计结果：&quot;) # 统计成功抓取的数量（数值型） success_count = len(df[df[&#x27;粉丝数&#x27;].apply(lambda x: isinstance(x, (int, float)) and x != &quot;&quot;)]) print(f&quot;- 成功抓取：&#123;success_count&#125;条&quot;) print(f&quot;- 失败数量：&#123;len(df) - success_count&#125;条&quot;) # 如果有成功抓取的，显示统计信息 if success_count &gt; 0: numeric_followers = df[df[&#x27;粉丝数&#x27;].apply(lambda x: isinstance(x, (int, float)))] if len(numeric_followers) &gt; 0: print(f&quot;- 平均粉丝数：&#123;int(numeric_followers[&#x27;粉丝数&#x27;].mean())&#125;人&quot;) print(f&quot;- 最高粉丝数：&#123;int(numeric_followers[&#x27;粉丝数&#x27;].max())&#125;人&quot;) print(f&quot;- 最低粉丝数：&#123;int(numeric_followers[&#x27;粉丝数&#x27;].min())&#125;人&quot;)if __name__ == &quot;__main__&quot;: asyncio.run(main()) spider_followers_retry123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215import reimport asyncioimport randomimport pandas as pdfrom playwright.async_api import async_playwright# 配置参数CONCURRENCY = 5 # 并发数量MIN_DELAY = 2 # 最小延迟(秒)MAX_DELAY = 8 # 最大延迟(秒)# 用户代理池USER_AGENTS = [ &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15&quot;]def parse_follower_count(text): &quot;&quot;&quot;解析粉丝数量文本，支持K、M等单位&quot;&quot;&quot; try: text = text.strip().upper() # 移除可能的逗号 text = text.replace(&#x27;,&#x27;, &#x27;&#x27;) # 处理K（千） if &#x27;K&#x27; in text: number = float(text.replace(&#x27;K&#x27;, &#x27;&#x27;)) return int(number * 1000) # 处理M（百万） elif &#x27;M&#x27; in text: number = float(text.replace(&#x27;M&#x27;, &#x27;&#x27;)) return int(number * 1000000) # 处理B（十亿） elif &#x27;B&#x27; in text: number = float(text.replace(&#x27;B&#x27;, &#x27;&#x27;)) return int(number * 1000000000) # 纯数字 else: return int(float(text)) except: return Noneasync def crawl_followers(index, homepage): &quot;&quot;&quot;异步爬取单个主页的粉丝数量&quot;&quot;&quot; result_msg = &quot;未抓取到粉丝数&quot; try: await asyncio.sleep(random.uniform(MIN_DELAY, MAX_DELAY)) async with async_playwright() as p: browser = await p.chromium.launch(headless=True) context = await browser.new_context( user_agent=random.choice(USER_AGENTS), viewport=&#123;&quot;width&quot;: 1920, &quot;height&quot;: 1080&#125; # 添加默认视口大小 ) page = await context.new_page() try: await page.goto(homepage, timeout=30000, wait_until=&quot;domcontentloaded&quot;) # 随机模拟人类操作 if random.random() &gt; 0.3: await page.mouse.move( random.randint(0, 500), random.randint(0, 500) ) await page.evaluate(&quot;window.scrollBy(0, window.innerHeight/2)&quot;) await asyncio.sleep(random.uniform(0.5, 1.5)) try: # 多种选择器尝试 selectors = [ &#x27;[data-e2e=&quot;followers-count&quot;]&#x27;, &#x27;[data-e2e=&quot;followers-number&quot;]&#x27;, &#x27;strong[data-e2e=&quot;followers-count&quot;]&#x27;, &#x27;strong[title*=&quot;Followers&quot;]&#x27;, &#x27;[title*=&quot;Followers&quot;]&#x27; ] follower_text = None for selector in selectors: try: await page.wait_for_selector(selector, timeout=8000) # 延长等待时间 follower_text = await page.locator(selector).first.inner_text() if follower_text: break except: continue # 如果以上选择器都失败，尝试通过文本匹配查找 if not follower_text: try: # 查找包含&quot;Followers&quot;文本的元素 followers_element = page.locator(&#x27;strong:near(:text(&quot;Followers&quot;))&#x27;) follower_text = await followers_element.first.inner_text(timeout=8000) except: pass if follower_text: # 解析粉丝数量 count = parse_follower_count(follower_text) if count is not None: return index, count else: result_msg = f&quot;解析失败: &#123;follower_text&#125;&quot; else: result_msg = &quot;页面元素未找到&quot; except Exception as e: result_msg = &quot;页面元素加载失败&quot; except Exception as e: result_msg = f&quot;页面加载失败: &#123;str(e)[:50]&#125;&quot; finally: await browser.close() except Exception as e: result_msg = f&quot;浏览器错误: &#123;str(e)[:50]&#125;&quot; return index, result_msgasync def main(): print(f&quot;启动粉丝数重试爬虫，并发数: &#123;CONCURRENCY&#125;&quot;) # 读取文件并预处理 file_name = &quot;tiktok_links_table_followers&quot; column_name = &quot;tiktok_url&quot; file_path = &quot;./result/&quot; + file_name + &quot;.xlsx&quot; df = pd.read_excel(file_path) df[&quot;粉丝数&quot;] = df[&quot;粉丝数&quot;].astype(str) output_path = &quot;./retry/&quot; + file_name + &quot;.xlsx&quot; # 构建重试条件：筛选失败或为空的记录 retry_condition = ( df[&quot;粉丝数&quot;].str.contains(&quot;失败&quot;, na=False) | df[&quot;粉丝数&quot;].str.contains(&quot;未抓取到&quot;, na=False) | df[&quot;粉丝数&quot;].str.contains(&quot;无效链接&quot;, na=False) | df[&quot;粉丝数&quot;].str.contains(&quot;元素&quot;, na=False) | df[&quot;粉丝数&quot;].str.contains(&quot;浏览器&quot;, na=False) | df[&quot;粉丝数&quot;].str.lower().isin([&quot;nan&quot;, &quot;none&quot;, &quot;null&quot;, &quot;&quot;]) ) retry_df = df[retry_condition] if len(retry_df) == 0: print(&quot;没有需要重试的记录&quot;) return print(f&quot;发现 &#123;len(retry_df)&#125; 条需要重试的记录&quot;) # 准备任务队列 tasks = [] for index, row in retry_df.iterrows(): homepage = row[column_name] if pd.isna(homepage) or not isinstance(homepage, str) or not homepage.startswith((&#x27;http&#x27;, &#x27;www&#x27;)): df.at[index, &quot;粉丝数&quot;] = &quot;无效链接格式&quot; continue tasks.append((index, homepage.strip())) # 分批处理任务 total = len(tasks) success_count = 0 for i in range(0, total, CONCURRENCY): batch = tasks[i:i + CONCURRENCY] batch_tasks = [crawl_followers(idx, url) for idx, url in batch] # 显示批次信息 batch_num = i // CONCURRENCY + 1 total_batches = (total + CONCURRENCY - 1) // CONCURRENCY print(f&quot; 处理批次 &#123;batch_num&#125;/&#123;total_batches&#125; (任务 &#123;i+1&#125;-&#123;min(i+CONCURRENCY, total)&#125;)&quot;) results = await asyncio.gather(*batch_tasks) # 处理结果 for index, result in results: original_status = df.at[index, &quot;粉丝数&quot;] df.at[index, &quot;粉丝数&quot;] = result if isinstance(result, int): status = &quot;✅ 成功&quot; success_count += 1 else: status = &quot;❌ 失败&quot; print(f&quot;行&#123;index+2&#125;: &#123;status&#125; | 原状态: &#123;original_status&#125; | 新结果: &#123;result&#125;&quot;) # 保存并输出统计 df.to_excel(output_path, index=False) print(&quot; &quot; + &quot;=&quot;*50) print(f&quot;任务完成，文件已保存: &#123;output_path&#125;&quot;) print(f&quot;总记录数: &#123;len(df)&#125;&quot;) print(f&quot;本次处理: &#123;len(retry_df)&#125; 条&quot;) print(f&quot;成功抓取: &#123;success_count&#125; 条&quot;) print(f&quot;仍失败: &#123;len(retry_df) - success_count&#125; 条&quot;) # 如果有成功抓取的，显示统计信息 if success_count &gt; 0: numeric_followers = df[df[&#x27;粉丝数&#x27;].apply(lambda x: isinstance(x, (int, float)) and str(x).isdigit())] if len(numeric_followers) &gt; 0: numeric_followers[&#x27;粉丝数&#x27;] = pd.to_numeric(numeric_followers[&#x27;粉丝数&#x27;], errors=&#x27;coerce&#x27;) print(f&quot;- 平均粉丝数: &#123;int(numeric_followers[&#x27;粉丝数&#x27;].mean())&#125;人&quot;) print(f&quot;- 最高粉丝数: &#123;int(numeric_followers[&#x27;粉丝数&#x27;].max())&#125;人&quot;) print(f&quot;- 最低粉丝数: &#123;int(numeric_followers[&#x27;粉丝数&#x27;].min())&#125;人&quot;) print(&quot;=&quot;*50)if __name__ == &quot;__main__&quot;: asyncio.run(main())","tags":["笔记"],"categories":["python"]},{"title":"tk标签页获取内容账号","path":"/2025/10/13/20251013/","content":"需要Python3.10以上的环境 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.common.exceptions import TimeoutExceptionfrom bs4 import BeautifulSoupimport timeimport randomimport csvfrom datetime import datetimeimport re# 依赖安装# pip3 install selenium beautifulsoup4# pip3 install webdriver-manager# pip3 install requests lxml html5libdef init_driver(headless=True): &quot;&quot;&quot;初始化浏览器驱动，增加反反爬措施&quot;&quot;&quot; options = webdriver.ChromeOptions() if headless: options.add_argument(&#x27;--headless&#x27;) options.add_argument(&#x27;--no-sandbox&#x27;) options.add_argument(&#x27;--disable-dev-shm-usage&#x27;) options.add_argument(&#x27;--disable-gpu&#x27;) options.add_argument(&#x27;--disable-blink-features=AutomationControlled&#x27;) options.add_argument(&#x27;--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;) options.add_argument(&#x27;--window-size=1920,1080&#x27;) options.add_experimental_option(&quot;excludeSwitches&quot;, [&quot;enable-automation&quot;]) options.add_experimental_option(&#x27;useAutomationExtension&#x27;, False) # 添加更多反检测参数 options.add_argument(&#x27;--disable-infobars&#x27;) options.add_argument(&#x27;--disable-extensions&#x27;) options.add_argument(&#x27;--disable-popup-blocking&#x27;) options.add_argument(&#x27;--disable-notifications&#x27;) options.add_argument(&#x27;--disable-web-security&#x27;) options.add_argument(&#x27;--disable-translate&#x27;) options.add_argument(&#x27;--disable-logging&#x27;) options.add_argument(&#x27;--disable-default-apps&#x27;) options.add_argument(&#x27;--disable-sync&#x27;) options.add_argument(&#x27;--disable-background-networking&#x27;) options.add_argument(&#x27;--disable-client-side-phishing-detection&#x27;) options.add_argument(&#x27;--disable-component-update&#x27;) options.add_argument(&#x27;--disable-hang-monitor&#x27;) options.add_argument(&#x27;--disable-prompt-on-repost&#x27;) options.add_argument(&#x27;--disable-renderer-backgrounding&#x27;) options.add_argument(&#x27;--disable-session-crashed-bubble&#x27;) options.add_argument(&#x27;--disable-sync&#x27;) options.add_argument(&#x27;--disable-web-resources&#x27;) options.add_argument(&#x27;--metrics-recording-only&#x27;) options.add_argument(&#x27;--no-first-run&#x27;) options.add_argument(&#x27;--safebrowsing-disable-auto-update&#x27;) options.add_argument(&#x27;--password-store=basic&#x27;) try: driver = webdriver.Chrome(options=options) # 执行JavaScript代码来隐藏自动化特征 driver.execute_script(&quot;Object.defineProperty(navigator, &#x27;webdriver&#x27;, &#123;get: () =&gt; undefined&#125;)&quot;) driver.execute_cdp_cmd(&#x27;Page.addScriptToEvaluateOnNewDocument&#x27;, &#123; &#x27;source&#x27;: &#x27;&#x27;&#x27; Object.defineProperty(navigator, &#x27;plugins&#x27;, &#123; get: () =&gt; [1, 2, 3, 4, 5], &#125;); Object.defineProperty(navigator, &#x27;languages&#x27;, &#123; get: () =&gt; [&#x27;en-US&#x27;, &#x27;en&#x27;], &#125;); const originalQuery = window.navigator.permissions.query; window.navigator.permissions.query = (parameters) =&gt; ( parameters.name === &#x27;notifications&#x27; ? Promise.resolve(&#123; state: Notification.permission &#125;) : originalQuery(parameters) ); &#x27;&#x27;&#x27; &#125;) return driver except Exception as e: print(f&quot;初始化浏览器失败: &#123;e&#125;&quot;) raisedef print_page_info(driver, step_name): &quot;&quot;&quot;打印页面信息到控制台&quot;&quot;&quot; print(f&quot; === &#123;step_name&#125; ===&quot;) print(f&quot;页面标题: &#123;driver.title&#125;&quot;) print(f&quot;页面URL: &#123;driver.current_url&#125;&quot;) print(f&quot;页面源代码长度: &#123;len(driver.page_source)&#125; 字符&quot;) # 检查页面内容特征 page_text = driver.page_source.lower() # 检查关键特征 checks = &#123; &quot;包含TikTok&quot;: &quot;tiktok&quot; in page_text, &quot;包含用户名元素&quot;: &#x27;data-e2e=&quot;challenge-item-username&quot;&#x27; in page_text, &quot;包含登录&quot;: &quot;login&quot; in page_text, &quot;包含验证码&quot;: &quot;captcha&quot; in page_text, &#125; for check_name, result in checks.items(): status = &quot;✓&quot; if result else &quot;✗&quot; print(f&quot;&#123;status&#125; &#123;check_name&#125;&quot;) return page_textdef get_total_videos_count(driver): &quot;&quot;&quot;获取标签下的作品总数&quot;&quot;&quot; try: # 尝试多种选择器查找作品总数元素 selectors = [ &#x27;h2[data-e2e=&quot;challenge-vvcount&quot;]&#x27;, &#x27;h2[data-e2e*=&quot;vvcount&quot;]&#x27;, &#x27;h2[class*=&quot;ShareSubTitle&quot;]&#x27;, &#x27;div[data-e2e*=&quot;vvcount&quot;]&#x27;, &#x27;span[data-e2e*=&quot;vvcount&quot;]&#x27; ] for selector in selectors: try: element = driver.find_element(By.CSS_SELECTOR, selector) if element: text = element.text.strip() # 使用正则表达式提取数字 match = re.search(r&#x27;(\\d+[\\d,]*)\\s*个作品&#x27;, text) if match: count_str = match.group(1).replace(&#x27;,&#x27;, &#x27;&#x27;) return int(count_str) print(f&quot;找到作品总数元素，但格式不匹配: &#123;text&#125;&quot;) except: continue # 如果没找到，尝试从页面源代码中查找 page_source = driver.page_source match = re.search(r&#x27;(\\d+[\\d,]*)\\s*个作品&#x27;, page_source) if match: count_str = match.group(1).replace(&#x27;,&#x27;, &#x27;&#x27;) return int(count_str) print(&quot;未找到作品总数元素&quot;) return 0 except Exception as e: print(f&quot;获取作品总数失败: &#123;e&#125;&quot;) return 0def scrape_tiktok_usernames(url, max_items=50, scroll_pause=2, headless=True): &quot;&quot;&quot; 采集TikTok标签页面的用户名数据（增强版） &quot;&quot;&quot; driver = None try: driver = init_driver(headless) # 设置页面加载超时 driver.set_page_load_timeout(60) driver.implicitly_wait(15) print(f&quot;正在访问页面: &#123;url&#125;&quot;) driver.get(url) # 等待页面加载 print(&quot;等待页面加载...&quot;) WebDriverWait(driver, 30).until( EC.presence_of_element_located((By.TAG_NAME, &quot;body&quot;)) ) # 打印初始页面信息 page_text = print_page_info(driver, &quot;初始页面&quot;) # 检查是否有重定向或错误页面 if &quot;error&quot; in driver.current_url.lower() or &quot;login&quot; in driver.current_url.lower(): print(&quot;检测到可能的错误页面或登录页面&quot;) return [] # 获取作品总数 total_videos = get_total_videos_count(driver) print(f&quot;标签下共有 &#123;total_videos&#125; 个作品&quot;) # 等待更长时间让内容加载 print(&quot;等待内容加载...&quot;) # 尝试多种等待策略 try: # 策略1: 等待特定元素出现 print(&quot;尝试等待特定元素...&quot;) WebDriverWait(driver, 20).until( EC.presence_of_element_located((By.CSS_SELECTOR, &#x27;div[data-e2e=&quot;challenge-item-list&quot;]&#x27;)) ) print(&quot;找到目标项目列表元素&quot;) except TimeoutException: print(&quot;未找到目标项目列表元素，尝试其他策略&quot;) # 策略2: 等待视频元素出现 try: print(&quot;尝试等待视频元素...&quot;) WebDriverWait(driver, 15).until( EC.presence_of_element_located((By.CSS_SELECTOR, &#x27;div[data-e2e*=&quot;video&quot;]&#x27;)) ) print(&quot;找到视频元素&quot;) except TimeoutException: print(&quot;未找到视频元素，尝试滚动加载&quot;) # 策略3: 滚动页面触发加载 for i in range(3): print(f&quot;滚动页面 &#123;i+1&#125;/3&quot;) driver.execute_script(&quot;window.scrollTo(0, document.body.scrollHeight);&quot;) time.sleep(2) # 打印等待后的页面信息 page_text = print_page_info(driver, &quot;等待后页面&quot;) # 检查是否包含目标元素 if &#x27;data-e2e=&quot;challenge-item-username&quot;&#x27; not in page_text: print(&quot;页面中未找到目标用户名元素&quot;) return [] collected_usernames = [] scroll_attempts = 0 max_scroll_attempts = 15 print(&quot;开始滚动采集用户名...&quot;) while len(collected_usernames) &lt; max_items and scroll_attempts &lt; max_scroll_attempts: print(f&quot; === 第 &#123;scroll_attempts + 1&#125; 次滚动 ===&quot;) # 滚动页面 driver.execute_script(&quot;window.scrollTo(0, document.body.scrollHeight);&quot;) scroll_attempts += 1 # 等待内容加载 - 使用更智能的等待 wait_time = scroll_pause + random.uniform(1.0, 3.0) print(f&quot;等待 &#123;wait_time:.1f&#125; 秒让内容加载...&quot;) time.sleep(wait_time) # 打印滚动后的页面信息 page_text = print_page_info(driver, f&quot;滚动后页面 &#123;scroll_attempts&#125;&quot;) # 提取用户名 soup = BeautifulSoup(driver.page_source, &#x27;html.parser&#x27;) usernames = extract_usernames(soup) print(f&quot;本次提取到 &#123;len(usernames)&#125; 个用户名&quot;) # 去重处理 new_usernames = [] for username in usernames: if username not in collected_usernames and len(collected_usernames) &lt; max_items: collected_usernames.append(username) new_usernames.append(username) print(f&quot;新增 &#123;len(new_usernames)&#125; 个用户名，总计 &#123;len(collected_usernames)&#125; 个&quot;) # 显示处理进度 if total_videos &gt; 0: progress = min(len(collected_usernames) / total_videos * 100, 100) print(f&quot;处理进度: &#123;len(collected_usernames)&#125;/&#123;total_videos&#125; (&#123;progress:.1f&#125;%)&quot;) # 如果没有新数据，尝试多次滚动后退出 if len(new_usernames) == 0 and scroll_attempts &gt; 5: print(&quot;连续多次滚动没有新用户名，停止采集&quot;) break print(f&quot;采集完成！共获取 &#123;len(collected_usernames)&#125; 个用户名&quot;) return collected_usernames except Exception as e: print(f&quot;采集过程中出现错误: &#123;str(e)&#125;&quot;) import traceback traceback.print_exc() return [] finally: if driver: driver.quit() print(&quot;浏览器已关闭&quot;)def extract_usernames(soup): &quot;&quot;&quot;提取用户名数据（增强版）&quot;&quot;&quot; usernames = [] print(&quot;开始提取用户名...&quot;) # 方法1: 使用CSS选择器 username_elements = soup.select(&#x27;p[data-e2e=&quot;challenge-item-username&quot;]&#x27;) print(f&quot;使用CSS选择器找到 &#123;len(username_elements)&#125; 个用户名元素&quot;) for element in username_elements: try: username = element.get_text(strip=True) if username and username not in usernames: usernames.append(username) print(f&quot;提取到用户名: &#123;username&#125;&quot;) except Exception as e: print(f&quot;提取用户名失败: &#123;e&#125;&quot;) # 方法2: 使用BeautifulSoup的find_all if len(username_elements) == 0: print(&quot;尝试使用find_all方法查找用户名元素...&quot;) username_elements = soup.find_all(&#x27;p&#x27;, attrs=&#123;&#x27;data-e2e&#x27;: &#x27;challenge-item-username&#x27;&#125;) print(f&quot;使用find_all找到 &#123;len(username_elements)&#125; 个用户名元素&quot;) for element in username_elements: try: username = element.get_text(strip=True) if username and username not in usernames: usernames.append(username) print(f&quot;提取到用户名: &#123;username&#125;&quot;) except Exception as e: print(f&quot;提取用户名失败: &#123;e&#125;&quot;) # 方法3: 尝试其他可能的选择器 if len(username_elements) == 0: print(&quot;尝试其他选择器查找用户名...&quot;) alternative_selectors = [ &#x27;p[data-e2e*=&quot;username&quot;]&#x27;, &#x27;p[class*=&quot;user-name&quot;]&#x27;, &#x27;div[data-e2e*=&quot;username&quot;]&#x27;, &#x27;span[data-e2e*=&quot;username&quot;]&#x27;, &#x27;a[data-e2e*=&quot;username&quot;]&#x27;, &#x27;div[class*=&quot;user-name&quot;]&#x27;, &#x27;span[class*=&quot;user-name&quot;]&#x27;, &#x27;a[class*=&quot;user-name&quot;]&#x27; ] for selector in alternative_selectors: try: elements = soup.select(selector) if elements: print(f&quot;使用选择器 &#x27;&#123;selector&#125;&#x27; 找到 &#123;len(elements)&#125; 个元素&quot;) for element in elements: try: username = element.get_text(strip=True) if username and username not in usernames: usernames.append(username) print(f&quot;提取到用户名: &#123;username&#125;&quot;) except Exception as e: print(f&quot;提取用户名失败: &#123;e&#125;&quot;) except Exception as e: print(f&quot;使用选择器 &#123;selector&#125; 失败: &#123;e&#125;&quot;) print(f&quot;最终提取到 &#123;len(usernames)&#125; 个用户名&quot;) return usernamesdef save_usernames_to_csv(usernames, filename=None): &quot;&quot;&quot;保存用户名到CSV表格&quot;&quot;&quot; if not usernames: print(&quot;没有用户名数据可保存&quot;) return None if not filename: timestamp = datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;) filename = f&#x27;tiktok_usernames_&#123;timestamp&#125;.csv&#x27; # 定义CSV表头 fieldnames = [&#x27;序号&#x27;, &#x27;用户名&#x27;, &#x27;主页地址&#x27;] with open(filename, &#x27;w&#x27;, newline=&#x27;&#x27;, encoding=&#x27;utf-8-sig&#x27;) as csvfile: writer = csv.DictWriter(csvfile, fieldnames=fieldnames) writer.writeheader() for i, username in enumerate(usernames, 1): writer.writerow(&#123; &#x27;序号&#x27;: i, &#x27;用户名&#x27;: username, &#x27;主页地址&#x27;: f&quot;https://www.tiktok.com/@&#123;username&#125;&quot; &#125;) print(f&quot;用户名数据已保存到CSV文件: &#123;filename&#125;&quot;) return filenamedef display_usernames_preview(usernames, count=10): &quot;&quot;&quot;显示用户名预览&quot;&quot;&quot; if not usernames: print(&quot;没有用户名数据可显示&quot;) return print(f&quot; === 采集到的用户名预览（前&#123;min(count, len(usernames))&#125;个）===&quot;) for i, username in enumerate(usernames[:count], 1): print(f&quot;&#123;i&#125;. &#123;username&#125; (主页: https://www.tiktok.com/@&#123;username&#125;)&quot;) print(f&quot; 总共采集到 &#123;len(usernames)&#125; 个用户名&quot;)if __name__ == &quot;__main__&quot;: TagName = &quot;xxx&quot; # 配置参数 TARGET_URL = &quot;https://www.tiktok.com/tag/&quot;+TagName MAX_ITEMS = 10 SCROLL_PAUSE = 3 HEADLESS_MODE = False # 先设置为 False 进行调试 print(&quot;开始采集 TikTok 用户名数据...&quot;) try: usernames = scrape_tiktok_usernames( url=TARGET_URL, max_items=MAX_ITEMS, scroll_pause=SCROLL_PAUSE, headless=HEADLESS_MODE ) if usernames: # 保存为CSV表格 csv_file = save_usernames_to_csv(usernames,TagName+&quot;.csv&quot;) # 显示用户名预览 display_usernames_preview(usernames) print(f&quot; 采集完成！共获取 &#123;len(usernames)&#125; 个用户名&quot;) print(f&quot;数据已保存到: &#123;csv_file&#125;&quot;) else: print(&quot;未采集到任何用户名数据&quot;) except Exception as e: print(f&quot;程序执行出错: &#123;e&#125;&quot;) import traceback traceback.print_exc() 代码2-去掉了滚动次数限制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.common.exceptions import TimeoutExceptionfrom bs4 import BeautifulSoupimport timeimport randomimport csvfrom datetime import datetimeimport re# 依赖安装# pip3 install selenium beautifulsoup4# pip3 install webdriver-manager# pip3 install requests lxml html5libdef init_driver(headless=True): &quot;&quot;&quot;初始化浏览器驱动，增加反反爬措施&quot;&quot;&quot; options = webdriver.ChromeOptions() if headless: options.add_argument(&#x27;--headless&#x27;) options.add_argument(&#x27;--no-sandbox&#x27;) options.add_argument(&#x27;--disable-dev-shm-usage&#x27;) options.add_argument(&#x27;--disable-gpu&#x27;) options.add_argument(&#x27;--disable-blink-features=AutomationControlled&#x27;) options.add_argument(&#x27;--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36&#x27;) options.add_argument(&#x27;--window-size=1920,1080&#x27;) options.add_experimental_option(&quot;excludeSwitches&quot;, [&quot;enable-automation&quot;]) options.add_experimental_option(&#x27;useAutomationExtension&#x27;, False) # 添加更多反检测参数 options.add_argument(&#x27;--disable-infobars&#x27;) options.add_argument(&#x27;--disable-extensions&#x27;) options.add_argument(&#x27;--disable-popup-blocking&#x27;) options.add_argument(&#x27;--disable-notifications&#x27;) options.add_argument(&#x27;--disable-web-security&#x27;) options.add_argument(&#x27;--disable-translate&#x27;) options.add_argument(&#x27;--disable-logging&#x27;) options.add_argument(&#x27;--disable-default-apps&#x27;) options.add_argument(&#x27;--disable-sync&#x27;) options.add_argument(&#x27;--disable-background-networking&#x27;) options.add_argument(&#x27;--disable-client-side-phishing-detection&#x27;) options.add_argument(&#x27;--disable-component-update&#x27;) options.add_argument(&#x27;--disable-hang-monitor&#x27;) options.add_argument(&#x27;--disable-prompt-on-repost&#x27;) options.add_argument(&#x27;--disable-renderer-backgrounding&#x27;) options.add_argument(&#x27;--disable-session-crashed-bubble&#x27;) options.add_argument(&#x27;--disable-sync&#x27;) options.add_argument(&#x27;--disable-web-resources&#x27;) options.add_argument(&#x27;--metrics-recording-only&#x27;) options.add_argument(&#x27;--no-first-run&#x27;) options.add_argument(&#x27;--safebrowsing-disable-auto-update&#x27;) options.add_argument(&#x27;--password-store=basic&#x27;) try: driver = webdriver.Chrome(options=options) # 执行JavaScript代码来隐藏自动化特征 driver.execute_script(&quot;Object.defineProperty(navigator, &#x27;webdriver&#x27;, &#123;get: () =&gt; undefined&#125;)&quot;) driver.execute_cdp_cmd(&#x27;Page.addScriptToEvaluateOnNewDocument&#x27;, &#123; &#x27;source&#x27;: &#x27;&#x27;&#x27; Object.defineProperty(navigator, &#x27;plugins&#x27;, &#123; get: () =&gt; [1, 2, 3, 4, 5], &#125;); Object.defineProperty(navigator, &#x27;languages&#x27;, &#123; get: () =&gt; [&#x27;en-US&#x27;, &#x27;en&#x27;], &#125;); const originalQuery = window.navigator.permissions.query; window.navigator.permissions.query = (parameters) =&gt; ( parameters.name === &#x27;notifications&#x27; ? Promise.resolve(&#123; state: Notification.permission &#125;) : originalQuery(parameters) ); &#x27;&#x27;&#x27; &#125;) return driver except Exception as e: print(f&quot;初始化浏览器失败: &#123;e&#125;&quot;) raisedef print_page_info(driver, step_name): &quot;&quot;&quot;打印页面信息到控制台&quot;&quot;&quot; print(f&quot; === &#123;step_name&#125; ===&quot;) print(f&quot;页面标题: &#123;driver.title&#125;&quot;) print(f&quot;页面URL: &#123;driver.current_url&#125;&quot;) print(f&quot;页面源代码长度: &#123;len(driver.page_source)&#125; 字符&quot;) # 检查页面内容特征 page_text = driver.page_source.lower() # 检查关键特征 checks = &#123; &quot;包含TikTok&quot;: &quot;tiktok&quot; in page_text, &quot;包含用户名元素&quot;: &#x27;data-e2e=&quot;challenge-item-username&quot;&#x27; in page_text, &quot;包含登录&quot;: &quot;login&quot; in page_text, &quot;包含验证码&quot;: &quot;captcha&quot; in page_text, &#125; for check_name, result in checks.items(): status = &quot;✓&quot; if result else &quot;✗&quot; print(f&quot;&#123;status&#125; &#123;check_name&#125;&quot;) return page_textdef get_total_videos_count(driver): &quot;&quot;&quot;获取标签下的作品总数&quot;&quot;&quot; try: # 尝试多种选择器查找作品总数元素 selectors = [ &#x27;h2[data-e2e=&quot;challenge-vvcount&quot;]&#x27;, &#x27;h2[data-e2e*=&quot;vvcount&quot;]&#x27;, &#x27;h2[class*=&quot;ShareSubTitle&quot;]&#x27;, &#x27;div[data-e2e*=&quot;vvcount&quot;]&#x27;, &#x27;span[data-e2e*=&quot;vvcount&quot;]&#x27; ] for selector in selectors: try: element = driver.find_element(By.CSS_SELECTOR, selector) if element: text = element.text.strip() # 使用正则表达式提取数字 match = re.search(r&#x27;(\\d+[\\d,]*)\\s*个作品&#x27;, text) if match: count_str = match.group(1).replace(&#x27;,&#x27;, &#x27;&#x27;) return int(count_str) print(f&quot;找到作品总数元素，但格式不匹配: &#123;text&#125;&quot;) except: continue # 如果没找到，尝试从页面源代码中查找 page_source = driver.page_source match = re.search(r&#x27;(\\d+[\\d,]*)\\s*个作品&#x27;, page_source) if match: count_str = match.group(1).replace(&#x27;,&#x27;, &#x27;&#x27;) return int(count_str) print(&quot;未找到作品总数元素&quot;) return 0 except Exception as e: print(f&quot;获取作品总数失败: &#123;e&#125;&quot;) return 0def scrape_tiktok_usernames(url, max_items=50, scroll_pause=2, headless=True): &quot;&quot;&quot; 采集TikTok标签页面的用户名数据（增强版） &quot;&quot;&quot; driver = None try: driver = init_driver(headless) # 设置页面加载超时 driver.set_page_load_timeout(60) driver.implicitly_wait(15) print(f&quot;正在访问页面: &#123;url&#125;&quot;) driver.get(url) # 等待页面加载 print(&quot;等待页面加载...&quot;) WebDriverWait(driver, 30).until( EC.presence_of_element_located((By.TAG_NAME, &quot;body&quot;)) ) # 打印初始页面信息 page_text = print_page_info(driver, &quot;初始页面&quot;) # 检查是否有重定向或错误页面 if &quot;error&quot; in driver.current_url.lower() or &quot;login&quot; in driver.current_url.lower(): print(&quot;检测到可能的错误页面或登录页面&quot;) return [] # 获取作品总数 total_videos = get_total_videos_count(driver) print(f&quot;标签下共有 &#123;total_videos&#125; 个作品&quot;) # 等待更长时间让内容加载 print(&quot;等待内容加载...&quot;) # 尝试多种等待策略 try: # 策略1: 等待特定元素出现 print(&quot;尝试等待特定元素...&quot;) WebDriverWait(driver, 20).until( EC.presence_of_element_located((By.CSS_SELECTOR, &#x27;div[data-e2e=&quot;challenge-item-list&quot;]&#x27;)) ) print(&quot;找到目标项目列表元素&quot;) except TimeoutException: print(&quot;未找到目标项目列表元素，尝试其他策略&quot;) # 策略2: 等待视频元素出现 try: print(&quot;尝试等待视频元素...&quot;) WebDriverWait(driver, 15).until( EC.presence_of_element_located((By.CSS_SELECTOR, &#x27;div[data-e2e*=&quot;video&quot;]&#x27;)) ) print(&quot;找到视频元素&quot;) except TimeoutException: print(&quot;未找到视频元素，尝试滚动加载&quot;) # 策略3: 滚动页面触发加载 for i in range(3): print(f&quot;滚动页面 &#123;i+1&#125;/3&quot;) driver.execute_script(&quot;window.scrollTo(0, document.body.scrollHeight);&quot;) time.sleep(2) # 打印等待后的页面信息 page_text = print_page_info(driver, &quot;等待后页面&quot;) # 检查是否包含目标元素 if &#x27;data-e2e=&quot;challenge-item-username&quot;&#x27; not in page_text: print(&quot;页面中未找到目标用户名元素&quot;) return [] collected_usernames = [] scroll_attempts = 0 # max_scroll_attempts = 15 print(&quot;开始滚动采集用户名...&quot;) while len(collected_usernames) &lt; max_items: print(f&quot; === 第 &#123;scroll_attempts + 1&#125; 次滚动 ===&quot;) # 滚动页面 driver.execute_script(&quot;window.scrollTo(0, document.body.scrollHeight);&quot;) scroll_attempts += 1 # 等待内容加载 - 使用更智能的等待 wait_time = scroll_pause + random.uniform(1.0, 3.0) print(f&quot;等待 &#123;wait_time:.1f&#125; 秒让内容加载...&quot;) time.sleep(wait_time) # 打印滚动后的页面信息 page_text = print_page_info(driver, f&quot;滚动后页面 &#123;scroll_attempts&#125;&quot;) # 提取用户名 soup = BeautifulSoup(driver.page_source, &#x27;html.parser&#x27;) usernames = extract_usernames(soup) print(f&quot;本次提取到 &#123;len(usernames)&#125; 个用户名&quot;) # 去重处理 new_usernames = [] for username in usernames: if username not in collected_usernames and len(collected_usernames) &lt; max_items: collected_usernames.append(username) new_usernames.append(username) print(f&quot;新增 &#123;len(new_usernames)&#125; 个用户名，总计 &#123;len(collected_usernames)&#125; 个&quot;) # 显示处理进度 if total_videos &gt; 0: progress = min(len(collected_usernames) / total_videos * 100, 100) print(f&quot;处理进度: &#123;len(collected_usernames)&#125;/&#123;total_videos&#125; (&#123;progress:.1f&#125;%)&quot;) # 如果没有新数据，尝试多次滚动后退出 if len(new_usernames) == 0 and scroll_attempts &gt; 10: print(&quot;连续多次滚动没有新用户名，停止采集&quot;) break print(f&quot;采集完成！共获取 &#123;len(collected_usernames)&#125; 个用户名&quot;) return collected_usernames except Exception as e: print(f&quot;采集过程中出现错误: &#123;str(e)&#125;&quot;) import traceback traceback.print_exc() return [] finally: if driver: driver.quit() print(&quot;浏览器已关闭&quot;)def extract_usernames(soup): &quot;&quot;&quot;提取用户名数据（增强版）&quot;&quot;&quot; usernames = [] print(&quot;开始提取用户名...&quot;) # 方法1: 使用CSS选择器 username_elements = soup.select(&#x27;p[data-e2e=&quot;challenge-item-username&quot;]&#x27;) print(f&quot;使用CSS选择器找到 &#123;len(username_elements)&#125; 个用户名元素&quot;) for element in username_elements: try: username = element.get_text(strip=True) if username and username not in usernames: usernames.append(username) print(f&quot;提取到用户名: &#123;username&#125;&quot;) except Exception as e: print(f&quot;提取用户名失败: &#123;e&#125;&quot;) # 方法2: 使用BeautifulSoup的find_all if len(username_elements) == 0: print(&quot;尝试使用find_all方法查找用户名元素...&quot;) username_elements = soup.find_all(&#x27;p&#x27;, attrs=&#123;&#x27;data-e2e&#x27;: &#x27;challenge-item-username&#x27;&#125;) print(f&quot;使用find_all找到 &#123;len(username_elements)&#125; 个用户名元素&quot;) for element in username_elements: try: username = element.get_text(strip=True) if username and username not in usernames: usernames.append(username) print(f&quot;提取到用户名: &#123;username&#125;&quot;) except Exception as e: print(f&quot;提取用户名失败: &#123;e&#125;&quot;) # 方法3: 尝试其他可能的选择器 if len(username_elements) == 0: print(&quot;尝试其他选择器查找用户名...&quot;) alternative_selectors = [ &#x27;p[data-e2e*=&quot;username&quot;]&#x27;, &#x27;p[class*=&quot;user-name&quot;]&#x27;, &#x27;div[data-e2e*=&quot;username&quot;]&#x27;, &#x27;span[data-e2e*=&quot;username&quot;]&#x27;, &#x27;a[data-e2e*=&quot;username&quot;]&#x27;, &#x27;div[class*=&quot;user-name&quot;]&#x27;, &#x27;span[class*=&quot;user-name&quot;]&#x27;, &#x27;a[class*=&quot;user-name&quot;]&#x27; ] for selector in alternative_selectors: try: elements = soup.select(selector) if elements: print(f&quot;使用选择器 &#x27;&#123;selector&#125;&#x27; 找到 &#123;len(elements)&#125; 个元素&quot;) for element in elements: try: username = element.get_text(strip=True) if username and username not in usernames: usernames.append(username) print(f&quot;提取到用户名: &#123;username&#125;&quot;) except Exception as e: print(f&quot;提取用户名失败: &#123;e&#125;&quot;) except Exception as e: print(f&quot;使用选择器 &#123;selector&#125; 失败: &#123;e&#125;&quot;) print(f&quot;最终提取到 &#123;len(usernames)&#125; 个用户名&quot;) return usernamesdef save_usernames_to_csv(usernames, filename=None): &quot;&quot;&quot;保存用户名到CSV表格&quot;&quot;&quot; if not usernames: print(&quot;没有用户名数据可保存&quot;) return None if not filename: timestamp = datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;) filename = f&#x27;tiktok_usernames_&#123;timestamp&#125;.csv&#x27; # 定义CSV表头 fieldnames = [&#x27;序号&#x27;, &#x27;用户名&#x27;, &#x27;主页地址&#x27;] with open(filename, &#x27;w&#x27;, newline=&#x27;&#x27;, encoding=&#x27;utf-8-sig&#x27;) as csvfile: writer = csv.DictWriter(csvfile, fieldnames=fieldnames) writer.writeheader() for i, username in enumerate(usernames, 1): writer.writerow(&#123; &#x27;序号&#x27;: i, &#x27;用户名&#x27;: username, &#x27;主页地址&#x27;: f&quot;https://www.tiktok.com/@&#123;username&#125;&quot; &#125;) print(f&quot;用户名数据已保存到CSV文件: &#123;filename&#125;&quot;) return filenamedef display_usernames_preview(usernames, count=10): &quot;&quot;&quot;显示用户名预览&quot;&quot;&quot; if not usernames: print(&quot;没有用户名数据可显示&quot;) return print(f&quot; === 采集到的用户名预览（前&#123;min(count, len(usernames))&#125;个）===&quot;) for i, username in enumerate(usernames[:count], 1): print(f&quot;&#123;i&#125;. &#123;username&#125; (主页: https://www.tiktok.com/@&#123;username&#125;)&quot;) print(f&quot; 总共采集到 &#123;len(usernames)&#125; 个用户名&quot;)if __name__ == &quot;__main__&quot;: TagName = &quot;xxx&quot; # 配置参数 TARGET_URL = &quot;https://www.tiktok.com/tag/&quot;+TagName MAX_ITEMS = 1800 SCROLL_PAUSE = 3 HEADLESS_MODE = False # 先设置为 False 进行调试 print(&quot;开始采集 TikTok 用户名数据...&quot;) try: usernames = scrape_tiktok_usernames( url=TARGET_URL, max_items=MAX_ITEMS, scroll_pause=SCROLL_PAUSE, headless=HEADLESS_MODE ) if usernames: # 保存为CSV表格 csv_file = save_usernames_to_csv(usernames,TagName+&quot;.csv&quot;) # 显示用户名预览 # display_usernames_preview(usernames) print(f&quot; 采集完成！共获取 &#123;len(usernames)&#125; 个用户名&quot;) print(f&quot;数据已保存到: &#123;csv_file&#125;&quot;) else: print(&quot;未采集到任何用户名数据&quot;) except Exception as e: print(f&quot;程序执行出错: &#123;e&#125;&quot;) import traceback traceback.print_exc()","tags":["笔记"],"categories":["其他"]},{"title":"tk简介里获取邮箱","path":"/2025/09/28/tkGetEmail/","content":"说明xlsx表格和spider表格有红人id,主页链接，粉丝数，类型，邮箱。这5列，参考下面 红人id:xxx主页链接：https://www.tiktok.com/@xxx spider.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117import reimport asyncioimport randomimport pandas as pdfrom playwright.async_api import async_playwright# 邮箱正则表达式EMAIL_REGEX = r&quot;[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]&#123;2,&#125;&quot;# 随机延迟范围（秒）MIN_DELAY = 2MAX_DELAY = 8# 用户代理池USER_AGENTS = [ &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15&quot;]async def crawl_email(index, homepage): &quot;&quot;&quot;异步爬取单个主页的邮箱&quot;&quot;&quot; result_msg = &quot;未抓取到邮箱&quot; # 默认状态 try: # 随机延迟 await asyncio.sleep(random.uniform(MIN_DELAY, MAX_DELAY)) async with async_playwright() as p: browser = await p.chromium.launch(headless=True) context = await browser.new_context( user_agent=random.choice(USER_AGENTS) ) page = await context.new_page() try: # 设置超时 await page.goto(homepage, timeout=30000, wait_until=&quot;domcontentloaded&quot;) # 随机滚动 if random.random() &gt; 0.5: await page.evaluate(&quot;window.scrollBy(0, window.innerHeight)&quot;) await asyncio.sleep(random.uniform(0.5, 2)) # 尝试获取bio信息 try: await page.wait_for_selector(&#x27;[data-e2e=&quot;user-bio&quot;]&#x27;, timeout=5000) bio_text = await page.locator(&#x27;[data-e2e=&quot;user-bio&quot;]&#x27;).inner_text() # 提取邮箱 emails = re.findall(EMAIL_REGEX, bio_text) if emails: return index, emails[0] # 成功抓取邮箱 except Exception as e: result_msg = &quot;页面元素加载失败&quot; except Exception as e: result_msg = &quot;页面加载失败&quot; finally: await browser.close() except Exception as e: result_msg = f&quot;浏览器启动失败: &#123;str(e)[:30]&#125;...&quot; # 截取部分错误信息 return index, result_msgasync def main(): file_name = &quot;stickertok&quot; column_name = &quot;主页地址&quot; # 读取Excel文件 file_path = &quot;./target/&quot; + file_name + &quot;.xlsx&quot; df = pd.read_excel(file_path) output_path = &quot;./result/&quot; + file_name + &quot;.xlsx&quot; # 处理邮箱列数据类型 if &quot;邮箱&quot; in df.columns: df[&quot;邮箱&quot;] = df[&quot;邮箱&quot;].astype(str) # 确保是字符串类型 else: df[&quot;邮箱&quot;] = &quot;&quot; # 新建列默认就是字符串类型 # 创建任务列表 tasks = [] for i, row in df.iterrows(): homepage = row.get(column_name) if pd.isna(homepage) or not isinstance(homepage, str): df.at[i, &quot;邮箱&quot;] = &quot;无效链接&quot; continue tasks.append(crawl_email(i, homepage)) # 并发执行任务 for i in range(0, len(tasks), 5): batch = tasks[i:i + 3] results = await asyncio.gather(*batch) # 更新结果 for index, result in results: df.at[index, &quot;邮箱&quot;] = result status = &quot;✅&quot; if &quot;@&quot; in str(result) else &quot;❌&quot; print(f&quot;&#123;status&#125; 索引:&#123;index&#125; &#123;df.at[index,column_name]&#125; -&gt; &#123;result&#125;&quot;) # 保存结果 df.to_excel(output_path, index=False) print(f&quot; 已保存到 &#123;output_path&#125;&quot;) print(f&quot;统计结果：&quot;) print(f&quot;- 成功抓取：&#123;len(df[df[&#x27;邮箱&#x27;].str.contains(&#x27;@&#x27;, na=False)])&#125;条&quot;) print(f&quot;- 失败数量：&#123;len(df) - len(df[df[&#x27;邮箱&#x27;].str.contains(&#x27;@&#x27;, na=False)])&#125;条&quot;)if __name__ == &quot;__main__&quot;: asyncio.run(main()) 启动我的环境是python3,安装依赖和启动命令如下 1234pip3 install playwright pandas openpyxlpython3 -m playwright installpython3 spider.py spider_retry.py页面加载失败重扫脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147import reimport asyncioimport randomimport pandas as pdfrom playwright.async_api import async_playwright# 配置参数CONCURRENCY = 5 # 并发数量EMAIL_REGEX = r&quot;[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]&#123;2,&#125;&quot;MIN_DELAY = 2 # 最小延迟(秒)MAX_DELAY = 8 # 最大延迟(秒)# 用户代理池USER_AGENTS = [ &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15&quot;]async def crawl_email(index, homepage): &quot;&quot;&quot;异步爬取单个主页的邮箱&quot;&quot;&quot; result_msg = &quot;未抓取到邮箱&quot; try: await asyncio.sleep(random.uniform(MIN_DELAY, MAX_DELAY)) async with async_playwright() as p: browser = await p.chromium.launch(headless=True) context = await browser.new_context( user_agent=random.choice(USER_AGENTS), viewport=&#123;&quot;width&quot;: 1920, &quot;height&quot;: 1080&#125; # 添加默认视口大小 ) page = await context.new_page() try: await page.goto(homepage, timeout=30000, wait_until=&quot;domcontentloaded&quot;) # 随机模拟人类操作 if random.random() &gt; 0.3: await page.mouse.move( random.randint(0, 500), random.randint(0, 500) ) await page.evaluate(&quot;window.scrollBy(0, window.innerHeight/2)&quot;) await asyncio.sleep(random.uniform(0.5, 1.5)) try: await page.wait_for_selector(&#x27;[data-e2e=&quot;user-bio&quot;]&#x27;, timeout=8000) # 延长等待时间 bio_text = await page.locator(&#x27;[data-e2e=&quot;user-bio&quot;]&#x27;).inner_text() emails = re.findall(EMAIL_REGEX, bio_text) if emails: return index, emails[0] except Exception as e: result_msg = &quot;页面元素加载失败&quot; except Exception as e: result_msg = f&quot;页面加载失败: &#123;str(e)[:50]&#125;&quot; finally: await browser.close() except Exception as e: result_msg = f&quot;浏览器错误: &#123;str(e)[:50]&#125;&quot; return index, result_msgasync def main(): print(f&quot;启动爬虫，并发数: &#123;CONCURRENCY&#125;&quot;) # 读取文件并预处理 file_name = &quot;3dsticker_result&quot; column_name = &quot;主页地址&quot; file_path = &quot;./result/&quot; + file_name + &quot;.xlsx&quot; df = pd.read_excel(file_path) df[&quot;邮箱&quot;] = df[&quot;邮箱&quot;].astype(str) output_path = &quot;./retry/&quot; + file_name + &quot;.xlsx&quot; # 构建重试条件 retry_condition = ( df[&quot;邮箱&quot;].str.contains(&quot;加载失败&quot;, na=False) | df[&quot;邮箱&quot;].str.lower().isin([&quot;nan&quot;, &quot;none&quot;, &quot;null&quot;, &quot;&quot;]) ) retry_df = df[retry_condition] if len(retry_df) == 0: print(&quot;没有需要重试的记录&quot;) return print(f&quot;发现 &#123;len(retry_df)&#125; 条需要重试的记录&quot;) # 准备任务队列 tasks = [] for index, row in retry_df.iterrows(): homepage = row[column_name] if pd.isna(homepage) or not isinstance(homepage, str) or not homepage.startswith((&#x27;http&#x27;, &#x27;www&#x27;)): df.at[index, &quot;邮箱&quot;] = &quot;无效链接格式&quot; continue tasks.append((index, homepage.strip())) # 分批处理任务 total = len(tasks) success_count = 0 for i in range(0, total, CONCURRENCY): batch = tasks[i:i + CONCURRENCY] batch_tasks = [crawl_email(idx, url) for idx, url in batch] # 显示批次信息 batch_num = i // CONCURRENCY + 1 total_batches = (total + CONCURRENCY - 1) // CONCURRENCY print(f&quot; 处理批次 &#123;batch_num&#125;/&#123;total_batches&#125; (任务 &#123;i+1&#125;-&#123;min(i+CONCURRENCY, total)&#125;)&quot;) results = await asyncio.gather(*batch_tasks) # 处理结果 for index, result in results: original_status = df.at[index, &quot;邮箱&quot;] df.at[index, &quot;邮箱&quot;] = result if &quot;@&quot; in str(result): status = &quot;✅ 成功&quot; success_count += 1 else: status = &quot;❌ 失败&quot; print(f&quot;行&#123;index+2&#125;: &#123;status&#125; | 原状态: &#123;original_status&#125; | 新结果: &#123;result&#125;&quot;) # 保存并输出统计 df.to_excel(output_path, index=False) print(&quot; &quot; + &quot;=&quot;*50) print(f&quot;任务完成，文件已保存: &#123;output_path&#125;&quot;) print(f&quot;总记录数: &#123;len(df)&#125;&quot;) print(f&quot;本次处理: &#123;len(retry_df)&#125; 条&quot;) print(f&quot;成功抓取: &#123;success_count&#125; 条&quot;) print(f&quot;仍失败: &#123;len(retry_df) - success_count&#125; 条&quot;) print(&quot;=&quot;*50)if __name__ == &quot;__main__&quot;: asyncio.run(main())","tags":["笔记"],"categories":["python"]},{"title":"mongodb自动备份","path":"/2025/09/01/20250901/","content":"使用 mongodump 结合 cron 任务来自动备份 MongoDB 数据库 查看mongodb安装位置，如果有用到1whereis mongod 安装 mongodump 工具查看是否安装了mongodump1mongodump --version 如果没有安装在 Debian/Ubuntu 上安装 12sudo apt updatesudo apt install mongodb-clients 在 CentOS/RHEL 上安装 1sudo yum install mongodb-org-tools 创建备份目录创建一个用于存储备份文件的目录，并设置合适的权限 12sudo mkdir -p /backup/mongodbsudo chown -R $(whoami) /backup/mongodb # 或将所有者更改为对MongoDB有权限的用户，如mongodb 编写备份脚本 (Shell Script)1234567891011121314151617181920212223242526272829303132333435#!/bin/bash# 定义备份目录BACKUP_DIR=&quot;/data/app/backup/mongodb&quot;# 定义日期格式DATE=$(date +%Y%m%d_%H%M%S)# 定义保留备份的天数DAYS_TO_KEEP=5# MongoDB 认证信息（如果启用了认证）# MONGO_USER=&quot;your_username&quot;# MONGO_PASS=&quot;your_password&quot;# MONGO_AUTH_DB=&quot;admin&quot; # 认证数据库，通常是 admin# 创建当前备份的目录mkdir -p $BACKUP_DIR/$DATE# 执行 mongodump# 如果无需认证，直接使用下面的命令mongodump --out $BACKUP_DIR/$DATE# 如果启用了认证，使用下面的命令（取消注释并替换你的信息）# mongodump --username $MONGO_USER --password $MONGO_PASS --authenticationDatabase $MONGO_AUTH_DB --out $BACKUP_DIR/$DATE# 压缩备份文件以节省空间tar -czf $BACKUP_DIR/mongodb_backup_$DATE.tar.gz -C $BACKUP_DIR $DATE# 删除压缩前的原始备份目录rm -rf $BACKUP_DIR/$DATE# 删除超过一定天数的旧备份find $BACKUP_DIR -name &quot;*.tar.gz&quot; -mtime +$DAYS_TO_KEEP -delete# 输出备份完成信息echo &quot;MongoDB backup completed: $BACKUP_DIR/mongodb_backup_$DATE.tar.gz&quot; 给脚本添加执行权限1sudo chmod +x /usr/local/bin/mongodb_backup.sh 配置 cron 定时任务编辑当前用户的 cron 任务表 1crontab -e 如果当前用户没有设置过，会让你选择编辑方式，输入数字即可选择 12345678910root@kremail-dev:/data/apps/backup# crontab -eno crontab for root - using an empty oneSelect an editor. To change later, run &#x27;select-editor&#x27;. 1. /bin/nano &lt;---- easiest 2. /usr/bin/vim.basic 3. /usr/bin/vim.tiny 4. /bin/edChoose 1-4 [1]: 然后再次输入 1crontab -e 添加一行配置来定时执行你的备份脚本。例如，下面的例子表示每天凌晨 2 点执行备份脚本 ,直接新起一行放进去即可 10 2 * * * /usr/local/bin/mongodb_backup.sh &gt;&gt; /var/log/mongodb_backup.log 2&gt;&amp;1 退出编辑器后，运行以下命令，你应该能看到你刚添加的那行任务 1crontab -l 可选）手动测试一次脚本：为了万无一失，你可以手动执行一次脚本，看看它是否能正常运行，并观察日志文件是否生成 123sh mongodb_backup.sh# 查看日志tail -f /var/log/mongodb_backup.log 如果报错： 123root@kremail-dev:/data/apps/backup# sh mongodb_backup.sh2025-09-01T07:52:00.596+0000 Failed: error creating intents to dump: error creating intents for database config: error getting collections for database `config`: (Unauthorized) not authorized on config to execute command &#123; listCollections: 1, filter: &#123;&#125;, cursor: &#123;&#125;, lsid: &#123; id: UUID(&quot;1255fd99-76ad-4d97-8b6b-1a8abcbd9697&quot;) &#125;, $db: &quot;config&quot; &#125;MongoDB backup completed: /data/apps/backup/mongodb/mongodb_backup_20250901_075200.tar.gz 错误信息 (Unauthorized) not authorized on config to execute command { listCollections: 1… 表明你用来执行备份的MongoDB用户账号权限不足，无法读取 config 数据库的集合列表。config 数据库通常用于存储分片集群的元数据，对其进行备份需要特定权限 1mongosh -u &lt;你的管理员用户名&gt; -p --authenticationDatabase admin 例如 1mongosh -u admin -p --authenticationDatabase admin 输入密码后执行 1use admin 12345db.createUser(&#123; user: &quot;backupuser&quot;, // 备份用户名 pwd: &quot;your_strong_password&quot;, // 设置一个强密码 roles: [ &#123; role: &quot;backup&quot;, db: &quot;admin&quot; &#125; ] // 授予内置的backup角色&#125;) 然后 ctrl+d退出MongoDB 修改备份脚本文件，再次执行然后成功 123456789101112131415161718root@kremail-dev:/data/apps/backup# sh mongodb_backup.sh 2025-09-01T08:00:19.345+0000 writing admin.system.users to /data/apps/backup/mongodb/20250901_080019/admin/system.users.bson2025-09-01T08:00:19.346+0000 done dumping admin.system.users (2 documents)2025-09-01T08:00:19.346+0000 writing admin.system.version to /data/apps/backup/mongodb/20250901_080019/admin/system.version.bson2025-09-01T08:00:19.346+0000 done dumping admin.system.version (2 documents)2025-09-01T08:00:19.346+0000 writing smart_email.emails to /data/apps/backup/mongodb/20250901_080019/smart_email/emails.bson2025-09-01T08:00:19.346+0000 writing smart_email.failed_actions to /data/apps/backup/mongodb/20250901_080019/smart_email/failed_actions.bson2025-09-01T08:00:19.346+0000 writing smart_email.processed_messages to /data/apps/backup/mongodb/20250901_080019/smart_email/processed_messages.bson2025-09-01T08:00:19.347+0000 writing smart_email.memories to /data/apps/backup/mongodb/20250901_080019/smart_email/memories.bson2025-09-01T08:00:19.351+0000 done dumping smart_email.memories (49 documents)2025-09-01T08:00:19.353+0000 writing smart_email.experts to /data/apps/backup/mongodb/20250901_080019/smart_email/experts.bson2025-09-01T08:00:19.356+0000 done dumping smart_email.processed_messages (1649 documents)2025-09-01T08:00:19.356+0000 writing smart_email.generation_result to /data/apps/backup/mongodb/20250901_080019/smart_email/generation_result.bson2025-09-01T08:00:19.356+0000 done dumping smart_email.experts (8 documents)2025-09-01T08:00:19.357+0000 done dumping smart_email.generation_result (1 document)2025-09-01T08:00:19.375+0000 done dumping smart_email.emails (1870 documents)2025-09-01T08:00:19.414+0000 done dumping smart_email.failed_actions (38696 documents)MongoDB backup completed: /data/apps/backup/mongodb/mongodb_backup_20250901_080019.tar.gz 验证备份自动化流程搭建好后，定期验证其可靠性很重要,检查备份文件,查看备份目录中是否生成了压缩文件 1ls -l /backup/mongodb/ 验证备份完整性：定期尝试从备份文件中恢复数据到测试环境是验证备份是否有效的最佳方式。可以使用 mongorestore 命令 1mongorestore --drop --gzip --archive=/backup/mongodb/mongodb_backup_20250901_020000.tar.gz 注意事项权限问题：确保执行 cron 任务的用户对备份目录、脚本文件以及 MongoDB 数据库本身有必要的读写和执行权限。资源占用：巨大的数据库备份可能会在备份期间暂时影响 MongoDB 服务器性能。可以考虑在业务低峰期安排备份任务。监控与日志：定期检查 /var/log/mongodb_backup.log（或你自定义的日志路径），确保备份任务正在按时运行且没有错误。远程与离线存储：为应对服务器本地灾难（如硬盘损坏），最好将备份文件复制到远程服务器或云存储（例如用 rsync, scp 或使用 rclone 同步到云）。安全：如果备份脚本中包含数据库密码，请确保只有足够权限的用户才能读取该脚本 (chmod 700 /usr/local/bin/mongodb_backup.sh) 其他问题，任务没有被执行系统重启后，一般情况下cron任务会继续执行，因为cron服务通常会自动随系统启动。但为了确保可靠，最好检查一下cron服务的状态。 1sudo systemctl status cron 如果状态显示为 inactive 或 dead，你需要启动它 12sudo systemctl start cron # 启动cronsudo systemctl enable cron # 设置开机自启（可选，确保重启后自动运行） 如果服务已运行但任务仍不执行，可以尝试重启cron服务以重新加载配置 1234567sudo systemctl restart cron```[1,7](@ref)#### 2. 查看系统日志Cron任务的执行情况通常会被记录在系统日志中，这是排查问题最直接的方式。使用以下命令查看与cron相关的日志条目：```bashgrep CRON /var/log/syslog 检查脚本权限与路径 1chmod +x /data/apps/backup/mongodb_backup.sh 路径问题：虽然在你的crontab中脚本路径是绝对路径，但要确保脚本内部所有命令也都使用绝对路径，或者已在脚本内部正确设置了环境变量（如PATH）。因为cron执行时的环境变量与用户登录shell不同 检查时间与时区 1date 查看系统日志 1grep CRON /var/log/syslog 结果如下 1234567891011121314151617181920212223242526272829303132root@kremail-prod:/data/apps/backup/mongodb# grep CRON /var/log/syslogSep 1 00:17:01 kremail-prod CRON[3779891]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 01:17:01 kremail-prod CRON[3788125]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 01:48:01 kremail-prod CRON[3793100]: (root) CMD ( test -x /etc/cron.daily/popularity-contest &amp;&amp; /etc/cron.daily/popularity-contest --crond)Sep 1 02:17:01 kremail-prod CRON[3797132]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 03:10:01 kremail-prod CRON[3804490]: (root) CMD (test -e /run/systemd/system || SERVICE_MODE=1 /sbin/e2scrub_all -A -r)Sep 1 03:17:01 kremail-prod CRON[3805548]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 04:17:01 kremail-prod CRON[3813664]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 05:17:01 kremail-prod CRON[3821165]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 06:17:01 kremail-prod CRON[3829465]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 06:25:01 kremail-prod CRON[3830582]: (root) CMD (test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily ))Sep 1 06:52:01 kremail-prod CRON[3834122]: (root) CMD (test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly ))Sep 1 07:17:01 kremail-prod CRON[3836896]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 08:17:01 kremail-prod CRON[3844972]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 09:17:01 kremail-prod CRON[3853988]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 09:17:02 kremail-prod cron[3853993]: (CRON) INFO (pidfile fd = 3)Sep 1 09:17:02 kremail-prod cron[3853993]: (CRON) INFO (Skipping @reboot jobs -- not system startup)Sep 1 09:19:55 kremail-prod cron[3854182]: (CRON) INFO (pidfile fd = 3)Sep 1 09:19:55 kremail-prod cron[3854182]: (CRON) INFO (Skipping @reboot jobs -- not system startup)Sep 1 10:00:01 kremail-prod CRON[3859738]: (root) CMD (/data/apps/backup/mongodb_backup.sh &gt;&gt; /data/apps/backup/log/mongodb_backup.log 2&gt;&amp;1)Sep 1 10:00:01 kremail-prod CRON[3859737]: (CRON) info (No MTA installed, discarding output)Sep 1 10:16:38 kremail-prod cron[3862303]: (CRON) INFO (pidfile fd = 3)Sep 1 10:16:38 kremail-prod cron[3862303]: (CRON) INFO (Skipping @reboot jobs -- not system startup)Sep 1 10:17:01 kremail-prod CRON[3862312]: (root) CMD ( cd / &amp;&amp; run-parts --report /etc/cron.hourly)Sep 1 10:18:18 kremail-prod cron[3862390]: (CRON) INFO (pidfile fd = 3)Sep 1 10:18:18 kremail-prod cron[3862390]: (CRON) INFO (Skipping @reboot jobs -- not system startup)Sep 1 10:20:01 kremail-prod CRON[3862503]: (root) CMD (/data/apps/backup/mongodb_backup.sh &gt;&gt; /data/apps/backup/log/mongodb_backup.log 2&gt;&amp;1)Sep 1 10:20:01 kremail-prod CRON[3862502]: (CRON) info (No MTA installed, discarding output)Sep 1 10:58:06 kremail-prod cron[3868159]: (CRON) INFO (pidfile fd = 3)Sep 1 10:58:06 kremail-prod cron[3868159]: (CRON) INFO (Skipping @reboot jobs -- not system startup)Sep 1 11:00:01 kremail-prod CRON[3868291]: (root) CMD (/data/apps/backup/mongodb_backup.sh &gt;&gt; /data/apps/backup/log/mongodb_backup.log 2&gt;&amp;1)Sep 1 11:00:01 kremail-prod CRON[3868290]: (CRON) info (No MTA installed, discarding output) 可以看到任务执行了，但是备份没有出来，回到对应目录，创建该任务的日志目录和日志文件，再次重启任务执行，功能正常 12345root@kremail-prod:/data/apps/backup# mkdir logroot@kremail-prod:/data/apps/backup# lslog mongodb mongodb_backup.shroot@kremail-prod:/data/apps/backup# cd log/root@kremail-prod:/data/apps/backup/log# touch mongodb_backup.log","tags":["笔记"],"categories":["其他"]},{"title":"乌班图安装MongoDB 6.x","path":"/2025/07/17/20250717/","content":"导入 MongoDB 公共 GPG 密钥1curl -fsSL https://pgp.mongodb.com/server-6.0.asc | sudo gpg -o /usr/share/keyrings/mongodb-server-6.0.gpg --dearmor 添加 MongoDB 6.x APT 源查看你的 Ubuntu 版本（以判断是 Focal 还是 Jammy） 1lsb_release -a 根据你的 Ubuntu 版本设置以下源：• 如果你是 Ubuntu 20.04（Focal）： 1echo &quot;deb [ signed-by=/usr/share/keyrings/mongodb-server-6.0.gpg ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list • 如果你是 Ubuntu 22.04（Jammy）： 1echo &quot;deb [ signed-by=/usr/share/keyrings/mongodb-server-6.0.gpg ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/6.0 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list 更新 APT 并安装 MongoDB12sudo apt updatesudo apt install -y mongodb-org 查看安装的版本1mongod --version 启动 MongoDB 服务1sudo systemctl start mongod 检查服务状态1sudo systemctl status mongod 设置开机自启1sudo systemctl enable mongod 添加安全验证尝试直接连接 1mongosh 然后访问数据库 12use adminshow dbs 如果 1234567test&gt; use adminswitched to db adminadmin&gt; show dbsadmin 40.00 KiBconfig 12.00 KiBlocal 72.00 KiBadmin&gt; 说明当前你是“未启用认证”状态，MongoDB 允许匿名访问，即： MongoDB 没有启用用户认证（authorization: enabled） 先加入管理员账号密码再开启认证，否则无法登录 1234567use admindb.createUser(&#123; user: &quot;admin&quot;, pwd: &quot;yourStrongPassword&quot;, // 改成你想设置的密码 roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;, &quot;readWriteAnyDatabase&quot; ]&#125;) 创建一个用户名为 admin 的用户• 密码为 yourStrongPassword• 这个用户被授予两个角色: 1.角色：userAdminAnyDatabase，数据库：admin ，含义 可以在任意数据库上创建/管理用户。这个角色必须在 admin 数据库中创建，MongoDB 规定的。 2.角色：readWriteAnyDatabase ，含义 允许对所有数据库进行读写操作 。 如果只是给某个业务数据库（如 myapp）创建普通用户，也可以这样 1234567use myappdb.createUser(&#123; user: &quot;myuser&quot;, pwd: &quot;mypassword&quot;, roles: [ &#123; role: &quot;readWrite&quot;, db: &quot;myapp&quot; &#125; ]&#125;) ctrl+d退出MongoDB 1.启用认证功能 1sudo vim /etc/mongod.conf 2.修改配置 加入或取消注释下面这一段 12security: authorization: &quot;enabled&quot; 重启 MongoDB 开放外部连接1.防火墙开放27017端口 2.修改配置 1sudo vim /etc/mongod.conf 找到 123net: port: 27017 bindIp: 127.0.0.1 改为 123net: port: 27017 bindIp: 0.0.0.0 然后重启 MongoDB 重启 MongoDB1sudo systemctl restart mongod Navicat 连接 卸载 MongoDB123sudo apt purge mongodb-org*sudo rm -r /var/log/mongodbsudo rm -r /var/lib/mongodb","tags":["笔记"],"categories":["其他"]},{"title":"jpom自动化构建python项目","path":"/2025/07/07/20250707/","content":"构建列表配置 这是配置，因为代码结构和jpom必须要有个产物目录，所以拉下代码后新建了个目录放进去 1mkdir -p code &amp;&amp; shopt -s dotglob &amp;&amp; mv ./* ./code/ 1code 脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136# !/bin/bashAPP_DIR=&quot;/data/apps/ai&quot;BIN_DIR=&quot;$APP_DIR&quot;LOG_DIR=&quot;$APP_DIR/logs&quot;LOG_FILE=&quot;$LOG_DIR/info.log&quot;NEW_PRO=&quot;code&quot;feishu_webhook2=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/xxx&quot;export TZ=&quot;Asia/Shanghai&quot;mkdir -p $BIN_DIR $LOG_DIR# 推送到飞书function push_to_feishu() &#123; content=&quot;$1&quot; cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) message=&quot;状态：$&#123;content&#125; &quot; message+=&quot;时间：$&#123;cur_datetime&#125;&quot; read -r -d &#x27;&#x27; json_payload &lt;&lt;EOF&#123; &quot;msg_type&quot;: &quot;text&quot;, &quot;content&quot;: &#123; &quot;text&quot;: &quot;$&#123;message&#125;&quot; &#125;&#125;EOF echo &quot;&gt;&gt;&gt; JSON Payload: $&#123;json_payload&#125;&quot;response2=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook2&#125;&quot;)echo &quot;&gt;&gt;&gt; 飞书响应2: $&#123;response2&#125; &lt;&lt;&lt;&quot;&#125;cleanup_logs() &#123; push_to_feishu &quot;正在清理 15 天前的日志...&quot; echo &quot;正在清理 15 天前的日志...&quot; &gt;&gt; $LOG_FILE find $LOG_DIR -type f -mtime +15 -exec rm -f &#123;&#125; \\; push_to_feishu &quot;日志清理完成...&quot; echo &quot;日志清理完成。&quot; &gt;&gt; $LOG_FILE&#125;# 停止老服务函数stop_old_service() &#123; echo &quot;尝试停止旧服务...&quot; | tee -a &quot;$LOG_FILE&quot; push_to_feishu &quot;尝试停止旧服务...&quot; old_pids=$(ps -ef | grep &quot;$APP_DIR/$NEW_PRO/main.py&quot; | grep -v grep | grep -v nohup | awk &#x27;&#123;print $2&#125;&#x27;) if [ -n &quot;$old_pids&quot; ]; then echo &quot;发现旧进程 PID: $old_pids，正在终止...&quot; | tee -a &quot;$LOG_FILE&quot; kill $old_pids sleep 2 # 确认是否成功终止 for pid in $old_pids; do if ps -p $pid &gt; /dev/null; then echo &quot;进程 $pid 未能终止，强制杀掉...&quot; | tee -a &quot;$LOG_FILE&quot; kill -9 $pid fi done push_to_feishu &quot;旧服务已停止&quot; else echo &quot;未找到旧服务进程，无需停止。&quot; | tee -a &quot;$LOG_FILE&quot; push_to_feishu &quot;未找到旧服务进程&quot; fi&#125;# 主逻辑echo &quot;======== AI服务开始 $(date) ========&quot; &gt; $LOG_FILEBUILD_JAR_PATH=$(pwd)cd $APP_DIR || &#123; echo &quot;目录 $APP_DIR 不存在！&quot; &gt;&gt; $LOG_FILE; exit 1; &#125;rm -rf $APP_DIR/$NEW_PROmv $BUILD_JAR_PATH/$NEW_PRO $BIN_DIR/ &gt; $LOG_FILE 2&gt;&amp;1status=$?if [ $status -eq 0 ]; then push_to_feishu &quot;项目打包成功&quot;else push_to_feishu &quot;项目包处理失败，状态码：$status&quot;fi# 检查并安装依赖PYTHON_EXEC=&quot;/usr/bin/python3.10&quot;REQ_FILE=&quot;$BIN_DIR/$NEW_PRO/requirements.txt&quot;if [ -f &quot;$REQ_FILE&quot; ]; then echo &quot;检测到 requirements.txt，开始安装依赖...&quot; | tee -a &quot;$LOG_FILE&quot; push_to_feishu &quot;开始安装 Python 依赖...&quot; $PYTHON_EXEC -m ensurepip --upgrade 2&gt;&amp;1 | tee -a &quot;$LOG_FILE&quot; $PYTHON_EXEC -m pip install --upgrade pip 2&gt;&amp;1 | tee -a &quot;$LOG_FILE&quot; $PYTHON_EXEC -m pip install -r &quot;$REQ_FILE&quot; 2&gt;&amp;1 | tee -a &quot;$LOG_FILE&quot; status=$&#123;PIPESTATUS[0]&#125; # 从 pipe 中正确获取 pip install 的退出状态 if [ $status -eq 0 ]; then echo &quot;依赖安装完成&quot; | tee -a &quot;$LOG_FILE&quot; push_to_feishu &quot;依赖安装完成&quot; else echo &quot;依赖安装失败，状态码：$status&quot; | tee -a &quot;$LOG_FILE&quot; push_to_feishu &quot;依赖安装失败，状态码：$status&quot; exit 1 fielse echo &quot;未找到 requirements.txt，跳过依赖安装&quot; | tee -a &quot;$LOG_FILE&quot; push_to_feishu &quot;未找到 requirements.txt，跳过依赖安装&quot;fi# 停止旧服务stop_old_serviceMAIN_SCRIPT=&quot;$BIN_DIR/$NEW_PRO/main.py&quot;RUN_LOG=&quot;$LOG_DIR/run.log&quot;if [ -f &quot;$MAIN_SCRIPT&quot; ]; then nohup $PYTHON_EXEC &quot;$MAIN_SCRIPT&quot; &gt;&gt; &quot;$RUN_LOG&quot; 2&gt;&amp;1 &amp; push_to_feishu &quot;Python 项目已启动: $MAIN_SCRIPT&quot; echo &quot;Python 项目已启动 PID=$!&quot; &gt;&gt; $LOG_FILEelse push_to_feishu &quot;Python 启动失败，未找到 $MAIN_SCRIPT&quot; echo &quot;未找到主程序：$MAIN_SCRIPT&quot; &gt;&gt; $LOG_FILE exit 1ficleanup_logspush_to_feishu &quot;AI服务部署完成...&quot;echo &quot;======== AI服务部署完成 $(date) ========&quot; &gt;&gt; $LOG_FILE 脚本安装依赖报错可以直接到服务器执行下面语句，可以查看具体报错原因 1/usr/bin/python3.10 -m pip install -r /data/apps/ai/dist/requirements.txt 示例 12root@kremail-dev:/data/apps/ai/code# /usr/bin/python3.10 -m pip install -r /data/apps/ai/code/test_env/usr/bin/python3.10: No module named pip 这里发现是没有安装pip 12wget https://bootstrap.pypa.io/get-pip.pysudo /usr/bin/python3.10 get-pip.py 这一步会直接安装 pip 到 Python 3.10 的路径下 安装python 更新系统并安装必要工具 12sudo apt updatesudo apt install software-properties-common -y 添加 deadsnakes PPA 1sudo add-apt-repository ppa:deadsnakes/ppa -y 再次更新包列表 1sudo apt update 安装 Python 3.10 1sudo apt install python3.10 -y 验证版本 1python3.10 --version","tags":["笔记"],"categories":["其他"]},{"title":"python3启动项目环境隔离问题处理","path":"/2025/07/07/2025090501/","content":"安装依赖报错 1234567891011121314151617181920212223242526272829303132333435mac@macdeMacBook-Pro ai-agent % pip3 install -r requirements.txterror: externally-managed-environment× This environment is externally managed╰─&gt; To install Python packages system-wide, try brew install xyz, where xyz is the package you are trying to install. If you wish to install a Python library that isn&#x27;t in Homebrew, use a virtual environment: python3 -m venv path/to/venv source path/to/venv/bin/activate python3 -m pip install xyz If you wish to install a Python application that isn&#x27;t in Homebrew, it may be easiest to use &#x27;pipx install xyz&#x27;, which will manage a virtual environment for you. You can install pipx with brew install pipx You may restore the old behavior of pip by passing the &#x27;--break-system-packages&#x27; flag to pip, or by adding &#x27;break-system-packages = true&#x27; to your pip.conf file. The latter will permanently disable this error. If you disable this error, we STRONGLY recommend that you additionally pass the &#x27;--user&#x27; flag to pip, or set &#x27;user = true&#x27; in your pip.conf file. Failure to do this can result in a broken Homebrew installation. Read more about this behavior here: &lt;https://peps.python.org/pep-0668/&gt;note: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.hint: See PEP 668 for the detailed specification. 创建虚拟环境（名字随便，通常叫 venv）1python3 -m venv venv 激活虚拟环境1source venv/bin/activate 再次安装依赖1pip3 install -r requirements.txt 以后每次启动项目，先激活虚拟环境1source venv/bin/activate 激活后，命令行前面会多一个 (venv) 提示，说明你在虚拟环境里 1(venv) mac@macdeMacBook-Pro ai-agent % 然后启动项目 1python3 main.py 退出虚拟环境命令1deactivate 总结问题来了，对a项目执行了python3 -m venv venv和source venv/bin/activate，这个时候需要安装b项目的依赖和启动b项目，同样在b项目的目录下面执行python3 -m venv venv和source venv/bin/activate，这样操作会和a项目的环境隔离冲突吗？答案是不会。虚拟环境是独立的，每个虚拟环境都有自己的Python解释器和独立的依赖库。在a项目目录下创建的虚拟环境不会影响b项目目录下创建的虚拟环境。因此，你可以在a项目目录下创建虚拟环境并激活，然后在b项目目录下创建另一个虚拟环境并激活，这样就可以在两个不同的虚拟环境中分别安装和运行a项目和b项目了。• 每个项目（a、b）都应该有自己的虚拟环境，这样依赖互不干扰。• 你在 a 项目里建的 venv 只对 a 有效；• 你在 b 项目里再建一个 venv，只对 b 有效；• 它们之间完全 隔离，不会冲突。 正确操作流程 12345cd apython3 -m venv venvsource venv/bin/activatepip install -r requirements.txtpython main.py # 或者对应的启动命令 针对 b 项目 12345cd bpython3 -m venv venvsource venv/bin/activatepip install -r requirements.txtpython app.py # 或者对应的启动命令 注意点激活虚拟环境时，你只能用 一个环境。• 如果你已经在 a/venv 里了，再去运行 b 项目，就会报依赖错误。• 所以要先退出 a 的虚拟环境，再进入 b 的虚拟环境。 如果你不想重复输入 source venv/bin/activate，可以用 工具管理多个虚拟环境，比如：• pyenv + pyenv-virtualenv• virtualenvwrapper这样就能很方便地在不同环境之间切换","tags":["笔记"],"categories":["python"]},{"title":"Ubuntu 20.04.6 安装redis5和mysql8","path":"/2025/06/11/20250611/","content":"安装redis5下载12sudo apt updatesudo apt-get install redis-server 看下redis的状态，确保他在运行 1sudo systemctl status redis-server 配置配置6379端口 1sudo ufw allow 6379 编辑redis配置文件 1sudo vim /etc/redis/redis.conf 找到bind指令修改为0.0.0.0 1bind 0.0.0.0 这允许Redis监听所有接口上的连接请求。确保protected-mode设置为no（如果你希望让Redis容易被访问） 1protected-mode no 也可以指定特定ip，多ip之间空格隔开，连不上试试protected-mode no或者protected-mode yes 1bind 127.0.0.1 x.x.x.x 为了安全，请设置requirepass指令来设置密码保护,找个地方添加下面这一行代码（有时候配置文件中没有requirepass 需要手动添加） your_password 改成你要设置的密码 vim下快速定位到requirepass所在行，按esc退出编辑状态，然后按 / 进入搜索模式，输入：/requirepass然后按回车，光标会跳到第一个匹配的地方。按 n 跳到下一个匹配，N 跳到上一个匹配 1requirepass your_password 保存并关闭配置文件 关闭1sudo systemctl stop redis 重启1sudo systemctl restart redis.service 如果找不到服务 可以搜索一下 1systemctl list-units --type=service | grep redis 设置redis.service 激活服务 1sudo systemctl enable redis-server.service 卸载1sudo apt remove redis-server 如果想彻底删除，包括配置文件，可以用 1sudo apt purge redis-server 删除残留的配置文件和数据（可选） 12sudo rm -rf /etc/redissudo rm -rf /var/lib/redis 确认 Redis 服务已被禁用（可选） 1sudo systemctl disable redis mysql8下载12sudo apt updatesudo apt-get install mysql-server 查看密码安装完成后mysql会自启。 打开debain.cnf，使用其中账密登录 123456789101112cat /etc/mysql/debian.cnf [client]host = localhostuser = debian-sys-maintpassword = iYNXokX3nuPfenXusocket = /var/run/mysqld/mysqld.sock[mysql_upgrade]host = localhostuser = debian-sys-maintpassword = iYNXokX3nuPfenXusocket = /var/run/mysqld/mysqld.sock 配置1mysql -u 用户名 -p 按提示输入密码，然后创建新用户并且赋予权限 12CREATE user &#x27;用户名&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;密码&#x27;;GRANT ALL PRIVILEGES ON *.* TO &#x27;用户名&#x27;@&#x27;%&#x27; with grant option; 然后Ctrl + D退出mysql 配置远程连接 1$ vim /etc/mysql/my.cnf 直接添加的下面两行 123[mysqld]bind-address = 0.0.0.0 重启mysql 1sudo service mysql restart 搞定收工","tags":["笔记"],"categories":["Linux"]},{"title":"Linux一些常用命令","path":"/2025/05/30/20250530/","content":"nginx配置文件路径12/etc/nginx/nginx.conf/etc/nginx/sites-available/default 验证配置文件1nginx -t 刷新配置文件1nginx -s reload 配置文件参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255# 全局 HTTPS 重定向配置server &#123;server_name default_server;location /.well-known/acme-challenge/ &#123;root /var/www/html;&#125; location / &#123; return 301 https://$host$request_uri; &#125; listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/teman.xxx.xx/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/teman.xxx.xx/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot&#125;# 80端口 -&gt; 301 重定向到 HTTPSserver &#123;listen 80;server_name default_server; location /.well-known/acme-challenge/ &#123; root /var/www/html; # Certbot 用于 HTTP 续期 &#125; location / &#123; return 301 https://$host$request_uri; &#125;&#125;# 配置官网server &#123;listen 443 ssl default_server;server_name home.xxx.xx; # 禁止网站被嵌入 add_header X-Frame-Options &quot;DENY&quot; always; add_header Content-Security-Policy &quot;frame-ancestors &#x27;none&#x27;;&quot; always; ssl_certificate /etc/letsencrypt/live/teman.xxx.xx/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/teman.xxx.xx/privkey.pem; # managed by Certbot root /data/apps/web/dist; index index.html; # 添加错误页面配置 error_page 404 /404.html; location / &#123; try_files $uri $uri/ $uri.html =404; &#125;&#125;# 配置xx客户端前端服务server &#123;listen 443 ssl;server_name www.xxx.xx xxx.xx;ssl_certificate /etc/letsencrypt/live/teman.xxx.xx/fullchain.pem; # managed by Certbotssl_certificate_key /etc/letsencrypt/live/teman.xxx.xx/privkey.pem; # managed by Certbot # 强制将www重定向到无www版本 if ($host = www.xxx.xx) &#123; return 301 https://xxx.xx$request_uri; &#125; root /data/apps/webmail/dist; index index.html; # 自定义错误页面配置 error_page 404 /index.html; location / &#123; try_files $uri $uri/ =404; &#125; # 处理自定义 404 页面 location = /404.html &#123; root /data/apps/webmail; internal; &#125;&#125;# 配置后台 管理端server &#123;listen 443 ssl;server_name teman.xxx.xx; ssl_certificate /etc/letsencrypt/live/teman.xxx.xx/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/teman.xxx.xx/privkey.pem; root /data/apps/webadmin/dist; index index.html; # 自定义错误页面配置 error_page 404 /index.html; location / &#123; try_files $uri $uri/ =404; &#125; # 处理自定义 404 页面 location = /404.html &#123; root /data/apps/webadmin; internal; &#125;&#125;# 配置客户端后端服务server &#123;listen 443 ssl;server_name backend.xxx.xx;client_max_body_size 30M; add_header X-Frame-Options &quot;DENY&quot; always; add_header Content-Security-Policy &quot;frame-ancestors &#x27;none&#x27;;&quot; always; ssl_certificate /etc/letsencrypt/live/teman.xxx.xx/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/teman.xxx.xx/privkey.pem; # managed by Certbot # 禁止访问 /aiServer/ 路径（必须放在靠前位置） location ^~ /aiServer/ &#123; return 403; &#125; #专门处理 WebSocket 通知的 location 块 location /api/v1/ws/ &#123; # 代理到您的 Spring Boot 应用地址 proxy_pass http://127.0.0.1:6001; # --- 以下是代理 WebSocket 的核心配置 --- # 1. 允许协议升级 proxy_http_version 1.1; # 2. 传递 &quot;Upgrade&quot; 请求头 (关键) # $http_upgrade 是一个 Nginx 内置变量，它会获取客户端请求中的 Upgrade 头 proxy_set_header Upgrade $http_upgrade; # 3. 传递 &quot;Connection&quot; 请求头 (关键) # 明确告知后端服务器要升级连接类型 proxy_set_header Connection &quot;upgrade&quot;; # --- 其他标准的代理头信息，确保后端能获取真实信息 --- proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # --- 针对长连接的超时设置 --- # 避免因默认的60秒超时导致 WebSocket 连接被意外断开 proxy_read_timeout 3600s; # 1小时 proxy_send_timeout 3600s; # 1小时 send_timeout 3600s; &#125; # 默认的 location 配置，不影响其他请求 location / &#123; proxy_pass http://127.0.0.1:6001; # 代理到本地服务 proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; &#125; # 针对 SSE 请求的特殊配置 location /service/logs/realtime &#123; proxy_pass http://127.0.0.1:6001; # 代理到本地服务 proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # SSE 关键优化 proxy_buffering off; # 禁用缓冲，确保数据流不中断 proxy_cache off; # 确保 Nginx 不缓存 SSE 响应 proxy_set_header Connection &#x27;&#x27;; # 避免 Nginx 添加 `Connection: close`，保持连接 chunked_transfer_encoding off; # 禁用 chunked 传输，SSE 不需要它 # 只针对 SSE 请求设置的超时 proxy_read_timeout 3600s; # 设置为较长时间（例如 3600 秒 = 1 小时） proxy_send_timeout 3600s; # 设置为较长时间 send_timeout 3600s; # 设置 Nginx 向客户端发送响应的超时时间 &#125; location /thirdParty/chat/conversationWithType &#123; proxy_pass http://127.0.0.1:6001; # 代理到本地服务 proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # SSE 关键优化 proxy_buffering off; # 禁用缓冲，确保数据流不中断 proxy_cache off; # 确保 Nginx 不缓存 SSE 响应 proxy_set_header Connection &#x27;&#x27;; # 避免 Nginx 添加 `Connection: close`，保持连接 chunked_transfer_encoding off; # 禁用 chunked 传输，SSE 不需要它 # 只针对 SSE 请求设置的超时 proxy_read_timeout 3600s; # 设置为较长时间（例如 3600 秒 = 1 小时） proxy_send_timeout 3600s; # 设置为较长时间 send_timeout 3600s; # 设置 Nginx 向客户端发送响应的超时时间 &#125;&#125;# 配置前端运营后台server &#123;listen 443 ssl;server_name ope.xxx.xx;ssl_certificate /etc/letsencrypt/live/teman.xxx.xx/fullchain.pem; # managed by Certbotssl_certificate_key /etc/letsencrypt/live/teman.xxx.xx/privkey.pem; # managed by Certbot root /data/apps/opeAdmin/dist; index index.html; # 自定义错误页面配置 error_page 404 /index.html; location / &#123; try_files $uri $uri/ =404; &#125; # 处理自定义 404 页面 location = /404.html &#123; root /data/apps/opeAdmin; internal; &#125;&#125;# 运维后台server &#123;listen 443 ssl;server_name ops.xxx.xx;client_max_body_size 30M; ssl_certificate /etc/letsencrypt/live/teman.xxx.xx/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/teman.xxx.xx/privkey.pem; # managed by Certbot # 默认的 location 配置，不影响其他请求 location / &#123; proxy_pass http://127.0.0.1:2122; # 代理到本地服务 proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; &#125;&#125; 其他 操作 命令 启动 Nginx sudo systemctl start nginx 停止 Nginx sudo systemctl stop nginx 重启 Nginx（强制） sudo systemctl restart nginx 平滑重载配置 sudo systemctl reload nginx 查看 Nginx 状态 sudo systemctl status nginx 检查配置语法 nginx -t 查看配置文件路径 nginx -V（查看 --conf-path） https证书安装环境12sudo apt updatesudo apt install certbot python3-certbot-nginx 生成证书在申请证书前，请确保要申请的域名（例如 example.com 或 www.example.com ）已经解析到服务器的 IP 地址，否则验证会失败 1sudo certbot --nginx -d xx.com -d mail.xx.com -d www.xx.com 有几个域名就-d几次,根据上面nginx配置的域名示例 1sudo certbot --nginx -d home.kretest.com -d www.kretest.com -d backend.kretest.com -d kretest.com -d mail.xx.com -d teman.kretest.com 续订证书证书到期后发现自动续订没有生效，然后去手动续订 全部续订1sudo certbot renew 续订后需要重启Nginx，或者把Nginx平滑重载配置 只续签某个证书1sudo certbot certonly --nginx -d xx.com -d mail.xx.com -d www.xx.com 续订后需要重启Nginx，或者把Nginx平滑重载配置 自动续签1systemctl list-timers | grep certbot 查看证书到期时间1sudo openssl x509 -in /etc/letsencrypt/live/xx.com/fullchain.pem -noout -dates 测试续签不会真的修改证书 1sudo certbot renew --dry-run 如果没有报错，就说明自动续订没问题 手动续订报错123456789101112131415161718192021222324root@kremail-dev:~# sudo certbot renewTraceback (most recent call last): File &quot;/usr/bin/certbot&quot;, line 6, in &lt;module&gt; from pkg_resources import load_entry_pointModuleNotFoundError: No module named &#x27;pkg_resources&#x27;Error in sys.excepthook:Traceback (most recent call last): File &quot;/usr/lib/python3/dist-packages/apport_python_hook.py&quot;, line 72, in apport_excepthook from apport.fileutils import likely_packaged, get_recent_crashes File &quot;/usr/lib/python3/dist-packages/apport/__init__.py&quot;, line 5, in &lt;module&gt; from apport.report import Report File &quot;/usr/lib/python3/dist-packages/apport/report.py&quot;, line 32, in &lt;module&gt; import apport.fileutils File &quot;/usr/lib/python3/dist-packages/apport/fileutils.py&quot;, line 12, in &lt;module&gt; import os, glob, subprocess, os.path, time, pwd, sys, requests_unixsocket File &quot;/usr/lib/python3/dist-packages/requests_unixsocket/__init__.py&quot;, line 1, in &lt;module&gt; import requestsModuleNotFoundError: No module named &#x27;requests&#x27;Original exception was:Traceback (most recent call last): File &quot;/usr/bin/certbot&quot;, line 6, in &lt;module&gt; from pkg_resources import load_entry_pointModuleNotFoundError: No module named &#x27;pkg_resources&#x27; 看日志代表机器上的 Certbot 是 Python 版，但是依赖缺失（大概率是 python3-pkg-resources 或 python3-requests 包没装，或者被误删了） 起初尝试补缺少的依赖 12sudo apt updatesudo apt install --reinstall python3-pkg-resources python3-requests 然后再执行手动续订，还是报错 123456789101112131415161718192021root@kremail-dev:~# sudo certbot renewTraceback (most recent call last): File &quot;/usr/bin/certbot&quot;, line 11, in &lt;module&gt; load_entry_point(&#x27;certbot==0.40.0&#x27;, &#x27;console_scripts&#x27;, &#x27;certbot&#x27;)() File &quot;/usr/lib/python3/dist-packages/pkg_resources/__init__.py&quot;, line 490, in load_entry_point return get_distribution(dist).load_entry_point(group, name) File &quot;/usr/lib/python3/dist-packages/pkg_resources/__init__.py&quot;, line 2854, in load_entry_point return ep.load() File &quot;/usr/lib/python3/dist-packages/pkg_resources/__init__.py&quot;, line 2445, in load return self.resolve() File &quot;/usr/lib/python3/dist-packages/pkg_resources/__init__.py&quot;, line 2451, in resolve module = __import__(self.module_name, fromlist=[&#x27;__name__&#x27;], level=0) File &quot;/usr/lib/python3/dist-packages/certbot/main.py&quot;, line 17, in &lt;module&gt; from certbot import account File &quot;/usr/lib/python3/dist-packages/certbot/account.py&quot;, line 10, in &lt;module&gt; import pyrfc3339 File &quot;/usr/lib/python3/dist-packages/pyrfc3339/__init__.py&quot;, line 17, in &lt;module&gt; from pyrfc3339.generator import generate File &quot;/usr/lib/python3/dist-packages/pyrfc3339/generator.py&quot;, line 1, in &lt;module&gt; import pytzModuleNotFoundError: No module named &#x27;pytz&#x27; 再补pytz，没有成功，而且如果继续提示缺别的模块（比如 acme, zope），就要一个个补，比较麻烦，然后想着直接重装 12sudo apt updatesudo apt install --reinstall certbot python3-certbot-nginx -y 重装证书后还是报错，算了，直接弃用，直接上脚本。 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bashset -eecho &quot;🔍 检查 Certbot 版本...&quot;if command -v certbot &gt;/dev/null 2&gt;&amp;1; then VERSION=$(certbot --version 2&gt;/dev/null | awk &#x27;&#123;print $2&#125;&#x27;) echo &quot;当前 Certbot 版本: $VERSION&quot;else VERSION=&quot;none&quot; echo &quot;未安装 Certbot&quot;fi# 如果版本太老（&lt;1.0），或者直接用 apt 安装的，卸载旧版if [[ &quot;$VERSION&quot; == &quot;none&quot; ]] || [[ &quot;$VERSION&quot; == 0.* ]] || dpkg -l | grep -q certbot; then echo &quot;🗑️ 移除旧版 Certbot (apt 包)...&quot; apt remove -y certbot python3-certbot-nginx || truefiecho &quot;📦 确保 snapd 已安装...&quot;apt update -yapt install -y snapdecho &quot;⬇️ 安装最新版 Certbot (snap 包)...&quot;snap install --classic certbotecho &quot;🔗 建立软链 /usr/bin/certbot&quot;ln -sf /snap/bin/certbot /usr/bin/certbotecho &quot;✅ Certbot 版本:&quot;certbot --versionecho &quot;🧪 测试续签 (--dry-run)...&quot;sudo certbot renew --dry-run || &#123; echo &quot;❌ 测试续签失败，请检查 Nginx 配置或 DNS 解析。&quot; exit 1&#125;echo &quot;🎉 Certbot 已更新并测试成功！证书续签已准备就绪。&quot; 1234touch fix_certbot.shvim fix_certbot.shchmod +x fix_certbot.shsudo bash fix_certbot.sh 搞定，然后重启Nginx，续订后需要过几分钟才生效。 执行完成后用上面步骤的命令查看一下到期时间，如果到期时间没有成功延期，尝试手动延期一下 1sudo certbot renew snap 版自带 systemd 定时任务，会每天自动运行一次 certbot renew，如果证书快到期就续订，并自动 reload Nginx/Apache。 1systemctl list-timers | grep certbot 如果有类似输出，说明每天会执行一次。 1Sat 2025-09-13 00:00:00 UTC ... snap.certbot.renew.timer certbot.renew.service 查看任务内容 12systemctl cat snap.certbot.renew.servicesystemctl cat snap.certbot.renew.timer 正常会看到它执行的是 1/usr/bin/snap run certbot renew --quiet 要测试自动续订的话执行上面步骤的测试续订 查看内存使用1free -h 查看日志12tail -f xxx.logtail -100f xxx.log 搜索日志1grep -C 3 &quot;开始BC匹配&quot; info.log 查看硬盘使用1df -h 查看硬盘使用排序1du -h --max-depth=1 / | sort -hr | head -n 10 查看硬盘使用排序，指定文件夹/data 是文件夹 可替换为具体的 1du -h --max-depth=1 /data | sort -hr | head -n 10 权限相关赋予可执行权限 1chmod +x xxx.sh 说明：为文件 script.sh 添加执行权限，使其可以被运行。适用于脚本或二进制文件。 赋予读、写、执行权限给所有用户 1chmod a+rwx file.txt 说明：a 表示所有用户（owner、group、others），+rwx 添加读（r）、写（w）、执行（x）权限。 仅给文件所有者添加执行权限 1chmod u+x file.sh 说明：u 表示文件所有者（user），+x 添加执行权限。 设置精确权限（八进制表示法） 1chmod 755 script.sh 说明：使用八进制设置权限：• 7 = 读(r) + 写(w) + 执行(x) = 4 + 2 + 1• 5 = 读(r) + 执行(x) = 4 + 1• 所以 755 表示：• 所有者：rwx• 所属组：r-x• 其他人：r-x vim 📝 所有命令默认为在「普通模式」下使用（按 Esc 退出插入模式后进入） 📌 导航相关 操作 命令 使用说明 跳转到第一行 gg 按 Esc 回到普通模式，再按 gg 跳转到最后一行 G 普通模式下按 G 跳转到第 N 行 :N 或 Ngg : 输入后需按回车；或直接用 Ngg 跳转到当前行第一个非空字符 ^ 普通模式下按 ^ 跳转到当前行最开始位置 0 普通模式下按 0 跳转到当前行行尾 $ 普通模式下按 $ 跳转到当前行第 N 个字符 `N ` 水平滚动到最左/右端 zs / ze 用于水平滚动的窗口或长行 🧹 删除 / 清空相关 操作 命令 使用说明 删除当前行 dd 普通模式下按 dd 删除 N 行 Ndd 例如 3dd 表示删除当前及其后两行 删除到行尾 D / d$ D 是 d$ 的简写，删除光标至行尾 删除到行首 d0 / d^ d0 含缩进，d^ 不含缩进 删除全文 ggdG 先跳到第一行 gg，然后 dG 删除至最后行 清空当前行 cc 删除当前行并自动进入插入模式 清空整个文件 :%d 命令模式输入，需回车 ✍️ 编辑相关 操作 命令 使用说明 插入（当前光标） i 进入插入模式，开始输入 插入（行首） I 插入到行首的第一个非空字符前 新建行并插入（下） o 当前行下方新建一行并进入插入模式 新建行并插入（上） O 当前行上方新建一行并进入插入模式 替换当前字符 r&lt;char&gt; 例如 ra 把当前字符替换为 a 连续替换字符 R 按 R 开始替换，Esc 退出 撤销 u 撤销上一步 重做 Ctrl + r 撤销的内容重新做 粘贴（后/前） p / P p 粘贴在光标后，P 粘贴在光标前 复制当前行 yy yank line 复制多行 Nyy 例如 3yy 复制三行 🔍 查找与替换 操作 命令 使用说明 向下查找关键字 /关键字 输入 /word 后按回车，n/N 浏览结果 向上查找关键字 ?关键字 输入 ?word 后按回车 查找下一个匹配项 n 与上次查找方向一致 查找上一个匹配项 N 与上次查找方向相反 替换当前行第一个匹配项 :s/旧/新/ 命令模式输入，替换当前行首次匹配 替换当前行所有匹配项 :s/旧/新/g 当前行全替换 替换全文所有匹配项 :%s/旧/新/g 所有行替换 替换全文并手动确认 :%s/旧/新/gc 每次替换前询问确认（y/n） 🗂️ 文件和窗口操作 操作 命令 使用说明 保存文件 :w 命令模式输入并回车 退出 :q 如文件无更改可直接退出 强制退出 :q! 不保存直接退出 保存并退出 :wq / ZZ ZZ 为普通模式下的大写 Z 两次 打开文件 :e 文件名 替换当前文件内容为指定文件 垂直选项卡分屏 :vsp 文件 垂直拆分窗口并打开文件 水平分屏 :sp 文件 水平拆分窗口并打开文件 窗口之间切换 Ctrl + w + w 依次切换当前所有窗口 其他1top 按下 Ctrl + C 就可以退出 1htop 按下 Ctrl + C 就可以退出 字段名 全称 / 中文名 含义 / 作用 取值范围与说明 是否越大越好 备注说明 PID Process ID 进程的唯一标识符 系统自动分配 否 用于终止进程或定位问题 USER 用户名 拥有该进程的用户 系统用户名或登录用户 否 用于区分用户进程 PRI Priority（优先级） 进程调度的优先级 数值越小表示优先级越高 是（越小越好） 与 NI 值相关，由内核计算 NI nice 值 用户可调整的进程优先级 -20（最高优先）到 19（最低优先） 否 影响 PRI 值，可用 nice/renice 修改 VIRT Virtual Memory 虚拟内存使用量 包括代码段、共享库、swap、映射文件等 否 不是实际占用内存，数值较大不一定表示问题 RES Resident Memory 实际使用的物理内存 真正驻留在 RAM 中的内存 否 越大表示物理内存占用越多 SHR Shared Memory 共享内存大小 与其他进程共享的内存（如共享库） 否 越大说明内存共享程度高，利用率好 S 状态（State） 当前进程状态 R（运行）、S（睡眠）、Z（僵尸）、T（停止）等 否 关注是否存在僵尸进程（Z）或长时间阻塞（D） CPU% CPU 占用率 当前进程使用的 CPU 百分比 多核系统可能超过 100% 是 持续高占用可能表示死循环或负载重 MEM% 内存占用率 当前进程使用的物理内存百分比 相对于系统总内存 是 用于快速找出大内存进程 TIME+ 累计 CPU 时间 使用的 CPU 总时间 格式为 MM:SS.hh 是 数值大说明运行时间长，可用于判断服务长期性 Command 启动命令 启动进程时的完整命令 含路径与参数 否 有助于辨认运行程序来源 MEM 内存总览（顶部） 系统物理内存使用情况 总量、使用、缓冲、空闲 否 内存占用过高系统性能下降 SWP 交换空间（Swap） 系统 swap 使用情况 总量、使用、空闲 否 使用 swap 说明内存不足，可能导致系统变慢 12sudo apt install cmatrixcmatrix 按下 Ctrl + C 就可以退出 mac终端安装cmatrix 12brew install cmatrixcmatrix 如果你想让它看起来更炫，可以加一些参数，比如： 1cmatrix -b -u 10 参数解释：• -b：粗体字符• -u 10：更新速度（数字越小越快） 按下 Ctrl + C 就可以退出 1curl wttr.in","tags":["笔记"],"categories":["Linux"]},{"title":"java发送飞书通知","path":"/2025/03/12/20250312/","content":"单纯做工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import com.fasterxml.jackson.databind.ObjectMapper;import org.apache.http.client.methods.HttpPost;import org.apache.http.entity.StringEntity;import org.apache.http.impl.nio.client.CloseableHttpAsyncClient;import org.apache.http.impl.nio.client.HttpAsyncClients;import org.apache.http.util.EntityUtils;import org.apache.http.HttpResponse;import java.nio.charset.StandardCharsets;import java.util.concurrent.CompletableFuture;import java.util.concurrent.Future;public class FeishuNotifier &#123; private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper(); private static final CloseableHttpAsyncClient HTTP_CLIENT = HttpAsyncClients.createDefault(); private static final String proWebhookUrl = &quot;https://open.feishu.cn/open-apis/bot/v2/hook/xxx&quot;; private static final String devWebhookUrl = &quot;https://open.feishu.cn/open-apis/bot/v2/hook/xxx&quot;; static &#123; HTTP_CLIENT.start(); // 启动异步 HTTP 客户端 &#125; public static void sendMessageAsync(String title, String content) &#123; String env = System.getenv(&quot;ENV&quot;); if (&quot;prod&quot;.equalsIgnoreCase(env)) &#123; sendMessage(proWebhookUrl, title, content); &#125; sendMessage(devWebhookUrl, title, content); &#125; private static void sendMessage(String webhookUrl, String title, String content) &#123; String message = &quot;【&quot; + title + &quot;】 &quot; + content; String jsonPayload = createJsonPayload(message); try &#123; // 创建 HttpPost 请求 HttpPost httpPost = new HttpPost(webhookUrl); httpPost.setHeader(&quot;Content-Type&quot;, &quot;application/json&quot;); httpPost.setEntity(new StringEntity(jsonPayload, StandardCharsets.UTF_8)); // 异步发送请求 Future&lt;HttpResponse&gt; futureResponse = HTTP_CLIENT.execute(httpPost, null); // 异步获取响应 CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; return futureResponse.get(); // 阻塞等待响应，但在 CompletableFuture 线程池中执行 &#125; catch (Exception e) &#123; throw new RuntimeException(&quot;&gt;&gt;&gt; 发送飞书通知失败: &quot; + e.getMessage(), e); &#125; &#125;).thenAcceptAsync(response -&gt; &#123; try &#123; // 打印飞书响应 String responseBody = EntityUtils.toString(response.getEntity(), StandardCharsets.UTF_8); System.out.println(&quot;&gt;&gt;&gt; 飞书响应: &quot; + responseBody); &#125; catch (Exception e) &#123; System.err.println(&quot;&gt;&gt;&gt; 解析飞书响应失败: &quot; + e.getMessage()); &#125; &#125;); &#125; catch (Exception e) &#123; System.err.println(&quot;&gt;&gt;&gt; 发送飞书通知异常: &quot; + e.getMessage()); &#125; &#125; private static String createJsonPayload(String message) &#123; try &#123; return OBJECT_MAPPER.writeValueAsString(new FeishuMessage(&quot;text&quot;, new FeishuContent(message))); &#125; catch (Exception e) &#123; throw new RuntimeException(&quot;JSON 序列化失败&quot;, e); &#125; &#125; private static class FeishuMessage &#123; public String msg_type; public FeishuContent content; public FeishuMessage(String msg_type, FeishuContent content) &#123; this.msg_type = msg_type; this.content = content; &#125; &#125; private static class FeishuContent &#123; public String text; public FeishuContent(String text) &#123; this.text = text; &#125; &#125;&#125; 按配置开关123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155package com.touchsmail.util;import cn.hutool.core.collection.CollUtil;import cn.hutool.core.util.ObjectUtil;import com.fasterxml.jackson.databind.JsonNode;import com.fasterxml.jackson.databind.ObjectMapper;import com.touchsmail.model.entity.SystemConfig;import com.touchsmail.service.system.SystemConfigService;import org.apache.http.client.methods.HttpPost;import org.apache.http.entity.StringEntity;import org.apache.http.impl.nio.client.CloseableHttpAsyncClient;import org.apache.http.impl.nio.client.HttpAsyncClients;import org.apache.http.util.EntityUtils;import org.apache.http.HttpResponse;import org.springframework.stereotype.Component;import org.springframework.beans.factory.annotation.Autowired;import javax.annotation.PostConstruct;import java.nio.charset.StandardCharsets;import java.util.ArrayList;import java.util.List;import java.util.concurrent.*;@Componentpublic class FeishuNotifier &#123; private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper(); private static final CloseableHttpAsyncClient HTTP_CLIENT = HttpAsyncClients.createDefault(); @Autowired private SystemConfigService systemConfigService; private static boolean notifierSwitch = false; private static List&lt;String&gt; robotList = new ArrayList&lt;&gt;(); private static final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1); public void startScheduledTask() &#123; scheduler.scheduleAtFixedRate(this::updateNotifierConfig, 0, 1, TimeUnit.MINUTES); // 每分钟执行一次 &#125; public void updateNotifierConfig() &#123; try &#123; SystemConfig notifierSwitchConfig = systemConfigService.getConfigByType(&quot;FeishuNotifier&quot;); if (ObjectUtil.isNotEmpty(notifierSwitchConfig)) &#123; String jsonConfig = notifierSwitchConfig.getDefaultConfigValue(); ObjectMapper objectMapper = new ObjectMapper(); JsonNode rootNode = objectMapper.readTree(jsonConfig); JsonNode feishuNode = rootNode.get(&quot;FeishuNotifier&quot;); if (feishuNode != null) &#123; if (feishuNode.has(&quot;notifierSwitch&quot;)) &#123; notifierSwitch = feishuNode.get(&quot;notifierSwitch&quot;).asBoolean(); &#125; robotList = new ArrayList&lt;&gt;(); JsonNode prodRobotNode = feishuNode.get(&quot;robots&quot;); if (prodRobotNode != null &amp;&amp; prodRobotNode.isArray()) &#123; for (JsonNode node : prodRobotNode) &#123; robotList.add(node.asText()); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; System.err.println(&quot;&gt;&gt;&gt; 读取 notifierSwitch 配置失败: &quot; + e.getMessage()); &#125; &#125; @PostConstruct public void init() &#123; // 启动异步 HTTP 客户端 HTTP_CLIENT.start(); // 启动定时任务 startScheduledTask(); &#125; public static void sendMessageAsync(String title, String content) &#123; if (!notifierSwitch) &#123; System.out.println(&quot;&gt;&gt;&gt; 飞书消息通知没开&quot;); return; &#125; if (CollUtil.isNotEmpty(robotList)) &#123; for (String robot : robotList) &#123; sendMessage(robot, title, content); &#125; &#125; else &#123; System.out.println(&quot;&gt;&gt;&gt; 飞书机器人为空&quot;); &#125; &#125; private static void sendMessage(String webhookUrl, String title, String content) &#123; String message = &quot;【&quot; + title + &quot;】 &quot; + content; String jsonPayload = createJsonPayload(message); try &#123; // 创建 HttpPost 请求 HttpPost httpPost = new HttpPost(webhookUrl); httpPost.setHeader(&quot;Content-Type&quot;, &quot;application/json&quot;); httpPost.setEntity(new StringEntity(jsonPayload, StandardCharsets.UTF_8)); // 异步发送请求 Future&lt;HttpResponse&gt; futureResponse = HTTP_CLIENT.execute(httpPost, null); // 异步获取响应 CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; return futureResponse.get(); // 阻塞等待响应，但在 CompletableFuture 线程池中执行 &#125; catch (Exception e) &#123; throw new RuntimeException(&quot;&gt;&gt;&gt; 发送飞书通知失败: &quot; + e.getMessage(), e); &#125; &#125;).thenAcceptAsync(response -&gt; &#123; try &#123; // 打印飞书响应 String responseBody = EntityUtils.toString(response.getEntity(), StandardCharsets.UTF_8); System.out.println(&quot;&gt;&gt;&gt; 飞书响应: &quot; + responseBody); &#125; catch (Exception e) &#123; System.err.println(&quot;&gt;&gt;&gt; 解析飞书响应失败: &quot; + e.getMessage()); &#125; &#125;); &#125; catch (Exception e) &#123; System.err.println(&quot;&gt;&gt;&gt; 发送飞书通知异常: &quot; + e.getMessage()); &#125; &#125; private static String createJsonPayload(String message) &#123; try &#123; return OBJECT_MAPPER.writeValueAsString(new FeishuMessage(&quot;text&quot;, new FeishuContent(message))); &#125; catch (Exception e) &#123; throw new RuntimeException(&quot;JSON 序列化失败&quot;, e); &#125; &#125; private static class FeishuMessage &#123; public String msg_type; public FeishuContent content; public FeishuMessage(String msg_type, FeishuContent content) &#123; this.msg_type = msg_type; this.content = content; &#125; &#125; private static class FeishuContent &#123; public String text; public FeishuContent(String text) &#123; this.text = text; &#125; &#125;&#125; 数据结构12345678&#123; &quot;FeishuNotifier&quot;: &#123; &quot;notifierSwitch&quot;: true, &quot;robots&quot;: [ &quot;https://open.feishu.cn/open-apis/bot/v2/hook/xxx&quot; ] &#125;&#125; 调用1FeishuNotifier.sendMessageAsync(&quot;xxx&quot;, &quot;xxx&quot;);","tags":["笔记"],"categories":["Java"]},{"title":"James实现自定义安全风控","path":"/2025/03/07/2025James Rejection/","content":"方式一注意，该方式只能处理外站发进来的邮件，站内收发不会出发触发 代码james-&gt;protocols-&gt;smtp-&gt;core-&gt;fastfail-&gt;RejectionHandler 123456789101112131415161718192021222324252627282930313233343536373839404142434445package org.apache.james.protocols.smtp.core.fastfail;import org.apache.james.core.MailAddress;import org.apache.james.core.MaybeSender;import org.apache.james.protocols.smtp.SMTPSession;import org.apache.james.protocols.smtp.hook.HookResult;import org.apache.james.protocols.smtp.hook.MailHook;import org.apache.james.protocols.smtp.hook.RcptHook;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * * @author xen * * @date 2025/3/5 **/public class RejectionHandler implements MailHook, RcptHook &#123; private static final Logger LOGGER = LoggerFactory.getLogger(RejectionHandler.class); @Override public HookResult doMail(SMTPSession session, MaybeSender sender) &#123; LOGGER.info(&quot;sender:&#123;&#125; 进入自定义拦截逻辑-doMail&quot;, sender.asString()); if (sender.asOptional().isPresent() &amp;&amp; isRejectedDomain(sender.asString())) &#123; LOGGER.info(&quot;sender:&#123;&#125; 拒收-doMail&quot;, sender.asString()); return HookResult.DENY; &#125; LOGGER.info(&quot;sender:&#123;&#125; 放行-doMail&quot;, sender.asString()); return HookResult.DECLINED; &#125; @Override public HookResult doRcpt(SMTPSession session, MaybeSender sender, MailAddress recipient) &#123; LOGGER.info(&quot;sender:&#123;&#125; 进入自定义拦截逻辑-doRcpt&quot;, sender.asString()); if (sender.asOptional().isPresent() &amp;&amp; isRejectedDomain(sender.asString())) &#123; LOGGER.info(&quot;sender:&#123;&#125; 拒收-doRcpt&quot;, sender.asString()); return HookResult.DENY; &#125; LOGGER.info(&quot;sender:&#123;&#125; 放行-doRcpt&quot;, sender.asString()); return HookResult.DECLINED; &#125; private boolean isRejectedDomain(String sender) &#123; return sender.endsWith(&quot;@gmail.com&quot;) || sender.endsWith(&quot;@xx.com&quot;); &#125;&#125; 修改配置文件conf/smtpserver.xml，在相应的 元素中添加该处理器的配置 12345678910111213&lt;smtpservers&gt; &lt;smtpserver enabled=&quot;true&quot;&gt; &lt;jmxName&gt;smtpserver-global&lt;/jmxName&gt; &lt;bind&gt;0.0.0.0:25&lt;/bind&gt; &lt;!-- 其他配置项 --&gt; &lt;handlerchain&gt; &lt;!-- 添加 RejectionHandler，尽量放在最前面 --&gt; &lt;handler class=&quot;org.apache.james.protocols.smtp.core.fastfail.RejectionHandler&quot;/&gt; &lt;!-- 其他处理器 --&gt; &lt;/handlerchain&gt; &lt;/smtpserver&gt; &lt;!-- 其他 smtpserver 配置 --&gt;&lt;/smtpservers&gt; 1&lt;handler class=&quot;org.apache.james.protocols.smtp.core.fastfail.RejectionHandler&quot;/&gt; 方式二修改配置文件服务器conf目录下的mailetcontainer.xml文件 1在&lt;processor state=&quot;transport&quot; enableJmx=&quot;true&quot;&gt;标签中添加下面的代码 收发件都触发1&lt;mailet match=&quot;All&quot; class=&quot;org.apache.james.mailetcontainer.impl.matchers.RejectionMailet&quot; /&gt; 只在收件触发1&lt;mailet match=&quot;RecipientIsLocal&quot; class=&quot;org.apache.james.mailetcontainer.impl.matchers.ReceiveEmailMailet&quot; /&gt; 限制邮箱域123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/**************************************************************** * Licensed to the Apache Software Foundation (ASF) under one * * or more contributor license agreements. See the NOTICE file * * distributed with this work for additional information * * regarding copyright ownership. The ASF licenses this file * * to you under the Apache License, Version 2.0 (the * * &quot;License&quot;); you may not use this file except in compliance * * with the License. You may obtain a copy of the License at * * * * http://www.apache.org/licenses/LICENSE-2.0 * * * * Unless required by applicable law or agreed to in writing, * * software distributed under the License is distributed on an * * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * * KIND, either express or implied. See the License for the * * specific language governing permissions and limitations * * under the License. * ****************************************************************/package org.apache.james.mailetcontainer.impl.matchers;import java.util.Arrays;import java.util.List;import java.util.Objects;import java.util.regex.Pattern;import java.util.stream.Collectors;import javax.mail.Message;import javax.mail.MessagingException;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeMessage;import org.apache.mailet.Mail;import org.apache.mailet.base.GenericMailet;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * * @author xen * * @date 2025/3/5 **/public class RejectionMailet extends GenericMailet &#123; public static final Logger LOGGER = LoggerFactory.getLogger(RejectionMailet.class); private final List&lt;String&gt; rejectedDomains = Arrays.asList(&quot;xx.xx&quot;, &quot;163.com&quot;); @Override public void service(Mail mail) throws MessagingException &#123; List&lt;String&gt; from = Arrays.stream(mail.getMessage().getFrom()).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); LOGGER.info(&quot;发件人:&#123;&#125; 进入 Mailet 自定义拦截逻辑-service&quot;, from); if (checkFormDomain(from)) &#123; LOGGER.info(&quot;发件人:&#123;&#125; 拒绝-service&quot;, from); mail.setState(Mail.GHOST); // 阻止进一步处理 sendRejectionNotification(mail, from); &#125; else &#123; LOGGER.info(&quot;发件人:&#123;&#125; 放行-service&quot;, from); &#125; &#125; private void sendRejectionNotification(Mail originalMail, List&lt;String&gt; recipients) &#123; try &#123; LOGGER.info(&quot;开始发拒收通知&quot;); MimeMessage notification = new MimeMessage(originalMail.getMessage().getSession()); // 设置发件人为 postmaster，避免被拦截 notification.setFrom(new InternetAddress(&quot;postmaster@xx.xx&quot;)); notification.setRecipients(Message.RecipientType.TO, InternetAddress.parse(String.join(&quot;,&quot;, recipients))); notification.setSubject(&quot;邮件被拒收通知&quot;); notification.setText(&quot;您的邮件因发件人域名被限制而无法送达。&quot;); getMailetContext().sendMail(notification); &#125; catch (Exception e) &#123; LOGGER.error(&quot;发送拒收通知失败&quot;, e); &#125; &#125; private Boolean checkFormDomain(List&lt;String&gt; from) &#123; if (rejectedDomains.isEmpty()) &#123; return false; &#125; String regex = rejectedDomains.stream() .filter(Objects::nonNull) .map(domain -&gt; Pattern.quote(domain.toLowerCase())) .collect(Collectors.joining(&quot;|&quot;, &quot;@(&quot;, &quot;)$&quot;)); Pattern pattern = Pattern.compile(regex, Pattern.CASE_INSENSITIVE); return from.stream() .filter(Objects::nonNull) .anyMatch(email -&gt; &#123; String lowerEmail = email.toLowerCase(); // 匹配拒绝域名且排除特定邮箱 return pattern.matcher(lowerEmail).find() &amp;&amp; !lowerEmail.equals(&quot;postmaster@xx.xx&quot;); &#125;); &#125;&#125; 限制邮箱域和邮箱地址和指定ip123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165/**************************************************************** * Licensed to the Apache Software Foundation (ASF) under one * * or more contributor license agreements. See the NOTICE file * * distributed with this work for additional information * * regarding copyright ownership. The ASF licenses this file * * to you under the Apache License, Version 2.0 (the * * &quot;License&quot;); you may not use this file except in compliance * * with the License. You may obtain a copy of the License at * * * * http://www.apache.org/licenses/LICENSE-2.0 * * * * Unless required by applicable law or agreed to in writing, * * software distributed under the License is distributed on an * * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * * KIND, either express or implied. See the License for the * * specific language governing permissions and limitations * * under the License. * ****************************************************************/package org.apache.james.mailetcontainer.impl.matchers;import java.util.Arrays;import java.util.List;import java.util.Objects;import java.util.regex.Pattern;import java.util.stream.Collectors;import javax.mail.Message;import javax.mail.MessagingException;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeMessage;import org.apache.mailet.Mail;import org.apache.mailet.base.GenericMailet;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.google.common.base.Strings;/** * * @author xen * * @date 2025/3/5 **/public class RejectionMailet extends GenericMailet &#123; public static final Logger LOGGER = LoggerFactory.getLogger(RejectionMailet.class); private final List&lt;String&gt; rejectedDomains = Arrays.asList(&quot;&quot;, &quot;163.com&quot;); private final List&lt;String&gt; rejectedFromEmailAddress = Arrays.asList(&quot;614164@qq.com&quot;, &quot;&quot;); private final List&lt;String&gt; rejectedToEmailAddress = Arrays.asList(&quot;&quot;, &quot;1@xx.xx&quot;); private final List&lt;String&gt; rejectedSenderIPs = Arrays.asList(&quot;209.85.166.196&quot;, &quot;203.0.113.5&quot;); @Override public void service(Mail mail) throws MessagingException &#123; List&lt;String&gt; from = Arrays.stream(mail.getMessage().getFrom()).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); // 获取收件人地址 List&lt;String&gt; to = Arrays.stream(mail.getMessage().getRecipients(Message.RecipientType.TO)) .map(m -&gt; ((InternetAddress) m).getAddress()) .collect(Collectors.toList()); LOGGER.info(&quot;发件人:&#123;&#125; 进入自定义拦截逻辑&quot;, from); String rejectionReason = getRejectionReason(from, to, mail.getRemoteAddr()); if (!Strings.isNullOrEmpty(rejectionReason)) &#123; mail.setState(Mail.GHOST); // 阻止进一步处理 sendRejectionNotification(mail, from, rejectionReason); &#125; &#125; private String getRejectionReason(List&lt;String&gt; from, List&lt;String&gt; to, String senderIP) &#123; if (checkFormDomain(from)) &#123; return &quot;Your mail cannot be delivered due to domain restrictions&quot;; &#125; else if (checkFormEmailAddress(from)) &#123; return &quot;Your email address is restricted and cannot be delivered&quot;; &#125; else if (checkToEmailAddress(to)) &#123; return &quot;The recipient&#x27;s email address is restricted and cannot be delivered&quot;; &#125; else if (checkSenderIP(senderIP)) &#123; return &quot;Your IP address is restricted and cannot send emails to this server&quot;; &#125; return &quot;&quot;; &#125; private void sendRejectionNotification(Mail originalMail, List&lt;String&gt; recipients, String content) &#123; try &#123; LOGGER.info(&quot;开始发拒收通知&quot;); MimeMessage notification = new MimeMessage(originalMail.getMessage().getSession()); // 设置发件人为 postmaster，避免被拦截 notification.setFrom(new InternetAddress(&quot;postmaster@xx.xx&quot;)); notification.setRecipients(Message.RecipientType.TO, InternetAddress.parse(String.join(&quot;,&quot;, recipients))); notification.setSubject(&quot;Mail rejected notification&quot;); notification.setText(content); getMailetContext().sendMail(notification); &#125; catch (Exception e) &#123; LOGGER.error(&quot;发送拒收通知失败&quot;, e); &#125; &#125; private Boolean checkFormDomain(List&lt;String&gt; from) &#123; if (rejectedDomains.isEmpty()) &#123; return false; &#125; String regex = rejectedDomains.stream() .filter(Objects::nonNull) .map(domain -&gt; Pattern.quote(domain.toLowerCase())) .collect(Collectors.joining(&quot;|&quot;, &quot;@(&quot;, &quot;)$&quot;)); Pattern pattern = Pattern.compile(regex, Pattern.CASE_INSENSITIVE); return from.stream() .filter(Objects::nonNull) .anyMatch(email -&gt; &#123; String lowerEmail = email.toLowerCase(); boolean b = pattern.matcher(lowerEmail).find() &amp;&amp; !lowerEmail.equals(&quot;postmaster@xx.xx&quot;); if (b) &#123; LOGGER.info(&quot;发件人:&#123;&#125; 域被拒绝&quot;, from); &#125; return b; &#125;); &#125; private Boolean checkFormEmailAddress(List&lt;String&gt; from) &#123; if (rejectedFromEmailAddress.isEmpty()) &#123; return false; &#125; boolean b = from.stream() .anyMatch(email -&gt; rejectedFromEmailAddress.contains(email) &amp;&amp; !&quot;postmaster@xx.xx&quot;.equals(email)); if (b) &#123; LOGGER.info(&quot;发件人:&#123;&#125; 邮箱地址被拒绝&quot;, from); &#125; return b; &#125; private Boolean checkToEmailAddress(List&lt;String&gt; to) &#123; if (rejectedToEmailAddress.isEmpty()) &#123; return false; &#125; LOGGER.info(&quot;收件人地址:&#123;&#125;&quot;, to); boolean b = to.stream() .anyMatch(email -&gt; rejectedToEmailAddress.contains(email) &amp;&amp; !&quot;postmaster@xx.xx&quot;.equals(email)); if (b) &#123; LOGGER.info(&quot;收件人:&#123;&#125; 邮箱地址被拒绝&quot;, to); &#125; return b; &#125; private Boolean checkSenderIP(String senderIP) &#123; if (rejectedSenderIPs.isEmpty()) &#123; return false; &#125; LOGGER.info(&quot;发件人IP地址:&#123;&#125;&quot;, senderIP); boolean b = rejectedSenderIPs.contains(senderIP); if (b) &#123; LOGGER.info(&quot;发件人IP:&#123;&#125; 被拒绝&quot;, senderIP); &#125; return b; &#125;&#125; 拓展一在配置文件中取数据 配置文件修改mailetcontainer.xml 123456&lt;mailet match=&quot;RecipientIsLocal&quot; class=&quot;org.apache.james.mailetcontainer.impl.matchers.RejectionMailet&quot;&gt; &lt;rejectedDomains&gt;example.com,163.com&lt;/rejectedDomains&gt; &lt;rejectedFromEmailAddress&gt;xx@qq.com,someone@example.com&lt;/rejectedFromEmailAddress&gt; &lt;rejectedToEmailAddress&gt;1@xx.xx,another@example.com&lt;/rejectedToEmailAddress&gt; &lt;rejectedSenderIPs&gt;209.85.166.xx,203.0.113.x&lt;/rejectedSenderIPs&gt;&lt;/mailet&gt; 代码调整123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203/**************************************************************** * Licensed to the Apache Software Foundation (ASF) under one * * or more contributor license agreements. See the NOTICE file * * distributed with this work for additional information * * regarding copyright ownership. The ASF licenses this file * * to you under the Apache License, Version 2.0 (the * * &quot;License&quot;); you may not use this file except in compliance * * with the License. You may obtain a copy of the License at * * * * http://www.apache.org/licenses/LICENSE-2.0 * * * * Unless required by applicable law or agreed to in writing, * * software distributed under the License is distributed on an * * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * * KIND, either express or implied. See the License for the * * specific language governing permissions and limitations * * under the License. * ****************************************************************/package org.apache.james.mailetcontainer.impl.matchers;import java.util.ArrayList;import java.util.Arrays;import java.util.Collections;import java.util.List;import java.util.Objects;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;import java.util.regex.Pattern;import java.util.stream.Collectors;import javax.mail.Message;import javax.mail.MessagingException;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeMessage;import org.apache.mailet.Mail;import org.apache.mailet.MailetConfig;import org.apache.mailet.base.GenericMailet;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.google.common.base.Strings;/** * * @author xen * * @date 2025/3/5 **/public class RejectionMailet extends GenericMailet &#123; public static final Logger LOGGER = LoggerFactory.getLogger(RejectionMailet.class); private volatile List&lt;String&gt; rejectedDomains = new ArrayList&lt;&gt;(); private volatile List&lt;String&gt; rejectedFromEmailAddress = new ArrayList&lt;&gt;(); private volatile List&lt;String&gt; rejectedToEmailAddress = new ArrayList&lt;&gt;(); private volatile List&lt;String&gt; rejectedSenderIPs = new ArrayList&lt;&gt;(); private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1); @Override public void init() throws MessagingException &#123; super.init(); loadConfiguration(); scheduler.scheduleAtFixedRate(this::loadConfiguration, 30, 30, TimeUnit.SECONDS); &#125; private void loadConfiguration() &#123; MailetConfig config = getMailetConfig(); rejectedDomains = parseConfig(config.getInitParameter(&quot;rejectedDomains&quot;)); rejectedFromEmailAddress = parseConfig(config.getInitParameter(&quot;rejectedFromEmailAddress&quot;)); rejectedToEmailAddress = parseConfig(config.getInitParameter(&quot;rejectedToEmailAddress&quot;)); rejectedSenderIPs = parseConfig(config.getInitParameter(&quot;rejectedSenderIPs&quot;)); LOGGER.info(&quot;配置已重新加载: rejectedDomains=&#123;&#125;, rejectedFromEmailAddress=&#123;&#125;, rejectedToEmailAddress=&#123;&#125;, rejectedSenderIPs=&#123;&#125;&quot;, rejectedDomains, rejectedFromEmailAddress, rejectedToEmailAddress, rejectedSenderIPs); &#125; private List&lt;String&gt; parseConfig(String configValue) &#123; if (Strings.isNullOrEmpty(configValue)) &#123; return Collections.emptyList(); &#125; return Arrays.stream(configValue.split(&quot;,&quot;)) .map(String::trim) .filter(s -&gt; !s.isEmpty()) .collect(Collectors.toList()); &#125; @Override public void destroy() &#123; scheduler.shutdown(); super.destroy(); &#125; @Override public void service(Mail mail) throws MessagingException &#123; List&lt;String&gt; from = Arrays.stream(mail.getMessage().getFrom()).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); // 获取收件人地址 List&lt;String&gt; to = Arrays.stream(mail.getMessage().getRecipients(Message.RecipientType.TO)) .map(m -&gt; ((InternetAddress) m).getAddress()) .collect(Collectors.toList()); LOGGER.info(&quot;发件人:&#123;&#125; 进入自定义拦截逻辑&quot;, from); String rejectionReason = getRejectionReason(from, to, mail.getRemoteAddr()); if (!Strings.isNullOrEmpty(rejectionReason)) &#123; mail.setState(Mail.GHOST); // 阻止进一步处理 sendRejectionNotification(mail, from, rejectionReason); &#125; &#125; private String getRejectionReason(List&lt;String&gt; from, List&lt;String&gt; to, String senderIP) &#123; if (checkFormDomain(from)) &#123; return &quot;Your mail cannot be delivered due to domain restrictions&quot;; &#125; else if (checkFormEmailAddress(from)) &#123; return &quot;Your email address is restricted and cannot be delivered&quot;; &#125; else if (checkToEmailAddress(to)) &#123; return &quot;The recipient&#x27;s email address is restricted and cannot be delivered&quot;; &#125; else if (checkSenderIP(senderIP)) &#123; return &quot;Your IP address is restricted and cannot send emails to this server&quot;; &#125; return &quot;&quot;; &#125; private void sendRejectionNotification(Mail originalMail, List&lt;String&gt; recipients, String content) &#123; try &#123; LOGGER.info(&quot;开始发拒收通知&quot;); MimeMessage notification = new MimeMessage(originalMail.getMessage().getSession()); // 设置发件人为 postmaster，避免被拦截 notification.setFrom(new InternetAddress(&quot;postmaster@xx.xx&quot;)); notification.setRecipients(Message.RecipientType.TO, InternetAddress.parse(String.join(&quot;,&quot;, recipients))); notification.setSubject(&quot;Mail rejected notification&quot;); notification.setText(content); getMailetContext().sendMail(notification); &#125; catch (Exception e) &#123; LOGGER.error(&quot;发送拒收通知失败&quot;, e); &#125; &#125; private Boolean checkFormDomain(List&lt;String&gt; from) &#123; if (rejectedDomains.isEmpty()) &#123; return false; &#125; String regex = rejectedDomains.stream() .filter(Objects::nonNull) .map(domain -&gt; Pattern.quote(domain.toLowerCase())) .collect(Collectors.joining(&quot;|&quot;, &quot;@(&quot;, &quot;)$&quot;)); Pattern pattern = Pattern.compile(regex, Pattern.CASE_INSENSITIVE); return from.stream() .filter(Objects::nonNull) .anyMatch(email -&gt; &#123; String lowerEmail = email.toLowerCase(); boolean b = pattern.matcher(lowerEmail).find() &amp;&amp; !lowerEmail.equals(&quot;postmaster@xx.xx&quot;); if (b) &#123; LOGGER.info(&quot;发件人:&#123;&#125; 域被拒绝&quot;, from); &#125; return b; &#125;); &#125; private Boolean checkFormEmailAddress(List&lt;String&gt; from) &#123; if (rejectedFromEmailAddress.isEmpty()) &#123; return false; &#125; boolean b = from.stream() .anyMatch(email -&gt; rejectedFromEmailAddress.contains(email) &amp;&amp; !&quot;postmaster@xx.xx&quot;.equals(email)); if (b) &#123; LOGGER.info(&quot;发件人:&#123;&#125; 邮箱地址被拒绝&quot;, from); &#125; return b; &#125; private Boolean checkToEmailAddress(List&lt;String&gt; to) &#123; if (rejectedToEmailAddress.isEmpty()) &#123; return false; &#125; LOGGER.info(&quot;收件人地址:&#123;&#125;&quot;, to); boolean b = to.stream() .anyMatch(email -&gt; rejectedToEmailAddress.contains(email) &amp;&amp; !&quot;postmaster@xx.xx&quot;.equals(email)); if (b) &#123; LOGGER.info(&quot;收件人:&#123;&#125; 邮箱地址被拒绝&quot;, to); &#125; return b; &#125; private Boolean checkSenderIP(String senderIP) &#123; if (rejectedSenderIPs.isEmpty()) &#123; return false; &#125; LOGGER.info(&quot;发件人IP地址:&#123;&#125;&quot;, senderIP); boolean b = rejectedSenderIPs.contains(senderIP); if (b) &#123; LOGGER.info(&quot;发件人IP:&#123;&#125; 被拒绝&quot;, senderIP); &#125; return b; &#125;&#125; 拓展二在配置文件中取数据+动态限制ip频次 配置文件修改mailetcontainer.xml 123456789&lt;mailet match=&quot;RecipientIsLocal&quot; class=&quot;org.apache.james.mailetcontainer.impl.matchers.RejectionMailet&quot;&gt; &lt;rejectedDomains&gt;example.com,163.com&lt;/rejectedDomains&gt; &lt;rejectedFromEmailAddress&gt;614164@qq.com,someone@example.com&lt;/rejectedFromEmailAddress&gt; &lt;rejectedToEmailAddress&gt;1@xx.xx,another@example.com&lt;/rejectedToEmailAddress&gt; &lt;rejectedSenderIPs&gt;209.85.166.196,203.0.113.5&lt;/rejectedSenderIPs&gt; &lt;ipLimitTime&gt;60000&lt;/ipLimitTime&gt; &lt;!-- 锁定时间，单位：秒 --&gt; &lt;ipRiskControlTime&gt;3600000&lt;/ipRiskControlTime&gt; &lt;!-- 风控时长，单位：秒 --&gt; &lt;ipFrequency&gt;100&lt;/ipFrequency&gt; &lt;!-- 风控时长内的最大请求次数 --&gt;&lt;/mailet&gt; 代码调整因为用的James代码，不想改动太多，直接在内存中操作，新增2个工具类，目录结构 12345matchers -RejectionMailet -utils -CacheUtil -ExpireMap CacheUtil12345678910111213141516171819202122232425package org.apache.james.mailetcontainer.impl.matchers.utils;/** * * @author xen * * @date 2025/3/5 **/public class CacheUtil &#123; /** * 缓存一些临时数据，类似于Redis操作 */ private static ExpireMap&lt;String, Object&gt; expireMap = new ExpireMap&lt;&gt;(); public static void put(String key, Object val, int expire) &#123; expireMap.put(key, val, expire); &#125; public static Object get(String key) &#123; return expireMap.get(key); &#125; public static void rem(String key) &#123; expireMap.remove(key); &#125;&#125; ExpireMap123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243package org.apache.james.mailetcontainer.impl.matchers.utils;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.*;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.ScheduledThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * * @author xen * * @date 2025/3/5 **/public class ExpireMap&lt;K, V&gt; extends ConcurrentHashMap&lt;K, V&gt; &#123; public static final Logger LOGGER = LoggerFactory.getLogger(ExpireMap.class); private static long DEFAULT_EXPIRE_SECONDS = 2 * 60; private ScheduledExecutorService executorService; /** * record cached data */ private Map&lt;K, Long&gt; expireDic = new ConcurrentHashMap&lt;&gt;(); Map&lt;K, Long&gt; getExpireDic() &#123; return this.expireDic; &#125; public ExpireMap() &#123; super(1 &lt;&lt; 4); executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;expiremap-schedule-pool-%d&quot;).daemon(true).build()); executorService.scheduleAtFixedRate(new CleanTask(this), 0, 60 * 60, TimeUnit.SECONDS); &#125; public ExpireMap(int initialCapacity) &#123; this(initialCapacity, 1, DEFAULT_EXPIRE_SECONDS); &#125; public ExpireMap(long period, long expireSeconds) &#123; this(1 &lt;&lt; 4, period, expireSeconds); &#125; public ExpireMap(int initialCapacity, long period, long expireSeconds) &#123; super(initialCapacity); DEFAULT_EXPIRE_SECONDS = expireSeconds; executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;expiremap-schedule-pool-%d&quot;).daemon(true).build()); executorService.scheduleAtFixedRate(new CleanTask(this), 0, period, TimeUnit.SECONDS); &#125; public ExpireMap(int delay, int period) &#123; super(1 &lt;&lt; 4); executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;expiremap-schedule-pool-%d&quot;).daemon(true).build()); executorService.scheduleAtFixedRate(new CleanTask(this), delay, period, TimeUnit.SECONDS); &#125; @Override public synchronized V put(K key, V value) &#123; expireDic.put(key, System.currentTimeMillis() + TimeUnit.SECONDS.toMillis(DEFAULT_EXPIRE_SECONDS)); return super.put(key, value); &#125; @Override public boolean containsKey(Object key) &#123; return !checkExpire(key) &amp;&amp; super.containsKey(key); &#125; public synchronized V put(K key, V value, long seconds) &#123; expireDic.put(key, System.currentTimeMillis() + TimeUnit.SECONDS.toMillis(seconds)); return super.put(key, value); &#125; public synchronized V put(K key, V value, long duration, TimeUnit unit) &#123; expireDic.put(key, System.currentTimeMillis() + TimeUnit.MILLISECONDS.convert(duration, unit)); return super.put(key, value); &#125; @Override public boolean isEmpty() &#123; return entrySet().size() == 0; &#125; @Override public boolean containsValue(Object value) &#123; if (value == null) &#123; return Boolean.FALSE; &#125; Set&lt;Entry&lt;K, V&gt;&gt; set = super.entrySet(); Iterator&lt;Entry&lt;K, V&gt;&gt; iterator = set.iterator(); while (iterator.hasNext()) &#123; Entry&lt;K, V&gt; entry = iterator.next(); if (value.equals(entry.getValue())) &#123; if (checkExpire(entry.getKey())) &#123; iterator.remove(); return Boolean.FALSE; &#125; else &#123; return Boolean.TRUE; &#125; &#125; &#125; return Boolean.FALSE; &#125; @Override public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; values = super.values(); if (values == null || values.size() &lt; 1) &#123; return values; &#125; Iterator&lt;V&gt; iterator = values.iterator(); while (iterator.hasNext()) &#123; V next = iterator.next(); if (!containsValue(next)) &#123; iterator.remove(); &#125; &#125; return values; &#125; @Override public int size() &#123; return entrySet().size(); &#125; @Override public V get(Object key) &#123; if (key == null) &#123; return null; &#125; if (checkExpire(key)) &#123; return null; &#125; return super.get(key); &#125; @Override public Set&lt;Entry&lt;K, V&gt;&gt; entrySet() &#123; Set&lt;Entry&lt;K, V&gt;&gt; entries = new HashSet&lt;&gt;(); Set&lt;Entry&lt;K, V&gt;&gt; set = super.entrySet(); for (Entry&lt;K, V&gt; kvEntry : set) &#123; if (!checkExpire(kvEntry.getKey())) &#123; entries.add(kvEntry); &#125; &#125; return entries; &#125; public void remove(String key) &#123; super.remove(key); &#125; public Integer superSize() &#123; return super.size(); &#125; @Override public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; for (Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; expireDic.put(e.getKey(), System.currentTimeMillis() + TimeUnit.SECONDS.toMillis(DEFAULT_EXPIRE_SECONDS)); &#125; super.putAll(m); &#125; public void putAllByExpire(Map&lt;? extends K, ? extends V&gt; m, int expire) &#123; for (Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; expireDic.put(e.getKey(), System.currentTimeMillis() + TimeUnit.SECONDS.toMillis(expire)); &#125; super.putAll(m); &#125; private static class CleanTask&lt;K, V&gt; extends TimerTask &#123; private ExpireMap&lt;K, V&gt; expireMap; CleanTask(ExpireMap&lt;K, V&gt; expireMap) &#123; this.expireMap = expireMap; &#125; @Override public void run() &#123; List&lt;String&gt; expireKey = new ArrayList&lt;&gt;(); expireMap.getExpireDic().forEach((k, v) -&gt; &#123; if (expireMap.checkExpire(k)) &#123; expireKey.add(String.valueOf(k)); &#125; &#125;); expireKey.forEach(key -&gt; &#123; LOGGER.info(&quot;缓存KEY[&#123;&#125;]已过期。&quot;, key); expireMap.remove(key); expireMap.getExpireDic().remove(key); &#125;); &#125; &#125; @Override public void clear() &#123; super.clear(); expireDic.clear(); &#125; private synchronized boolean checkExpire(Object key) &#123; if (!expireDic.containsKey(key)) &#123; return Boolean.FALSE; &#125; long expiryTime = expireDic.get(key); return System.currentTimeMillis() &gt; expiryTime; &#125; public static void main(String[] args) throws InterruptedException &#123; ExpireMap&lt;String, String&gt; map = new ExpireMap&lt;&gt;(0, 1); map.put(&quot;aaa&quot;, &quot;test&quot;, 6, TimeUnit.SECONDS); map.put(&quot;bbb&quot;, &quot;test&quot;, 2, TimeUnit.SECONDS); map.put(&quot;ccc&quot;, &quot;test&quot;, 3, TimeUnit.SECONDS); map.put(&quot;ddd&quot;, &quot;test&quot;, 4, TimeUnit.SECONDS); map.put(&quot;fff&quot;, &quot;test&quot;, 5, TimeUnit.SECONDS); for (int i = 0; i &lt; 100; i++) &#123; Thread.sleep(1000); printMap(map); System.out.println(&quot;expireDic：&quot; + map.expireDic.size()); System.out.println(&quot;map：&quot; + map.superSize()); &#125; Thread.sleep(10000000); &#125; private static void putData(ExpireMap&lt;String, String&gt; map) &#123; for (int i = 0; i &lt; 1000; i++) &#123; map.put(&quot;test&quot; + (System.currentTimeMillis() + i), &quot;jfdsaj&quot; + UUID.randomUUID().toString()); &#125; &#125; private static void printMap(ExpireMap&lt;String, String&gt; map) &#123; LOGGER.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;map size:&#123;&#125;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;, map.size()); &#125;&#125; RejectionMailet123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276/**************************************************************** * Licensed to the Apache Software Foundation (ASF) under one * * or more contributor license agreements. See the NOTICE file * * distributed with this work for additional information * * regarding copyright ownership. The ASF licenses this file * * to you under the Apache License, Version 2.0 (the * * &quot;License&quot;); you may not use this file except in compliance * * with the License. You may obtain a copy of the License at * * * * http://www.apache.org/licenses/LICENSE-2.0 * * * * Unless required by applicable law or agreed to in writing, * * software distributed under the License is distributed on an * * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * * KIND, either express or implied. See the License for the * * specific language governing permissions and limitations * * under the License. * ****************************************************************/package org.apache.james.mailetcontainer.impl.matchers;import java.util.ArrayList;import java.util.Arrays;import java.util.Collections;import java.util.List;import java.util.Objects;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;import java.util.regex.Pattern;import java.util.stream.Collectors;import javax.mail.Message;import javax.mail.MessagingException;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeMessage;import org.apache.james.mailetcontainer.impl.matchers.utils.CacheUtil;import org.apache.mailet.Mail;import org.apache.mailet.MailetConfig;import org.apache.mailet.base.GenericMailet;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.google.common.base.Strings;/** * * @author xen * * @date 2025/3/5 **/public class RejectionMailet extends GenericMailet &#123; public static final Logger LOGGER = LoggerFactory.getLogger(RejectionMailet.class); //静态风控 private volatile List&lt;String&gt; rejectedDomains = new ArrayList&lt;&gt;();//拒绝的邮箱域 private volatile List&lt;String&gt; rejectedFromEmailAddress = new ArrayList&lt;&gt;();//拒绝的发件邮箱 private volatile List&lt;String&gt; rejectedToEmailAddress = new ArrayList&lt;&gt;();//拒绝的收件邮箱 private volatile List&lt;String&gt; rejectedSenderIPs = new ArrayList&lt;&gt;();//拒绝的发件邮箱服务器的ip地址 //动态风控 private volatile Long ipLimitTime;//锁定时间，秒 private volatile Long ipRiskControlTime;//风控时长，秒 private volatile Long ipFrequency;//ip在风控时长内的最大请求次数 private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1); @Override public void init() throws MessagingException &#123; super.init(); loadConfiguration(); scheduler.scheduleAtFixedRate(this::loadConfiguration, 30, 30, TimeUnit.SECONDS); &#125; private void loadConfiguration() &#123; MailetConfig config = getMailetConfig(); rejectedDomains = parseConfig(config.getInitParameter(&quot;rejectedDomains&quot;)); rejectedFromEmailAddress = parseConfig(config.getInitParameter(&quot;rejectedFromEmailAddress&quot;)); rejectedToEmailAddress = parseConfig(config.getInitParameter(&quot;rejectedToEmailAddress&quot;)); rejectedSenderIPs = parseConfig(config.getInitParameter(&quot;rejectedSenderIPs&quot;)); ipLimitTime = parseLongConfig(config.getInitParameter(&quot;ipLimitTime&quot;)); ipRiskControlTime = parseLongConfig(config.getInitParameter(&quot;ipRiskControlTime&quot;)); ipFrequency = parseLongConfig(config.getInitParameter(&quot;ipFrequency&quot;)); LOGGER.info(&quot;james风控动态刷新配置: rejectedDomains=&#123;&#125;, rejectedFromEmailAddress=&#123;&#125;, rejectedToEmailAddress=&#123;&#125;, rejectedSenderIPs=&#123;&#125;, ipLimitTime=&#123;&#125;, ipRiskControlTime=&#123;&#125;, ipFrequency=&#123;&#125;&quot;, rejectedDomains, rejectedFromEmailAddress, rejectedToEmailAddress, rejectedSenderIPs, ipLimitTime, ipRiskControlTime, ipFrequency); &#125; private List&lt;String&gt; parseConfig(String configValue) &#123; if (Strings.isNullOrEmpty(configValue)) &#123; return Collections.emptyList(); &#125; return Arrays.stream(configValue.split(&quot;,&quot;)) .map(String::trim) .filter(s -&gt; !s.isEmpty()) .collect(Collectors.toList()); &#125; private Long parseLongConfig(String configValue) &#123; try &#123; return Long.parseLong(configValue); &#125; catch (NumberFormatException e) &#123; LOGGER.warn(&quot;Invalid long value for config: &#123;&#125;&quot;, configValue); return null; &#125; &#125; @Override public void destroy() &#123; scheduler.shutdown(); super.destroy(); &#125; @Override public void service(Mail mail) throws MessagingException &#123; List&lt;String&gt; from = Arrays.stream(mail.getMessage().getFrom()).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); // 获取收件人地址 List&lt;String&gt; to = Arrays.stream(mail.getMessage().getRecipients(Message.RecipientType.TO)) .map(m -&gt; ((InternetAddress) m).getAddress()) .collect(Collectors.toList()); LOGGER.info(&quot;发件人:&#123;&#125; 进入自定义拦截逻辑&quot;, from); String rejectionReason = getRejectionReason(from, to, mail.getRemoteAddr()); if (!Strings.isNullOrEmpty(rejectionReason)) &#123; mail.setState(Mail.GHOST); // 阻止进一步处理 sendRejectionNotification(mail, from, rejectionReason); &#125; &#125; private String getRejectionReason(List&lt;String&gt; from, List&lt;String&gt; to, String senderIP) &#123; if (checkFormDomain(from)) &#123; return &quot;Your mail cannot be delivered due to domain restrictions&quot;; &#125; else if (checkFormEmailAddress(from)) &#123; return &quot;Your email address is restricted and cannot be delivered&quot;; &#125; else if (checkToEmailAddress(to)) &#123; return &quot;The recipient&#x27;s email address is restricted and cannot be delivered&quot;; &#125; else if (checkSenderIP(senderIP)) &#123; return &quot;Your IP address is restricted and cannot send emails to this server&quot;; &#125; else if (dynamicIPRiskControl(senderIP)) &#123; return &quot;The operation is too frequent and has been locked&quot;; &#125; return &quot;&quot;; &#125; private void sendRejectionNotification(Mail originalMail, List&lt;String&gt; recipients, String content) &#123; try &#123; LOGGER.info(&quot;开始发拒收通知&quot;); MimeMessage notification = new MimeMessage(originalMail.getMessage().getSession()); // 设置发件人为 postmaster，避免被拦截 notification.setFrom(new InternetAddress(&quot;postmaster@xx.xx&quot;)); notification.setRecipients(Message.RecipientType.TO, InternetAddress.parse(String.join(&quot;,&quot;, recipients))); notification.setSubject(&quot;Mail rejected notification&quot;); notification.setText(content); getMailetContext().sendMail(notification); &#125; catch (Exception e) &#123; LOGGER.error(&quot;发送拒收通知失败&quot;, e); &#125; &#125; private Boolean checkFormDomain(List&lt;String&gt; from) &#123; if (rejectedDomains.isEmpty()) &#123; return false; &#125; String regex = rejectedDomains.stream() .filter(Objects::nonNull) .map(domain -&gt; Pattern.quote(domain.toLowerCase())) .collect(Collectors.joining(&quot;|&quot;, &quot;@(&quot;, &quot;)$&quot;)); Pattern pattern = Pattern.compile(regex, Pattern.CASE_INSENSITIVE); return from.stream() .filter(Objects::nonNull) .anyMatch(email -&gt; &#123; String lowerEmail = email.toLowerCase(); boolean b = pattern.matcher(lowerEmail).find() &amp;&amp; !lowerEmail.equals(&quot;postmaster@xx.xx&quot;); if (b) &#123; LOGGER.info(&quot;发件人:&#123;&#125; 域被拒绝&quot;, from); &#125; return b; &#125;); &#125; private Boolean checkFormEmailAddress(List&lt;String&gt; from) &#123; if (rejectedFromEmailAddress.isEmpty()) &#123; return false; &#125; boolean b = from.stream() .anyMatch(email -&gt; rejectedFromEmailAddress.contains(email) &amp;&amp; !&quot;postmaster@xx.xx&quot;.equals(email)); if (b) &#123; LOGGER.info(&quot;发件人:&#123;&#125; 邮箱地址被拒绝&quot;, from); &#125; return b; &#125; private Boolean checkToEmailAddress(List&lt;String&gt; to) &#123; if (rejectedToEmailAddress.isEmpty()) &#123; return false; &#125; LOGGER.info(&quot;收件人地址:&#123;&#125;&quot;, to); boolean b = to.stream() .anyMatch(email -&gt; rejectedToEmailAddress.contains(email) &amp;&amp; !&quot;postmaster@xx.xx&quot;.equals(email)); if (b) &#123; LOGGER.info(&quot;收件人:&#123;&#125; 邮箱地址被拒绝&quot;, to); &#125; return b; &#125; private Boolean checkSenderIP(String senderIP) &#123; if (rejectedSenderIPs.isEmpty()) &#123; return false; &#125; LOGGER.info(&quot;发件人IP地址:&#123;&#125;&quot;, senderIP); boolean b = rejectedSenderIPs.contains(senderIP); if (b) &#123; LOGGER.info(&quot;发件人IP:&#123;&#125; 被拒绝&quot;, senderIP); &#125; return b; &#125; private Boolean dynamicIPRiskControl(String senderIP) &#123; long currentTime = System.currentTimeMillis() / 1000; // 检查IP是否已被锁定 Object lockExpireTimeObj = CacheUtil.get(senderIP); if (lockExpireTimeObj != null) &#123; long lockExpireTime = (Long) lockExpireTimeObj; if (currentTime &lt; lockExpireTime) &#123; LOGGER.info(&quot;动态风控，IP地址:&#123;&#125;，处于锁定状态&quot;, senderIP); return true; // IP处于锁定状态 &#125; else &#123; LOGGER.info(&quot;动态风控，IP地址:&#123;&#125;，锁定过期，移除记录&quot;, senderIP); CacheUtil.rem(senderIP); // 锁定过期，移除记录 &#125; &#125; String frequencyKey = senderIP + &quot;:frequency&quot;; List&lt;Long&gt; requestTimes; // 同步块保证同一IP的并发安全 synchronized ((frequencyKey).intern()) &#123; // 获取请求时间记录 requestTimes = (List&lt;Long&gt;) CacheUtil.get(frequencyKey); if (requestTimes == null) &#123; requestTimes = new ArrayList&lt;&gt;(); &#125; LOGGER.info(&quot;动态风控，IP地址:&#123;&#125;，频次:&#123;&#125;&quot;, senderIP, requestTimes.size()); // 清理超出风控时长的记录 long thresholdTime = currentTime - ipRiskControlTime; requestTimes.removeIf(time -&gt; time &lt; thresholdTime); // 判断是否超过频率限制 if (requestTimes.size() &gt;= ipFrequency) &#123; // 触发锁定，记录锁定时间 long lockTime = currentTime + ipLimitTime; CacheUtil.put(senderIP, lockTime, ipLimitTime); CacheUtil.rem(frequencyKey); // 清除频率记录 LOGGER.info(&quot;动态风控，IP地址:&#123;&#125;，触发锁定&quot;, senderIP); return true; &#125; // 添加当前请求时间并更新缓存 requestTimes.add(currentTime); CacheUtil.put(frequencyKey, requestTimes, ipRiskControlTime); &#125; return false; &#125;&#125; 拓展三(推荐)该拓展是在拓展二的基础上改造而来，首先重命名了类为RiskMailet #### 配置文件修改 因为配置文件不知道动态刷新，动态读取到的内容一直会是服务刚起来时候的数据 mailetcontainer.xml 12345678910111213141516171819202122&lt;mailet match=&quot;RecipientIsLocal&quot; class=&quot;org.apache.james.mailetcontainer.impl.matchers.RiskMailet&quot;&gt; &lt;postmaster&gt;postmaster@xx.xx&lt;/postmaster&gt; &lt;domainNameWhitelist&gt;example.com,163.com&lt;/domainNameWhitelist&gt; &lt;fromEmailAddressBlacklist&gt;614164@qq.com,someone@example.com&lt;/fromEmailAddressBlacklist&gt; &lt;toEmailAddressBlacklist&gt;1@xx.xx,another@example.com&lt;/toEmailAddressBlacklist&gt; &lt;ipAddressBlacklist&gt;209.85.166.196,203.0.113.5&lt;/ipAddressBlacklist&gt; &lt;ipLimitTime&gt;60000&lt;/ipLimitTime&gt; &lt;!-- 锁定时间，单位：秒 --&gt; &lt;ipRiskControlTime&gt;3600000&lt;/ipRiskControlTime&gt; &lt;!-- 风控时长，单位：秒 --&gt; &lt;ipFrequency&gt;100&lt;/ipFrequency&gt; &lt;!-- 风控时长内的最大请求次数 --&gt; &lt;dynamicIpWhitelist&gt;example.com,163.com&lt;/dynamicIpWhitelist&gt; &lt;fromLimitTime&gt;60000&lt;/fromLimitTime&gt; &lt;fromRiskControlTime&gt;3600000&lt;/fromRiskControlTime&gt; &lt;fromFrequency&gt;100&lt;/fromFrequency&gt; &lt;dynamicFromWhitelist&gt;example.com,163.com&lt;/dynamicFromWhitelist&gt; &lt;toLimitTime&gt;60000&lt;/toLimitTime&gt; &lt;toRiskControlTime&gt;3600000&lt;/toRiskControlTime&gt; &lt;toFrequency&gt;100&lt;/toFrequency&gt; &lt;dynamicToWhitelist&gt;example.com,163.com&lt;/dynamicToWhitelist&gt; &lt;rateLimitCapacity&gt;60000&lt;/rateLimitCapacity&gt; &lt;rateLimitRefillTokens&gt;3600000&lt;/rateLimitRefillTokens&gt; &lt;rateLimitInterval&gt;100&lt;/rateLimitInterval&gt;&lt;!-- 单位：秒 --&gt;&lt;/mailet&gt; json改用走接口的形式来支持动态刷新，这是接口返回的数据格式 123456789101112131415161718192021222324252627282930313233&#123; &quot;james&quot;: &#123; &quot;risk&quot;: &#123; &quot;riskSwitch&quot;: true, &quot;riskLogSwitch&quot;: true, &quot;refreshInterval&quot;: 60, &quot;host&quot;: &quot;xx.xx&quot;, &quot;jamesServerIp&quot;: &quot;xx.xx.xx.xx&quot;, &quot;postmaster&quot;: &quot;postmaster@xx.xx&quot;, &quot;otherClientSwitch&quot;: true, &quot;notificationLimitTime&quot;: 2, &quot;domainNameWhitelist&quot;: [ &quot;gmail.com&quot; ], &quot;fromEmailAddressBlacklist&quot;: [], &quot;toEmailAddressBlacklist&quot;: [], &quot;fromLimitTime&quot;: 3600, &quot;fromRiskControlTime&quot;: 86400, &quot;fromFrequency&quot;: 30, &quot;dynamicFromWhitelist&quot;: [], &quot;toLimitTime&quot;: 3600, &quot;toRiskControlTime&quot;: 86400, &quot;toFrequency&quot;: 100, &quot;dynamicToWhitelist&quot;: [], &quot;rateLimitCapacity&quot;: 20000, &quot;rateLimitRefillTokens&quot;: 50, &quot;rateLimitInterval&quot;: 10 &#125;, &quot;listener&quot;: &#123; &quot;receiptCallback&quot;: true &#125; &#125;&#125; RateLimiter123456matchers -RejectionMailet -utils -CacheUtil -ExpireMap -RateLimiter 限流用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171package org.apache.james.mailetcontainer.impl.matchers.utils;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * * @author xen * * @date 2025/3/6 **/public class RateLimiter &#123; private static RateLimiter instance; // 单例实例 private final Map&lt;String, TokenBucket&gt; cache = new ConcurrentHashMap&lt;&gt;(); private long maxTokens; // 每个桶的最大令牌数量 private long refillTokens; // 每秒补充的令牌数量 private long refillInterval; // 补充令牌的时间间隔，单位是秒 // 确保线程安全 private final Lock lock = new ReentrantLock(); private RateLimiter(long maxTokens, long refillTokens, long refillInterval) &#123; this.maxTokens = maxTokens; this.refillTokens = refillTokens; this.refillInterval = refillInterval; &#125; // 单例 public static synchronized RateLimiter getInstance(long maxTokens, long refillTokens, long refillInterval) &#123; if (instance == null) &#123; instance = new RateLimiter(maxTokens, refillTokens, refillInterval); &#125; return instance; &#125; // 获取或创建一个针对特定IP或域名的令牌桶 private TokenBucket getOrCreateBucket(String key) &#123; return cache.computeIfAbsent(key, k -&gt; new TokenBucket(maxTokens, refillTokens, refillInterval)); &#125; // 判断当前令牌桶的令牌是否足够 public boolean tryConsume(String key) &#123; TokenBucket bucket = getOrCreateBucket(key); return bucket.tryConsume(); &#125; // 获取当前剩余的令牌数量 public long getAvailableTokens(String key) &#123; TokenBucket bucket = getOrCreateBucket(key); return bucket.getAvailableTokens(); &#125; // 重置指定IP或域名的限流桶 public void resetBucket(String key) &#123; cache.remove(key); &#125; // 刷新限流器配置 public void refreshConfig(long maxTokens, long refillTokens, long refillInterval) &#123; lock.lock(); try &#123; this.maxTokens = maxTokens; this.refillTokens = refillTokens; this.refillInterval = refillInterval; // 清空所有令牌桶，强制重新配置 cache.clear(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void clear() &#123; lock.lock(); try &#123; // 清空所有令牌桶，强制重新配置 cache.clear(); &#125; finally &#123; lock.unlock(); &#125; &#125; // 内部类：令牌桶 private class TokenBucket &#123; private final long maxTokens; // 每个桶的最大令牌数量 private final long refillTokens; // 每秒补充的令牌数量 private final long refillInterval; // 补充令牌的时间间隔（秒） private long currentTokens; // 当前剩余的令牌数量 private long lastRefillTime; // 上次补充令牌的时间（毫秒） private final Lock lock; // 用于线程安全的锁 public TokenBucket(long maxTokens, long refillTokens, long refillInterval) &#123; this.maxTokens = maxTokens; this.refillTokens = refillTokens; this.refillInterval = refillInterval; this.currentTokens = maxTokens; this.lastRefillTime = System.currentTimeMillis(); this.lock = new ReentrantLock(); &#125; // 获取当前剩余令牌数量 public long getAvailableTokens() &#123; refill(); return currentTokens; &#125; // 尝试消耗一个令牌 public boolean tryConsume() &#123; lock.lock(); try &#123; refill(); if (currentTokens &gt; 0) &#123; currentTokens--; return true; // 成功消耗令牌 &#125; else &#123; return false; // 没有足够的令牌 &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; // 补充令牌 private void refill() &#123; long now = System.currentTimeMillis(); long elapsedTime = now - lastRefillTime; // 计算经过的时间是否大于补充令牌的时间间隔 if (elapsedTime &gt;= refillInterval * 1000) &#123; // 计算补充的令牌数量 long tokensToAdd = (elapsedTime / (refillInterval * 1000)) * refillTokens; // 更新剩余令牌数，确保不会超过最大容量 currentTokens = Math.min(maxTokens, currentTokens + tokensToAdd); lastRefillTime = now; // 更新上次补充令牌的时间 &#125; &#125; &#125; // 示例用法 public static void main(String[] args) throws InterruptedException &#123; // 创建RateLimiter实例，设置每个桶的容量为10，每秒补充2个令牌 RateLimiter rateLimiter = RateLimiter.getInstance(10, 2, 1); String ipAddress = &quot;192.168.1.1&quot;; // 尝试消耗令牌 if (rateLimiter.tryConsume(ipAddress)) &#123; System.out.println(ipAddress + &quot; 请求被允许&quot;); &#125; else &#123; System.out.println(ipAddress + &quot; 请求被限流&quot;); &#125; // 输出剩余的令牌数量 System.out.println(ipAddress + &quot; 剩余令牌数量: &quot; + rateLimiter.getAvailableTokens(ipAddress)); // 等待2秒钟再尝试请求 Thread.sleep(2000); // 再次尝试消耗令牌 if (rateLimiter.tryConsume(ipAddress)) &#123; System.out.println(ipAddress + &quot; 请求被允许&quot;); &#125; else &#123; System.out.println(ipAddress + &quot; 请求被限流&quot;); &#125; // 动态刷新限流配置 rateLimiter.refreshConfig(15, 3, 1); // 更新为新的配置 // 重置该IP的限流桶 rateLimiter.resetBucket(ipAddress); &#125;&#125; RiskMailet123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642/**************************************************************** * Licensed to the Apache Software Foundation (ASF) under one * * or more contributor license agreements. See the NOTICE file * * distributed with this work for additional information * * regarding copyright ownership. The ASF licenses this file * * to you under the Apache License, Version 2.0 (the * * &quot;License&quot;); you may not use this file except in compliance * * with the License. You may obtain a copy of the License at * * * * http://www.apache.org/licenses/LICENSE-2.0 * * * * Unless required by applicable law or agreed to in writing, * * software distributed under the License is distributed on an * * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * * KIND, either express or implied. See the License for the * * specific language governing permissions and limitations * * under the License. * ****************************************************************/package org.apache.james.mailetcontainer.impl.matchers;import java.io.IOException;import java.net.URI;import java.net.http.HttpClient;import java.net.http.HttpRequest;import java.net.http.HttpResponse;import java.util.ArrayList;import java.util.Arrays;import java.util.List;import java.util.Map;import java.util.Objects;import java.util.Set;import java.util.concurrent.CompletableFuture;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.ScheduledFuture;import java.util.concurrent.TimeUnit;import java.util.stream.Collectors;import javax.mail.Message;import javax.mail.MessagingException;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeMessage;import org.apache.james.mailetcontainer.impl.matchers.utils.CacheUtil;import org.apache.james.mailetcontainer.impl.matchers.utils.RateLimiter;import org.apache.mailet.Mail;import org.apache.mailet.base.GenericMailet;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.fasterxml.jackson.databind.JsonNode;import com.fasterxml.jackson.databind.ObjectMapper;import com.google.common.base.Strings;/** * * @author xen * * @date 2025/3/5 **/public class RiskMailet extends GenericMailet &#123; public static final Logger LOGGER = LoggerFactory.getLogger(RiskMailet.class); //风控配置 private volatile Boolean riskSwitch = false; private volatile Boolean riskLogSwitch = false; private volatile Integer refreshInterval = 60;//秒 private volatile String postmaster;//发送通知的邮箱 private volatile String host; private volatile String jamesServerIp; private volatile Boolean otherClientSwitch = false; private volatile Integer notificationLimitTime = 60;//一个账号间隔内只发送一次通知 //静态风控 private volatile List&lt;String&gt; domainNameWhitelist = new ArrayList&lt;&gt;();//域名白名单 private volatile List&lt;String&gt; fromEmailAddressBlacklist = new ArrayList&lt;&gt;();//发件人黑名单 private volatile List&lt;String&gt; toEmailAddressBlacklist = new ArrayList&lt;&gt;();//收件人黑名单 //动态风控 //发件人 private volatile Long fromLimitTime;//锁定时间，秒 private volatile Long fromRiskControlTime;//风控时长，秒 private volatile Long fromFrequency;//风控时长内的最大请求次数 private volatile List&lt;String&gt; dynamicFromWhitelist = new ArrayList&lt;&gt;();//白名单 //收件人 private volatile Long toLimitTime;//锁定时间，秒 private volatile Long toRiskControlTime;//风控时长，秒 private volatile Long toFrequency;//风控时长内的最大请求次数 private volatile List&lt;String&gt; dynamicToWhitelist = new ArrayList&lt;&gt;();//白名单 //限流 private volatile Long rateLimitCapacity;//令牌桶容量 private volatile Long rateLimitRefillTokens;//刷新令牌的数量 private volatile Long rateLimitInterval;//刷新令牌的间隔、毫秒 private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1); private final HttpClient httpClient = HttpClient.newHttpClient(); private final ObjectMapper objectMapper = new ObjectMapper(); private ScheduledFuture&lt;?&gt; scheduledFuture; private static final String CONFIG_API_URL = &quot;http://127.0.0.1:6001/api/mail/config/risk&quot;; private static final String LOG_API_URL = &quot;http://127.0.0.1:6001/api/mail/risk/log&quot;; @Override public void init() throws MessagingException &#123; super.init(); fetchRiskConfigAsync(); synchronized (this) &#123; if (scheduledFuture != null &amp;&amp; !scheduledFuture.isCancelled()) &#123; scheduledFuture.cancel(true); &#125; scheduledFuture = scheduler.scheduleAtFixedRate(this::fetchRiskConfigAsync, 0, refreshInterval, TimeUnit.SECONDS); &#125; &#125; private void fetchRiskConfigAsync() &#123; CompletableFuture.runAsync(() -&gt; &#123; try &#123; HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(CONFIG_API_URL)) .POST(HttpRequest.BodyPublishers.noBody()) .build(); HttpResponse&lt;String&gt; response = httpClient.send(request, HttpResponse.BodyHandlers.ofString()); if (response.statusCode() == 200) &#123; parseRiskConfig(response.body()); &#125; else &#123; LOGGER.error(&quot;获取风控配置失败，状态码: &#123;&#125;&quot;, response.statusCode()); &#125; &#125; catch (Exception e) &#123; LOGGER.error(&quot;获取风控配置异常: &#123;&#125;&quot;, e.getMessage()); &#125; &#125;); &#125; private void fetchRiskLogAsync(String type, String content) &#123; CompletableFuture.runAsync(() -&gt; &#123; try &#123; // 构造请求体 JSON ObjectMapper objectMapper = new ObjectMapper(); String requestBody = objectMapper.writeValueAsString(Map.of( &quot;type&quot;, type, &quot;content&quot;, content )); HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(LOG_API_URL)) .header(&quot;Content-Type&quot;, &quot;application/json&quot;) .POST(HttpRequest.BodyPublishers.ofString(requestBody)) .build(); HttpResponse&lt;String&gt; response = httpClient.send(request, HttpResponse.BodyHandlers.ofString()); if (response.statusCode() == 200) &#123; LOGGER.info(&quot;发送风控日志成功&quot;); &#125; else &#123; LOGGER.error(&quot;发送风控日志失败，状态码: &#123;&#125;&quot;, response.statusCode()); &#125; &#125; catch (Exception e) &#123; LOGGER.error(&quot;发送风控日志异常: &#123;&#125;&quot;, e.getMessage(), e); &#125; &#125;); &#125; private void parseRiskConfig(String responseBody) &#123; try &#123; JsonNode root = objectMapper.readTree(responseBody).get(&quot;msg&quot;).get(&quot;defaultConfigValue&quot;); JsonNode jamesConfig = objectMapper.readTree(root.asText()); JsonNode riskConfig = jamesConfig.get(&quot;james&quot;).get(&quot;risk&quot;); JsonNode uIDEventListenerConfig = jamesConfig.get(&quot;james&quot;).get(&quot;listener&quot;); // 解析监听器配置并更新变量 if (uIDEventListenerConfig.hasNonNull(&quot;receiptCallback&quot;)) &#123; UIDEventListener.receiptCallback = uIDEventListenerConfig.get(&quot;receiptCallback&quot;).asBoolean(); &#125; // 解析风控配置并更新变量 if (riskConfig.hasNonNull(&quot;riskSwitch&quot;)) &#123; this.riskSwitch = riskConfig.get(&quot;riskSwitch&quot;).asBoolean(); &#125; if (riskConfig.hasNonNull(&quot;riskLogSwitch&quot;)) &#123; this.riskLogSwitch = riskConfig.get(&quot;riskLogSwitch&quot;).asBoolean(); &#125; if (riskConfig.hasNonNull(&quot;refreshInterval&quot;)) &#123; int newRefreshInterval = riskConfig.get(&quot;refreshInterval&quot;).asInt(); if (newRefreshInterval &gt; 0 &amp;&amp; newRefreshInterval != refreshInterval) &#123; this.refreshInterval = newRefreshInterval; // 取消旧任务 if (scheduledFuture != null &amp;&amp; !scheduledFuture.isCancelled()) &#123; scheduledFuture.cancel(true); // 强制中断旧任务 &#125; // 重新调度新任务 synchronized (this) &#123; if (scheduledFuture != null &amp;&amp; !scheduledFuture.isCancelled()) &#123; scheduledFuture.cancel(true); &#125; scheduledFuture = scheduler.scheduleAtFixedRate(this::fetchRiskConfigAsync, 0, refreshInterval, TimeUnit.SECONDS); &#125; &#125; &#125; if (riskConfig.hasNonNull(&quot;host&quot;)) &#123; this.host = riskConfig.get(&quot;host&quot;).asText(); &#125; if (riskConfig.hasNonNull(&quot;jamesServerIp&quot;)) &#123; this.jamesServerIp = riskConfig.get(&quot;jamesServerIp&quot;).asText(); &#125; if (riskConfig.hasNonNull(&quot;postmaster&quot;)) &#123; this.postmaster = riskConfig.get(&quot;postmaster&quot;).asText(); &#125; if (riskConfig.hasNonNull(&quot;otherClientSwitch&quot;)) &#123; this.otherClientSwitch = riskConfig.get(&quot;otherClientSwitch&quot;).asBoolean(); &#125; if (riskConfig.hasNonNull(&quot;notificationLimitTime&quot;)) &#123; this.notificationLimitTime = riskConfig.get(&quot;notificationLimitTime&quot;).asInt(); &#125; // 静态风控配置 if (riskConfig.hasNonNull(&quot;domainNameWhitelist&quot;)) &#123; this.domainNameWhitelist.clear(); riskConfig.get(&quot;domainNameWhitelist&quot;).forEach(node -&gt; domainNameWhitelist.add(node.asText())); &#125; if (riskConfig.hasNonNull(&quot;fromEmailAddressBlacklist&quot;)) &#123; this.fromEmailAddressBlacklist.clear(); riskConfig.get(&quot;fromEmailAddressBlacklist&quot;).forEach(node -&gt; fromEmailAddressBlacklist.add(node.asText())); &#125; if (riskConfig.hasNonNull(&quot;toEmailAddressBlacklist&quot;)) &#123; this.toEmailAddressBlacklist.clear(); riskConfig.get(&quot;toEmailAddressBlacklist&quot;).forEach(node -&gt; toEmailAddressBlacklist.add(node.asText())); &#125; // 动态风控配置 if (riskConfig.hasNonNull(&quot;fromLimitTime&quot;)) &#123; this.fromLimitTime = riskConfig.get(&quot;fromLimitTime&quot;).asLong(); &#125; if (riskConfig.hasNonNull(&quot;fromRiskControlTime&quot;)) &#123; this.fromRiskControlTime = riskConfig.get(&quot;fromRiskControlTime&quot;).asLong(); &#125; if (riskConfig.hasNonNull(&quot;fromFrequency&quot;)) &#123; this.fromFrequency = riskConfig.get(&quot;fromFrequency&quot;).asLong(); &#125; if (riskConfig.hasNonNull(&quot;dynamicFromWhitelist&quot;)) &#123; this.dynamicFromWhitelist.clear(); riskConfig.get(&quot;dynamicFromWhitelist&quot;).forEach(node -&gt; dynamicFromWhitelist.add(node.asText())); &#125; if (riskConfig.hasNonNull(&quot;toLimitTime&quot;)) &#123; this.toLimitTime = riskConfig.get(&quot;toLimitTime&quot;).asLong(); &#125; if (riskConfig.hasNonNull(&quot;toRiskControlTime&quot;)) &#123; this.toRiskControlTime = riskConfig.get(&quot;toRiskControlTime&quot;).asLong(); &#125; if (riskConfig.hasNonNull(&quot;toFrequency&quot;)) &#123; this.toFrequency = riskConfig.get(&quot;toFrequency&quot;).asLong(); &#125; if (riskConfig.hasNonNull(&quot;dynamicToWhitelist&quot;)) &#123; this.dynamicToWhitelist.clear(); riskConfig.get(&quot;dynamicToWhitelist&quot;).forEach(node -&gt; dynamicToWhitelist.add(node.asText())); &#125; // 限流配置 if (riskConfig.hasNonNull(&quot;rateLimitCapacity&quot;) &amp;&amp; riskConfig.hasNonNull(&quot;rateLimitRefillTokens&quot;) &amp;&amp; riskConfig.hasNonNull(&quot;rateLimitInterval&quot;)) &#123; Long newRateLimitCapacity = riskConfig.get(&quot;rateLimitCapacity&quot;).asLong(); Long newRateLimitRefillTokens = riskConfig.get(&quot;rateLimitRefillTokens&quot;).asLong(); Long newRateLimitInterval = riskConfig.get(&quot;rateLimitInterval&quot;).asLong(); if (!newRateLimitCapacity.equals(rateLimitCapacity) || !newRateLimitRefillTokens.equals(rateLimitRefillTokens) || !newRateLimitInterval.equals(rateLimitInterval)) &#123; rateLimitCapacity = newRateLimitCapacity; rateLimitRefillTokens = newRateLimitRefillTokens; rateLimitInterval = newRateLimitInterval; LOGGER.info(&quot;刷新限流配置&quot;); RateLimiter rateLimiter = RateLimiter.getInstance(rateLimitCapacity, rateLimitRefillTokens, rateLimitInterval); rateLimiter.refreshConfig(newRateLimitCapacity, newRateLimitRefillTokens, newRateLimitInterval); &#125; &#125; else &#123; LOGGER.info(&quot;清空限流配置&quot;); try &#123; RateLimiter rateLimiter = RateLimiter.getInstance(rateLimitCapacity, rateLimitRefillTokens, rateLimitInterval); rateLimiter.clear(); &#125; catch (Exception e) &#123; LOGGER.error(&quot;清空限流配置报错：&#123;&#125;&quot;, e.getMessage()); &#125; &#125; LOGGER.info(&quot;风控配置已更新: riskSwitch=&#123;&#125;,riskLogSwitch=&#123;&#125;, refreshInterval=&#123;&#125;, host=&#123;&#125;, jamesServerIp=&#123;&#125;, postmaster=&#123;&#125;, &quot; + &quot;otherClientSwitch=&#123;&#125;, notificationLimitTime=&#123;&#125;, domainNameWhitelist=&#123;&#125;, fromEmailAddressBlacklist=&#123;&#125;, &quot; + &quot;toEmailAddressBlacklist=&#123;&#125;, fromLimitTime=&#123;&#125;, fromRiskControlTime=&#123;&#125;, fromFrequency=&#123;&#125;, dynamicFromWhitelist=&#123;&#125;, &quot; + &quot;toLimitTime=&#123;&#125;, toRiskControlTime=&#123;&#125;, toFrequency=&#123;&#125;, dynamicToWhitelist=&#123;&#125;, rateLimitCapacity=&#123;&#125;, &quot; + &quot;rateLimitRefillTokens=&#123;&#125;, rateLimitInterval=&#123;&#125;&quot;, riskSwitch, riskLogSwitch, refreshInterval, host, jamesServerIp, postmaster, otherClientSwitch, notificationLimitTime, domainNameWhitelist, fromEmailAddressBlacklist, toEmailAddressBlacklist, fromLimitTime, fromRiskControlTime, fromFrequency, dynamicFromWhitelist, toLimitTime, toRiskControlTime, toFrequency, dynamicToWhitelist, rateLimitCapacity, rateLimitRefillTokens, rateLimitInterval); &#125; catch (IOException e) &#123; LOGGER.error(&quot;解析风控配置异常: &#123;&#125;&quot;, e.getMessage()); e.fillInStackTrace(); &#125; &#125; @Override public void destroy() &#123; scheduler.shutdown(); super.destroy(); &#125; @Override public void service(Mail mail) throws MessagingException &#123; try &#123; List&lt;String&gt; from = Arrays.stream(mail.getMessage().getFrom()).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); if (!riskSwitch) &#123; LOGGER.info(&quot;风控开关没开，跳过风控&quot;); &#125; else if (!from.isEmpty() &amp;&amp; (!Strings.isNullOrEmpty(postmaster) &amp;&amp; postmaster.equals(from.get(0)))) &#123; LOGGER.info(&quot;postmaster账户发的邮件，跳过风控&quot;); &#125; else &#123; // 获取收件人地址 List&lt;String&gt; to = Arrays.stream(mail.getMessage().getRecipients(Message.RecipientType.TO)) .map(m -&gt; ((InternetAddress) m).getAddress()) .collect(Collectors.toList()); LOGGER.info(&quot;发件人:&#123;&#125; 进入自定义拦截逻辑&quot;, from); String rejectionReason = getRiskReason(from, to, mail.getRemoteAddr()); if (!Strings.isNullOrEmpty(rejectionReason)) &#123; LOGGER.info(&quot;走完风控流程，被拦截...&quot;); mail.setState(Mail.GHOST); // 阻止进一步处理 sendRejectionNotification(mail, from, rejectionReason); &#125; else &#123; LOGGER.info(&quot;走完风控流程，放行...&quot;); &#125; &#125; &#125; catch (Exception e) &#123; LOGGER.error(e.getMessage()); &#125; &#125; private void riskLog(List&lt;String&gt; from, String type, String content) &#123; if (riskLogSwitch) &#123; if (CacheUtil.get(&quot;notification-&quot; + from.get(0)) != null) &#123; LOGGER.info(&quot;&#123;&#125;时间限制内已经推送过风控日志终止本次推送，避免频繁派发&quot;, from.get(0)); return; &#125; fetchRiskLogAsync(type, content); &#125; else &#123; LOGGER.info(&quot;风控日志推送未开启，跳过发送风控日志&quot;); &#125; &#125; private String getRiskReason(List&lt;String&gt; from, List&lt;String&gt; to, String sendServerIp) &#123; LOGGER.info(&quot;发件服务器ip:&#123;&#125; 进入自定义拦截逻辑&quot;, sendServerIp); if (!checkFormDomain(from)) &#123; riskLog(from, &quot;白名单&quot;, from.get(0) + &quot;不在邮箱域白名单，发件进来被拒&quot;); return &quot;Your mail cannot be delivered due to domain restrictions&quot;; &#125; else if (checkOtherClient(from, sendServerIp)) &#123; riskLog(from, &quot;第三方客户端&quot;, from.get(0) + &quot;使用第三方客户端进行发件被拦截&quot;); LOGGER.info(&quot;风控拦截，使用第三方客户端进行发件&quot;); return &quot;This operation poses a security risk and has been restricted&quot;; &#125; else if (checkFormEmailAddress(from)) &#123; riskLog(from, &quot;发件人黑名单&quot;, from.get(0) + &quot;发件人黑名单用户发件被拦截&quot;); return &quot;Your email address is restricted and cannot be delivered&quot;; &#125; else if (checkToEmailAddress(to)) &#123; riskLog(from, &quot;收件人黑名单&quot;, String.join(&quot;,&quot;, to) + &quot;收件人黑名单用户收件被拦截&quot;); return &quot;The recipient&#x27;s email address is restricted and cannot be delivered：&quot; + String.join(&quot;,&quot;, to); &#125; else if (batchDynamicRiskControl(from, fromLimitTime, fromRiskControlTime, fromFrequency, dynamicFromWhitelist, &quot;发件人&quot;)) &#123; riskLog(from, &quot;发件人限流&quot;, from.get(0) + &quot;发件超额被拦截&quot;); return &quot;The operation is too frequent and has been locked -f&quot;; &#125; else if (batchDynamicRiskControl(to, toLimitTime, toRiskControlTime, toFrequency, dynamicToWhitelist, &quot;收件人&quot;)) &#123; riskLog(from, &quot;收件人限流&quot;, String.join(&quot;,&quot;, to) + &quot;收件超额被拦截&quot;); return &quot;The operation is too frequent and has been locked -t：&quot; + String.join(&quot;,&quot;, to); &#125; else if (batchDynamicRiskControl(from)) &#123; riskLog(from, &quot;邮箱域限流&quot;, getDomainFromEmail(from.get(0)) + &quot;域流量超额被拦截&quot;); return &quot;The request has been locked due to excessive request attempts&quot;; &#125; return &quot;&quot;; &#125; public boolean batchDynamicRiskControl(List&lt;String&gt; targets) &#123; if (targets.isEmpty()) &#123; return false; &#125; boolean isLimited = false; // 标记是否有目标被锁定 //保证每个元素都走完流程 for (String target : targets) &#123; boolean result = applyDomainOrIpRateLimit(getDomainFromEmail(target)); if (result) &#123; isLimited = true; // 只要有一个目标被锁定，最终就返回 true &#125; &#125; return isLimited; // 遍历完整个列表后，返回最终结果 &#125; public boolean avoidLocalhost(String target, String type) &#123; if (&quot;127.0.0.1&quot;.equals(target) || &quot;localhost&quot;.equals(target)) &#123; LOGGER.info(&quot;&#123;&#125;,本机ip，跳过&quot;, type); return false; &#125; if (!Strings.isNullOrEmpty(postmaster) &amp;&amp; postmaster.equals(target)) &#123; LOGGER.info(&quot;&#123;&#125;,postmaster账户，跳过&quot;, type); return false; &#125; return true; &#125; private boolean applyDomainOrIpRateLimit(String target) &#123; if (rateLimitCapacity == null || rateLimitRefillTokens == null || rateLimitInterval == null) &#123; LOGGER.info(&quot;未配置限流参数，跳过限流&quot;); return false; &#125; if (!avoidLocalhost(target, &quot;限流&quot;)) &#123; return false; &#125; RateLimiter rateLimiter = RateLimiter.getInstance(rateLimitCapacity, rateLimitRefillTokens, rateLimitInterval); LOGGER.info(&quot;目标:&#123;&#125; 剩余令牌数量:&#123;&#125;&quot;, target, rateLimiter.getAvailableTokens(target)); // 检查令牌是否足够 if (rateLimiter.tryConsume(target)) &#123; return false; // 未限流 &#125; else &#123; LOGGER.info(&quot;目标:&#123;&#125; 超过限流阈值，触发限制&quot;, target); return true; // 已限流 &#125; &#125; private void sendRejectionNotification(Mail originalMail, List&lt;String&gt; recipients, String content) &#123; try &#123; if (Strings.isNullOrEmpty(postmaster)) &#123; LOGGER.info(&quot;没有配置通知邮箱，跳过发送拒收通知&quot;); return; &#125; Object o = CacheUtil.get(&quot;notification-&quot; + recipients.get(0)); if (o != null) &#123; LOGGER.info(&quot;&#123;&#125;时间限制内已经发过拒收通知,终止本次通知，避免频繁派发&quot;, recipients.get(0)); return; &#125; LOGGER.info(&quot;开始发拒收通知&quot;); MimeMessage notification = new MimeMessage(originalMail.getMessage().getSession()); notification.setFrom(new InternetAddress(postmaster)); notification.setRecipients(Message.RecipientType.TO, InternetAddress.parse(String.join(&quot;,&quot;, recipients))); notification.setSubject(&quot;Mail rejected notification&quot;); // notification.setText(content); notification.setText(content, &quot;UTF-8&quot;, &quot;html&quot;); getMailetContext().sendMail(notification); CacheUtil.put(&quot;notification-&quot; + recipients.get(0), recipients, Long.valueOf(notificationLimitTime)); &#125; catch (Exception e) &#123; LOGGER.error(&quot;发送拒收通知失败&quot;, e); &#125; &#125; public static String getDomainFromEmail(String email) &#123; if (Strings.isNullOrEmpty(email) || !email.contains(&quot;@&quot;)) &#123; return null; &#125; return email.substring(email.lastIndexOf(&#x27;@&#x27;) + 1).toLowerCase(); &#125; public Boolean checkOtherClient(List&lt;String&gt; from, String sendServerIp) &#123; if (!otherClientSwitch) &#123; LOGGER.info(&quot;未开启第三方客户端发件限制，跳过邮箱客户端校验&quot;); return false; &#125; return host.equals(getDomainFromEmail(from.get(0))) &amp;&amp; !jamesServerIp.equals(sendServerIp) &amp;&amp; !&quot;127.0.0.1&quot;.equals(sendServerIp) &amp;&amp; !&quot;localhost&quot;.equals(sendServerIp); &#125; public Boolean checkFormDomain(List&lt;String&gt; from) &#123; if (domainNameWhitelist.isEmpty()) &#123; LOGGER.info(&quot;未配置邮箱域白名单，跳过白名单校验&quot;); return false; &#125; Set&lt;String&gt; lowerCaseWhitelist = domainNameWhitelist.stream() .filter(Objects::nonNull) .map(String::toLowerCase) .collect(Collectors.toSet()); boolean b = from.stream() .filter(Objects::nonNull) .allMatch(email -&gt; &#123; if (!Strings.isNullOrEmpty(postmaster) &amp;&amp; postmaster.equalsIgnoreCase(email)) &#123; return true; // 直接通过，不检查域名 &#125; return lowerCaseWhitelist.contains(getDomainFromEmail(email)); &#125;); if (!b) &#123; LOGGER.info(&quot;发件域:&#123;&#125; 不在白名单，被拒&quot;, from); &#125; return b; &#125; private Boolean checkFormEmailAddress(List&lt;String&gt; from) &#123; if (fromEmailAddressBlacklist.isEmpty()) &#123; LOGGER.info(&quot;未配置发件人黑名单，跳过发件人黑名单校验&quot;); return false; &#125; boolean b = from.stream() .anyMatch(email -&gt; fromEmailAddressBlacklist.contains(email) &amp;&amp; (Strings.isNullOrEmpty(postmaster) || !postmaster.equals(email)) ); if (b) &#123; LOGGER.info(&quot;发件人:&#123;&#125; 邮箱地址被拒绝&quot;, from); &#125; return b; &#125; private Boolean checkToEmailAddress(List&lt;String&gt; to) &#123; if (toEmailAddressBlacklist.isEmpty()) &#123; LOGGER.info(&quot;未配置收件人黑名单，跳过收件人黑名单校验&quot;); return false; &#125; LOGGER.info(&quot;收件人地址:&#123;&#125;&quot;, to); boolean b = to.stream() .anyMatch(email -&gt; toEmailAddressBlacklist.contains(email) &amp;&amp; (Strings.isNullOrEmpty(postmaster) || !postmaster.equals(email)) ); if (b) &#123; LOGGER.info(&quot;收件人:&#123;&#125; 邮箱地址被拒绝&quot;, to); &#125; return b; &#125; public boolean batchDynamicRiskControl(List&lt;String&gt; targets, Long limitTime, Long riskControlTime, Long frequency, List&lt;String&gt; dynamicWhitelist, String type) &#123; if (targets.isEmpty()) &#123; return false; &#125; boolean isLimited = false; // 标记是否有目标被锁定 //保证每个元素都走完流程 for (String target : targets) &#123; boolean result = dynamicRiskControl(target, limitTime, riskControlTime, frequency, dynamicWhitelist, type); if (result) &#123; isLimited = true; // 只要有一个目标被锁定，最终就返回 true &#125; &#125; return isLimited; // 遍历完整个列表后，返回最终结果 &#125; private Boolean dynamicRiskControl(String target, Long limitTime, Long riskControlTime, Long frequency, List&lt;String&gt; dynamicWhitelist, String type) &#123; if (Strings.isNullOrEmpty(target) || null == limitTime || null == riskControlTime || null == frequency) &#123; LOGGER.info(&quot;&#123;&#125;的动态配置不全，跳过&quot;, type); return false; &#125; if (!avoidLocalhost(target, &quot;动态风控&quot;)) &#123; return false; &#125; if (!dynamicWhitelist.isEmpty() &amp;&amp; dynamicWhitelist.stream().anyMatch(target::equals)) &#123; LOGGER.info(&quot;&#123;&#125;-动态配置&#123;&#125;存在白名单中，跳过&quot;, type, target); return false; &#125; long currentTime = System.currentTimeMillis() / 1000; // 检查目标是否已被锁定 Object lockExpireTimeObj = CacheUtil.get(target); if (lockExpireTimeObj != null) &#123; long lockExpireTime = (Long) lockExpireTimeObj; if (currentTime &lt; lockExpireTime) &#123; LOGGER.info(&quot;动态风控，目标:&#123;&#125;，处于锁定状态&quot;, target); return true; // 目标处于锁定状态 &#125; else &#123; LOGGER.info(&quot;动态风控，目标:&#123;&#125;，锁定过期，移除记录&quot;, target); CacheUtil.rem(target); // 锁定过期，移除记录 &#125; &#125; String frequencyKey = target + &quot;:frequency&quot;; List&lt;Long&gt; requestTimes; // 同步块保证同一目标的并发安全 synchronized ((frequencyKey).intern()) &#123; // 获取请求时间记录 requestTimes = (List&lt;Long&gt;) CacheUtil.get(frequencyKey); if (requestTimes == null) &#123; requestTimes = new ArrayList&lt;&gt;(); &#125; LOGGER.info(&quot;动态风控，目标:&#123;&#125;，频次:&#123;&#125;&quot;, target, requestTimes.size()); // 清理超出风控时长的记录 long thresholdTime = currentTime - riskControlTime; requestTimes.removeIf(time -&gt; time &lt; thresholdTime); // 判断是否超过频率限制 if (requestTimes.size() &gt;= frequency) &#123; // 触发锁定，记录锁定时间 long lockTime = currentTime + limitTime; CacheUtil.put(target, lockTime, limitTime); CacheUtil.rem(frequencyKey); // 清除频率记录 LOGGER.info(&quot;动态风控，目标:&#123;&#125;，触发锁定&quot;, target); return true; &#125; // 添加当前请求时间并更新缓存 requestTimes.add(currentTime); CacheUtil.put(frequencyKey, requestTimes, riskControlTime); &#125; return false; &#125;&#125;","tags":["笔记"],"categories":["James"]},{"title":"James添加收件监听","path":"/2025/03/03/2025James Hook2/","content":"前言这个监听器可以获取到uid 替换依赖脚本UpdateDependency.sh 123456789101112131415161718192021222324252627282930313233#!/bin/bash# jar包名字DEP_JAR=&quot;james-server-mailetcontainer-impl-3.8.1.jar&quot;# 日志的绝对路径NOHUP_OUT=&quot;$(pwd)/nohup.out&quot;# 原jar所在的目录（相对路径或绝对路径均可）LIB_PATH=&quot;james-server-distributed-app.lib&quot;# 新jar包的源目录和目标目录SRC_DIR=&quot;/home/kevin&quot;DEST_DIR=&quot;/data/apps/mail/james-server-distributed-app/james-server-distributed-app.lib&quot;# 在项目根目录下执行PID=$(jps -l | grep &quot;james-server-distributed-app.jar&quot; | awk &#x27;&#123;print $1&#125;&#x27;)if [ -n &quot;$PID&quot; ]; then echo &quot;找到进程ID: $PID，正在杀死 james-server-distributed-app.jar 进程...&quot; kill -9 &quot;$PID&quot;else echo &quot;未找到运行中的 james-server-distributed-app.jar 进程。&quot;fi# 删除日志文件rm -rf &quot;$NOHUP_OUT&quot;# 删除原有依赖rm -rf &quot;$LIB_PATH&quot;/&quot;$DEP_JAR&quot;# 将新依赖从源目录移动到目标目录mv &quot;$SRC_DIR&quot;/&quot;$DEP_JAR&quot; &quot;$DEST_DIR&quot;/# 启动服务（后台运行）java -Dworking.directory=. -Dlogback.configurationFile=conf/logback.xml \\ -Djdk.tls.ephemeralDHKeySize=2048 -jar james-server-distributed-app.jar &amp; 脚本放James服务器根目录，赋值权限 1chmod +x UpdateDependency.sh 运行 1./UpdateDependency.sh 添加监听器UIDEventListener,注意类文件路径，不是所有模块都可以添加监听器 当前类文件放在server/mailet/mailetcontainer-impl/src/main/java/org.apache.james.mailetcontainer/impl/matchers目录里面 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package org.apache.james.mailetcontainer.impl.matchers;import org.apache.james.events.Event;import org.apache.james.events.EventListener;import org.apache.james.events.Group;import org.apache.james.mailbox.MessageUid;import org.apache.james.mailbox.events.MailboxEvents;import org.apache.james.mailbox.model.MailboxId;import org.reactivestreams.Publisher;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import reactor.core.publisher.Mono;public class UIDEventListener implements EventListener.ReactiveGroupEventListener &#123; public static class UIDEventListenerGroup extends Group &#123; &#125; private static final Group GROUP = new UIDEventListenerGroup(); private static final String HTTP_ENDPOINT = &quot;http://thirdparty.example.com/api/receive&quot;; public static final Logger LOGGER = LoggerFactory.getLogger(UIDEventListener.class); @Override public Publisher&lt;Void&gt; reactiveEvent(Event event) &#123; if (event instanceof MailboxEvents.Added) &#123; MailboxEvents.Added addedEvent = (MailboxEvents.Added) event; MailboxId mailboxId = addedEvent.getMailboxId(); for (MessageUid uid : addedEvent.getUids()) &#123; String jsonData = String.format(&quot;&#123;\\&quot;mailboxId\\&quot;: \\&quot;%s\\&quot;, \\&quot;uid\\&quot;: \\&quot;%s\\&quot;&#125;&quot;, mailboxId.serialize(), uid.asLong()); sendHttpRequest(jsonData); &#125; &#125; return Mono.empty(); &#125; @Override public ExecutionMode getExecutionMode() &#123; // 这里返回异步模式，若需要同步请改为 ExecutionMode.SYNCHRONOUS（根据实际需求） return ExecutionMode.ASYNCHRONOUS; &#125; @Override public boolean isHandling(Event event) &#123; // 仅处理 MailboxEvents.Added 事件 return event instanceof MailboxEvents.Added; &#125; private void sendHttpRequest(String jsonData) &#123; LOGGER.info(&quot;收件触发: &#123;&#125;&quot;, jsonData); &#125; @Override public Group getDefaultGroup() &#123; return GROUP; &#125;&#125; 修改配置文件服务器conf目录下的listeners.xml文件，新建或者添加 123&lt;listener&gt; &lt;class&gt;org.apache.james.mailetcontainer.impl.matchers.UIDEventListener&lt;/class&gt;&lt;/listener&gt; 完整示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 &lt;?xml version=&quot;1.0&quot;?&gt;&lt;!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. --&gt;&lt;!-- Read https://james.apache.org/server/config-listeners.html for further details --&gt;&lt;listeners&gt; &lt;executeGroupListeners&gt;true&lt;/executeGroupListeners&gt; &lt;listener&gt; &lt;class&gt;org.apache.james.mailbox.cassandra.MailboxOperationLoggingListener&lt;/class&gt; &lt;/listener&gt; &lt;listener&gt; &lt;class&gt;org.apache.james.mailetcontainer.impl.matchers.UIDEventListener&lt;/class&gt; &lt;/listener&gt; &lt;!-- Enable to populate JMAP EmailQueryView --&gt; &lt;!-- &lt;listener&gt; &lt;class&gt;org.apache.james.jmap.event.PopulateEmailQueryViewListener&lt;/class&gt; &lt;async&gt;true&lt;/async&gt; &lt;/listener&gt; --&gt; &lt;listener&gt; &lt;class&gt;org.apache.james.rspamd.RspamdListener&lt;/class&gt; &lt;/listener&gt; &lt;!-- &lt;listener&gt; &lt;class&gt;org.apache.james.spamassassin.SpamAssassinListener&lt;/class&gt; &lt;async&gt;true&lt;/async&gt; &lt;/listener&gt;--&gt;&lt;/listeners&gt; 重启James1./bin/james-server.sh stop 1./bin/james-server.sh start 或者jps找到james的进程再kill -9 杀掉进程 12345678910root@touchs-test:/data/apps/mail# jps1092272 touchs.jar1110035 Jps24307 agent-2.11.11.jar682496 james-server-distributed-app.jar72491 OpenSearch72492 PerformanceAnalyzerApp240781 server-2.11.11.jarroot@touchs-test:/data/apps/mail# kill -9 682496root@touchs-test:/data/apps/mail# 1java -Dworking.directory=. -Dlogback.configurationFile=conf/logback.xml -Djdk.tls.ephemeralDHKeySize=2048 -jar james-server-distributed-app.jar &amp; 或者jar包上传后直接用上面的脚本处理 拓展触发后调用异步调用接口 接收端1234567891011121314151617181920212223import com.touchsmail.common.domain.AjaxResult;import io.swagger.annotations.ApiOperation;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@Slf4j@RestController@RequestMapping(&quot;/api/mail/hook&quot;)public class EmailHookController &#123; /** * 邮箱服务器接收邮件回调 */ @ApiOperation(value = &quot;邮箱服务器接收邮件回调&quot;) @PostMapping(&quot;/receive&quot;) public AjaxResult receiveEmails(@RequestBody String param) &#123; return AjaxResult.success(param); &#125;&#125; 推送端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361package org.apache.james.mailetcontainer.impl.matchers;import java.io.ByteArrayInputStream;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.InputStream;import java.net.URI;import java.net.http.HttpClient;import java.net.http.HttpRequest;import java.net.http.HttpResponse;import java.util.ArrayList;import java.util.Arrays;import java.util.Base64;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.concurrent.CompletableFuture;import java.util.stream.Collectors;import javax.inject.Inject;import javax.mail.Address;import javax.mail.BodyPart;import javax.mail.Message;import javax.mail.MessagingException;import javax.mail.Multipart;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeMessage;import org.apache.commons.lang3.StringUtils;import org.apache.james.events.Event;import org.apache.james.events.EventListener;import org.apache.james.events.Group;import org.apache.james.mailbox.MailboxManager;import org.apache.james.mailbox.MailboxSession;import org.apache.james.mailbox.MessageManager;import org.apache.james.mailbox.MessageUid;import org.apache.james.mailbox.events.MailboxEvents;import org.apache.james.mailbox.exception.MailboxException;import org.apache.james.mailbox.model.FetchGroup;import org.apache.james.mailbox.model.MailboxId;import org.apache.james.mailbox.model.MessageRange;import org.reactivestreams.Publisher;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.fasterxml.jackson.databind.ObjectMapper;import reactor.core.publisher.Flux;import reactor.core.publisher.Mono;import reactor.core.scheduler.Schedulers;public class UIDEventListener implements EventListener.ReactiveGroupEventListener &#123; private final MailboxManager mailboxManager; private static final Logger LOGGER = LoggerFactory.getLogger(UIDEventListener.class); public static volatile Boolean receiptCallback = false; @Inject public UIDEventListener(MailboxManager mailboxManager) &#123; this.mailboxManager = mailboxManager; &#125; @Override public Publisher&lt;Void&gt; reactiveEvent(Event event) &#123; if (!receiptCallback) &#123; LOGGER.info(&quot;收件回调未打开&quot;); return Mono.empty(); &#125; else if (event instanceof MailboxEvents.Added) &#123; MailboxEvents.Added addedEvent = (MailboxEvents.Added) event; MailboxSession session = mailboxManager.createSystemSession(event.getUsername()); return Flux.fromIterable(addedEvent.getUids()) .flatMap(uid -&gt; processMessage(addedEvent.getMailboxId(), uid, session)) .onErrorResume(e -&gt; &#123; LOGGER.error(&quot;Message processing failed&quot;, e); return Mono.empty(); &#125;) .then(); &#125; return Mono.empty(); &#125; // 在消息处理链中传递文件夹名称 private Mono&lt;Void&gt; processMessage(MailboxId mailboxId, MessageUid uid, MailboxSession session) &#123; return Mono.usingWhen( Mono.fromCallable(() -&gt; mailboxManager.getMailbox(mailboxId, session)), messageManager -&gt; &#123; String folderName = extractFolderName(messageManager, mailboxId); return fetchMessageContent(messageManager, uid, session) .flatMap(this::parseMimeMessage) .flatMap(mimeMessage -&gt; sendNotification(mailboxId, uid, mimeMessage, folderName)); &#125;, messageManager -&gt; Mono.empty() ) .doOnError(e -&gt; LOGGER.warn(&quot;Failed to process UID:&#123;&#125; in mailbox:&#123;&#125;&quot;, uid.asLong(), mailboxId.serialize(), e)) .onErrorResume(e -&gt; Mono.empty()); &#125; // 增加文件夹名称参数传递 private Mono&lt;Void&gt; sendNotification(MailboxId mailboxId, MessageUid uid, MimeMessage mimeMessage, String folderName) &#123; try &#123; sendAsyncHttpRequest(mimeMessage, mailboxId, uid, folderName); return Mono.empty(); &#125; catch (Exception e) &#123; return Mono.error(e); &#125; &#125; // 新增文件夹名称提取方法 private String extractFolderName(MessageManager messageManager, MailboxId mailboxId) &#123; try &#123; return messageManager.getMailboxPath().getName(); &#125; catch (Exception e) &#123; LOGGER.warn(&quot;Cannot get folder name for mailboxId:&#123;&#125;&quot;, mailboxId); return &quot;unknown_folder&quot;; &#125; &#125; // 增加JSON特殊字符转义处理‌:ml-citation&#123;ref=&quot;1&quot; data=&quot;citationList&quot;&#125; private String escapeJsonString(String input) &#123; return input.replace(&quot;\\&quot;&quot;, &quot;\\\\\\&quot;&quot;) .replace(&quot;\\\\&quot;, &quot;\\\\\\\\&quot;) .replace(&quot;\\b&quot;, &quot;\\\\b&quot;) .replace(&quot;\\f&quot;, &quot;\\\\f&quot;) .replace(&quot; &quot;, &quot;\\ &quot;) .replace(&quot;\\r&quot;, &quot;\\\\r&quot;) .replace(&quot;\\t&quot;, &quot;\\\\t&quot;); &#125; private Mono&lt;byte[]&gt; fetchMessageContent(MessageManager manager, MessageUid uid, MailboxSession session) &#123; return Mono.from(manager.getMessagesReactive(MessageRange.one(uid), FetchGroup.FULL_CONTENT, session)) .publishOn(Schedulers.boundedElastic()) .handle((messageResult, sink) -&gt; &#123; try (InputStream is = messageResult.getFullContent().getInputStream()) &#123; sink.next(is.readAllBytes()); &#125; catch (MailboxException | IOException e) &#123; sink.error(new RuntimeException(e)); &#125; &#125;); &#125; private Mono&lt;MimeMessage&gt; parseMimeMessage(byte[] content) &#123; return Mono.fromCallable(() -&gt; new MimeMessage(null, new ByteArrayInputStream(content))); &#125; private void sendAsyncHttpRequest(MimeMessage message, MailboxId mailboxId, MessageUid uid, String folderName) throws MessagingException, IOException &#123; HttpClient httpClient = HttpClient.newHttpClient(); Map&lt;String, Object&gt; stringObjectMap = buildRequestBody(message, mailboxId, uid, folderName); ObjectMapper objectMapper = new ObjectMapper(); String requestBody = objectMapper.writeValueAsString(stringObjectMap); HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(&quot;http://127.0.0.1:6001/api/mail/hook/receive&quot;)) .header(&quot;Content-Type&quot;, &quot;application/json&quot;) .POST(HttpRequest.BodyPublishers.ofString(requestBody)) .build(); // 发送异步请求 CompletableFuture&lt;HttpResponse&lt;String&gt;&gt; futureResponse = httpClient.sendAsync(request, HttpResponse.BodyHandlers.ofString()); // 处理异步响应 futureResponse.thenAccept(response -&gt; &#123; int statusCode = response.statusCode(); String responseBody = response.body(); if (statusCode == 200) &#123; LOGGER.info(&quot;收件钩子：推送成功&quot;); &#125; else &#123; LOGGER.error(&quot;收件钩子：邮件推送失败，状态码: &#123;&#125; ,响应内容: &#123;&#125; &quot;, statusCode, responseBody); &#125; &#125;).exceptionally(ex -&gt; &#123; LOGGER.error(&quot;收件钩子：邮件推送时发生异常: &#123;&#125;&quot;, ex.toString()); return null; &#125;); &#125; private Map&lt;String, Object&gt; buildRequestBody(MimeMessage message, MailboxId mailboxId, MessageUid uid, String folderName) throws MessagingException, IOException &#123; Map&lt;String, Object&gt; emailData = new HashMap&lt;&gt;(); // 异步去获取邮件正文 CompletableFuture&lt;Object&gt; futureResult = handleRelatedContentAsync(message); Address[] tos = message.getRecipients(Message.RecipientType.TO); Address[] ccs = message.getRecipients(Message.RecipientType.CC); Address[] bccs = message.getRecipients(Message.RecipientType.BCC); List&lt;String&gt; to = new ArrayList&lt;&gt;(); List&lt;String&gt; cc = new ArrayList&lt;&gt;(); List&lt;String&gt; bcc = new ArrayList&lt;&gt;(); if (tos != null &amp;&amp; tos.length &gt; 0) &#123; to = Arrays.stream(tos).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); &#125; if (ccs != null &amp;&amp; ccs.length &gt; 0) &#123; cc = Arrays.stream(ccs).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); &#125; if (bccs != null &amp;&amp; bccs.length &gt; 0) &#123; bcc = Arrays.stream(bccs).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); &#125; List&lt;String&gt; from = Arrays.stream(message.getFrom()).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); emailData.put(&quot;subject&quot;, message.getSubject()); emailData.put(&quot;from&quot;, from); emailData.put(&quot;to&quot;, to); emailData.put(&quot;cc&quot;, cc); emailData.put(&quot;bcc&quot;, bcc); emailData.put(&quot;mailboxId&quot;, mailboxId.serialize()); emailData.put(&quot;folderName&quot;, escapeJsonString(folderName)); emailData.put(&quot;uid&quot;, uid.asLong()); emailData.put(&quot;messageID&quot;, message.getMessageID()); emailData.put(&quot;date&quot;, message.getReceivedDate()); emailData.put(&quot;content&quot;, futureResult.join()); return emailData; &#125; private CompletableFuture&lt;Object&gt; handleRelatedContentAsync(Message message) &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; if (message.isMimeType(&quot;text/plain&quot;) || message.isMimeType(&quot;text/html&quot;)) &#123; return message.getContent().toString(); &#125; else if (message.isMimeType(&quot;multipart/*&quot;)) &#123; Multipart multipart = (Multipart) message.getContent(); StringBuilder htmlContent = new StringBuilder(); Map&lt;String, String&gt; imageMap = new HashMap&lt;&gt;(); buildMultipartResout(multipart, htmlContent, imageMap); return htmlContent.toString(); &#125; return &quot;unknown content format&quot;; &#125; catch (Exception e) &#123; // 记录错误日志 LOGGER.error(&quot;Error processing related content&quot;, e); return &quot;error&quot;; &#125; &#125;); &#125; private void buildMultipartResout(Multipart multipart, StringBuilder htmlContent, Map&lt;String, String&gt; imageMap) throws Exception &#123; // 遍历所有部分，收集HTML内容和图片 for (int i = 0; i &lt; multipart.getCount(); i++) &#123; BodyPart part = multipart.getBodyPart(i); // 处理 multipart/related 类型 if (part.getContentType().contains(&quot;multipart/related&quot;) || part.getContentType().contains(&quot;multipart/RELATED&quot;)) &#123; buildMultipartResout((Multipart) part.getContent(), htmlContent, imageMap); &#125; else if (part.isMimeType(&quot;multipart/alternative&quot;) || part.getContentType().contains(&quot;multipart/ALTERNATIVE&quot;)) &#123; processMultipartAlternative(part, htmlContent, imageMap); &#125; else if (part.isMimeType(&quot;image/*&quot;)) &#123; processImg(part, imageMap); &#125; else if (part.getContent() instanceof Multipart) &#123; processMultipartAlternative(part, htmlContent, imageMap); &#125; else if (part.isMimeType(&quot;text/html&quot;)) &#123; htmlContent.append(part.getContent().toString()); &#125; else &#123; // 可能是附件 LOGGER.warn(&quot;其他部分 ContentType: &quot; + part.getContentType()); &#125; &#125; String content = getContent(htmlContent, imageMap); htmlContent.setLength(0); htmlContent.append(StringUtils.isEmpty(content) ? &quot;unknown content format&quot; : content); &#125; private void processMultipartAlternative(BodyPart part, StringBuilder htmlContent, Map&lt;String, String&gt; imageMap) throws Exception &#123; if (part.getContent() instanceof Multipart) &#123; Multipart alternative = (Multipart) part.getContent(); for (int i = 0; i &lt; alternative.getCount(); i++) &#123; BodyPart subPart = alternative.getBodyPart(i); if (subPart.isMimeType(&quot;text/html&quot;)) &#123; htmlContent.append(subPart.getContent()).append(&quot;&lt;br/&gt;&quot;); &#125; else if (subPart.isMimeType(&quot;image/*&quot;)) &#123; processImg(subPart, imageMap); &#125; else if (subPart.isMimeType(&quot;multipart/alternative&quot;) || subPart.getContentType().contains(&quot;multipart/ALTERNATIVE&quot;)) &#123; processMultipartAlternative(subPart, htmlContent, imageMap); &#125; else if (subPart.getContentType().contains(&quot;multipart/related&quot;) || subPart.getContentType().contains(&quot;multipart/RELATED&quot;)) &#123; processMultipartAlternative(subPart, htmlContent, imageMap); &#125; else &#123; LOGGER.warn(&quot;[processMultipartAlternative]其他部分 ContentType: &quot; + subPart.getContentType()); &#125; &#125; &#125; else &#123; LOGGER.warn(&quot;multipart/ALTERNATIVE 的内容不是 Multipart 类型&quot;); &#125; &#125; private static String getContent(StringBuilder htmlContent, Map&lt;String, String&gt; imageMap) &#123; String content = htmlContent.toString(); // 如果找到HTML内容和图片，进行替换 if (!imageMap.isEmpty()) &#123; for (Map.Entry&lt;String, String&gt; entry : imageMap.entrySet()) &#123; String contentId = entry.getKey(); String base64Image = entry.getValue(); // 替换HTML中的图片引用 String imgPattern = &quot;cid:&quot; + contentId; String base64Pattern = &quot;data:image/jpeg;base64,&quot; + base64Image; content = content.replace(imgPattern, base64Pattern); &#125; &#125; return content; &#125; private void processImg(BodyPart part, Map&lt;String, String&gt; imageMap) throws MessagingException, IOException &#123; // 获取Content-ID String[] contentIds = part.getHeader(&quot;Content-ID&quot;); if (contentIds != null &amp;&amp; contentIds.length &gt; 0) &#123; String contentId = contentIds[0].replaceAll(&quot;[&lt;&gt;]&quot;, &quot;&quot;); // 转换图片为base64 String base64Image = convertImageToBase64(part); imageMap.put(contentId, base64Image); &#125; &#125; private String convertImageToBase64(BodyPart part) throws MessagingException, IOException &#123; try (InputStream is = part.getInputStream()) &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[4096]; int bytesRead; while ((bytesRead = is.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesRead); &#125; return Base64.getEncoder().encodeToString(baos.toByteArray()); &#125; &#125; @Override public ExecutionMode getExecutionMode() &#123; return ExecutionMode.ASYNCHRONOUS; &#125; @Override public boolean isHandling(Event event) &#123; return event instanceof MailboxEvents.Added; &#125; @Override public Group getDefaultGroup() &#123; return new UIDEventListenerGroup(); &#125; public static class UIDEventListenerGroup extends Group &#123; &#125;&#125; 编译依赖注意顺序，否则编译会报错，不知道顺序可以问一下ai 在该模块的根目录下编译，编译好之后把jar包放到服务器james的依赖目录（james-server-distributed-app.lib）里面，然后重启James 123edy@EDYs-MacBook-Air mailetcontainer-impl % pwd/Users/edy/Documents/ProjectCode/James382/JamesByKre/server/mailet/mailetcontainer-impledy@EDYs-MacBook-Air mailetcontainer-impl % mvn clean install -Dmaven.test.skip=true -e 1mvn clean install -Dmaven.test.skip=true -e","tags":["笔记"],"categories":["James"]},{"title":"googleusercontent.com 未加密这封邮件","path":"/2025/02/26/2025jamesNoSSL/","content":"前言james邮箱发送邮件到谷歌邮箱提示googleusercontent.com 未加密这封邮件 当前已确认465和587端口是开启的，证书用的是certbot python3-certbot-nginx mailetcontainer.xml：mailetcontainer.xml中查找下面配置，有就改成一样，没有就新增 1234567891011121314&lt;processor state=&quot;relay&quot; enableJmx=&quot;true&quot;&gt; &lt;mailet match=&quot;All&quot; class=&quot;RemoteDelivery&quot;&gt; &lt;outgoingQueue&gt;outgoing&lt;/outgoingQueue&gt; &lt;delayTime&gt;5000, 100000, 500000&lt;/delayTime&gt; &lt;maxRetries&gt;3&lt;/maxRetries&gt; &lt;maxDnsProblemRetries&gt;0&lt;/maxDnsProblemRetries&gt; &lt;deliveryThreads&gt;10&lt;/deliveryThreads&gt; &lt;sendpartial&gt;true&lt;/sendpartial&gt; &lt;bounceProcessor&gt;bounces&lt;/bounceProcessor&gt; &lt;useTLS&gt;true&lt;/useTLS&gt; &lt;startTLS&gt;true&lt;/startTLS&gt; &lt;authRequired&gt;false&lt;/authRequired&gt; &lt;/mailet&gt; &lt;/processor&gt;","tags":["笔记"],"categories":["James"]},{"title":"i118n国际化","path":"/2025/02/26/2025022601/","content":"前言无需添加额外依赖，最多为节省代码量使用了lombok插件，在pom.xml引入 1234&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 新增代码在工具包里增加以下类 LocaleConfig12345678910111213141516171819202122232425262728293031323334package com.touchsmail.common.conf;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.support.ResourceBundleMessageSource;import org.springframework.web.servlet.LocaleResolver;import org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolver;import java.util.Locale;@Configurationpublic class LocaleConfig &#123; @Bean public ResourceBundleMessageSource messageSource() &#123;// Locale.setDefault(Locale.CHINA); ResourceBundleMessageSource source = new ResourceBundleMessageSource(); //设置国际化文件存储路径和名称 i18n目录，messages文件名 source.setBasenames(&quot;i18n/messages&quot;); //设置根据key如果没有获取到对应的文本信息,则返回key作为信息 source.setUseCodeAsDefaultMessage(true); //设置字符编码 source.setDefaultEncoding(&quot;UTF-8&quot;); return source; &#125; @Bean public LocaleResolver localeResolver() &#123; AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver(); localeResolver.setDefaultLocale(Locale.CHINA); // 设置默认的Locale,英文Locale.US return localeResolver; &#125;&#125; I18nUtils1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.touchsmail.common.utils;import org.springframework.context.MessageSource;import org.springframework.context.i18n.LocaleContextHolder;import org.springframework.stereotype.Component;import java.util.Locale;@Componentpublic class I18nUtils &#123; /** * 使用懒加载方式实例化messageSource国际化工具 */ private static class Lazy &#123; private static final MessageSource messageSource = SpringUtil2.getBean(MessageSource.class); &#125; private static MessageSource getInstance() &#123; return Lazy.messageSource; &#125; /** * 获取国际化消息 * * @param code 消息键 * @return 国际化消息 */ public static String getMessage(String code) &#123; Locale locale = LocaleContextHolder.getLocale(); return getInstance().getMessage(code, null, locale); &#125; /** * 获取带参数的国际化消息 * * @param code 消息键 * @param args 参数 * @return 国际化消息 */ public static String getMessage(String code, Object... args) &#123; Locale locale = LocaleContextHolder.getLocale(); return getInstance().getMessage(code, args, locale); &#125;&#125; SpringUtil21234567891011121314151617181920212223242526272829package com.touchsmail.common.utils;import lombok.AccessLevel;import lombok.NoArgsConstructor;import lombok.NonNull;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.stereotype.Component;@Component@NoArgsConstructor(access = AccessLevel.PRIVATE)public class SpringUtil2 implements ApplicationContextAware &#123; private static ApplicationContext applicationContext = null; @Override public void setApplicationContext(@NonNull ApplicationContext applicationContext) throws BeansException &#123; if (SpringUtil2.applicationContext == null) &#123; SpringUtil2.applicationContext = applicationContext; &#125; &#125; /** * 通过class获取Bean. */ public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz) &#123; return applicationContext.getBean(clazz); &#125;&#125; 语言包在resources目录下新建i118n目录，右键i118n目录-&gt;新建-&gt;资源包(Resource Bundle)添加国际化文件右边加号添加2个，en_US存放英语，zh_CH存放中文 另外记得把idea的文件编码格式改成utf8,要不然中文可能会乱码，idea-设置-编辑-文件编码，属性文件默认编码，全局编码，项目编码都设置为UTF-8 12345resources -i118n -messages.properties -messages_en_US.properties -messages_zh_CN.properties messages_zh_CN.properties 12345return.ok=操作成功!return.failed=操作失败!return.loginOk=登录成功!return.pwd_error=密码错误!return.account_lock=账号已被锁定&#123;0&#125;分钟,请稍后重试! messages_en_US.properties 12345return.ok=Success!return.failed=Fail!return.loginOk=Login succeeded!return.pwd_error=PW error!return.account_lock=The account has been locked for &#123;0&#125; minutes. Please try again later! 调用1I18nUtils.getMessage() 前端传值123456789curl --location --request POST &#x27;http://localhost:6001/manager/user/login&#x27; \\--header &#x27;Authorization: Bearer plZw9T2kbOgTJIBqnZielUUUwkhBm0zSg9AIJ4JH8VBFleCKaD0hvNIUwZ9iYjsJTrI882MvvvP9Qbn5Ea6bgpLKbaEKefCcnQcnxFdDCMa4jCq7kBjunJ48SDW7HVED&#x27; \\--header &#x27;User-Agent: Apifox/1.0.0 (https://apifox.com)&#x27; \\--header &#x27;Content-Type: application/json&#x27; \\--header &#x27;Accept: */*&#x27; \\--header &#x27;Accept-Language: zh-CN&#x27; \\--header &#x27;Host: localhost:6001&#x27; \\--header &#x27;Connection: keep-alive&#x27; \\--data-raw &#x27;&#123;&#125;&#x27; 1// 即header 中添加 &#x27;Accept-Language: zh-CN&#x27;","tags":["笔记"],"categories":["Java"]},{"title":"James添加收件钩子","path":"/2025/02/25/2025James Hook/","content":"前言这个钩子是存储前的钩子，只能拿到MessageID拿不到uid信息 添加监听器ReceiveEmailMailet,注意类文件路径，不是所有模块都可以添加监听器 当前类文件放在server/mailet/mailetcontainer-impl/src/main/java/org.apache.james.mailetcontainer/impl/matchers目录里面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/**************************************************************** * Licensed to the Apache Software Foundation (ASF) under one * * or more contributor license agreements. See the NOTICE file * * distributed with this work for additional information * * regarding copyright ownership. The ASF licenses this file * * to you under the Apache License, Version 2.0 (the * * &quot;License&quot;); you may not use this file except in compliance * * with the License. You may obtain a copy of the License at * * * * http://www.apache.org/licenses/LICENSE-2.0 * * * * Unless required by applicable law or agreed to in writing, * * software distributed under the License is distributed on an * * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * * KIND, either express or implied. See the License for the * * specific language governing permissions and limitations * * under the License. * ****************************************************************/package org.apache.james.mailetcontainer.impl.matchers;import java.io.IOException;import javax.mail.MessagingException;import org.apache.mailet.Mail;import org.apache.mailet.base.GenericMailet;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class ReceiveEmailMailet extends GenericMailet &#123; public static final Logger LOGGER = LoggerFactory.getLogger(ReceiveEmailMailet.class); @Override public void service(Mail mail) throws MessagingException &#123; LOGGER.info(&quot;收到邮件了&#123;&#125;&quot;,mail.getName()); LOGGER.info(&quot;收到邮件了,Subject: &#123;&#125;&quot;, mail.getMessage().getSubject()); LOGGER.info(&quot;收到邮件了,MessageID: &#123;&#125;&quot;, mail.getMessage().getMessageID()); try &#123; LOGGER.info(&quot;收到邮件了,Content: &#123;&#125;&quot;, mail.getMessage().getContent()); &#125; catch (IOException e) &#123; LOGGER.error(e.toString()); &#125; &#125;&#125; 修改配置文件服务器conf目录下的mailetcontainer.xml文件 1在&lt;processor state=&quot;transport&quot; enableJmx=&quot;true&quot;&gt;标签中添加下面的代码 收发件都触发1&lt;mailet match=&quot;All&quot; class=&quot;org.apache.james.mailetcontainer.impl.matchers.ReceiveEmailMailet&quot; /&gt; 只在收件触发1&lt;mailet match=&quot;RecipientIsLocal&quot; class=&quot;org.apache.james.mailetcontainer.impl.matchers.ReceiveEmailMailet&quot; /&gt; 重启James1./bin/james-server.sh stop 1./bin/james-server.sh start 或者jps找到james的进程再kill -9 杀掉进程 12345678910root@touchs-test:/data/apps/mail# jps1092272 touchs.jar1110035 Jps24307 agent-2.11.11.jar682496 james-server-distributed-app.jar72491 OpenSearch72492 PerformanceAnalyzerApp240781 server-2.11.11.jarroot@touchs-test:/data/apps/mail# kill -9 682496root@touchs-test:/data/apps/mail# 1java -Dworking.directory=. -Dlogback.configurationFile=conf/logback.xml -Djdk.tls.ephemeralDHKeySize=2048 -jar james-server-distributed-app.jar &amp; 拓展触发后调用异步调用接口 接收端1234567891011121314151617181920212223import com.touchsmail.common.domain.AjaxResult;import io.swagger.annotations.ApiOperation;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@Slf4j@RestController@RequestMapping(&quot;/api/mail/hook&quot;)public class EmailHookController &#123; /** * 邮箱服务器接收邮件回调 */ @ApiOperation(value = &quot;邮箱服务器接收邮件回调&quot;) @PostMapping(&quot;/receive&quot;) public AjaxResult receiveEmails(@RequestBody String param) &#123; return AjaxResult.success(param); &#125;&#125; 推送端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230/**************************************************************** * Licensed to the Apache Software Foundation (ASF) under one * * or more contributor license agreements. See the NOTICE file * * distributed with this work for additional information * * regarding copyright ownership. The ASF licenses this file * * to you under the Apache License, Version 2.0 (the * * &quot;License&quot;); you may not use this file except in compliance * * with the License. You may obtain a copy of the License at * * * * http://www.apache.org/licenses/LICENSE-2.0 * * * * Unless required by applicable law or agreed to in writing, * * software distributed under the License is distributed on an * * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * * KIND, either express or implied. See the License for the * * specific language governing permissions and limitations * * under the License. * ****************************************************************/package org.apache.james.mailetcontainer.impl.matchers;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.InputStream;import java.net.URI;import java.net.http.HttpClient;import java.net.http.HttpRequest;import java.net.http.HttpResponse;import java.util.Arrays;import java.util.Base64;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.concurrent.CompletableFuture;import java.util.stream.Collectors;import javax.mail.BodyPart;import javax.mail.Message;import javax.mail.MessagingException;import javax.mail.Multipart;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeMessage;import org.apache.commons.lang3.StringUtils;import org.apache.mailet.Mail;import org.apache.mailet.base.GenericMailet;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.fasterxml.jackson.databind.ObjectMapper;public class ReceiveEmailMailet extends GenericMailet &#123; public static final Logger LOGGER = LoggerFactory.getLogger(ReceiveEmailMailet.class); @Override public void service(Mail mail) throws MessagingException &#123; LOGGER.info(&quot;收件钩子：Subject: &#123;&#125;&quot;, mail.getMessage().getSubject()); LOGGER.info(&quot;收件钩子：MessageID: &#123;&#125;&quot;, mail.getMessage().getMessageID()); try &#123; sendAsyncHttpRequest(mail); &#125; catch (IOException e) &#123; LOGGER.error(e.toString()); &#125; &#125; private void sendAsyncHttpRequest(Mail mail) throws MessagingException, IOException &#123; HttpClient httpClient = HttpClient.newHttpClient(); Map&lt;String, Object&gt; stringObjectMap = buildRequestBody(mail); ObjectMapper objectMapper = new ObjectMapper(); String requestBody = objectMapper.writeValueAsString(stringObjectMap); HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(&quot;http://127.0.0.1:6001/api/mail/hook/receive&quot;)) .header(&quot;Content-Type&quot;, &quot;application/json&quot;) .POST(HttpRequest.BodyPublishers.ofString(requestBody)) .build(); // 发送异步请求 CompletableFuture&lt;HttpResponse&lt;String&gt;&gt; futureResponse = httpClient.sendAsync(request, HttpResponse.BodyHandlers.ofString()); // 处理异步响应 futureResponse.thenAccept(response -&gt; &#123; int statusCode = response.statusCode(); String responseBody = response.body(); if (statusCode == 200) &#123; LOGGER.info(&quot;收件钩子：推送成功&quot;); &#125; else &#123; LOGGER.error(&quot;收件钩子：邮件推送失败，状态码: &#123;&#125; ,响应内容: &#123;&#125; &quot;, statusCode, responseBody); &#125; &#125;).exceptionally(ex -&gt; &#123; LOGGER.error(&quot;收件钩子：邮件推送时发生异常: &#123;&#125;&quot;, ex.toString()); return null; &#125;); &#125; private Map&lt;String, Object&gt; buildRequestBody(Mail mail) throws MessagingException, IOException &#123; Map&lt;String, Object&gt; emailData = new HashMap&lt;&gt;(); MimeMessage message = mail.getMessage(); // 异步去获取邮件正文 CompletableFuture&lt;Object&gt; futureResult = handleRelatedContentAsync(message); List&lt;String&gt; to = Arrays.stream(message.getRecipients(Message.RecipientType.TO)).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); List&lt;String&gt; from = Arrays.stream(message.getFrom()).map(m -&gt; ((InternetAddress) m).getAddress()).collect(Collectors.toList()); emailData.put(&quot;subject&quot;, message.getSubject()); emailData.put(&quot;from&quot;, from); emailData.put(&quot;to&quot;, to); emailData.put(&quot;messageID&quot;, mail.getMessage().getMessageID()); emailData.put(&quot;date&quot;, message.getReceivedDate()); emailData.put(&quot;content&quot;, futureResult.join()); return emailData; &#125; private CompletableFuture&lt;Object&gt; handleRelatedContentAsync(Message message) &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; if (message.isMimeType(&quot;text/plain&quot;) || message.isMimeType(&quot;text/html&quot;)) &#123; return message.getContent().toString(); &#125; else if (message.isMimeType(&quot;multipart/*&quot;)) &#123; Multipart multipart = (Multipart) message.getContent(); StringBuilder htmlContent = new StringBuilder(); Map&lt;String, String&gt; imageMap = new HashMap&lt;&gt;(); buildMultipartResout(multipart, htmlContent, imageMap); return htmlContent.toString(); &#125; return &quot;unknown content format&quot;; &#125; catch (Exception e) &#123; // 记录错误日志 LOGGER.error(&quot;Error processing related content&quot;, e); return &quot;error&quot;; &#125; &#125;); &#125; private void buildMultipartResout(Multipart multipart, StringBuilder htmlContent, Map&lt;String, String&gt; imageMap) throws Exception &#123; // 遍历所有部分，收集HTML内容和图片 for (int i = 0; i &lt; multipart.getCount(); i++) &#123; BodyPart part = multipart.getBodyPart(i); // 处理 multipart/related 类型 if (part.getContentType().contains(&quot;multipart/related&quot;) || part.getContentType().contains(&quot;multipart/RELATED&quot;)) &#123; buildMultipartResout((Multipart) part.getContent(), htmlContent, imageMap); &#125; else if (part.isMimeType(&quot;multipart/alternative&quot;) || part.getContentType().contains(&quot;multipart/ALTERNATIVE&quot;)) &#123; processMultipartAlternative(part, htmlContent, imageMap); &#125; else if (part.isMimeType(&quot;image/*&quot;)) &#123; processImg(part, imageMap); &#125; else if (part.getContent() instanceof Multipart) &#123; processMultipartAlternative(part, htmlContent, imageMap); &#125; else if (part.isMimeType(&quot;text/html&quot;)) &#123; htmlContent.append(part.getContent().toString()); &#125; else &#123; // 可能是附件 LOGGER.warn(&quot;其他部分 ContentType: &quot; + part.getContentType()); &#125; &#125; String content = getContent(htmlContent, imageMap); htmlContent.setLength(0); htmlContent.append(StringUtils.isEmpty(content) ? &quot;unknown content format&quot; : content); &#125; private void processMultipartAlternative(BodyPart part, StringBuilder htmlContent, Map&lt;String, String&gt; imageMap) throws Exception &#123; if (part.getContent() instanceof Multipart) &#123; Multipart alternative = (Multipart) part.getContent(); for (int i = 0; i &lt; alternative.getCount(); i++) &#123; BodyPart subPart = alternative.getBodyPart(i); if (subPart.isMimeType(&quot;text/html&quot;)) &#123; htmlContent.append(subPart.getContent()).append(&quot;&lt;br/&gt;&quot;); &#125; else if (subPart.isMimeType(&quot;image/*&quot;)) &#123; processImg(subPart, imageMap); &#125; else if (subPart.isMimeType(&quot;multipart/alternative&quot;) || subPart.getContentType().contains(&quot;multipart/ALTERNATIVE&quot;)) &#123; processMultipartAlternative(subPart, htmlContent, imageMap); &#125; else if (subPart.getContentType().contains(&quot;multipart/related&quot;) || subPart.getContentType().contains(&quot;multipart/RELATED&quot;)) &#123; processMultipartAlternative(subPart, htmlContent, imageMap); &#125; else &#123; LOGGER.warn(&quot;[processMultipartAlternative]其他部分 ContentType: &quot; + subPart.getContentType()); &#125; &#125; &#125; else &#123; LOGGER.warn(&quot;multipart/ALTERNATIVE 的内容不是 Multipart 类型&quot;); &#125; &#125; private static String getContent(StringBuilder htmlContent, Map&lt;String, String&gt; imageMap) &#123; String content = htmlContent.toString(); // 如果找到HTML内容和图片，进行替换 if (!imageMap.isEmpty()) &#123; for (Map.Entry&lt;String, String&gt; entry : imageMap.entrySet()) &#123; String contentId = entry.getKey(); String base64Image = entry.getValue(); // 替换HTML中的图片引用 String imgPattern = &quot;cid:&quot; + contentId; String base64Pattern = &quot;data:image/jpeg;base64,&quot; + base64Image; content = content.replace(imgPattern, base64Pattern); &#125; &#125; return content; &#125; private void processImg(BodyPart part, Map&lt;String, String&gt; imageMap) throws MessagingException, IOException &#123; // 获取Content-ID String[] contentIds = part.getHeader(&quot;Content-ID&quot;); if (contentIds != null &amp;&amp; contentIds.length &gt; 0) &#123; String contentId = contentIds[0].replaceAll(&quot;[&lt;&gt;]&quot;, &quot;&quot;); // 转换图片为base64 String base64Image = convertImageToBase64(part); imageMap.put(contentId, base64Image); &#125; &#125; private String convertImageToBase64(BodyPart part) throws MessagingException, IOException &#123; try (InputStream is = part.getInputStream()) &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[4096]; int bytesRead; while ((bytesRead = is.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesRead); &#125; return Base64.getEncoder().encodeToString(baos.toByteArray()); &#125; &#125;&#125; 编译依赖注意顺序，否则编译会报错，不知道顺序可以问一下ai 在该模块的根目录下编译，编译好之后把jar包放到服务器james的依赖目录（james-server-distributed-app.lib）里面，然后重启James 123edy@EDYs-MacBook-Air mailetcontainer-impl % pwd/Users/edy/Documents/ProjectCode/James382/JamesByKre/server/mailet/mailetcontainer-impledy@EDYs-MacBook-Air mailetcontainer-impl % mvn clean install -Dmaven.test.skip=true -e 1mvn clean install -Dmaven.test.skip=true -e","tags":["笔记"],"categories":["James"]},{"title":"谷歌云防火墙开关端口和锁定ip","path":"/2025/02/11/20250211/","content":"防火墙开关端口在上方的搜索栏中搜索vpc，选择vpc networks 并进入 在左侧的导航中，点击防火墙策略 页面出来后再点击右上角的 创建防火墙规则 名称随便写，符合要求就行 网络，需要查看服务器中用的哪个网络 目标标记则是服务器的标记 填充设置 多端口用英文逗号隔开，设置好点创建即可 锁定ip谷歌云服务器，重启后ip会变，需要手动锁定ip","tags":["随笔"],"categories":["其他"]},{"title":"james分布式版本部署一","path":"/2025/02/10/2025james01/","content":"前言服务器系统：Ubuntu 20.04.6 LTS 总项目地址官方文档3.8.2项目地址james3.8.2下载地址 当前安装james3.8.2版本 基础环境James 3.8.2需要 Java 运行时环境，Java 版本 11。 123sudo apt updatesudo apt install openjdk-11-jdksudo apt install maven 在运行 James 之前，应将环境变量 JAVA_HOME 设置为 JRE 主目录,如果不确定可以先查看一下。 设置JAVA_HOME1echo $JAVA_HOME 我这里执行上面的命令并无结果输出，也就是没有设置这个环境变量。 1234root@mail-test:/# java -versionopenjdk version &quot;11.0.26&quot; 2025-01-21OpenJDK Runtime Environment (build 11.0.26+4-post-Ubuntu-1ubuntu120.04)OpenJDK 64-Bit Server VM (build 11.0.26+4-post-Ubuntu-1ubuntu120.04, mixed mode, sharing) 123456root@mail-test:/# mvn -vApache Maven 3.6.3Maven home: /usr/share/mavenJava version: 11.0.26, vendor: Ubuntu, runtime: /usr/lib/jvm/java-11-openjdk-amd64Default locale: en, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;5.15.0-1075-gcp&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot; 可以看出这台测试服务器之前安装过java 11.0.26,maven 3.6.3，所以需要先找出之前的安装路径。 1sudo update-alternatives --config java 123root@mail-test:/# update-alternatives --config javaThere is only one alternative in link group java (providing /usr/bin/java): /usr/lib/jvm/java-11-openjdk-amd64/bin/javaNothing to configure. 打开 /etc/environment 文件进行编辑 1sudo nano /etc/environment mac系统，编辑完成后按control+x键退出编辑，按y键保存,如果没有退出，再敲一下回车键 或者 1vim /etc/environment 在文件末尾添加以下行，注意不要把路径直接指向bin目录 1JAVA_HOME=&quot;/usr/lib/jvm/java-11-openjdk-amd64&quot; 保存并退出编辑器 1234root@mail-test:/usr/lib/jvm/java-11-openjdk-amd64/bin# nano /etc/environmentroot@mail-test:/usr/lib/jvm/java-11-openjdk-amd64/bin# cat /etc/environmentPATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin&quot;JAVA_HOME=&quot;/usr/lib/jvm/java-11-openjdk-amd64&quot; 使更改生效 1source /etc/environment 通过以下命令来验证 JAVA_HOME 是否设置正确 123root@mail-test:/usr/lib/jvm/java-11-openjdk-amd64/bin# echo $JAVA_HOME/usr/lib/jvm/java-11-openjdk-amd64root@mail-test:/usr/lib/jvm/java-11-openjdk-amd64/bin# 为了确保系统能够找到 Java 可执行文件，还需要将 JAVA_HOME/bin 添加到 PATH 环境变量中 打开 ~/.bashrc 或 ~/.bash_profile 文件进行编辑 1nano ~/.bashrc 在文件末尾添加以下行 1export PATH=$JAVA_HOME/bin:$PATH 使更改生效 1source ~/.bashrc 安装Libc6先验证是否安装了 1234root@mail-test:/# dpkg -l | grep libc6ii libc6:amd64 2.31-0ubuntu9.17 amd64 GNU C Library: Shared librariesii libc6-dev:amd64 2.31-0ubuntu9.17 amd64 GNU C Library: Development Libraries and Header Filesroot@mail-test:/# 这台服务器已经安装了，所以跳过，如果没有安装需要先安装一下，例如 1sudo apt-get install libc6-i386 libc6-dev-i386 更新系统和安装必要的软件包123sudo apt updatesudo apt upgrade -ysudo apt install -y apt-transport-https ca-certificates curl software-properties-common 安装中间件-Docker（方式一）安装Docker添加 Docker 的官方 GPG 密钥，使用 GPG 密钥来验证软件包的完整性 1curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg 添加 Docker 的 APT 软件源 将 Docker 的官方仓库添加到 APT 源列表 1echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null 更新软件包索引并安装 Docker 从 Docker 的官方仓库安装 Docker 引擎 12sudo apt updatesudo apt install -y docker-ce docker-ce-cli containerd.io 验证 Docker 是否安装成功 运行以下命令，检查 Docker 是否正常工作 1234# 显示 Docker 的版本sudo docker --version# 运行一个测试容器，验证 Docker 是否正常工作sudo docker run hello-world (可选)允许非root用户运行默认情况下，Docker 需要 root 权限。如果希望普通用户也能使用 Docker，可以将用户添加到 docker 用户组 将当前用户添加到 docker 组 1sudo usermod -aG docker $USER 重新登录或运行以下命令使更改生效 1newgrp docker 验证是否无需 sudo 即可运行 Docker 1docker run hello-world 设置 Docker 开机自启12sudo systemctl enable dockersudo systemctl start docker （可选）安装DockerComposeDocker Compose 是用于定义和运行多容器 Docker 应用的工具。 下载 Docker Compose 二进制文件 1sudo curl -L &quot;https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 设置权限 1sudo chmod +x /usr/local/bin/docker-compose 验证安装 1docker-compose --version 安装中间件在 Docker 上为 James 环境创建自己的用户网络 123root@mail-test:/home/james# docker network create --driver bridge jamesf876feff33f65ba730ac5e5adfb77489bb293ff7f1d208102007a8af4fc51d84root@mail-test:/home/james# 安装cassandra:3.11.101docker run -d --network james -p 9042:9042 --name=cassandra cassandra:3.11.10 安装opensearch:2.1.01docker run -d --network james -p 9200:9200 --name=opensearch --env &#x27;discovery.type=single-node&#x27; opensearchproject/opensearch:2.1.0 安装rabbitmq:3.9.181docker run -d --network james -p 5672:5672 -p 15672:15672 --name=rabbitmq rabbitmq:3.9.18-management 安装延时插件-项目有用到下载插件 1wget https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/download/3.9.0/rabbitmq_delayed_message_exchange-3.9.0.ez 拷贝插件到docker容器中，其中a0f2970be979为容器id 1docker cp rabbitmq_delayed_message_exchange-3.9.0.ez a0f2970be979:/plugins/ 进入docker容器 1docker exec -it a0f2970be979 /bin/bash 启用插件 1rabbitmq-plugins enable rabbitmq_delayed_message_exchange 安装zenko/cloudserver:8.2.61docker run -d --network james --env &#x27;REMOTE_MANAGEMENT_DISABLE=1&#x27; --env &#x27;SCALITY_ACCESS_KEY_ID=accessKey1&#x27; --env &#x27;SCALITY_SECRET_ACCESS_KEY=secretKey1&#x27; --name=s3 zenko/cloudserver:8.2.6 安装TIka1docker run -d --name tika -p 9998:9998 apache/tika 在 James 所在的服务器上，使用 curl 测试是否可以访问 Tika 服务 1curl http://&lt;docker-host-ip&gt;:9998/tika 123root@mail-test:/home/james# curl http://127.0.0.1:9998/tikaThis is Tika Server (Apache Tika 3.1.0). Please PUTroot@mail-test:/home/james# 安装中间件-手动（方式二）安装opensearch:2.1.0下载1wget https://artifacts.opensearch.org/releases/bundle/opensearch/2.1.0/opensearch-2.1.0-linux-x64.tar.gz 解压1root@mail-test:/data/runTime/opensearch# tar -xzf opensearch-2.1.0-linux-x64.tar.gz 配置1cd opensearch-2.1.0 编辑 config/opensearch.yml my-opensearch-cluster123456789101112#下面3个是集群配置，按默认的或者按这个配置node.name: my-node-1discovery.seed_hosts: [&quot;127.0.0.1&quot;]cluster.initial_master_nodes: [&quot;my-node-1&quot;]#放开修改配置信息如下：network.host: 0.0.0.0#放开/新增，去掉注释，注意格式，空格discovery.type: single-node#新增plugins.security.disabled: trueplugins.security.ssl.http.enabled: false 开机自启（方式一）1sudo nano /etc/systemd/system/opensearch.service 添加以下内容 123456789101112131415161718192021222324[Unit]Description=OpenSearchAfter=network.target[Service]User=nobodyGroup=nogroup# OpenSearch 启动命令ExecStart=/data/runTime/opensearch/opensearch-2.1.0/bin/opensearch# 重启策略Restart=always# 环境变量（如果需要）Environment=OPENSEARCH_HOME=/data/runTime/opensearch/opensearch-2.1.0Environment=OPENSEARCH_PATH_CONF=/data/runTime/opensearch/opensearch-2.1.0/config# 限制资源使用（可选）LimitNOFILE=65535LimitNPROC=4096[Install]WantedBy=multi-user.target 如果不想指定特定的用户和组，但仍然希望以非 root 用户运行 OpenSearch，可以采取以下方法： 方法 1：使用系统默认用户 大多数 Linux 系统都有一个默认的普通用户（例如 nobody 或 daemon），可以直接使用这些用户 方法 2：不指定用户（不推荐） 如果坚持不指定用户，可以直接删除 User 和 Group 配置 123[Service]ExecStart=/data/runTime/opensearch/opensearch-2.1.0/bin/opensearchRestart=always 保存并退出，然后启用并启动服务 123sudo systemctl daemon-reloadsudo systemctl enable opensearchsudo systemctl start opensearch 这一步执行失败了 12root@mail-test:/data/runTime/opensearch/opensearch-2.1.0# sudo systemctl start opensearchFailed to start opensearch.service: Unit opensearch.service has a bad unit file setting. 先确定路径是否有问题 12root@mail-test:/data/runTime/opensearch/opensearch-2.1.0# ls -l /data/runTime/opensearch/opensearch-2.1.0/bin/opensearch-rwxr-xr-x 1 ubuntu ubuntu 3030 Jan 1 1970 /data/runTime/opensearch/opensearch-2.1.0/bin/opensearch 确保用户和组权限 1sudo chown -R nobody:nogroup /data/runTime/opensearch/opensearch-2.1.0 再次尝试启动服务 1sudo systemctl start opensearch 如果启动失败，查看详细日志 1sudo journalctl -u opensearch.service -f 12345root@mail-test:/data/runTime/opensearch/opensearch-2.1.0# sudo journalctl -u opensearch.service -f-- Logs begin at Wed 2025-02-12 02:15:58 UTC. --Feb 12 03:53:26 mail-test systemd[1]: opensearch.service: Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services. Refusing.Feb 12 03:59:14 mail-test systemd[1]: opensearch.service: Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services. Refusing.Feb 12 03:59:18 mail-test systemd[1]: opensearch.service: Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services. Refusing. 存在多个 ExecStart= 配置项，而 systemd 不允许在非 Type=oneshot 的服务中定义多个 ExecStart,返回前面步骤把配置文件中多多已经删掉了 在修改服务文件后，需要重新加载 systemd 配置 1sudo systemctl daemon-reload 再次启动后启动成功 直接启动（方式二）opensearch根目录执行 1./bin/opensearch -d 验证安装1curl -X GET &quot;localhost:9200&quot; 成功示例 12345678910111213141516171819root@mail-test:/data/runTime/opensearch/opensearch-2.1.0# curl -X GET &quot;localhost:9200&quot;&#123; &quot;name&quot; : &quot;mail-test&quot;, &quot;cluster_name&quot; : &quot;opensearch&quot;, &quot;cluster_uuid&quot; : &quot;t3Ux-LhvTLWb75geNvP0Ig&quot;, &quot;version&quot; : &#123; &quot;distribution&quot; : &quot;opensearch&quot;, &quot;number&quot; : &quot;2.1.0&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;388c80ad94529b1d9aad0a735c4740dce2932a32&quot;, &quot;build_date&quot; : &quot;2022-06-30T21:31:04.823801692Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;9.2.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;7.10.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;7.0.0&quot; &#125;, &quot;tagline&quot; : &quot;The OpenSearch Project: https://opensearch.org/&quot;&#125;root@mail-test:/data/runTime/opensearch/opensearch-2.1.0# OpenSearchDashboards（可选）OpenSearch Dashboards 是 OpenSearch 的可视化工具 12345678910root@mail-test:/data/runTime/opensearch/opensearch-2.1.0# cd ../../root@mail-test:/data/runTime# mkdir opensearch-dashboards-210root@mail-test:/data/runTime# cd opensearch-dashboards-210/root@mail-test:/data/runTime/opensearch-dashboards-210#wget https://artifacts.opensearch.org/releases/bundle/opensearch-dashboards/2.1.0/opensearch-dashboards-2.1.0-linux-x64.tar.gztar -xzf opensearch-dashboards-2.1.0-linux-x64.tar.gzcd opensearch-dashboards-2.1.0#开机自启的话不执行下面这条手动启动./bin/opensearch-dashboards 编辑 config/opensearch_dashboards.yml 12345678server.uuid: &quot;4caaa2ac-c82f-4b5e-9831-6a30c96e4b10&quot;server.host: &quot;0.0.0.0&quot; # 监听所有 IPserver.port: 5601 # 默认端口opensearch.hosts: [&quot;http://localhost:9200&quot;] # OpenSearch 集群地址opensearch.ssl.verificationMode: none # 如果使用自签名证书，禁用 SSL 验证#关闭登陆功能，需要opensearch.yml中配置了plugins.security.disabled: trueopensearch_security.enabled: false 在 OpenSearch Dashboards 2.0.1 版本中，server.uuid 必须是真正符合 RFC 4122 UUID 标准的字符串，而不能是任意字符串 这里千万注意 opensearch.hosts: [“http://localhost:9200&quot;] # OpenSearch 集群地址默认是https，如果没配证书，这里记得用http 开放权限 12sudo chown -R nobody:nogroup /data/runTime/opensearch-dashboards-210/opensearch-dashboards-2.1.0/datasudo chmod -R 755 /data/runTime/opensearch-dashboards-210/opensearch-dashboards-2.1.0/data OpenSearchDashboards自启（可选）在 /etc/systemd/system/ 目录下创建一个新的服务文件，例如 opensearch-dashboards.service 1sudo nano /etc/systemd/system/opensearch-dashboards.service 编写服务文件内容 12345678910111213141516171819202122232425[Unit]Description=OpenSearch DashboardsAfter=network.target[Service]# 运行 OpenSearch Dashboards 的用户和组（可选）User=nobodyGroup=nogroup# OpenSearch Dashboards 启动命令ExecStart=/data/runTime/opensearch-dashboards-210/opensearch-dashboards-2.1.0/bin/opensearch-dashboards# 重启策略Restart=always# 环境变量（可选）Environment=OPENSEARCH_DASHBOARDS_HOME=/data/runTime/opensearch-dashboards-210/opensearch-dashboards-2.1.0Environment=OPENSEARCH_DASHBOARDS_PATH_CONF=/data/runTime/opensearch-dashboards-210/opensearch-dashboards-2.1.0/config# 资源限制（可选）LimitNOFILE=65535LimitNPROC=4096[Install]WantedBy=multi-user.target 确保服务文件的权限正确 1sudo chmod 644 /etc/systemd/system/opensearch-dashboards.service 重新加载 systemd 配置 1sudo systemctl daemon-reload 启用开机自启 1sudo systemctl enable opensearch-dashboards 列出所有开机自启项目，按下箭头可以往下加载 1systemctl list-unit-files --type=service --state=enabled 启动 OpenSearch Dashboards 服务 12sudo systemctl start opensearch-dashboardssudo systemctl status opensearch-dashboards 验证 1http://&lt;服务器IP&gt;:5601 或者 1curl -X GET &quot;localhost:5601&quot; 如果页面正常加载，说明 OpenSearch Dashboards 已成功启动,如果不能访问看看端口是否打开 如果防火墙端口已开，但是还是无法访问 确保端口 5601 没有被其他进程占用 1sudo lsof -i :5601 检查 OpenSearch 集群状态 1curl -X GET &quot;localhost:9200/_cluster/health?pretty&quot; 查看日志 如果根目录下没有logs文件夹则运行下面命令 1sudo journalctl -u opensearch-dashboards.service --since &quot;2 hours ago&quot; --no-pager 访问 http://&lt;服务器IP&gt;:5601 页面提示 OpenSearch Dashboards server is not ready yet 返回看配置那一步 安装rabbitmq:3.8.2前置环境我这里之前安装了1次，没成功，卸载并清理残留 12345sudo apt-get remove --purge erlangsudo apt-get autoremovesudo apt-get remove --purge rabbitmq-serversudo apt-get autoremove 导入MQ的GPGKey12# 从 rabbitmq.com 导入签名密钥curl -fsSL https://www.rabbitmq.com/rabbitmq-release-signing-key.asc | sudo apt-key add - 添加APT 仓库RabbitMQ 官方仓库依托于 Cloudsmith，现在分为 Erlang 和 RabbitMQ 两个仓库，需要分别添加 1234567# 添加 RabbitMQ Erlang 仓库echo &quot;deb https://dl.cloudsmith.io/public/rabbitmq/rabbitmq-erlang/deb/ubuntu focal main&quot; \\ | sudo tee /etc/apt/sources.list.d/rabbitmq-erlang.list# 添加 RabbitMQ Server 仓库echo &quot;deb https://dl.cloudsmith.io/public/rabbitmq/rabbitmq-server/deb/ubuntu focal main&quot; \\ | sudo tee /etc/apt/sources.list.d/rabbitmq-server.list 更新软件包索引1sudo apt-get update 查找可用版本1apt-cache madison rabbitmq-server 示例 12345root@mail-test:/data/runTime/rabbitmq# apt-cache madison rabbitmq-serverrabbitmq-server | 3.8.3-0ubuntu0.2 | http://us-west1.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packagesrabbitmq-server | 3.8.3-0ubuntu0.2 | http://security.ubuntu.com/ubuntu focal-security/main amd64 Packagesrabbitmq-server | 3.8.2-0ubuntu1 | http://us-west1.gce.archive.ubuntu.com/ubuntu focal/main amd64 Packagesroot@mail-test:/data/runTime/rabbitmq# 安装指定版本12# 假设仓库中显示的 3.9.18 版本号带有 -1(或其他后缀)sudo apt-get install rabbitmq-server=3.8.2-0ubuntu1 如果提示需要安装依赖 Erlang，也可以直接安装依赖,这里执行没有提示 1sudo apt-get install rabbitmq-server=3.9.18-1 erlang-base erlang-crypto erlang-public-key erlang-ssl 启动并验证1sudo systemctl status rabbitmq-server 开机自启列出所有开机自启项目，按下箭头可以往下加载 1systemctl list-unit-files --type=service --state=enabled 发现rabbitmq自动设置了开机启动，如果列表里面没有，则用下面的命令设置一下 1sudo systemctl enable rabbitmq-server 检查状态1sudo systemctl status rabbitmq-server 启用RabbitMQ管理插件1sudo rabbitmq-plugins enable rabbitmq_management 启用插件后，你可以通过浏览器访问RabbitMQ的管理界面,默认的用户名和密码是guest/guest guest 用户是一个特殊的默认用户，它的默认配置是仅允许通过 localhost 登录，最好新增账号 1http://&lt;your-server-ip&gt;:15672/ 如果登陆 rabbitmq网页提示 User can only log in via localhost 1rabbitmqctl set_permissions -p / &lt;username&gt; &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 1234567root@mail-test:/data/runTime/rabbitmq# sudo rabbitmqctl add_user xen q12345678Adding user &quot;xen&quot; ...root@mail-test:/data/runTime/rabbitmq# sudo rabbitmqctl set_user_tags xen administratorSetting tags for user &quot;xen&quot; to [administrator] ...root@mail-test:/data/runTime/rabbitmq# sudo rabbitmqctl set_permissions -p / xen &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;Setting permissions for user &quot;xen&quot; in vhost &quot;/&quot; ...root@mail-test:/data/runTime/rabbitmq# 这将允许用户 从任何主机访问 RabbitMQ。 开放端口tcp:5672,15672 安装延时消息插件，项目有用到下载插件 1wget https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/download/3.9.0/rabbitmq_delayed_message_exchange-3.9.0.ez rabbitmq安装目录通常是 1/usr/lib/rabbitmq/lib/rabbitmq_server-&lt;VERSION&gt;/ 那么这里应该就是 1/usr/lib/rabbitmq/lib/rabbitmq_server-3.8.2/ 如果找不到，对于从官方仓库或本地 .deb 文件安装的 RabbitMQ 包可以执行下面语句 1dpkg -L rabbitmq-server 启用插件 123456root@mail-test:/data/runTime/rabbitmq# lsrabbitmq_delayed_message_exchange-3.9.0.ezroot@mail-test:/data/runTime/rabbitmq# mv rabbitmq_delayed_message_exchange-3.9.0.ez /usr/lib/rabbitmq/lib/rabbitmq_server-3.8.2/plugins/root@mail-test:/data/runTime/rabbitmq#rabbitmq-plugins enable rabbitmq_delayed_message_exchange 查看是否启用成功 1rabbitmq_delayed_message_exchange 创建用户（可选）可以通过以下命令创建一个新的RabbitMQ用户 123sudo rabbitmqctl add_user &lt;username&gt; &lt;password&gt;sudo rabbitmqctl set_user_tags &lt;username&gt; administratorsudo rabbitmqctl set_permissions -p / &lt;username&gt; &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 安装TIka无版本限制 下载1wget https://dlcdn.apache.org/tika/2.9.3/tika-server-standard-2.9.3.jar 12345root@mail-test:/data/runTime# mkdir tikaroot@mail-test:/data/runTime# lsopensearch opensearch-dashboards-210 rabbitmq tikaroot@mail-test:/data/runTime# cd tika/root@mail-test:/data/runTime/tika# wget https://dlcdn.apache.org/tika/2.8.0/tika-app-2.8.0.jar 如果404 则先到 Tika 官方下载页面 查看当前最新可用版本，然后使用对应的下载链接,或者替换链接中的版本号 官方下载页面 1wget https://dlcdn.apache.org/tika/2.9.3/tika-server-standard-2.9.3.jar 开机自启1sudo nano /etc/systemd/system/tika.service 写入以下内容 1234567891011[Unit]Description=Apache Tika ServerAfter=network.target[Service]Type=simpleExecStart=/usr/bin/java -jar /data/runTime/tika/tika-server-standard-2.9.3.jar -p 9998Restart=on-failure[Install]WantedBy=multi-user.target 加载并启动服务 123sudo systemctl daemon-reloadsudo systemctl enable tikasudo systemctl start tika 检查服务状态 1systemctl status tika 安装cassandra 4.0.10添加 Cassandra 官方仓库 导入 GPG 密钥,此命令会从 Apache 官方下载 Cassandra 的密钥并添加到系统的密钥管理中。 1wget -q -O - https://downloads.apache.org/cassandra/KEYS | sudo apt-key add - 添加 Cassandra 仓库到 sources.list 1wget -q -O - https://downloads.apache.org/cassandra/KEYS | sudo apt-key add - Cassandra 4.0.x 版本对应的仓库地址通常为 40x，请在 /etc/apt/sources.list.d/ 下创建新的源文件 12echo &quot;deb [arch=amd64] https://deb.apache.org/cassandra 40x main&quot; \\ | sudo tee /etc/apt/sources.list.d/cassandra.sources.list 更新包索引 1sudo apt-get update 查看可用版本（可选） 1apt-cache madison cassandra 安装指定版本 1sudo apt-get install cassandra=4.0.10 一直没法正确执行，放弃 下载前往 Apache Cassandra 下载页，或其 官方镜像，找到 4.0.10（4.0.x 系列）的链接后，进入对应的 deb 目录 官方镜像 Apache Cassandra 下载页 我这里进的 官方镜像 ，选择版本后文件如下 12345678[ ] apache-cassandra-4.0.17-bin.tar.gz 2025-02-06 10:02 46M [TXT] apache-cassandra-4.0.17-bin.tar.gz.asc 2025-02-06 10:02 833 [TXT] apache-cassandra-4.0.17-bin.tar.gz.sha256 2025-02-06 10:02 65 [TXT] apache-cassandra-4.0.17-bin.tar.gz.sha512 2025-02-06 10:02 129 [ ] apache-cassandra-4.0.17-src.tar.gz 2025-02-06 10:02 13M [TXT] apache-cassandra-4.0.17-src.tar.gz.asc 2025-02-06 10:02 833 [TXT] apache-cassandra-4.0.17-src.tar.gz.sha256 2025-02-06 10:02 65 [TXT] apache-cassandra-4.0.17-src.tar.gz.sha512 2025-02-06 10:02 129 右键文件获取下载链接 1wget https://downloads.apache.org/cassandra/4.0.17/apache-cassandra-4.0.17-bin.tar.gz 解压 1tar -xzvf apache-cassandra-4.0.17-bin.tar.gz 环境变量编辑~/.bashrc文件，添加Cassandra的路径,直接执行下面语句 12echo &#x27;export CASSANDRA_HOME=/data/runTime/cassandra401&#x27; &gt;&gt; ~/.bashrcecho &#x27;export PATH=$PATH:$CASSANDRA_HOME/bin&#x27; &gt;&gt; ~/.bashrc 使更改生效 1source ~/.bashrc 配置编辑/conf/cassandra.yaml文件，根据需要调整配置，如数据存储路径、监听地址等 1nano /data/runTime/cassandra401/conf/cassandra.yaml 常见配置项： data_file_directories: 数据文件存储路径commitlog_directory: 提交日志存储路径saved_caches_directory: 缓存存储路径listen_address: Cassandra节点监听地址rpc_address: 远程过程调用地址 创建系统专用用户为 Cassandra 创建一个专用用户（例如 cassandra），并确保该用户对 Cassandra 的安装目录和数据目录有适当的权限 1sudo useradd -r -s /bin/false cassandra 更改目录权限 将 Cassandra 安装目录和数据目录的所有权更改为新创建的 cassandra 用户。 假设 Cassandra 安装在 /data/runTime/cassandra401/，数据目录在 /var/lib/cassandra，日志目录在 /var/log/cassandra，运行以下命令 123sudo chown -R cassandra:cassandra /data/runTime/cassandra401/sudo chown -R cassandra:cassandra /var/lib/cassandrasudo chown -R cassandra:cassandra /var/log/cassandra 开机启动创建Systemd服务文件 1sudo nano /etc/systemd/system/cassandra.service 添加以下内容 123456789101112[Unit]Description=Apache CassandraAfter=network.target[Service]User=cassandraGroup=cassandraExecStart=/data/runTime/cassandra401/bin/cassandra -fRestart=always[Install]WantedBy=multi-user.target 启用并启动服务 123sudo systemctl daemon-reloadsudo systemctl enable cassandrasudo systemctl start cassandra 检查服务状态 1sudo systemctl status cassandra 如果启动失败，查看日志 123456789Feb 13 03:34:16 mail-test cassandra[205447]: Running Cassandra as root user or group is not recommended - please start Cassandra using a different system user.Feb 13 03:34:16 mail-test cassandra[205447]: If you really want to force running Cassandra as root, use -R command line option.Feb 13 03:34:16 mail-test systemd[1]: cassandra.service: Main process exited, code=exited, status=1/FAILUREFeb 13 03:34:16 mail-test systemd[1]: cassandra.service: Failed with result &#x27;exit-code&#x27;.Feb 13 03:34:16 mail-test systemd[1]: cassandra.service: Scheduled restart job, restart counter is at 5.Feb 13 03:34:16 mail-test systemd[1]: Stopped Apache Cassandra.Feb 13 03:34:16 mail-test systemd[1]: cassandra.service: Start request repeated too quickly.Feb 13 03:34:16 mail-test systemd[1]: cassandra.service: Failed with result &#x27;exit-code&#x27;.Feb 13 03:34:16 mail-test systemd[1]: Failed to start Apache Cassandra. 报错如下：不建议使用root用户或root组运行Cassandra，请使用其他系统用户启动Cassandra 已返回上面步骤，修改自启配置 1sudo journalctl -u cassandra.service --since &quot;2 hours ago&quot; --no-pager 启动进入Cassandra目录并启动服务 1bin/cassandra -f 防火墙配置tcp:9042,7000 验证1nodetool status 使用CQL Shell启动CQL Shell与Cassandra交互 1bin/cqlsh 其他如果忘记了安装目录，可以用下面的命令查找配置文件 1sudo find / -name cassandra.yaml 2&gt;/dev/null 集群参考配置 Cassandra 4.0.10 集群主要是对各个节点的配置文件（通常是 cassandra.yaml）进行修改，确保各节点能够相互发现并正确通信。下面是一个基本的配置步骤说明，未验证，仅供参考 统一集群名称，在所有节点的 cassandra.yaml 中，将 cluster_name 设置为相同的值，例如 1cluster_name: &#x27;MyCluster&#x27; 配置种子节点（Seeds），种子节点用于初始的节点发现，至少指定一个稳定的 IP。建议配置两个或更多，例如 1seeds: &quot;192.168.1.1,192.168.1.2&quot; 注意：种子节点列表在每个节点中都应保持一致 设置节点通信地址，listen_address：指定本机用于集群内部节点间通信的 IP 地址（通常为机器实际的私网 IP） 1listen_address: 192.168.1.X # 各节点各自的IP地址 rpc_address：用于客户端（如 cqlsh）连接的地址，常设置为 0.0.0.0 或本机 IP 1rpc_address: 0.0.0.0 如果节点在 NAT 或云环境下部署，还需要设置broadcast_address：对外公布的 IP 地址，用于集群内部的对等通信。broadcast_rpc_address：对外公布的 RPC 连接地址。 选择合适的 Snitch配置 endpoint_snitch 以反映数据中心、机架等拓扑信息。通常建议使用 1endpoint_snitch: GossipingPropertyFileSnitch 如有需要，可编辑 cassandra-rackdc.properties 文件，配置数据中心和机架信息 启动并检查集群状态在每个节点修改好配置后启动 Cassandra 服务。使用 nodetool status 命令检查集群状态，确保所有节点状态为 UN（Up/Normal）。其他注意事项确保各节点之间网络互通，防火墙或安全组已开放必要的端口（如 7000、7001、9042 等）。每个节点的硬件配置、JVM 参数等也应根据实际负载进行调优 官方文档 安装nginx更新软件包索引1sudo apt update 安装1sudo apt install nginx 验证安装版本1nginx -v 配置文件路径使用 apt 安装 nginx 后，其默认的配置文件存放在 /etc/nginx 目录下，主要配置文件为： 1/etc/nginx/nginx.conf 此外，虚拟主机（站点）的配置文件通常存放在： 1/etc/nginx/sites-available 1/etc/nginx/sites-enabled 开机自启使用 apt 安装 nginx 后，Ubuntu 系统通常会自动启用 nginx 的 systemd 服务，这样 nginx 就会在开机时自动启动。可以使用以下命令检查 nginx 是否已设置为开机自启 1sudo systemctl is-enabled nginx 如果输出结果为 enabled，说明 nginx 已经设置为开机自启；如果输出结果为 disabled 或其他状态，则可以手动启用，执行 1sudo systemctl enable nginx","tags":["笔记"],"categories":["James"]},{"title":"james分布式版本部署二","path":"/2025/02/10/2025james02/","content":"一些配置OpenSearchOpenSearch 要确保把SSL访问关闭，且安全认证取消，不然James是无法访问的。 docker如果通过命令 docker exec -it opensearch bash 进入到 OpenSearch 客户端，运行命令 12345678910#进入到 OpenSearch 客户端docker exec -it opensearch bashvi /config/opensearch.yml#修改配置信息如下：network.host: 0.0.0.0#放开，去掉注释，注意格式，空格discovery.type: single-node#新增plugins.security.disabled: trueplugins.security.ssl.http.enabled: false 退出容器 使用 exit 或 Ctrl + D 退出并停止容器。使用 Ctrl + P + Q 退出但不停止容器。使用 docker ps 检查容器状态 重启容器 1docker restart opensearch 手动手动安装的OpenSearch无需配置，在前面安装的时候已经配置好了 DNS 配置添加以下配置可以成功发送Gmail邮箱，否则会被Gmail退信 添加或更新 SPF 记录： 在你的域的 DNS 管理界面中，添加或更新 SPF 记录（即添加TXT解析）以包含发件 IP 地址 x.x.x.x。以下是一个示例 SPF 记录：添加TXT解析，名称为@ 值为：v=spf1 a mx ip4:x.x.x.x -all添加TXT解析，名称为mail 值为：v=spf1 a mx ip4:x.x.x.x -all添加A解析，名称为mail 值为：服务器ipv=spf1 表示这是一个 SPF 记录。ip4:x.x.x.x 允许 x.x.x.x 代表 域名.后缀 发送邮件。-all 表示仅允许明确列出的 IP 地址发送邮件，其他 IP 地址将被拒绝。 验证 SPF 记录是否生效： 等待 DNS 记录生效（通常几分钟到 48 小时），在服务器中输入命令 12345dig +short TXT 域名.后缀#示例root@mail-test:/data/james/james382/conf# dig +short TXT 域名.后缀&quot;pf1 a mx ip4:x.x.x.x -all&quot;root@mail-test:/data/james/james382/conf# 配置 DMARC添加 DMARC 记录到 DNS： 在你的 DNS 中添加 DMARC TXT 记录名称：_dmarc值例如： 1v=DMARC1; p=quarantine; rua=mailto:postmaster@域名.后缀; pct=100; adkim=s; aspf=s p=reject 表示未通过 SPF/DKIM 的邮件将被拒收。rua=mailto:dmarc-reports@域名.后缀 表示将 DMARC 报告发送到指定邮箱 验证 DMARC 是否生效 mxtoolbox 输入域名（域名.后缀），点击MX Lookup验证 nginx配置文件参考123456root@mail:/# nginx -vnginx version: nginx/1.18.0 (Ubuntu)root@mail:/# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successfulroot@mail:/# 这个是配置文件路径： /etc/nginx/nginx.conf 下面是配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485user www-data;worker_processes auto;pid /run/nginx.pid;include /etc/nginx/modules-enabled/*.conf;events &#123; worker_connections 768; # multi_accept on;&#125;http &#123; ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125;#mail &#123;# # See sample authentication script at:# # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript# # # auth_http localhost/auth.php;# # pop3_capabilities &quot;TOP&quot; &quot;USER&quot;;# # imap_capabilities &quot;IMAP4rev1&quot; &quot;UIDPLUS&quot;;# # server &#123;# listen localhost:110;# protocol pop3;# proxy on;# &#125;# # server &#123;# listen localhost:143;# protocol imap;# proxy on;# &#125;#&#125; 查看后发现不对，切换路径 1234cd /etc/nginx/sites-availableroot@mail:/etc/nginx/sites-available# lsdefaultroot@mail:/etc/nginx/sites-available# cat default 输出如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# 全局 HTTPS 重定向配置server &#123; listen 80; server_name 域名.ai www.域名.ai www.域名.com backend.域名.com 域名.com 域名.ai www.域名.ai teman.域名.ai; location /.well-known/acme-challenge/ &#123; root /var/www/html; &#125; location / &#123; return 301 https://$host$request_uri; &#125;&#125;# 配置官网静态文件服务server &#123; listen 443 ssl; server_name temail.ai www.域名.ai; ssl_certificate /etc/letsencrypt/live/temail.ai/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/temail.ai/privkey.pem; # managed by Certbot root /data/apps/website; index index.html; location / &#123; try_files $uri $uri/ =404; &#125;&#125;# 配置邮箱客户端前端服务server &#123; listen 443 ssl; server_name www.域名.com 域名.com; ssl_certificate /etc/letsencrypt/live/mail.域名.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/mail.域名.com/privkey.pem; root /data/apps/webmail/dist; index index.html; # 自定义错误页面配置 error_page 404 /index.html; location / &#123; try_files $uri $uri/ =404; &#125; # 处理自定义 404 页面 location = /404.html &#123; root /data/apps/webmail; internal; &#125;&#125;# 配置邮箱后台服务server &#123; listen 443 ssl; server_name teman.域名.ai; ssl_certificate /etc/letsencrypt/live/teman.域名.ai/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/teman.域名.ai/privkey.pem; root /data/apps/webadmin/dist; index index.html; # 自定义错误页面配置 error_page 404 /index.html; location / &#123; try_files $uri $uri/ =404; &#125; # 处理自定义 404 页面 location = /404.html &#123; root /data/apps/webadmin; internal; &#125;&#125;# 配置邮箱客户端后端服务server &#123; listen 443 ssl; server_name backend.域名.com; client_max_body_size 30M; ssl_certificate /etc/letsencrypt/live/mail.域名.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/mail.域名.com/privkey.pem; location / &#123; proxy_pass http://127.0.0.1:6001; # 转发到本地监听的服务 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; &#125;&#125; 测试服配置示例，共启用了home.kretest.comwww.kretest.combackend.kretest.comkretest.comteman.kretest.commail.kretest.com这些域名，可以先提前解析好，后面生成证书的时候需要用到 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# 全局 HTTPS 重定向配置server &#123; listen 80; server_name home.kretest.com www.kretest.com backend.kretest.com kretest.com teman.kretest.com; location /.well-known/acme-challenge/ &#123; root /var/www/html; &#125; location / &#123; return 301 https://$host$request_uri; &#125;&#125;# 配置官网静态文件服务server &#123; listen 443 ssl; server_name home.kretest.com; ssl_certificate /etc/letsencrypt/live/mail.kretest.com/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/mail.kretest.com/privkey.pem; # managed by Certbot root /data/apps/website; index index.html; location / &#123; try_files $uri $uri/ =404; &#125;&#125;# 配置邮箱客户端前端服务server &#123; listen 443 ssl; server_name www.kretest.com kretest.com; ssl_certificate /etc/letsencrypt/live/mail.kretest.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/mail.kretest.com/privkey.pem; root /data/apps/webmail/dist; index index.html; # 自定义错误页面配置 error_page 404 /index.html; location / &#123; try_files $uri $uri/ =404; &#125; # 处理自定义 404 页面 location = /404.html &#123; root /data/apps/webmail; internal; &#125;&#125;# 配置邮箱后台服务server &#123; listen 443 ssl; server_name teman.kretest.com; ssl_certificate /etc/letsencrypt/live/mail.kretest.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/mail.kretest.com/privkey.pem; root /data/apps/webadmin/dist; index index.html; # 自定义错误页面配置 error_page 404 /index.html; location / &#123; try_files $uri $uri/ =404; &#125; # 处理自定义 404 页面 location = /404.html &#123; root /data/apps/webadmin; internal; &#125;&#125;# 配置邮箱客户端后端服务server &#123; listen 443 ssl; server_name backend.kretest.com; client_max_body_size 30M; ssl_certificate /etc/letsencrypt/live/mail.kretest.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/mail.kretest.com/privkey.pem; location / &#123; proxy_pass http://127.0.0.1:6001; # 转发到本地监听的服务 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; &#125;&#125; 修改后重启nginx 1sudo systemctl restart nginx 安装 JamesJames 下载地址：https://dlcdn.apache.org/james/server/3.8.2/james-server-distributed-guice.zip 如果链接无法访问，可能是官方更新了版本，浏览器访问 https://dlcdn.apache.org/james/server/ 查看版本 1wget https://dlcdn.apache.org/james/server/3.8.2/james-server-distributed-guice.zip 我之前下载james的安装包丢在home/james下面 1234567891011mv james-server-distributed-guice.zip /data/james/unzip james-server-distributed-guice.ziproot@mail-test:/data/james# lsjames-server-distributed-app james-server-distributed-guice.ziproot@mail-test:/data/james# rm -rf james-server-distributed-guice.zip root@mail-test:/data/james# lsjames-server-distributed-approot@mail-test:/data/james# mv james-server-distributed-app james382root@mail-test:/data/james# lsjames382root@mail-test:/data/james# 配置 jamesssl证书方式（推荐）证书安装12sudo apt updatesudo apt install certbot python3-certbot-nginx 在申请证书前，请确保要申请的域名（例如 example.com 或 www.example.com ）已经解析到服务器的 IP 地址，否则验证会失败 1sudo certbot --nginx -d xx.com -d mail.xx.com -d www.xx.com 有几个域名就-d几次,根据上面nginx配置的域名示例 1sudo certbot --nginx -d home.kretest.com -d www.kretest.com -d backend.kretest.com -d kretest.com -d mail.xx.com -d teman.kretest.com 可能报错一： 这里执行报nginx相关的错误，启动nginx报错，80端口被占用 1234567root@mail-test:/etc/letsencrypt# sudo lsof -i :80COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEgoogle_gu 548101 root 3u IPv4 2625353 0t0 TCP mail-test.us-west1-b.c.atouch-live-20240921.internal:54170-&gt;metadata.google.internal:http (ESTABLISHED)google_os 553385 root 3u IPv4 2630491 0t0 TCP mail-test.us-west1-b.c.atouch-live-20240921.internal:48900-&gt;metadata.google.internal:http (ESTABLISHED)apache2 597884 root 4u IPv6 2813783 0t0 TCP *:http (LISTEN)apache2 597886 www-data 4u IPv6 2813783 0t0 TCP *:http (LISTEN)apache2 597887 www-data 4u IPv6 2813783 0t0 TCP *:http (LISTEN) google_gu 和 google_os：这些进程是 Google Cloud 的元数据服务客户端，用于与 Google Cloud 的元数据服务器 (metadata.google.internal) 通信。它们使用的是 出站连接（从你的服务器到 Google 的元数据服务器），而不是监听 80 端口。因此，它们不会影响 Nginx 启动。可以忽略这些进程。apache2：apache2 是 Apache HTTP 服务器，它正在监听 80 端口（TCP *:http 表示监听所有 IPv4 和 IPv6 地址的 80 端口）。这是导致 Nginx 无法启动的原因，因为 Apache 已经占用了 80 端口。 1234sudo systemctl stop apache2 # 停止 Apachesudo systemctl disable apache2 # 禁用 Apache，防止它开机自启sudo systemctl start nginxsystemctl status nginx # 查看nginx启动状态 如果nginx已经启动成功，但是生成证书操作还报红色错误说nginx配置不对，则打开nginx配置文件，把所有关于ssl和443的配置注释掉再来执行生成证书操作。 可能报错二： 123456789root@mail-test:/data/runTime/james/james382# sudo certbot --nginx -d home.kretest.com -d www.kretest.com -d backend.kretest.com -d kretest.com -d mail.kretest.com -d teman.kretest.comSaving debug log to /var/log/letsencrypt/letsencrypt.logError while running nginx -c /etc/nginx/nginx.conf -t.nginx: [emerg] cannot load certificate &quot;/etc/letsencrypt/live/home.kretest.com/fullchain.pem&quot;: BIO_new_file() failed (SSL: error:02001002:system library:fopen:No such file or directory:fopen(&#x27;/etc/letsencrypt/live/home.kretest.com/fullchain.pem&#x27;,&#x27;r&#x27;) error:2006D080:BIO routines:BIO_new_file:no such file)nginx: configuration file /etc/nginx/nginx.conf test failedThe nginx plugin is not working; there may be problems with your existing configuration.The error was: MisconfigurationError(&#x27;Error while running nginx -c /etc/nginx/nginx.conf -t. nginx: [emerg] cannot load certificate &quot;/etc/letsencrypt/live/home.kretest.com/fullchain.pem&quot;: BIO_new_file() failed (SSL: error:02001002:system library:fopen:No such file or directory:fopen(\\&#x27;/etc/letsencrypt/live/home.kretest.com/fullchain.pem\\&#x27;,\\&#x27;r\\&#x27;) error:2006D080:BIO routines:BIO_new_file:no such file) nginx: configuration file /etc/nginx/nginx.conf test failed &#x27;) 这是因为之前nginx中配置了证书，但是现在找不到证书,这里先一撸到底，全删掉，等下又设置回来 123456789101112# 全局 HTTPS 重定向配置server &#123; listen 80; server_name home.kretest.com www.kretest.com backend.kretest.com kretest.com teman.kretest.com; location /.well-known/acme-challenge/ &#123; root /var/www/html; &#125; location / &#123; return 301 https://$host$request_uri; &#125;&#125; 执行如下 1234567891011121314151617181920212223root@mail-test:/etc/nginx/sites-available# sudo certbot --nginx -d home.kretest.com -d www.kretest.com -d backend.kretest.com -d kretest.com -d mail.kretest.com -d teman.kretest.comSaving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator nginx, Installer nginxEnter email address (used for urgent renewal and security notices) (Enter &#x27;c&#x27; tocancel): xxx@gmail.com- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Please read the Terms of Service athttps://letsencrypt.org/documents/LE-SA-v1.4-April-3-2024.pdf. You must agree inorder to register with the ACME server athttps://acme-v02.api.letsencrypt.org/directory- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(A)gree/(C)ancel: a- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Would you be willing to share your email address with the Electronic FrontierFoundation, a founding partner of the Let&#x27;s Encrypt project and the non-profitorganization that develops Certbot? We&#x27;d like to send you email about our workencrypting the web, EFF news, campaigns, and ways to support digital freedom.- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(Y)es/(N)o: nObtaining a new certificatePerforming the following challenges: 可能出现的问题，创建命令里面有多个域名，但是最终只生成出来了1个证书，这是因为申请的是一个多域名证书（SAN证书），即在一个证书中包含了多个域名的信息 Certbot 已生成 Let’s Encrypt 证书，路径如下：• 公钥证书：/etc/letsencrypt/live/域名/fullchain.pem• 私钥：/etc/letsencrypt/live/域名/privkey.pem 确保 James 用户对这些文件有读取权限 1234567891011121314151617181920212223242526272829root@mail-test:/etc/nginx/sites-available# cd /etc/letsencrypt/live/mail.kretest.comroot@mail-test:/etc/letsencrypt/live/mail.kretest.com# lsREADME cert.pem chain.pem fullchain.pem privkey.pemroot@mail-test:/etc/letsencrypt/live/mail.kretest.com# lltotal 12drwxr-xr-x 2 root root 4096 Feb 13 08:34 ./drwx------ 3 root root 4096 Feb 13 08:33 ../-rw-r--r-- 1 root root 692 Feb 13 08:33 READMElrwxrwxrwx 1 root root 40 Feb 13 08:34 cert.pem -&gt; ../../archive/mail.kretest.com/cert2.pemlrwxrwxrwx 1 root root 41 Feb 13 08:34 chain.pem -&gt; ../../archive/mail.kretest.com/chain2.pemlrwxrwxrwx 1 root root 45 Feb 13 08:34 fullchain.pem -&gt; ../../archive/mail.kretest.com/fullchain2.pemlrwxrwxrwx 1 root root 43 Feb 13 08:34 privkey.pem -&gt; ../../archive/mail.kretest.com/privkey2.pemroot@mail-test:/etc/letsencrypt/live/mail.kretest.com# cd ../../archive/mail.kretest.com/root@mail-test:/etc/letsencrypt/archive/mail.kretest.com# lscert1.pem cert2.pem chain1.pem chain2.pem fullchain1.pem fullchain2.pem privkey1.pem privkey2.pemroot@mail-test:/etc/letsencrypt/archive/mail.kretest.com# lltotal 40drwxr-xr-x 2 root root 4096 Feb 13 08:34 ./drwx------ 3 root root 4096 Feb 13 08:33 ../-rw-r--r-- 1 root root 1773 Feb 13 08:33 cert1.pem-rw-r--r-- 1 root root 1895 Feb 13 08:34 cert2.pem-rw-r--r-- 1 root root 1801 Feb 13 08:33 chain1.pem-rw-r--r-- 1 root root 1801 Feb 13 08:34 chain2.pem-rw-r--r-- 1 root root 3574 Feb 13 08:33 fullchain1.pem-rw-r----- 1 root root 3696 Feb 13 08:34 fullchain2.pem-rw------- 1 root root 1704 Feb 13 08:33 privkey1.pem-rw-r----- 1 root root 1704 Feb 13 08:34 privkey2.pemroot@mail-test:/etc/letsencrypt/archive/mail.kretest.com# sudo chmod 640 privkey2.pem root@mail-test:/etc/letsencrypt/archive/mail.kretest.com# sudo chmod 640 fullchain2.pem 12345678910sudo chmod 640 /etc/letsencrypt/live/域名/privkey.pemsudo chmod 640 /etc/letsencrypt/live/域名/fullchain.pem#检测组名是否存在getent group james#如果组名不存在则创建sudo groupadd jamessudo chown root:james /etc/letsencrypt/live/域名/privkey.pemsudo chown root:james /etc/letsencrypt/live/域名/fullchain.pem 在james项目的根目录新建文件夹encrypt，把生成的证书移动进来 12345678910111213mkdir encrypt#mv /etc/letsencrypt/live/域名.com/privkey.pem /data/james/james382/encrypt/#mv /etc/letsencrypt/live/域名.com/fullchain.pem /data/james/james382/encrypt/chmod 777 encrypt#注意要看看，/etc/letsencrypt/live/域名.com/下的证书是不是真的文件，如是一个相对路径的软连接，删除或者复制都无效了。那么则需要进入真实路径去复制或者移动#cp -L /etc/letsencrypt/live/kretest.com/privkey.pem /data/james/james382/encrypt/#cp -L /etc/letsencrypt/live/kretest.com/fullchain.pem /data/james/james382/encrypt/cp 证书真实绝对路径 /data/james/james382/encrypt/chmod 777 privkey.pemchmod 777 fullchain.pem 示例 1234567root@mail-test:/data/runTime/james/james382# cp /etc/letsencrypt/archive/mail.kretest.com/privkey2.pem /data/runTime/james/james382/encrypt/privkey.pemroot@mail-test:/data/runTime/james/james382# cp /etc/letsencrypt/archive/mail.kretest.com/fullchain2.pem /data/runTime/james/james382/encrypt/fullchain.pemroot@mail-test:/data/runTime/james/james382# cd encrypt/root@mail-test:/data/runTime/james/james382/encrypt# lsfullchain.pem privkey.pemroot@mail-test:/data/runTime/james/james382/encrypt# chmod 777 privkey.pemroot@mail-test:/data/runTime/james/james382/encrypt# chmod 777 fullchain.pem 修改 James 配置James默认配置文件在系统文件位于 ./conf 文件夹下 blob.properties主要需要调整 ObjectStorage on S3 模块，将之前搭建好的 S3 服务器配置信息填上去 12345bjectstorage.s3.endPoint=https://xx-xx.s3.amazonaws.com/mail/ # S3 的读取器地址，换成自己的IP和端口objectstorage.s3.bucketName=xx-xx（这个可能需要新增）objectstorage.s3.region=us-east-1objectstorage.s3.accessKeyId=accessKey1 # S3 的accessKey（创建的时候有指定）objectstorage.s3.secretKey=secretKey1 # S3 的secretKey（创建的时候有指定） 修改后的blob.properties文件参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131# ============================================= BlobStore Implementation ==================================# Read https://james.apache.org/server/config-blobstore.html for further details# Choose your BlobStore implementation# Mandatory, allowed values are: cassandra, s3# *WARNING*: JAMES-3591 Cassandra is not made to store large binary content, its use will be suboptimal compared to# alternatives (namely S3 compatible BlobStores backed by for instance S3, MinIO or Ozone)implementation=s3# ========================================= Deduplication ========================================# If you choose to enable deduplication, the mails with the same content will be stored only once.# Warning: Once this feature is enabled, there is no turning back as turning it off will lead to the deletion of all# the mails sharing the same content once one is deleted.# Mandatory, Allowed values are: true, falsededuplication.enable=false# deduplication.family needs to be incremented every time the deduplication.generation.duration is changed# Positive integer, defaults to 1# deduplication.gc.generation.family=1# Duration of generation.# Deduplication only takes place within a singe generation.# Only items two generation old can be garbage collected. (This prevent concurrent insertions issues and# accounts for a clock skew).# deduplication.family needs to be incremented everytime this parameter is changed.# Duration. Default unit: days. Defaults to 30 days.# deduplication.gc.generation.duration=30days# ========================================= Encryption ========================================# If you choose to enable encryption, the blob content will be encrypted before storing them in the BlobStore.# Warning: Once this feature is enabled, there is no turning back as turning it off will lead to all content being# encrypted. This comes at a performance impact but presents you from leaking data if, for instance the third party# offering you a S3 service is compromised.# Optional, Allowed values are: true, false, defaults to falseencryption.aes.enable=false# Mandatory (if AES encryption is enabled) salt and password. Salt needs to be an hexadecimal encoded string#encryption.aes.password=xxx#encryption.aes.salt=73616c7479# Optional, defaults to PBKDF2WithHmacSHA512#encryption.aes.private.key.algorithm=PBKDF2WithHmacSHA512# ========================================= Cassandra BlobStore Cache ======================================# A cassandra cache can be enabled to reduce latency when reading small blobs frequently# A dedicated keyspace with a replication factor of one is then used# Cache eviction policy is TTL based# Only blobs below a given threshold will be stored.# To be noted that blobs are stored within a single Cassandra row, hence a low threshold should be used.# Enable the cache? Optional and default to false. Must be a boolean.cache.enable=false# Cache eviction policy is TTL based. Optional and defaults to 7 days. Must be a duration.# Valid units: ms, sec, min, hour, day, week, month, year# cache.cassandra.ttl=7days# Timeout after which this cache should be bypassed. Optional and defaults to 100ms. Can not exceed 1 hour.# Must be a duration Valid units: ms, sec, min, hour, day, week, month, year# cache.cassandra.timeout=100ms# Maximum size of stored objects expressed in bytes. Must be strictly positive. Defaults to 8192.# Units: bytes, Kib, MiB, GiB, TiB# cache.sizeThresholdInBytes=8 KiB# ============================================== ObjectStorage ============================================# ========================================= ObjectStorage Buckets ==========================================# bucket names prefix# Optional, default no prefix# objectstorage.bucketPrefix=prod-# Default bucket name# Optional, default is bucketPrefix + `default`# objectstorage.namespace=james# ========================================= ObjectStorage on S3 =============================================# Mandatory if you choose s3 storage service, S3 authentication endpoint#objectstorage.s3.endPoint=http://xx.xx.0.6:8000/objectstorage.s3.endPoint=https://xxx-mail.s3.amazonaws.com/mail/# AWS S3 å­å¨æ¡¶åç§°objectstorage.s3.bucketName=xxx-mail# Mandatory if you choose s3 storage service, S3 region#objectstorage.s3.region=eu-west-1objectstorage.s3.region=us-east-1# Mandatory if you choose aws-s3 storage service, access key id configured in S3objectstorage.s3.accessKeyId=xxx# Mandatory if you choose s3 storage service, secret key configured in S3objectstorage.s3.secretKey=xx/xxx# Optional if you choose s3 storage service: The trust store file, secret, and algorithm to use# when connecting to the storage service. If not specified falls back to Java defaults.#objectstorage.s3.truststore.path=#objectstorage.s3.truststore.type=JKS#objectstorage.s3.truststore.secret=#objectstorage.s3.truststore.algorithm=SunX509# optional: Object read in memory will be rejected if they exceed the size limit exposed here. Size, exemple `100M`.# Supported units: K, M, G, defaults to B if no unit is specified. If unspecified, big object won&#x27;t be prevented# from being loaded in memory. This settings complements protocol limits.# objectstorage.s3.in.read.limit=50M# ============================================ Blobs Exporting ==============================================# Read https://james.apache.org/server/config-blob-export.html for further details# Choosing blob exporting mechanism, allowed mechanism are: localFile, linshare# LinShare is a file sharing service, will be explained in the below section# Optional, default is localFileblob.export.implementation=localFile# ======================================= Local File Blobs Exporting ========================================# Optional, directory to store exported blob, directory path follows James file system format# default is file://var/blobExportingblob.export.localFile.directory=file://var/blobExporting# ======================================= LinShare File Blobs Exporting ========================================# LinShare is a sharing service where you can use james, connects to an existing LinShare server and shares files to# other mail addresses as long as those addresses available in LinShare. For example you can deploy James and LinShare# sharing the same LDAP repository# Mandatory if you choose LinShare, url to connect to LinShare service# blob.export.linshare.url=http://linshare:8080# ======================================= LinShare Configuration BasicAuthentication ===================================# Authentication is mandatory if you choose LinShare, TechnicalAccount is need to connect to LinShare specific service.# For Example: It will be formalized to &#x27;Authorization: Basic &#123;Credential of UUID/password&#125;&#x27;# blob.export.linshare.technical.account.uuid=Technical_Account_UUID# blob.export.linshare.technical.account.password=password cassandra.properties这里用的是容器里的环境，先获取cassandra的ip，如果是手动安装的直接输入对应的ip和端口 12345678root@mail-test:/data/james/james382/conf# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES13447441cafe apache/tika &quot;/bin/sh -c &#x27;exec ja…&quot; 41 minutes ago Up 41 minutes 0.0.0.0:9998-&gt;9998/tcp, :::9998-&gt;9998/tcp tikaec1302b389dd zenko/cloudserver:8.2.6 &quot;/usr/src/app/docker…&quot; 42 minutes ago Up 42 minutes 8000/tcp s3c25c0f731ca5 rabbitmq:3.9.18-management &quot;docker-entrypoint.s…&quot; 43 minutes ago Up 43 minutes 4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, :::5672-&gt;5672/tcp, 15671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp, :::15672-&gt;15672/tcp rabbitmqd4fcf76d86f9 opensearchproject/opensearch:2.1.0 &quot;./opensearch-docker…&quot; 2 hours ago Up 2 hours 9300/tcp, 9600/tcp, 0.0.0.0:9200-&gt;9200/tcp, :::9200-&gt;9200/tcp, 9650/tcp opensearch7efb7cd0942e cassandra:3.11.10 &quot;docker-entrypoint.s…&quot; 2 hours ago Up 2 hours 7000-7001/tcp, 7199/tcp, 9160/tcp, 0.0.0.0:9042-&gt;9042/tcp, :::9042-&gt;9042/tcp cassandraroot@mail-test:/data/james/james382/conf# 123456root@mail-test:/data/james/james382/conf# docker ps -q | xargs -n 1 docker inspect --format &#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125; &#123;&#123;.Name&#125;&#125;&#x27; | sed &#x27;s/ \\// /&#x27;172.17.0.2 tika172.18.0.5 s3172.18.0.4 rabbitmq172.18.0.3 opensearch172.18.0.2 cassandra 123cassandra.nodes=cassandra # cassandra 的服务器地址信息，如172.19.0.2:9042#集群的话用逗号隔开，例如 x.x.x.6:9042,x.x.x.7:9042,x.x.x.8:9042#cassandra.replication.factor=1这个数字等于机器数量，假设上面的集群3台机器，这里就写3 imapserver.xml主要调整SSL信息，注意会有2处配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;tls socketTLS=&quot;false&quot; startTLS=&quot;true&quot;&gt; &lt;!-- To create a new keystore execute: keytool -genkey -alias james -keyalg RSA -storetype PKCS12 -keystore /path/to/james/conf/keystore --&gt; &lt;!--&lt;keystore&gt;file://conf/keystore&lt;/keystore&gt; &lt;keystoreType&gt;PKCS12&lt;/keystoreType&gt; &lt;secret&gt;123456&lt;/secret&gt; &lt;provider&gt;org.bouncycastle.jce.provider.BouncyCastleProvider&lt;/provider&gt;--&gt; &lt;!-- Alternatively TLS keys can be supplied via PEM files --&gt; &lt;privateKey&gt;file://encrypt/privkey.pem&lt;/privateKey&gt; &lt;certificates&gt;file://encrypt/fullchain.pem&lt;/certificates&gt; &lt;!-- An optional secret might be specified for the private key --&gt; &lt;!-- &lt;secret&gt;james72laBalle&lt;/secret&gt; --&gt; &lt;/tls&gt; &lt;imapserver enabled=&quot;true&quot;&gt; &lt;jmxName&gt;imapserver-ssl&lt;/jmxName&gt; &lt;bind&gt;0.0.0.0:993&lt;/bind&gt; &lt;connectionBacklog&gt;200&lt;/connectionBacklog&gt; &lt;tls socketTLS=&quot;true&quot; startTLS=&quot;false&quot;&gt; &lt;!-- To create a new keystore execute: keytool -genkey -alias james -keyalg RSA -storetype PKCS12 -keystore /path/to/james/conf/keystore --&gt; &lt;!--&lt;keystore&gt;file://conf/keystore&lt;/keystore&gt; &lt;keystoreType&gt;PKCS12&lt;/keystoreType&gt; &lt;secret&gt;123456&lt;/secret&gt; &lt;provider&gt;org.bouncycastle.jce.provider.BouncyCastleProvider&lt;/provider&gt;--&gt; &lt;!-- Alternatively TLS keys can be supplied via PEM files --&gt; &lt;privateKey&gt;file://encrypt/privkey.pem&lt;/privateKey&gt; &lt;certificates&gt;file://encrypt/fullchain.pem&lt;/certificates&gt; &lt;!-- An optional secret might be specified for the private key --&gt; &lt;!-- &lt;secret&gt;james72laBalle&lt;/secret&gt; --&gt; &lt;/tls&gt; &lt;connectionLimit&gt;0&lt;/connectionLimit&gt; &lt;connectionLimitPerIP&gt;0&lt;/connectionLimitPerIP&gt; &lt;idleTimeInterval&gt;120&lt;/idleTimeInterval&gt; &lt;idleTimeIntervalUnit&gt;SECONDS&lt;/idleTimeIntervalUnit&gt; &lt;enableIdle&gt;true&lt;/enableIdle&gt; &lt;auth&gt; &lt;plainAuthEnabled&gt;true&lt;/plainAuthEnabled&gt; &lt;/auth&gt; &lt;/imapserver&gt;&lt;/imapservers&gt; opensearch.properties12opensearch.masterHost=opensearch # opensearch的服务器连接IP和端口opensearch.port=9200 pop3server.xml主要调整SSL信息 1234567891011121314151617&lt;pop3servers&gt; &lt;pop3server enabled=&quot;false&quot;&gt; &lt;jmxName&gt;pop3server&lt;/jmxName&gt; &lt;bind&gt;0.0.0.0:110&lt;/bind&gt; &lt;connectionBacklog&gt;200&lt;/connectionBacklog&gt; &lt;tls socketTLS=&quot;false&quot; startTLS=&quot;false&quot;&gt; &lt;privateKey&gt;file://encrypt/privkey.pem&lt;/privateKey&gt; &lt;certificates&gt;file://encrypt/fullchain.pem&lt;/certificates&gt; &lt;/tls&gt; &lt;connectiontimeout&gt;1200&lt;/connectiontimeout&gt; &lt;connectionLimit&gt;0&lt;/connectionLimit&gt; &lt;connectionLimitPerIP&gt;0&lt;/connectionLimitPerIP&gt; &lt;handlerchain&gt; &lt;handler class=&quot;org.apache.james.pop3server.core.CoreCmdHandlerLoader&quot;/&gt; &lt;/handlerchain&gt; &lt;/pop3server&gt;&lt;/pop3servers&gt; rabbitmq.properties12uri=amqp://rabbitmq:5672 # rabbitmq的服务器连接IP和端口management.uri=http://rabbitmq:15672 # rabbitmq的服务器连接IP和端口 smtpserver.xml主要调整SSL秘钥信息，注意会有3处配置，记得把mail.域名.xx解析到服务器，注意格式 1234567891011&lt;connectionBacklog&gt;200&lt;/connectionBacklog&gt; &lt;tls socketTLS=&quot;false&quot; startTLS=&quot;true&quot;&gt; &lt;privateKey&gt;file://encrypt/privkey.pem&lt;/privateKey&gt; &lt;certificates&gt;file://encrypt/fullchain.pem&lt;/certificates&gt; &lt;/tls&gt; &lt;helo&gt; &lt;autodetect&gt;false&lt;/autodetect&gt; &lt;autodetectIP&gt;false&lt;/autodetectIP&gt; &lt;defaultFQDN&gt;mail.域名.xx&lt;/defaultFQDN&gt; &lt;/helo&gt; &lt;connectiontimeout&gt;360&lt;/connectiontimeout&gt; tika.properties1tika.host=tika # tika的服务器连接IP和端口 webadmin.properties修改IP和端口 12345678910 port=8000 #这里写0000就可以 host=0.0.0.0 #在文件最下面追加 # 启用功能模块mailbox.enabled=truemessage.enabled=true# 启用扩展路由（包括邮件操作 API）extensions.routes=org.apache.james.webadmin.routes.MailboxesRoutes,org.apache.james.webadmin.routes.MessagesRoutes jmap.properties123456789101112131415161718192021222324252627282930313233343536# Configuration file for JMAP# Read https://james.apache.org/server/config-jmap.html for further detailsenabled=truejmap.port=3000# tls.keystoreURL=file://conf/keystore# tls.secret=123456# Alternatively TLS keys can be supplied via PEM filestls.privateKey=file://encrypt/privkey.pemtls.certificates=file://encrypt/fullchain.pem# An optional secret might be specified for the private key# tls.secret=james72laBalle## If you wish to use OAuth authentication, you should provide a valid JWT public key.# The following entry specify the link to the URL of the public key file,# which should be a PEM format file.## jwt.publickeypem.url=file://conf/jwt_publickey# Should simple Email/query be resolved against a Cassandra projection, or should we resolve them against OpenSearch?# This enables a higher resilience, but the projection needs to be correctly populated. False by default.# view.email.query.enabled=true# If you want to specify authentication strategies for Jmap draft version# For custom Authentication Strategy not inside package &quot;org.apache.james.jmap.http&quot;, you have to specify its FQDN# authentication.strategy.draft=AccessTokenAuthenticationStrategy,JWTAuthenticationStrategy,QueryParameterAccessTokenAuthenticationStrategy# If you want to specify authentication strategies for Jmap rfc-8621 version# For custom Authentication Strategy not inside package &quot;org.apache.james.jmap.http&quot;, you have to specify its FQDN# authentication.strategy.rfc8621=JWTAuthenticationStrategy,BasicAuthenticationStrategy# Prevent server side request forgery by preventing calls to the private network ranges. Defaults to true, can be disabled for testing.# webpush.prevent.server.side.request.forgery=false 启动脚本james项目根目录新建bin目录，james-server.sh文件，代码如下 注意：1.JAMES_HOME最后面不要带斜杠2.提前创建好logs文件夹 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#!/bin/bash# 配置路径JAMES_HOME=&quot;/data/runTime/james/james382&quot;JAMES_CMD=&quot;java -Xms4g -Xmx8g -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m \\-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=40 -XX:+ParallelRefProcEnabled \\-XX:+UseStringDeduplication -Dworking.directory=. -Dlogback.configurationFile=conf/logback.xml \\-Djdk.tls.ephemeralDHKeySize=2048 -jar james-server-distributed-app.jar&quot;JAMES_LOG=&quot;$JAMES_HOME/logs/james.log&quot;PID_FILE=&quot;$JAMES_HOME/james.pid&quot;# 检查 PID 文件是否存在且有效is_running() &#123; if [ -f &quot;$PID_FILE&quot; ]; then PID=$(cat &quot;$PID_FILE&quot;) if kill -0 &quot;$PID&quot; 2&gt;/dev/null; then return 0 # 服务正在运行 else rm -f &quot;$PID_FILE&quot; # 清理无效的 PID 文件 fi fi return 1 # 服务未运行&#125;# 启动服务start() &#123; if is_running; then echo &quot;James is already running with PID $(cat &quot;$PID_FILE&quot;).&quot; exit 1 fi echo &quot;Starting James...&quot; cd &quot;$JAMES_HOME&quot; || exit 1 # 使用 setsid 启动服务并重定向日志 setsid $JAMES_CMD &gt;&gt; &quot;$JAMES_LOG&quot; 2&gt;&amp;1 &amp; echo $! &gt; &quot;$PID_FILE&quot; sleep 20 if is_running; then echo &quot;James started successfully with PID $(cat &quot;$PID_FILE&quot;).&quot; else echo &quot;Failed to start James. Check logs for details: $JAMES_LOG&quot; exit 1 fi&#125;# 停止服务stop() &#123; if ! is_running; then echo &quot;James is not running.&quot; exit 1 fi echo &quot;Stopping James...&quot; kill &quot;$(cat &quot;$PID_FILE&quot;)&quot; sleep 3 if ! is_running; then echo &quot;James stopped successfully.&quot; rm -f &quot;$PID_FILE&quot; else echo &quot;Failed to stop James.&quot; exit 1 fi&#125;# 重启服务restart() &#123; stop sleep 2 start&#125;# 检查服务状态status() &#123; if is_running; then echo &quot;James is running with PID $(cat &quot;$PID_FILE&quot;).&quot; else echo &quot;James is not running.&quot; fi&#125;# 清理旧日志cleanup_logs() &#123; echo &quot;Cleaning up old logs...&quot; find &quot;$JAMES_HOME/logs&quot; -type f -name &quot;*.log&quot; -mtime +7 -exec rm -f &#123;&#125; \\; echo &quot;Log cleanup completed.&quot;&#125;# 主逻辑case &quot;$1&quot; in start) start ;; stop) stop ;; restart) restart ;; status) status ;; cleanup-logs) cleanup_logs ;; *) echo &quot;Usage: $0 &#123;start|stop|restart|status|cleanup-logs&#125;&quot; exit 1 ;;esac 为脚本添加执行权限1sudo chmod +x bin/james-server.sh 启动James 服务1./bin/james-server.sh start 或者重启James 服务1./bin/james-server.sh restart 如果启动报错，查看一下证书12345678root@mail-test:/data/james/james382# cd encrypt/root@mail-test:/data/james/james382/encrypt# lltotal 8drwxrwxrwx 2 root root 4096 Feb 11 03:15 ./drwxr-xr-x 7 root root 4096 Feb 11 02:46 ../lrwxrwxrwx 1 root root 45 Feb 11 03:15 fullchain.pem -&gt; ../../archive/kretest.com-0001/fullchain1.pemlrwxrwxrwx 1 root root 43 Feb 11 03:15 privkey.pem -&gt; ../../archive/kretest.com-0001/privkey1.pemroot@mail-test:/data/james/james382/encrypt# 可以发现encrypt文件下的证书文件有问题，并不是真的存在，而是类似于一个软连接，且连接地址并不存在，倒回查看证书生成操作 手动启动根目录执行 1./bin/james-server.sh start 开机启动james开机启动可能会有问题，导致服务不停重启 可以考虑上面的手动启动 检查 james 是否已设置为开机自启 1sudo systemctl is-enabled james 1sudo nano /etc/systemd/system/james.service 添加内容 1234[Service]# 请确认系统中有该用户，或修改为合适的用户# Type=simple# User=james 12345678910111213141516171819202122232425[Unit]Description=Apache James Mail ServerAfter=network.targetRequires=network.target[Service]Type=forkingUser=rootGroup=rootWorkingDirectory=/data/runTime/james/james382# 使用脚本的参数启动服务ExecStart=/bin/bash /data/runTime/james/james382/bin/james.sh startExecStop=/bin/bash /data/runTime/james/james382/bin/james.sh stopExecReload=/bin/bash /data/runTime/james/james382/bin/james.sh restartPIDFile=/data/runTime/james/james382/james.pidRestart=on-failureRestartSec=5StartLimitIntervalSec=300StartLimitBurst=5[Install]WantedBy=multi-user.target 重载 systemd 配置 1sudo systemctl daemon-reload 开机启动并启动服务 12sudo systemctl enable jamessudo systemctl start james 关闭开机启动 1sudo systemctl disable james 检查 james 是否已设置为开机自启 1sudo systemctl is-enabled james 检查服务状态 1sudo systemctl status james 如果启动失败，则查看日志 1sudo journalctl -u james.service --since &quot;2 hours ago&quot; --no-pager 配置自动续期Let’s Encrypt 证书默认有效期为 90 天，Certbot 会自动续期。为了确保 James 使用的证书始终是最新的，需要在续期后重新加载 James 自动续期状态检测1sudo certbot renew --dry-run 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071root@mail-test:/# sudo certbot renew --dry-runSaving debug log to /var/log/letsencrypt/letsencrypt.log- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Processing /etc/letsencrypt/renewal/kretest.com-0001.conf- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Traceback (most recent call last): File &quot;/usr/lib/python3/dist-packages/certbot/renewal.py&quot;, line 65, in _reconstitute renewal_candidate = storage.RenewableCert(full_path, config) File &quot;/usr/lib/python3/dist-packages/certbot/storage.py&quot;, line 465, in __init__ self._check_symlinks() File &quot;/usr/lib/python3/dist-packages/certbot/storage.py&quot;, line 522, in _check_symlinks raise errors.CertStorageError(certbot.errors.CertStorageError: expected /etc/letsencrypt/live/kretest.com-0001/cert.pem to be a symlinkRenewal configuration file /etc/letsencrypt/renewal/kretest.com-0001.conf is broken. Skipping.- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Processing /etc/letsencrypt/renewal/kretest.com-0002.conf- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Cert not due for renewal, but simulating renewal for dry runPlugins selected: Authenticator nginx, Installer nginxRenewing an existing certificatePerforming the following challenges:http-01 challenge for kretest.comhttp-01 challenge for www.kretest.comWaiting for verification...Cleaning up challengesDry run: skipping deploy hook command: /etc/letsencrypt/renewal-hooks/deploy/restart-james.sh- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -new certificate deployed with reload of nginx server; fullchain is/etc/letsencrypt/live/kretest.com-0002/fullchain.pem- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Processing /etc/letsencrypt/renewal/kretest.com.conf- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Traceback (most recent call last): File &quot;/usr/lib/python3/dist-packages/certbot/renewal.py&quot;, line 65, in _reconstitute renewal_candidate = storage.RenewableCert(full_path, config) File &quot;/usr/lib/python3/dist-packages/certbot/storage.py&quot;, line 465, in __init__ self._check_symlinks() File &quot;/usr/lib/python3/dist-packages/certbot/storage.py&quot;, line 522, in _check_symlinks raise errors.CertStorageError(certbot.errors.CertStorageError: expected /etc/letsencrypt/live/kretest.com/cert.pem to be a symlinkRenewal configuration file /etc/letsencrypt/renewal/kretest.com.conf is broken. Skipping.- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -** DRY RUN: simulating &#x27;certbot renew&#x27; close to cert expiry** (The test certificates below have not been saved.)Congratulations, all renewals succeeded. The following certs have been renewed: /etc/letsencrypt/live/kretest.com-0002/fullchain.pem (success)Additionally, the following renewal configurations were invalid: /etc/letsencrypt/renewal/kretest.com-0001.conf (parsefail) /etc/letsencrypt/renewal/kretest.com.conf (parsefail)** DRY RUN: simulating &#x27;certbot renew&#x27; close to cert expiry** (The test certificates above have not been saved.)- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -0 renew failure(s), 2 parse failure(s)IMPORTANT NOTES: - Your account credentials have been saved in your Certbot configuration directory at /etc/letsencrypt. You should make a secure backup of this folder now. This configuration directory will also contain certificates and private keys obtained by Certbot so making regular backups of this folder is ideal.root@mail-test:/# 从输出日志中可以看出，Certbot 在尝试续期时遇到了两个问题： /etc/letsencrypt/renewal/kretest.com-0001.conf 和 /etc/letsencrypt/renewal/kretest.com.conf 配置文件损坏：错误信息表明，Certbot 期望 /etc/letsencrypt/live/kretest.com-0001/cert.pem 和 /etc/letsencrypt/live/kretest.com/cert.pem 是符号链接（symlink），但实际不是。这可能是由于手动修改了证书文件或符号链接被意外删除。kretest.com-0002 证书续期成功：该证书的续期测试成功，说明 Certbot 的配置和运行环境没有问题 删除损坏的配置文件 如果不需要这些证书，可以直接删除损坏的配置文件 12rm /etc/letsencrypt/renewal/kretest.com-0001.confrm /etc/letsencrypt/renewal/kretest.com.conf 重新获取证书（如果需要） 如果证书已损坏且无法修复，可以删除旧证书并重新获取 12sudo certbot delete --cert-name kretest.com-0001sudo certbot delete --cert-name kretest.com 再次执行 12345678910111213141516171819202122232425262728293031root@mail-test:/# sudo certbot renew --dry-runSaving debug log to /var/log/letsencrypt/letsencrypt.log- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Processing /etc/letsencrypt/renewal/kretest.com-0002.conf- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Cert not due for renewal, but simulating renewal for dry runPlugins selected: Authenticator nginx, Installer nginxRenewing an existing certificatePerforming the following challenges:http-01 challenge for kretest.comhttp-01 challenge for www.kretest.comWaiting for verification...Cleaning up challengesDry run: skipping deploy hook command: /etc/letsencrypt/renewal-hooks/deploy/restart-james.sh- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -new certificate deployed with reload of nginx server; fullchain is/etc/letsencrypt/live/kretest.com-0002/fullchain.pem- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -** DRY RUN: simulating &#x27;certbot renew&#x27; close to cert expiry** (The test certificates below have not been saved.)Congratulations, all renewals succeeded. The following certs have been renewed: /etc/letsencrypt/live/kretest.com-0002/fullchain.pem (success)** DRY RUN: simulating &#x27;certbot renew&#x27; close to cert expiry** (The test certificates above have not been saved.)- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -root@mail-test:/# 强制续期1sudo certbot renew --force-renewal 续期钩子重启james自动续期后重启 James 编辑 Certbot 的续期钩子脚本 1sudo nano /etc/letsencrypt/renewal-hooks/deploy/restart-james.sh 如果不存在这个脚本，则新建1个，restart-james.sh完整代码如下 123456789101112131415161718192021222324252627#!/bin/bash# 定义源和目标路径TARGET_DIR=&quot;/data/runTime/james/james382/encrypt/&quot;CERT_DIR=&quot;/etc/letsencrypt/live/mail.xx.com/&quot;# 定义文件名FILES=(&quot;fullchain.pem&quot; &quot;privkey.pem&quot;)# 遍历文件列表并复制for FILE in &quot;$&#123;FILES[@]&#125;&quot;; do # 如果目标文件已存在，先删除旧文件（可选） if [ -f &quot;$&#123;TARGET_DIR&#125;$&#123;FILE&#125;&quot; ]; then rm -f &quot;$&#123;TARGET_DIR&#125;$&#123;FILE&#125;&quot; fi # 复制新文件 cp -f &quot;$&#123;CERT_DIR&#125;$&#123;FILE&#125;&quot; &quot;$&#123;TARGET_DIR&#125;$&#123;FILE&#125;&quot; # 设置文件权限 chmod 600 &quot;$&#123;TARGET_DIR&#125;$&#123;FILE&#125;&quot;done# 重启 James 服务systemctl restart jamesecho &quot;SSL 文件已更新并重启 James 服务&quot; 为脚本添加执行权限1sudo chmod +x /etc/letsencrypt/renewal-hooks/deploy/restart-james.sh 密钥库方式（弃用）生成密钥库1keytool -genkey -alias james -keyalg RSA -keystore conf/keystore 这里为了方便测试密码设置的是 q12345678 12345678910111213141516171819root@mail-test:/data/james/james382# keytool -genkey -alias james -keyalg RSA -keystore conf/keystoreEnter keystore password: Re-enter new password: What is your first and last name? [Unknown]: xenWhat is the name of your organizational unit? [Unknown]: xenWhat is the name of your organization? [Unknown]: xenWhat is the name of your City or Locality? [Unknown]: xenWhat is the name of your State or Province? [Unknown]: xenWhat is the two-letter country code for this unit? [Unknown]: xenIs CN=xen, OU=xen, O=xen, L=xen, ST=xen, C=xen correct? [no]: yesroot@mail-test:/data/james/james382# 修改配置James默认配置文件在系统文件位于 ./conf 文件夹下 blob.properties主要需要调整 ObjectStorage on S3 模块，将之前搭建好的 S3 服务器配置信息填上去 12345bjectstorage.s3.endPoint=https://xx-xx.s3.amazonaws.com/mail/ # S3 的读取器地址，换成自己的IP和端口objectstorage.s3.bucketName=xx-xxobjectstorage.s3.region=us-east-1objectstorage.s3.accessKeyId=accessKey1 # S3 的accessKey（创建的时候有指定）objectstorage.s3.secretKey=secretKey1 # S3 的secretKey（创建的时候有指定） 修改后的blob.properties文件参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131# ============================================= BlobStore Implementation ==================================# Read https://james.apache.org/server/config-blobstore.html for further details# Choose your BlobStore implementation# Mandatory, allowed values are: cassandra, s3# *WARNING*: JAMES-3591 Cassandra is not made to store large binary content, its use will be suboptimal compared to# alternatives (namely S3 compatible BlobStores backed by for instance S3, MinIO or Ozone)implementation=s3# ========================================= Deduplication ========================================# If you choose to enable deduplication, the mails with the same content will be stored only once.# Warning: Once this feature is enabled, there is no turning back as turning it off will lead to the deletion of all# the mails sharing the same content once one is deleted.# Mandatory, Allowed values are: true, falsededuplication.enable=false# deduplication.family needs to be incremented every time the deduplication.generation.duration is changed# Positive integer, defaults to 1# deduplication.gc.generation.family=1# Duration of generation.# Deduplication only takes place within a singe generation.# Only items two generation old can be garbage collected. (This prevent concurrent insertions issues and# accounts for a clock skew).# deduplication.family needs to be incremented everytime this parameter is changed.# Duration. Default unit: days. Defaults to 30 days.# deduplication.gc.generation.duration=30days# ========================================= Encryption ========================================# If you choose to enable encryption, the blob content will be encrypted before storing them in the BlobStore.# Warning: Once this feature is enabled, there is no turning back as turning it off will lead to all content being# encrypted. This comes at a performance impact but presents you from leaking data if, for instance the third party# offering you a S3 service is compromised.# Optional, Allowed values are: true, false, defaults to falseencryption.aes.enable=false# Mandatory (if AES encryption is enabled) salt and password. Salt needs to be an hexadecimal encoded string#encryption.aes.password=xxx#encryption.aes.salt=73616c7479# Optional, defaults to PBKDF2WithHmacSHA512#encryption.aes.private.key.algorithm=PBKDF2WithHmacSHA512# ========================================= Cassandra BlobStore Cache ======================================# A cassandra cache can be enabled to reduce latency when reading small blobs frequently# A dedicated keyspace with a replication factor of one is then used# Cache eviction policy is TTL based# Only blobs below a given threshold will be stored.# To be noted that blobs are stored within a single Cassandra row, hence a low threshold should be used.# Enable the cache? Optional and default to false. Must be a boolean.cache.enable=false# Cache eviction policy is TTL based. Optional and defaults to 7 days. Must be a duration.# Valid units: ms, sec, min, hour, day, week, month, year# cache.cassandra.ttl=7days# Timeout after which this cache should be bypassed. Optional and defaults to 100ms. Can not exceed 1 hour.# Must be a duration Valid units: ms, sec, min, hour, day, week, month, year# cache.cassandra.timeout=100ms# Maximum size of stored objects expressed in bytes. Must be strictly positive. Defaults to 8192.# Units: bytes, Kib, MiB, GiB, TiB# cache.sizeThresholdInBytes=8 KiB# ============================================== ObjectStorage ============================================# ========================================= ObjectStorage Buckets ==========================================# bucket names prefix# Optional, default no prefix# objectstorage.bucketPrefix=prod-# Default bucket name# Optional, default is bucketPrefix + `default`# objectstorage.namespace=james# ========================================= ObjectStorage on S3 =============================================# Mandatory if you choose s3 storage service, S3 authentication endpoint#objectstorage.s3.endPoint=http://xx.xx.0.6:8000/objectstorage.s3.endPoint=https://xxx-mail.s3.amazonaws.com/mail/# AWS S3 å­å¨æ¡¶åç§°objectstorage.s3.bucketName=xxx-mail# Mandatory if you choose s3 storage service, S3 region#objectstorage.s3.region=eu-west-1objectstorage.s3.region=us-east-1# Mandatory if you choose aws-s3 storage service, access key id configured in S3objectstorage.s3.accessKeyId=xxx# Mandatory if you choose s3 storage service, secret key configured in S3objectstorage.s3.secretKey=xx/xxx# Optional if you choose s3 storage service: The trust store file, secret, and algorithm to use# when connecting to the storage service. If not specified falls back to Java defaults.#objectstorage.s3.truststore.path=#objectstorage.s3.truststore.type=JKS#objectstorage.s3.truststore.secret=#objectstorage.s3.truststore.algorithm=SunX509# optional: Object read in memory will be rejected if they exceed the size limit exposed here. Size, exemple `100M`.# Supported units: K, M, G, defaults to B if no unit is specified. If unspecified, big object won&#x27;t be prevented# from being loaded in memory. This settings complements protocol limits.# objectstorage.s3.in.read.limit=50M# ============================================ Blobs Exporting ==============================================# Read https://james.apache.org/server/config-blob-export.html for further details# Choosing blob exporting mechanism, allowed mechanism are: localFile, linshare# LinShare is a file sharing service, will be explained in the below section# Optional, default is localFileblob.export.implementation=localFile# ======================================= Local File Blobs Exporting ========================================# Optional, directory to store exported blob, directory path follows James file system format# default is file://var/blobExportingblob.export.localFile.directory=file://var/blobExporting# ======================================= LinShare File Blobs Exporting ========================================# LinShare is a sharing service where you can use james, connects to an existing LinShare server and shares files to# other mail addresses as long as those addresses available in LinShare. For example you can deploy James and LinShare# sharing the same LDAP repository# Mandatory if you choose LinShare, url to connect to LinShare service# blob.export.linshare.url=http://linshare:8080# ======================================= LinShare Configuration BasicAuthentication ===================================# Authentication is mandatory if you choose LinShare, TechnicalAccount is need to connect to LinShare specific service.# For Example: It will be formalized to &#x27;Authorization: Basic &#123;Credential of UUID/password&#125;&#x27;# blob.export.linshare.technical.account.uuid=Technical_Account_UUID# blob.export.linshare.technical.account.password=password cassandra.properties如果用的是Docker容器里的环境，先获取cassandra的ip，否则直接写对应的环境ip 12345678root@mail-test:/data/james/james382/conf# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES13447441cafe apache/tika &quot;/bin/sh -c &#x27;exec ja…&quot; 41 minutes ago Up 41 minutes 0.0.0.0:9998-&gt;9998/tcp, :::9998-&gt;9998/tcp tikaec1302b389dd zenko/cloudserver:8.2.6 &quot;/usr/src/app/docker…&quot; 42 minutes ago Up 42 minutes 8000/tcp s3c25c0f731ca5 rabbitmq:3.9.18-management &quot;docker-entrypoint.s…&quot; 43 minutes ago Up 43 minutes 4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, :::5672-&gt;5672/tcp, 15671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp, :::15672-&gt;15672/tcp rabbitmqd4fcf76d86f9 opensearchproject/opensearch:2.1.0 &quot;./opensearch-docker…&quot; 2 hours ago Up 2 hours 9300/tcp, 9600/tcp, 0.0.0.0:9200-&gt;9200/tcp, :::9200-&gt;9200/tcp, 9650/tcp opensearch7efb7cd0942e cassandra:3.11.10 &quot;docker-entrypoint.s…&quot; 2 hours ago Up 2 hours 7000-7001/tcp, 7199/tcp, 9160/tcp, 0.0.0.0:9042-&gt;9042/tcp, :::9042-&gt;9042/tcp cassandraroot@mail-test:/data/james/james382/conf# 123456root@mail-test:/data/james/james382/conf# docker ps -q | xargs -n 1 docker inspect --format &#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125; &#123;&#123;.Name&#125;&#125;&#x27; | sed &#x27;s/ \\// /&#x27;172.17.0.2 tika172.18.0.5 s3172.18.0.4 rabbitmq172.18.0.3 opensearch172.18.0.2 cassandra 123cassandra.nodes=cassandra # cassandra 的服务器地址信息，如172.19.0.2:9042#集群的话用逗号隔开，例如 x.x.x.6:9042,x.x.x.7:9042,x.x.x.8:9042#cassandra.replication.factor=1这个数字等于机器数量，假设上面的集群3台机器，这里就写3 imapserver.xml主要调整SSL秘钥信息，注意会有2处配置（秘钥信息请看步骤3） 1234&lt;keystore&gt;file://conf/keystore&lt;/keystore&gt;&lt;keystoreType&gt;PKCS12&lt;/keystoreType&gt;#改这个密码&lt;secret&gt;james72laBalle&lt;/secret&gt; opensearch.properties12opensearch.masterHost=opensearch # opensearch的服务器连接IP和端口opensearch.port=9200 pop3server.xml主要调整SSL秘钥信息（秘钥信息请看步骤3） 1234&lt;keystore&gt;file://conf/keystore&lt;/keystore&gt;&lt;keystoreType&gt;PKCS12&lt;/keystoreType&gt;#改这个密码&lt;secret&gt;james72laBalle&lt;/secret&gt; rabbitmq.properties12uri=amqp://rabbitmq:5672 # rabbitmq的服务器连接IP和端口management.uri=http://rabbitmq:15672 # rabbitmq的服务器连接IP和端口 smtpserver.xml主要调整SSL秘钥信息，注意会有多处配置（秘钥信息请看步骤3） 123&lt;keystore&gt;file://conf/keystore&lt;/keystore&gt;&lt;keystoreType&gt;PKCS12&lt;/keystoreType&gt;&lt;secret&gt;james72laBalle&lt;/secret&gt; tika.properties1tika.host=tika # tika的服务器连接IP和端口 webadmin.properties修改IP和端口 12345678910 port=8000 #这里写0000就可以 host=0.0.0.0 #在文件最下面追加 # 启用功能模块mailbox.enabled=truemessage.enabled=true# 启用扩展路由（包括邮件操作 API）extensions.routes=org.apache.james.webadmin.routes.MailboxesRoutes,org.apache.james.webadmin.routes.MessagesRoutes jmap.properties12345tls.keystoreURL=file://conf/keystore （秘钥信息请看步骤3）#改这个密码tls.secret=james72laBalle#加上这个jmap.port=3000 启动 James进入到 James 项目根目录执行命令 1java -Dworking.directory=. -Dlogback.configurationFile=conf/logback.xml -Djdk.tls.ephemeralDHKeySize=2048 -jar james-server-distributed-app.jar &amp; 配置 DKIM生成 DKIM 密钥对： 在 James 服务器上生成一个 DKIM 密钥对 在James的根目录执行 12openssl genrsa -out private.key 2048openssl rsa -in private.key -pubout -out public.key 配置 James 使用 DKIM 签名 将生成的 private.key 和 public.key 移动到conf目录中 配置 conf/dkim.properties 没有就创建 1234vim conf/dkim.propertiesdkim.domain=域名.后缀dkim.selector=defaultdkim.privateKeyPath=./conf/private.key 添加 DKIM 公钥到 DNS 将 public.key 的内容添加到域名的 DNS TXT 记录中。TXT 记录的名称为：default._domainkeyTXT 记录的值：v=DKIM1; k=rsa; p= 值示例:v=DKIM1; k=rsa; p=公钥的内容 验证 DKIM 是否生效： 使用 DKIM 验证工具（如 DKIM Core）测试 DNS 配置是否正确 1dig default._domainkey.域名.后缀 TXT 修改/data/runTime/james/james382/conf目录下的配置文件mailetcontainer.xml 在配置文件中找到在它下面新增这一段，私钥左对齐， d=kretest.com这里需要更改为实际域名 123456789101112131415161718192021222324 &lt;mailet match=&quot;All&quot; class=&quot;org.apache.james.jdkim.mailets.DKIMSign&quot;&gt; &lt;signatureTemplate&gt;v=1; s=default; d=kretest.com; h=from : to : subject : date : message-id; a=rsa-sha256; bh=; b=;&lt;/signatureTemplate&gt; &lt;privateKey&gt;-----BEGIN RSA PRIVATE KEY-----MIIEpAIBAAKCAQEA04P/Qkn33jmKI19rp8cs9XLNKEUvFNl5YCJdMg1TtBFvN98qmWcxvkbanlxLSIrdO4hJpmMP8E171/aO/ZfWGrVExbmC/Y8fFi29kmBPvyTcgPmDryAQvlC4eRldOGaUNYQmUIql/zFNzC35nESAgaTeNCP68qlHwtXj0nonmPooWZOlA5L+y5+dq6WNi43QXnA4DMqPQ+nMwBYpXjcgTePb10sJqtC1K6R7iEy6Prjbg9jkLlh/YQti81hCV5/ZTtFtqVb2AheQmHbj2hgMHc2dJIGjFfRJOvVulMI8twxpBcwfZymDwC3KLfcNYP630ddH6EQvtJT29sJfpGJME05epH5Z4pIAUeBVvQ+AO7MAn7JiH5fuXBsgxrZ7rFjrjNBUgCjHwoOjVk06FcRj9YAL1a78a4cR6UzuzDfhw+Of0/+aDi2jHoHwfOoJIasYRIgzb+J2bnnQxQxaKbFqQgMCgYEAuqn9tNcwEmCXBUEhBgnW+FGUnSSHlXsYhqv7kRcRTo5nGV6di6eNXKGzE85aZ/uIKCsC6WES/oRtk2nvArArIfdLXrVXIf8h1R9DAfMPdu2i3ReQuDtc3QjMEgKpLIwwuq/YW1KyrZhkyQhdvBdvpmGdL97zIekNpvOSKIJba38CgYBTcpjDRkMN6SV8u0HKuuxoC6ZaXPFsByGopd6+9tidpe/j+ovYj8Pb4rKCERnq+flFwnk36U1VAY+cATKxnvX/SxE/MYR25tgfJl9Lxs01O7hXc/tTvbTo0LqG6xs01CsWknoE/RNPWb+TKg05nKAW7eekWpCZiDFx2qKH93Mx7QKBgQDb6yo7Y7EqhF88ht7NSFLF0QVSaQFhzQYhShQv0soZj//2n1FIVFKnl1u3kAd3UUwYc93zoWKrRIAzmVrQ/QYPGo3N9mADUBLjX84eQsywVjRhvuiCNRexnq2fbAR8ef49TIos3PJN8EJO6Q+uCeN5sEaFC5XJqL0W1IFIts/ojQ==-----END RSA PRIVATE KEY-----&lt;/privateKey&gt;&lt;/mailet&gt; 完整配置参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. --&gt;&lt;!-- Read https://james.apache.org/server/config-mailetcontainer.html for further details --&gt;&lt;mailetcontainer enableJmx=&quot;true&quot;&gt; &lt;context&gt; &lt;!-- When the domain part of the postmaster mailAddress is missing, the default domain is appended. You can configure it to (for example) &lt;postmaster&gt;postmaster@myDomain.com&lt;/postmaster&gt; --&gt; &lt;postmaster&gt;postmaster&lt;/postmaster&gt; &lt;/context&gt; &lt;spooler&gt; &lt;threads&gt;20&lt;/threads&gt; &lt;errorRepository&gt;cassandra://var/mail/error/&lt;/errorRepository&gt; &lt;/spooler&gt; &lt;processors&gt; &lt;processor state=&quot;root&quot; enableJmx=&quot;true&quot;&gt; &lt;mailet match=&quot;All&quot; class=&quot;PostmasterAlias&quot;/&gt; &lt;mailet match=&quot;RelayLimit=30&quot; class=&quot;Null&quot;/&gt; &lt;mailet match=&quot;All&quot; class=&quot;ToProcessor&quot;&gt; &lt;processor&gt;transport&lt;/processor&gt; &lt;/mailet&gt; &lt;/processor&gt; &lt;processor state=&quot;error&quot; enableJmx=&quot;true&quot;&gt; &lt;mailet match=&quot;All&quot; class=&quot;MetricsMailet&quot;&gt; &lt;metricName&gt;mailetContainerErrors&lt;/metricName&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;Bounce&quot;&gt; &lt;onMailetException&gt;ignore&lt;/onMailetException&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;ToRepository&quot;&gt; &lt;repositoryPath&gt;cassandra://var/mail/error/&lt;/repositoryPath&gt; &lt;onMailetException&gt;propagate&lt;/onMailetException&gt; &lt;/mailet&gt; &lt;/processor&gt; &lt;processor state=&quot;transport&quot; enableJmx=&quot;true&quot;&gt; &lt;!-- &lt;mailet match=&quot;All&quot; class=&quot;org.apache.james.jdkim.mailets.DKIMSign&quot;&gt; &lt;signatureTemplate&gt;v=1; s=default; d=touchsmail.com; h=from:to:received:received; a=rsa-sha256; bh=; b=;&lt;/signatureTemplate&gt; &lt;privateKeyFilepath&gt;file://dkim/dkim_private.key&lt;/privateKeyFilepath&gt; &lt;forceCRLF&gt;false&lt;/forceCRLF&gt; &lt;debug&gt;true&lt;/debug&gt; &lt;/mailet&gt;--&gt; &lt;mailet match=&quot;All&quot; class=&quot;org.apache.james.jdkim.mailets.DKIMSign&quot;&gt; &lt;signatureTemplate&gt;v=1; s=default; d=xxx.com; h=from : to : subject : date : message-id; a=rsa-sha256; bh=; b=;&lt;/signatureTemplate&gt; &lt;privateKey&gt;-----BEGIN RSA PRIVATE KEY-----MIIEpAIBAAKCAQEA5C+HETgshKcHrSuuodJYph+3j4eHkrcvALTKsnGqDPrR4V0CRsofqHlgO4JyDuZLKcwVj6J7R34b0L2se8+CIkakpllFXkZ7FfAw/71yCzJJ5KhLEoZIwE5G+ay8R3On7TDjIDeMRKTtxkYEa/2MlOyG5T4x6cW82mT1oYWz7WMBOOeTTRTa/e0KNkvLzuGpLSETyOn0qKXmVe0JyTtCqQx9fgToIIUbCNXCTmei3U3eEajjXa1KhmyeKSL+L0M6Gdj5B267NGTXVQlLTBwOLFduGpkNJIKeQk7EOo7FvKYVFct/UZd90ygTSTQ0GR4QUP1Wup2ESXSvYBie0idkJGiLrtEWpWsFbiyH+CbajMypaGSq5U0OmtFbbDZ++8T724/mvDThTwbhVIaw+d9NZr60Yg6B91rPaUoCpxAsXK8WkrZoUEmL/mS6M2jrLOX7tiYJdwKBgQCvhnSJNWngeg9VjIRWEc80kiNsbqOnHpbePgvjQw1h0LkCAffQ9uq2U13IUMZYOdpgvgykLVeCAzrQAzjvS/GyuurFXRZ2EhXphVvkj/q4/y0ZkNO3veYB+lICwJtXfwlqzKgIcKX2j7c7RcEUxFoKInR9A+YsLX8DDEelKHKmGQKBgQCD+7xpDVpR6N082QPl7A4IEh2S9bRz1b135ipbi4Oks8Xgu+JxWMq0J7uAAA258xD2T5REfW4fKuIXzSNBo2ovEHcpqSt6jGvc5rCBYPV6Q3CDmRMu8pSVagtW9gaNnxJUo3BYc55L+sPNjDZsmZSe+TekJZ9tCgGBcosZM+PMwQ==-----END RSA PRIVATE KEY-----&lt;/privateKey&gt;&lt;/mailet&gt; &lt;matcher name=&quot;relay-allowed&quot; match=&quot;org.apache.james.mailetcontainer.impl.matchers.Or&quot;&gt; &lt;matcher match=&quot;SMTPAuthSuccessful&quot;/&gt; &lt;matcher match=&quot;SMTPIsAuthNetwork&quot;/&gt; &lt;matcher match=&quot;SentByMailet&quot;/&gt; &lt;matcher match=&quot;org.apache.james.jmap.mailet.SentByJmap&quot;/&gt; &lt;/matcher&gt; &lt;mailet match=&quot;All&quot; class=&quot;RemoveMimeHeader&quot;&gt; &lt;name&gt;bcc&lt;/name&gt; &lt;onMailetException&gt;ignore&lt;/onMailetException&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;RecipientRewriteTable&quot;&gt; &lt;errorProcessor&gt;rrt-error&lt;/errorProcessor&gt; &lt;/mailet&gt; &lt;mailet match=&quot;RecipientIsLocal&quot; class=&quot;ToProcessor&quot;&gt; &lt;processor&gt;local-delivery&lt;/processor&gt; &lt;/mailet&gt; &lt;mailet match=&quot;HostIsLocal&quot; class=&quot;ToProcessor&quot;&gt; &lt;processor&gt;local-address-error&lt;/processor&gt; &lt;notice&gt;550 - Requested action not taken: no such user here&lt;/notice&gt; &lt;/mailet&gt; &lt;mailet match=&quot;relay-allowed&quot; class=&quot;ToProcessor&quot;&gt; &lt;processor&gt;relay&lt;/processor&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;ToProcessor&quot;&gt; &lt;processor&gt;relay-denied&lt;/processor&gt; &lt;/mailet&gt; &lt;/processor&gt; &lt;processor state=&quot;local-delivery&quot; enableJmx=&quot;true&quot;&gt; &lt;mailet match=&quot;All&quot; class=&quot;VacationMailet&quot;&gt; &lt;onMailetException&gt;ignore&lt;/onMailetException&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;Sieve&quot;&gt; &lt;onMailetException&gt;ignore&lt;/onMailetException&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;AddDeliveredToHeader&quot;/&gt; &lt;mailet match=&quot;All&quot; class=&quot;org.apache.james.jmap.mailet.filter.JMAPFiltering&quot;&gt; &lt;onMailetException&gt;ignore&lt;/onMailetException&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;LocalDelivery&quot;/&gt; &lt;/processor&gt; &lt;processor state=&quot;relay&quot; enableJmx=&quot;true&quot;&gt; &lt;mailet match=&quot;All&quot; class=&quot;RemoteDelivery&quot;&gt; &lt;outgoingQueue&gt;outgoing&lt;/outgoingQueue&gt; &lt;delayTime&gt;5000, 100000, 500000&lt;/delayTime&gt; &lt;maxRetries&gt;3&lt;/maxRetries&gt; &lt;maxDnsProblemRetries&gt;0&lt;/maxDnsProblemRetries&gt; &lt;deliveryThreads&gt;10&lt;/deliveryThreads&gt; &lt;sendpartial&gt;true&lt;/sendpartial&gt; &lt;bounceProcessor&gt;bounces&lt;/bounceProcessor&gt; &lt;/mailet&gt; &lt;/processor&gt; &lt;processor state=&quot;local-address-error&quot; enableJmx=&quot;true&quot;&gt; &lt;mailet match=&quot;All&quot; class=&quot;MetricsMailet&quot;&gt; &lt;metricName&gt;mailetContainerLocalAddressError&lt;/metricName&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;Bounce&quot;&gt; &lt;attachment&gt;none&lt;/attachment&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;ToRepository&quot;&gt; &lt;repositoryPath&gt;cassandra://var/mail/address-error/&lt;/repositoryPath&gt; &lt;/mailet&gt; &lt;/processor&gt; &lt;processor state=&quot;relay-denied&quot; enableJmx=&quot;true&quot;&gt; &lt;mailet match=&quot;All&quot; class=&quot;MetricsMailet&quot;&gt; &lt;metricName&gt;mailetContainerRelayDenied&lt;/metricName&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;Bounce&quot;&gt; &lt;attachment&gt;none&lt;/attachment&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;ToRepository&quot;&gt; &lt;repositoryPath&gt;cassandra://var/mail/relay-denied/&lt;/repositoryPath&gt; &lt;notice&gt;Warning: You are sending an e-mail to a remote server. You must be authenticated to perform such an operation&lt;/notice&gt; &lt;/mailet&gt; &lt;/processor&gt; &lt;processor state=&quot;bounces&quot; enableJmx=&quot;true&quot;&gt; &lt;mailet match=&quot;All&quot; class=&quot;MetricsMailet&quot;&gt; &lt;metricName&gt;bounces&lt;/metricName&gt; &lt;/mailet&gt; &lt;mailet match=&quot;All&quot; class=&quot;DSNBounce&quot;&gt; &lt;passThrough&gt;false&lt;/passThrough&gt; &lt;/mailet&gt; &lt;/processor&gt; &lt;processor state=&quot;rrt-error&quot; enableJmx=&quot;false&quot;&gt; &lt;mailet match=&quot;All&quot; class=&quot;ToRepository&quot;&gt; &lt;repositoryPath&gt;cassandra://var/mail/rrt-error/&lt;/repositoryPath&gt; &lt;passThrough&gt;true&lt;/passThrough&gt; &lt;/mailet&gt; &lt;mailet match=&quot;IsSenderInRRTLoop&quot; class=&quot;Null&quot;/&gt; &lt;mailet match=&quot;All&quot; class=&quot;Bounce&quot;/&gt; &lt;/processor&gt; &lt;/processors&gt;&lt;/mailetcontainer&gt; 修改后重启james 12./bin/james-server.sh stop./bin/james-server.sh start 安装 James 客户端James 客户端需要 James 源代码中自己编译打包后运行，步骤如下 源码包 下载1wget https://dlcdn.apache.org/james/server/3.8.2/james-project-3.8.2-source-release.zip 解压并进入目录123456root@mail-test:/data/james# unzip james-project-3.8.2-source-release.ziproot@mail-test:/data/james# mv james-project-3.8.2 james-projectroot@mail-test:/data/james# lsjames-project james-project-3.8.2-source-release.zip james382root@mail-test:/data/james# cd james-project/server/apps/webadmin-cliroot@mail-test:/data/james/james-project/server/apps/webadmin-cli# 打包编译1mvn clean package -Dmaven.test.skip=true 进入客户端目录1234root@mail-test:/data/james/james-project# cd server/apps/webadmin-cli/root@mail-test:/data/james/james-project/server/apps/webadmin-cli# lsREADME.md james-cli pom.xml src targetroot@mail-test:/data/james/james-project/server/apps/webadmin-cli# 添加域1./james-cli --url http://127.0.0.1:9999 domain create &lt;domainToBeCreated&gt; 执行之前先确认james服务正在运行，我执行报错了，且确认james服务正在运行中，报错信息如下 1234567891011121314151617181920212223242526272829303132333435root@mail-test:/data/james/james-project/server/apps/webadmin-cli# ./james-cli --url http://127.0.0.1:9999 domain create kretest.comSLF4J: No SLF4J providers were found.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.feign.RetryableException: Unexpected end of file from server executing PUT http://127.0.0.1:9999/domains/kretest.com at feign.FeignException.errorExecuting(FeignException.java:268) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:131) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:91) at feign.ReflectiveFeign$FeignInvocationHandler.invoke(ReflectiveFeign.java:100) at com.sun.proxy.$Proxy9.createADomain(Unknown Source) at org.apache.james.webadmin.httpclient.DomainClient.createADomain(DomainClient.java:43) at org.apache.james.cli.domain.DomainCreateCommand.call(DomainCreateCommand.java:41) at org.apache.james.cli.domain.DomainCreateCommand.call(DomainCreateCommand.java:28) at picocli.CommandLine.executeUserObject(CommandLine.java:1953) at picocli.CommandLine.access$1300(CommandLine.java:145) at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2358) at picocli.CommandLine$RunLast.handle(CommandLine.java:2352) at picocli.CommandLine$RunLast.handle(CommandLine.java:2314) at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2179) at picocli.CommandLine$RunLast.execute(CommandLine.java:2316) at picocli.CommandLine.execute(CommandLine.java:2078) at org.apache.james.cli.WebAdminCli.execute(WebAdminCli.java:79) at org.apache.james.cli.WebAdminCli.main(WebAdminCli.java:67)Caused by: java.net.SocketException: Unexpected end of file from server at java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:917) at java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:724) at java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:914) at java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:724) at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1652) at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1557) at java.base/java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527) at feign.Client$Default.convertResponse(Client.java:110) at feign.Client$Default.execute(Client.java:106) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:121) ... 16 more 查看之前配置的webadmin.properties文件，发现我配置的端口是8000，修改后执行如下 12345root@mail-test:/data/james/james-project/server/apps/webadmin-cli# ./james-cli --url http://127.0.0.1:8000 domain create kretest.comSLF4J: No SLF4J providers were found.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.root@mail-test:/data/james/james-project/server/apps/webadmin-cli# 查看域列表1./james-cli --url http://127.0.0.1:8000 domain list 1234567root@mail-test:/data/james/james-project/server/apps/webadmin-cli# ./james-cli --url http://127.0.0.1:8000 domain listSLF4J: No SLF4J providers were found.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.kretest.comlocalhostroot@mail-test:/data/james/james-project/server/apps/webadmin-cli# 添加用户1./james-cli --url http://127.0.0.1:9999 user create &lt;username&gt; --password 示例 123456root@mail-test:/data/james/james-project/server/apps/webadmin-cli# ./james-cli --url http://127.0.0.1:8000 user create x@xx.com --passwordEnter value for --password (Password): SLF4J: No SLF4J providers were found.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.The user was created successfully 查看用户列表1./james-cli --url http://127.0.0.1:8000 user list 更多指令更多指令 测试James这里用的thunderbird客户端 thunderbird 打开客户端输入昵称 输入上面创建的邮箱账号 输入邮箱密码 登陆测试 第一次发送邮件测试报错，报错信息为证书不匹配之类的错误，后面又发送了几次，除开第一次，其他的都成功了 如果收件箱没看到邮箱，可以看一下垃圾箱 测试完发件功能，测试收件，发现收不到邮件 防火墙需要打开以下端口 25,110,143,465,587,993,995 opensearch查看邮件1curl -X POST &quot;http://mail.xx.ai:9200/mailbox_v1/_search&quot; -H &quot;Content-Type: application/json&quot; -d &#x27;&#123;&quot;aggregations&quot;:&#123;&quot;unique_message_count&quot;:&#123;&quot;cardinality&quot;:&#123;&quot;field&quot;:&quot;mimeMessageID&quot;&#125;&#125;&#125;,&quot;collapse&quot;:&#123;&quot;field&quot;:&quot;mimeMessageID&quot;&#125;,&quot;from&quot;:0,&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;minimum_should_match&quot;:&quot;1&quot;,&quot;should&quot;:[&#123;&quot;term&quot;:&#123;&quot;from.address.raw&quot;:&#123;&quot;value&quot;:&quot;test007@xx.ai&quot;&#125;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;to.address.raw&quot;:&#123;&quot;value&quot;:&quot;test007@xx.ai&quot;&#125;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;cc.address.raw&quot;:&#123;&quot;value&quot;:&quot;test007@xx.ai&quot;&#125;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;bcc.address.raw&quot;:&#123;&quot;value&quot;:&quot;test007@xx.ai&quot;&#125;&#125;&#125;,&#123;&quot;nested&quot;:&#123;&quot;path&quot;:&quot;headers&quot;,&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;must&quot;:[&#123;&quot;term&quot;:&#123;&quot;headers.name&quot;:&#123;&quot;value&quot;:&quot;delivered-to&quot;&#125;&#125;&#125;,&#123;&quot;term&quot;:&#123;&quot;headers.value&quot;:&#123;&quot;value&quot;:&quot;test007@xx.ai&quot;&#125;&#125;&#125;]&#125;&#125;&#125;&#125;]&#125;&#125;,&quot;size&quot;:5,&quot;sort&quot;:[&#123;&quot;date&quot;:&#123;&quot;order&quot;:&quot;desc&quot;&#125;&#125;]&#125;&#x27;","tags":["笔记"],"categories":["James"]},{"title":"jpom构建前端vue后自动部署，消息推送","path":"/2025/02/06/2025020605/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# !/bin/bashAPP_DIR=&quot;/data/apps/webmail&quot;BIN_DIR=&quot;$APP_DIR&quot;LOG_DIR=&quot;$APP_DIR/logs&quot;LOG_FILE=&quot;$LOG_DIR/info.log&quot;NEW_PRO=&quot;dist&quot;feishu_webhook=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/token1&quot;feishu_webhook2=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/token2&quot;export TZ=&quot;Asia/Shanghai&quot;mkdir -p $BIN_DIR $LOG_DIR# 推送到飞书function push_to_feishu() &#123; content=&quot;$1&quot; cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) message=&quot;状态：$&#123;content&#125; &quot; message+=&quot;时间：$&#123;cur_datetime&#125;&quot; read -r -d &#x27;&#x27; json_payload &lt;&lt;EOF&#123; &quot;msg_type&quot;: &quot;text&quot;, &quot;content&quot;: &#123; &quot;text&quot;: &quot;$&#123;message&#125;&quot; &#125;&#125;EOF echo &quot;&gt;&gt;&gt; JSON Payload: $&#123;json_payload&#125;&quot;#response=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook&#125;&quot;)#echo &quot;&gt;&gt;&gt; 飞书响应: $&#123;response&#125; &lt;&lt;&lt;&quot;#response2=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook2&#125;&quot;)#echo &quot;&gt;&gt;&gt; 飞书响应2: $&#123;response2&#125; &lt;&lt;&lt;&quot;&#125;cleanup_logs() &#123; push_to_feishu &quot;正在清理 15 天前的日志...&quot; echo &quot;正在清理 15 天前的日志...&quot; &gt;&gt; $LOG_FILE find $LOG_DIR -type f -mtime +15 -exec rm -f &#123;&#125; \\; push_to_feishu &quot;日志清理完成...&quot; echo &quot;日志清理完成。&quot; &gt;&gt; $LOG_FILE&#125;# 主逻辑echo &quot;======== 前端部署开始 $(date) ========&quot; &gt; $LOG_FILEpush_to_feishu &quot;打包完成&quot;push_to_feishu &quot;前端部署开始&quot;BUILD_JAR_PATH=$(pwd)cd $APP_DIR || &#123; echo &quot;目录 $APP_DIR 不存在！&quot; &gt;&gt; $LOG_FILE; exit 1; &#125;rm -rf $APP_DIR/$NEW_PROmv $BUILD_JAR_PATH/$NEW_PRO $BIN_DIR/ &gt; $LOG_FILE 2&gt;&amp;1push_to_feishu &quot;正在移动前端项目，0表示成功，移动结果$?...&quot;ficleanup_logspush_to_feishu &quot;前端部署完成...&quot;echo &quot;======== 前端部署完成 $(date) ========&quot; &gt;&gt; $LOG_FILE 前端构建命令 1npm i &amp;&amp; npm run build 产物目录: dist","tags":["笔记"],"categories":["其他"]},{"title":"jpom构建java服务后自动部署，回滚，消息推送","path":"/2025/02/06/2025020603/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164# !/bin/bashAPP_DIR=&quot;/data/apps/touchs&quot;BIN_DIR=&quot;$APP_DIR/bin&quot;HISTORY_DIR=&quot;$BIN_DIR/history&quot;LOG_DIR=&quot;$APP_DIR/logs&quot;LOG_FILE=&quot;$LOG_DIR/info.log&quot;JAR_NAME=&quot;touchs.jar&quot;NEW_JAR=&quot;target/$JAR_NAME&quot;feishu_webhook=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/token1&quot;feishu_webhook2=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/token2&quot;export TZ=&quot;Asia/Shanghai&quot;mkdir -p $BIN_DIR $HISTORY_DIR $LOG_DIRbackup_old_version() &#123; if [ -f &quot;$BIN_DIR/$JAR_NAME&quot; ]; then TIMESTAMP=$(date +%Y%m%d%H%M%S) BACKUP_NAME=&quot;$&#123;JAR_NAME%.jar&#125;-$TIMESTAMP.jar&quot; mv &quot;$BIN_DIR/$JAR_NAME&quot; &quot;$HISTORY_DIR/$BACKUP_NAME&quot; # 清理多余的历史备份，只保留最新的3个 BACKUP_PATTERN=&quot;$&#123;JAR_NAME%.jar&#125;-*.jar&quot; BACKUPS=($(ls -t &quot;$HISTORY_DIR&quot;/$BACKUP_PATTERN 2&gt;/dev/null)) BACKUP_COUNT=$&#123;#BACKUPS[@]&#125; if [ &quot;$BACKUP_COUNT&quot; -gt 3 ]; then for ((i=3; i&lt;BACKUP_COUNT; i++)); do rm -f &quot;$&#123;BACKUPS[$i]&#125;&quot; done fi else push_to_feishu &quot;未发现旧版本 JAR 包，无需备份。&quot; fi&#125;# 推送到飞书function push_to_feishu() &#123; content=&quot;$1&quot; cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) message=&quot;当前操作：$&#123;content&#125; &quot; message+=&quot;进行时间：$&#123;cur_datetime&#125; &quot; read -r -d &#x27;&#x27; json_payload &lt;&lt;EOF&#123; &quot;msg_type&quot;: &quot;text&quot;, &quot;content&quot;: &#123; &quot;text&quot;: &quot;$&#123;message&#125;&quot; &#125;&#125;EOF echo &quot;&gt;&gt;&gt; JSON Payload: $&#123;json_payload&#125;&quot;response=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook&#125;&quot;)echo &quot;&gt;&gt;&gt; 飞书响应: $&#123;response&#125; &lt;&lt;&lt;&quot;response2=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook2&#125;&quot;)echo &quot;&gt;&gt;&gt; 飞书响应2: $&#123;response2&#125; &lt;&lt;&lt;&quot;&#125;# 函数：启动应用start_app() &#123; push_to_feishu &quot;正在启动应用...&quot; nohup java -jar &quot;$BIN_DIR/$JAR_NAME&quot; &gt; $LOG_FILE 2&gt;&amp;1 &amp; sleep 10 APP_PID=$(pgrep -f $JAR_NAME) if [ -z &quot;$APP_PID&quot; ]; then push_to_feishu &quot;应用启动失败...&quot; return 1 else push_to_feishu &quot;应用启动成功，PID: $APP_PID&quot; return 0 fi&#125;rollback() &#123; push_to_feishu &quot;正在回滚到上一版本...&quot; push_to_feishu &quot;正在停止当前服务...&quot; APP_PID=$(pgrep -f $JAR_NAME) if [ -n &quot;$APP_PID&quot; ]; then kill -9 $APP_PID push_to_feishu &quot;当前服务已停止，PID: $APP_PID&quot; echo &quot;当前服务已停止，PID: $APP_PID&quot; &gt;&gt; $LOG_FILE else push_to_feishu &quot;当前服务未运行，无需停止...&quot; echo &quot;当前服务未运行，无需停止。&quot; &gt;&gt; $LOG_FILE fi # 查找最新备份文件 LATEST_BACKUP=$(ls -t $HISTORY_DIR | head -n 1) if [ -n &quot;$LATEST_BACKUP&quot; ]; then push_to_feishu &quot;发现备份文件：$LATEST_BACKUP，正在回滚...&quot; echo &quot;发现备份文件：$LATEST_BACKUP，正在回滚...&quot; &gt;&gt; $LOG_FILE mv &quot;$HISTORY_DIR/$LATEST_BACKUP&quot; &quot;$BIN_DIR/$JAR_NAME&quot; push_to_feishu &quot;备份文件已恢复为当前版本：$LATEST_BACKUP&quot; echo &quot;备份文件已恢复为当前版本：$LATEST_BACKUP&quot; &gt;&gt; $LOG_FILE else echo &quot;未找到任何备份文件，回滚失败！&quot; &gt;&gt; $LOG_FILE return 1 fi push_to_feishu &quot;正在启动回滚版本...&quot; echo &quot;正在启动回滚版本...&quot; &gt;&gt; $LOG_FILE start_app if [ $? -eq 0 ]; then push_to_feishu &quot;回滚成功，服务已启动...&quot; echo &quot;回滚成功，服务已启动。&quot; &gt;&gt; $LOG_FILE else push_to_feishu &quot;回滚失败，服务未能启动，请检查日志...&quot; echo &quot;回滚失败，服务未能启动，请检查日志。&quot; &gt;&gt; $LOG_FILE fi&#125;cleanup_logs() &#123; push_to_feishu &quot;正在清理 15 天前的日志...&quot; echo &quot;正在清理 15 天前的日志...&quot; &gt;&gt; $LOG_FILE find $LOG_DIR -type f -mtime +15 -exec rm -f &#123;&#125; \\; push_to_feishu &quot;日志清理完成...&quot; echo &quot;日志清理完成。&quot; &gt;&gt; $LOG_FILE&#125;# 主逻辑echo &quot;======== 部署开始 $(date) ========&quot; &gt; $LOG_FILEpush_to_feishu &quot;服务端部署开始&quot;BUILD_JAR_PATH=$(pwd)push_to_feishu &quot;路径：$BUILD_JAR_PATH/$NEW_JAR ，$BIN_DIR/&quot;cd $APP_DIR || &#123; echo &quot;目录 $APP_DIR 不存在！&quot; &gt;&gt; $LOG_FILE; exit 1; &#125;backup_old_version# if [ -e &quot;$BUILD_JAR_PATH/$NEW_JAR&quot; ]; then# push_to_feishu &quot;文件 $(pwd)/$NEW_JAR 存在&quot;# else# push_to_feishu &quot;文件 $(pwd)/$NEW_JAR 不存在&quot;# fimv $BUILD_JAR_PATH/$NEW_JAR $BIN_DIR/ &gt; $LOG_FILE 2&gt;&amp;1push_to_feishu &quot;正在停止旧应用...&quot;echo &quot;正在停止旧应用...&quot; &gt;&gt; $LOG_FILEAPP_PID=$(pgrep -f $JAR_NAME)if [ -n &quot;$APP_PID&quot; ]; thenkill -9 $APP_PIDpush_to_feishu &quot;旧应用已停止...&quot;echo &quot;旧应用已停止。&quot; &gt;&gt; $LOG_FILEelsepush_to_feishu &quot;未检测到运行中的应用...&quot;echo &quot;未检测到运行中的应用。&quot; &gt;&gt; $LOG_FILEfistart_appif [ $? -ne 0 ]; thenrollbackficleanup_logspush_to_feishu &quot;服务端部署完成...&quot;echo &quot;======== 部署完成 $(date) ========&quot; &gt;&gt; $LOG_FILE 把脚本放在在线构建-构建列表-选中要用的构建-发布操作-本地命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165# !/bin/bashAPP_DIR=&quot;/data/apps/touchs&quot;BIN_DIR=&quot;$APP_DIR/bin&quot;HISTORY_DIR=&quot;$BIN_DIR/history&quot;LOG_DIR=&quot;$APP_DIR/logs&quot;LOG_FILE=&quot;$LOG_DIR/info.log&quot;JAR_NAME=&quot;touchs.jar&quot;NEW_JAR=&quot;target/$JAR_NAME&quot;feishu_webhook=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/token1&quot;feishu_webhook2=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/token2&quot;export TZ=&quot;Asia/Shanghai&quot;mkdir -p $BIN_DIR $HISTORY_DIR $LOG_DIRbackup_old_version() &#123; if [ -f &quot;$BIN_DIR/$JAR_NAME&quot; ]; then TIMESTAMP=$(date +%Y%m%d%H%M%S) BACKUP_NAME=&quot;$&#123;JAR_NAME%.jar&#125;-$TIMESTAMP.jar&quot; mv &quot;$BIN_DIR/$JAR_NAME&quot; &quot;$HISTORY_DIR/$BACKUP_NAME&quot; # 清理多余的历史备份，只保留最新的3个 BACKUP_PATTERN=&quot;$&#123;JAR_NAME%.jar&#125;-*.jar&quot; BACKUPS=($(ls -t &quot;$HISTORY_DIR&quot;/$BACKUP_PATTERN 2&gt;/dev/null)) BACKUP_COUNT=$&#123;#BACKUPS[@]&#125; if [ &quot;$BACKUP_COUNT&quot; -gt 3 ]; then for ((i=3; i&lt;BACKUP_COUNT; i++)); do rm -f &quot;$&#123;BACKUPS[$i]&#125;&quot; done fi else push_to_feishu &quot;未发现旧版本 JAR 包，无需备份。&quot; fi&#125;# 推送到飞书function push_to_feishu() &#123; content=&quot;$1&quot; cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) message=&quot;状态：$&#123;content&#125; &quot; message+=&quot;时间：$&#123;cur_datetime&#125;&quot; read -r -d &#x27;&#x27; json_payload &lt;&lt;EOF&#123; &quot;msg_type&quot;: &quot;text&quot;, &quot;content&quot;: &#123; &quot;text&quot;: &quot;$&#123;message&#125;&quot; &#125;&#125;EOF echo &quot;&gt;&gt;&gt; JSON Payload: $&#123;json_payload&#125;&quot;response=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook&#125;&quot;)echo &quot;&gt;&gt;&gt; 飞书响应: $&#123;response&#125; &lt;&lt;&lt;&quot;response2=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook2&#125;&quot;)echo &quot;&gt;&gt;&gt; 飞书响应2: $&#123;response2&#125; &lt;&lt;&lt;&quot;&#125;# 函数：启动应用start_app() &#123; push_to_feishu &quot;正在启动新版本...&quot; nohup java -jar &quot;$BIN_DIR/$JAR_NAME&quot; &gt; $LOG_FILE 2&gt;&amp;1 &amp; sleep 10 APP_PID=$(pgrep -f $JAR_NAME) if [ -z &quot;$APP_PID&quot; ]; then push_to_feishu &quot;新版本启动失败...&quot; return 1 else push_to_feishu &quot;新版本启动成功，PID: $APP_PID&quot; return 0 fi&#125;rollback() &#123; push_to_feishu &quot;正在回滚到上一版本...&quot; push_to_feishu &quot;正在停止当前服务...&quot; APP_PID=$(pgrep -f $JAR_NAME) if [ -n &quot;$APP_PID&quot; ]; then kill -9 $APP_PID push_to_feishu &quot;当前服务已停止，PID: $APP_PID&quot; echo &quot;当前服务已停止，PID: $APP_PID&quot; &gt;&gt; $LOG_FILE else push_to_feishu &quot;当前服务未运行，无需停止...&quot; echo &quot;当前服务未运行，无需停止。&quot; &gt;&gt; $LOG_FILE fi # 查找最新备份文件 LATEST_BACKUP=$(ls -t $HISTORY_DIR | head -n 1) if [ -n &quot;$LATEST_BACKUP&quot; ]; then push_to_feishu &quot;发现备份文件：$LATEST_BACKUP，正在回滚...&quot; echo &quot;发现备份文件：$LATEST_BACKUP，正在回滚...&quot; &gt;&gt; $LOG_FILE mv &quot;$HISTORY_DIR/$LATEST_BACKUP&quot; &quot;$BIN_DIR/$JAR_NAME&quot; push_to_feishu &quot;备份文件已恢复为当前版本：$LATEST_BACKUP&quot; echo &quot;备份文件已恢复为当前版本：$LATEST_BACKUP&quot; &gt;&gt; $LOG_FILE else echo &quot;未找到任何备份文件，回滚失败！&quot; &gt;&gt; $LOG_FILE return 1 fi push_to_feishu &quot;正在启动回滚版本...&quot; echo &quot;正在启动回滚版本...&quot; &gt;&gt; $LOG_FILE start_app if [ $? -eq 0 ]; then push_to_feishu &quot;回滚成功，服务已启动...&quot; echo &quot;回滚成功，服务已启动。&quot; &gt;&gt; $LOG_FILE else push_to_feishu &quot;回滚失败，服务未能启动，请检查日志...&quot; echo &quot;回滚失败，服务未能启动，请检查日志。&quot; &gt;&gt; $LOG_FILE fi&#125;cleanup_logs() &#123; push_to_feishu &quot;正在清理 15 天前的日志...&quot; echo &quot;正在清理 15 天前的日志...&quot; &gt;&gt; $LOG_FILE find $LOG_DIR -type f -mtime +15 -exec rm -f &#123;&#125; \\; push_to_feishu &quot;日志清理完成...&quot; echo &quot;日志清理完成。&quot; &gt;&gt; $LOG_FILE&#125;# 主逻辑echo &quot;======== 部署开始 $(date) ========&quot; &gt; $LOG_FILEpush_to_feishu &quot;打包完毕&quot;push_to_feishu &quot;开始部署&quot;BUILD_JAR_PATH=$(pwd)cd $APP_DIR || &#123; echo &quot;目录 $APP_DIR 不存在！&quot; &gt;&gt; $LOG_FILE; exit 1; &#125;backup_old_version# if [ -e &quot;$BUILD_JAR_PATH/$NEW_JAR&quot; ]; then# push_to_feishu &quot;文件 $(pwd)/$NEW_JAR 存在&quot;# else# push_to_feishu &quot;文件 $(pwd)/$NEW_JAR 不存在&quot;# fimv $BUILD_JAR_PATH/$NEW_JAR $BIN_DIR/ &gt; $LOG_FILE 2&gt;&amp;1push_to_feishu &quot;正在停止旧版本...&quot;echo &quot;正在停止旧版本...&quot; &gt;&gt; $LOG_FILEAPP_PID=$(pgrep -f $JAR_NAME)if [ -n &quot;$APP_PID&quot; ]; thenkill -9 $APP_PIDpush_to_feishu &quot;旧版本已停止...&quot;echo &quot;旧版本已停止。&quot; &gt;&gt; $LOG_FILEelsepush_to_feishu &quot;未检测到运行中的应用...&quot;echo &quot;未检测到运行中的应用。&quot; &gt;&gt; $LOG_FILEfistart_appif [ $? -ne 0 ]; thenrollbackficleanup_logspush_to_feishu &quot;部署完成...&quot;echo &quot;======== 部署完成 $(date) ========&quot; &gt;&gt; $LOG_FILE","tags":["笔记"],"categories":["其他"]},{"title":"java发布和回滚脚本","path":"/2025/02/06/2025020602/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127#!/bin/bash# 配置常量APP_DIR=&quot;/data/apps/touchs&quot;BIN_DIR=&quot;$APP_DIR/bin&quot;HISTORY_DIR=&quot;$BIN_DIR/history&quot;LOG_DIR=&quot;$APP_DIR/logs&quot;LOG_FILE=&quot;$LOG_DIR/info.log&quot;JAR_NAME=&quot;touchs.jar&quot;NEW_JAR=&quot;target/$JAR_NAME&quot;# 确保必要的目录存在mkdir -p $BIN_DIR $HISTORY_DIR $LOG_DIR# 函数：备份旧版本backup_old_version() &#123; if [ -f &quot;$BIN_DIR/$JAR_NAME&quot; ]; then TIMESTAMP=$(date +%Y%m%d%H%M%S) mv &quot;$BIN_DIR/$JAR_NAME&quot; &quot;$HISTORY_DIR/$&#123;JAR_NAME%.jar&#125;-$TIMESTAMP.jar&quot; echo &quot;旧版本已备份：$HISTORY_DIR/$&#123;JAR_NAME%.jar&#125;-$TIMESTAMP.jar&quot; &gt;&gt; $LOG_FILE else echo &quot;未发现旧版本 JAR 包，无需备份。&quot; &gt;&gt; $LOG_FILE fi&#125;# 函数：启动应用start_app() &#123; echo &quot;正在启动应用...&quot; &gt;&gt; $LOG_FILE nohup java -jar &quot;$BIN_DIR/$JAR_NAME&quot; &gt; $LOG_FILE 2&gt;&amp;1 &amp; sleep 5 APP_PID=$(pgrep -f $JAR_NAME) if [ -z &quot;$APP_PID&quot; ]; then echo &quot;应用启动失败！&quot; &gt;&gt; $LOG_FILE return 1 else echo &quot;应用启动成功，PID: $APP_PID&quot; &gt;&gt; $LOG_FILE return 0 fi&#125;# 函数：回滚到上一版本rollback() &#123; echo &quot;正在回滚到上一版本...&quot; &gt;&gt; $LOG_FILE # 强制停止当前运行服务 echo &quot;正在停止当前服务...&quot; &gt;&gt; $LOG_FILE APP_PID=$(pgrep -f $JAR_NAME) if [ -n &quot;$APP_PID&quot; ]; then kill -9 $APP_PID echo &quot;当前服务已停止，PID: $APP_PID&quot; &gt;&gt; $LOG_FILE else echo &quot;当前服务未运行，无需停止。&quot; &gt;&gt; $LOG_FILE fi # 查找最新备份文件 LATEST_BACKUP=$(ls -t $HISTORY_DIR | head -n 1) if [ -n &quot;$LATEST_BACKUP&quot; ]; then echo &quot;发现备份文件：$LATEST_BACKUP，正在回滚...&quot; &gt;&gt; $LOG_FILE mv &quot;$HISTORY_DIR/$LATEST_BACKUP&quot; &quot;$BIN_DIR/$JAR_NAME&quot; echo &quot;备份文件已恢复为当前版本：$LATEST_BACKUP&quot; &gt;&gt; $LOG_FILE else echo &quot;未找到任何备份文件，回滚失败！&quot; &gt;&gt; $LOG_FILE return 1 fi # 启动回滚版本 echo &quot;正在启动回滚版本...&quot; &gt;&gt; $LOG_FILE start_app if [ $? -eq 0 ]; then echo &quot;回滚成功，服务已启动。&quot; &gt;&gt; $LOG_FILE else echo &quot;回滚失败，服务未能启动，请检查日志。&quot; &gt;&gt; $LOG_FILE fi&#125;# 函数：清理旧日志cleanup_logs() &#123; echo &quot;正在清理 15 天前的日志...&quot; &gt;&gt; $LOG_FILE find $LOG_DIR -type f -mtime +15 -exec rm -f &#123;&#125; \\; echo &quot;日志清理完成。&quot; &gt;&gt; $LOG_FILE&#125;# 主逻辑case &quot;$1&quot; in deploy) echo &quot;======== 部署开始 $(date) ========&quot; &gt; $LOG_FILE cd $APP_DIR || &#123; echo &quot;目录 $APP_DIR 不存在！&quot; &gt;&gt; $LOG_FILE; exit 1; &#125; echo &quot;正在检查或拉取最新代码...&quot; &gt;&gt; $LOG_FILE if [ ! -d &quot;.git&quot; ]; then echo &quot;未检测到 Git 仓库，正在初始化...&quot; &gt;&gt; $LOG_FILE git init git remote add origin https://xxx:令牌@github.com/xxx/xxx.git fi git reset --hard git pull origin dev || &#123; echo &quot;代码拉取失败！&quot; &gt;&gt; $LOG_FILE; exit 1; &#125; echo &quot;正在构建项目...&quot; &gt;&gt; $LOG_FILE mvn clean package -DskipTests || &#123; echo &quot;构建失败！&quot; &gt;&gt; $LOG_FILE; exit 1; &#125; backup_old_version mv $NEW_JAR $BIN_DIR/$JAR_NAME echo &quot;正在停止旧应用...&quot; &gt;&gt; $LOG_FILE APP_PID=$(pgrep -f $JAR_NAME) if [ -n &quot;$APP_PID&quot; ]; then kill -9 $APP_PID echo &quot;旧应用已停止。&quot; &gt;&gt; $LOG_FILE else echo &quot;未检测到运行中的应用。&quot; &gt;&gt; $LOG_FILE fi start_app if [ $? -ne 0 ]; then rollback fi cleanup_logs echo &quot;======== 部署完成 $(date) ========&quot; &gt;&gt; $LOG_FILE ;; rollback) echo &quot;======== 回滚开始 $(date) ========&quot; &gt; $LOG_FILE rollback echo &quot;======== 回滚完成 $(date) ========&quot; &gt;&gt; $LOG_FILE ;; cleanup_logs) cleanup_logs ;; *) echo &quot;用法: $0 &#123;deploy|rollback|cleanup_logs&#125;&quot; ;;esac 示例 1：运行 deploy 操作 1./deploy.sh deploy 示例 2：运行 rollback 操作 1./deploy.sh rollback","tags":["笔记"],"categories":["其他"]},{"title":"JPOM绑定服务日志","path":"/2025/02/06/2025020601/","content":"jpom-系统管理-资产管理-机器管理，新增机器 账号&amp;密码节点的默认账号：jpomAgent 节点的默认密码：为随机生成 启动时候会在控制台输出：Automatically generate authorized account:jpomAgent password:xxxxx Authorization information storage location：/home/jpom/agent/data/agent_authorize.json 节点账号密码在安装启动成功后会输出到控制台，请根据输出到内容填写。 如果自己修改了账号密码则填写修改后的。 节点账号和密码安装 Agent 的时候有输出，查看路径：/agent安装目录/data/agent_authorize.json (如果 application.yml 自定义配置了账号密码不会出现此文件) 官方文档 然后分配到空间 jpom-功能管理-节点&amp;项目-逻辑节点，手动新增 系统会自动加载出来刚刚添加到机器，点击右边的分配，选择工作空间，就会同步过来 jpom-功能管理-节点&amp;项目-项目列表，新增 项目目录最好用项目物理路径的父路径，这样可以看到项目所有文件 点这里进去看日志 如果看不了，到这里配置一下 jpom-系统管理-资产管理-机器管理- 点一下机器名称-右上角授权配置 或者到这里新增一个日志搜索 点击日志文件 右键菜单,可以实时追踪日志,这个日志列表，数据会累加，最好看之前刷新一下列表 如果有问题，可以试着执行一下 1bash ./bin/Agent.sh restart -s --auto-push-to-server &#x27;http://127.0.0.1:2122/api/node/receive_push?token=cea7b585677c5a466bf2372ae9d6be9176566c6b&amp;workspaceId=DEFAULT&#x27; &amp;&amp; tail -f ./logs/agent.log 项目监控","tags":["笔记"],"categories":["其他"]},{"title":"JPOM构建通知到飞书","path":"/2025/02/05/2025020506/","content":"飞书添加机器人，并取得链接 jpom添加脚本 单机器人脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190#!/bin/bashset -x# 设置时区为上海时区export TZ=&quot;Asia/Shanghai&quot;echo &quot;&gt;&gt;&gt; 脚本开始执行 &lt;&lt;&lt;&quot;######################################自定义参数区域######################################## Jpom链接jpom_url=&quot;http://xx.xx:2122&quot;# 飞书机器人 webhook 地址（请替换为你实际的地址）feishu_webhook=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/token&quot;# 如果需要，可以设置关注的事件标题或状态（数组），用于过滤特定消息feishu_watch_titles=(&quot;监控告警&quot;)feishu_watch_status=(&quot;失败&quot;)######################################自定义参数区域######################################## URL编码函数（如需要链接中使用）urlencode() &#123; local string=&quot;$1&quot; local encoded=&quot;&quot; local length=&quot;$&#123;#string&#125;&quot; for (( i = 0; i &lt; length; i++ )); do local c=&quot;$&#123;string:i:1&#125;&quot; case &quot;$c&quot; in [a-zA-Z0-9.~_-]) encoded+=&quot;$c&quot; ;; *) encoded+=$(printf &#x27;%%%02X&#x27; &quot;&#x27;$c&quot;) ;; esac done echo &quot;$encoded&quot;&#125;# 检查变量是否存在于数组中array_contains() &#123; local target=&quot;$1&quot; shift local array=(&quot;$@&quot;) for item in &quot;$&#123;array[@]&#125;&quot;; do if [ &quot;$item&quot; == &quot;$target&quot; ]; then return 0 # 存在返回 0 fi done return 1 # 不存在返回 1&#125;# 推送到飞书function push_to_feishu() &#123; # 参数：$1: title, $2: status, $3: name, 后续为内容数组 title=&quot;$1&quot; status=&quot;$2&quot; name=&quot;$3&quot; shift 3 contents=(&quot;$@&quot;) cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) # 构建消息内容（纯文本，换行用 ） message=&quot;【$&#123;title&#125;】 &quot; message+=&quot;项目：$&#123;name&#125; &quot; message+=&quot;状态：$&#123;status&#125; &quot; message+=&quot;时间：$&#123;cur_datetime&#125; &quot; message+=&quot;链接：$&#123;jpom_url&#125; &quot; for content in &quot;$&#123;contents[@]&#125;&quot;; do message+=&quot;$&#123;content&#125; &quot; done echo &quot;&gt;&gt;&gt; 将发送的消息内容：&quot; echo -e &quot;$&#123;message&#125;&quot; # 构造 JSON 消息体 read -r -d &#x27;&#x27; json_payload &lt;&lt;EOF&#123; &quot;msg_type&quot;: &quot;text&quot;, &quot;content&quot;: &#123; &quot;text&quot;: &quot;$&#123;message&#125;&quot; &#125;&#125;EOF echo &quot;&gt;&gt;&gt; JSON Payload: $&#123;json_payload&#125;&quot; # 发送通知，并输出响应信息 response=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook&#125;&quot;) echo &quot;&gt;&gt;&gt; 飞书响应: $&#123;response&#125; &lt;&lt;&lt;&quot;&#125;# 通用推送函数function common_push() &#123; # 参数：$1: title, $2: status, $3: name, 后续为内容数组 title=&quot;$1&quot; status=&quot;$2&quot; name=&quot;$3&quot; shift 3 contents=(&quot;$@&quot;) send_notify=1 if [ &quot;$&#123;title&#125;&quot; == &quot;监控告警&quot; ]; then if ! array_contains &quot;$&#123;title&#125;&quot; &quot;$&#123;feishu_watch_titles[@]&#125;&quot; &amp;&amp; ! array_contains &quot;$&#123;status&#125;&quot; &quot;$&#123;feishu_watch_status[@]&#125;&quot;; then send_notify=0 fi fi if [ $&#123;send_notify&#125; -eq 1 ]; then push_to_feishu &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; else echo &quot;&gt;&gt;&gt; 消息未满足推送条件，不发送 &lt;&lt;&lt;&quot; fi&#125;# 构建事件推送function build_event_push() &#123; echo &quot;&gt;&gt;&gt; 进入构建事件推送逻辑 &lt;&lt;&lt;&quot; echo &quot;trigger_build_id: $&#123;trigger_build_id&#125;&quot; echo &quot;trigger_build_name: $&#123;trigger_build_name&#125;&quot; echo &quot;trigger_build_number_id: $&#123;trigger_build_number_id&#125;&quot; echo &quot;trigger_trigger_user: $&#123;trigger_trigger_user&#125;&quot; echo &quot;trigger_type: $&#123;trigger_type&#125;&quot; title=&quot;构建通知&quot; cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) name=&quot;$&#123;trigger_build_name&#125;&quot; contents=( &quot;任务：#$&#123;trigger_build_number_id&#125;&quot; # &quot;项目：$&#123;trigger_build_name&#125;&quot; # &quot;执行人：$&#123;trigger_trigger_user&#125;&quot; # &quot;时间：$&#123;cur_datetime&#125;&quot; ) case &quot;$&#123;trigger_type&#125;&quot; in &quot;startReady&quot; ) status=&quot;开始&quot; common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; &quot;success&quot; ) status=&quot;成功&quot; common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; &quot;stop&quot; | &quot;error&quot; ) status=&quot;失败&quot; contents+=(&quot; 错误信息：$&#123;trigger_status_msg&#125;&quot;) common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; * ) echo &quot;&gt;&gt;&gt; 未知的 trigger_type: $&#123;trigger_type&#125; &lt;&lt;&lt;&quot; ;; esac&#125;# 监控事件推送function monitor_event_push() &#123; echo &quot;&gt;&gt;&gt; 进入监控事件推送逻辑 &lt;&lt;&lt;&quot; echo &quot;trigger_monitor_id: $&#123;trigger_monitor_id&#125;&quot; title=&quot;监控告警&quot; cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) name=&quot;$&#123;trigger_project_name&#125;&quot; contents=( &quot;监控：$&#123;trigger_monitor_name&#125;&quot; &quot;节点：$&#123;trigger_node_name&#125;&quot; &quot;项目：$&#123;trigger_project_name&#125;&quot; &quot;时间：$&#123;cur_datetime&#125;&quot; &quot;内容：$&#123;trigger_title&#125;&quot; ) case &quot;$&#123;trigger_run_status&#125;&quot; in &quot;true&quot; ) status=&quot;恢复&quot; common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; &quot;false&quot; ) status=&quot;异常&quot; common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; * ) echo &quot;&gt;&gt;&gt; 未知的 trigger_run_status: $&#123;trigger_run_status&#125; &lt;&lt;&lt;&quot; ;; esac&#125;# 根据传入的环境变量判断调用哪种事件推送逻辑if [ -n &quot;$trigger_build_id&quot; ]; then build_event_pushelif [ -n &quot;$trigger_monitor_id&quot; ]; then monitor_event_pushelse echo &quot;&gt;&gt;&gt; 未检测到触发变量，执行默认测试调用 &lt;&lt;&lt;&quot; # 默认测试调用，测试飞书消息发送 push_to_feishu &quot;测试标题&quot; &quot;测试状态&quot; &quot;测试项目&quot; &quot;测试内容1&quot; &quot;测试内容2&quot;fi 多机器人脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193#!/bin/bashset -x# 设置时区为上海时区export TZ=&quot;Asia/Shanghai&quot;echo &quot;&gt;&gt;&gt; 脚本开始执行 &lt;&lt;&lt;&quot;######################################自定义参数区域######################################## Jpom链接jpom_url=&quot;http://xxx.xx:2122&quot;# 飞书机器人 webhook 地址（请替换为你实际的地址）feishu_webhook=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/token1&quot;feishu_webhook2=&quot;https://open.feishu.cn/open-apis/bot/v2/hook/token2&quot;# 如果需要，可以设置关注的事件标题或状态（数组），用于过滤特定消息feishu_watch_titles=(&quot;监控告警&quot;)feishu_watch_status=(&quot;失败&quot;)######################################自定义参数区域######################################## URL编码函数（如需要链接中使用）urlencode() &#123; local string=&quot;$1&quot; local encoded=&quot;&quot; local length=&quot;$&#123;#string&#125;&quot; for (( i = 0; i &lt; length; i++ )); do local c=&quot;$&#123;string:i:1&#125;&quot; case &quot;$c&quot; in [a-zA-Z0-9.~_-]) encoded+=&quot;$c&quot; ;; *) encoded+=$(printf &#x27;%%%02X&#x27; &quot;&#x27;$c&quot;) ;; esac done echo &quot;$encoded&quot;&#125;# 检查变量是否存在于数组中array_contains() &#123; local target=&quot;$1&quot; shift local array=(&quot;$@&quot;) for item in &quot;$&#123;array[@]&#125;&quot;; do if [ &quot;$item&quot; == &quot;$target&quot; ]; then return 0 # 存在返回 0 fi done return 1 # 不存在返回 1&#125;# 推送到飞书function push_to_feishu() &#123; # 参数：$1: title, $2: status, $3: name, 后续为内容数组 title=&quot;$1&quot; status=&quot;$2&quot; name=&quot;$3&quot; shift 3 contents=(&quot;$@&quot;) cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) # 构建消息内容（纯文本，换行用 ） message=&quot;【$&#123;title&#125;】 &quot; message+=&quot;名称：$&#123;name&#125; &quot; message+=&quot;状态：$&#123;status&#125; &quot; message+=&quot;时间：$&#123;cur_datetime&#125; &quot; # message+=&quot;链接：$&#123;jpom_url&#125; &quot; for content in &quot;$&#123;contents[@]&#125;&quot;; do message+=&quot;$&#123;content&#125;&quot; done echo &quot;&gt;&gt;&gt; 将发送的消息内容：&quot; echo -e &quot;$&#123;message&#125;&quot; # 构造 JSON 消息体 read -r -d &#x27;&#x27; json_payload &lt;&lt;EOF&#123; &quot;msg_type&quot;: &quot;text&quot;, &quot;content&quot;: &#123; &quot;text&quot;: &quot;$&#123;message&#125;&quot; &#125;&#125;EOF echo &quot;&gt;&gt;&gt; JSON Payload: $&#123;json_payload&#125;&quot; # 发送通知，并输出响应信息 response=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook&#125;&quot;) echo &quot;&gt;&gt;&gt; 飞书响应: $&#123;response&#125; &lt;&lt;&lt;&quot; response2=$(curl -H &quot;Content-Type: application/json&quot; -X POST -d &quot;$&#123;json_payload&#125;&quot; &quot;$&#123;feishu_webhook2&#125;&quot;) echo &quot;&gt;&gt;&gt; 飞书响应2: $&#123;response2&#125; &lt;&lt;&lt;&quot;&#125;# 通用推送函数function common_push() &#123; # 参数：$1: title, $2: status, $3: name, 后续为内容数组 title=&quot;$1&quot; status=&quot;$2&quot; name=&quot;$3&quot; shift 3 contents=(&quot;$@&quot;) send_notify=1 if [ &quot;$&#123;title&#125;&quot; == &quot;监控告警&quot; ]; then if ! array_contains &quot;$&#123;title&#125;&quot; &quot;$&#123;feishu_watch_titles[@]&#125;&quot; &amp;&amp; ! array_contains &quot;$&#123;status&#125;&quot; &quot;$&#123;feishu_watch_status[@]&#125;&quot;; then send_notify=0 fi fi if [ $&#123;send_notify&#125; -eq 1 ]; then push_to_feishu &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; else echo &quot;&gt;&gt;&gt; 消息未满足推送条件，不发送 &lt;&lt;&lt;&quot; fi&#125;# 构建事件推送function build_event_push() &#123; echo &quot;&gt;&gt;&gt; 进入构建事件推送逻辑 &lt;&lt;&lt;&quot; echo &quot;trigger_build_id: $&#123;trigger_build_id&#125;&quot; echo &quot;trigger_build_name: $&#123;trigger_build_name&#125;&quot; echo &quot;trigger_build_number_id: $&#123;trigger_build_number_id&#125;&quot; echo &quot;trigger_trigger_user: $&#123;trigger_trigger_user&#125;&quot; echo &quot;trigger_type: $&#123;trigger_type&#125;&quot; title=&quot;test环境构建通知-多机器人测试&quot; cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) name=&quot;$&#123;trigger_build_name&#125;&quot; contents=( # &quot;任务：#$&#123;trigger_build_number_id&#125;&quot; # &quot;项目：$&#123;trigger_build_name&#125;&quot; &quot;执行人：$&#123;trigger_trigger_user&#125;&quot; # &quot;时间：$&#123;cur_datetime&#125;&quot; ) case &quot;$&#123;trigger_type&#125;&quot; in &quot;startReady&quot; ) status=&quot;开始构建&quot; common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; &quot;success&quot; ) status=&quot;构建成功&quot; common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; &quot;stop&quot; | &quot;error&quot; ) status=&quot;构建失败&quot; contents+=(&quot; 错误信息：$&#123;trigger_status_msg&#125;&quot;) common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; * ) echo &quot;&gt;&gt;&gt; 未知的 trigger_type: $&#123;trigger_type&#125; &lt;&lt;&lt;&quot; ;; esac&#125;# 监控事件推送function monitor_event_push() &#123; echo &quot;&gt;&gt;&gt; 进入监控事件推送逻辑 &lt;&lt;&lt;&quot; echo &quot;trigger_monitor_id: $&#123;trigger_monitor_id&#125;&quot; title=&quot;监控告警&quot; cur_datetime=$(date +&quot;%Y-%m-%d %H:%M:%S&quot;) name=&quot;$&#123;trigger_project_name&#125;&quot; contents=( &quot;监控：$&#123;trigger_monitor_name&#125;&quot; &quot;节点：$&#123;trigger_node_name&#125;&quot; &quot;项目：$&#123;trigger_project_name&#125;&quot; &quot;时间：$&#123;cur_datetime&#125;&quot; &quot;内容：$&#123;trigger_title&#125;&quot; ) case &quot;$&#123;trigger_run_status&#125;&quot; in &quot;true&quot; ) status=&quot;恢复&quot; common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; &quot;false&quot; ) status=&quot;异常&quot; common_push &quot;$&#123;title&#125;&quot; &quot;$&#123;status&#125;&quot; &quot;$&#123;name&#125;&quot; &quot;$&#123;contents[@]&#125;&quot; ;; * ) echo &quot;&gt;&gt;&gt; 未知的 trigger_run_status: $&#123;trigger_run_status&#125; &lt;&lt;&lt;&quot; ;; esac&#125;# 根据传入的环境变量判断调用哪种事件推送逻辑if [ -n &quot;$trigger_build_id&quot; ]; then build_event_pushelif [ -n &quot;$trigger_monitor_id&quot; ]; then monitor_event_pushelse echo &quot;&gt;&gt;&gt; 未检测到触发变量，执行默认测试调用 &lt;&lt;&lt;&quot; # 默认测试调用，测试飞书消息发送 push_to_feishu &quot;测试标题&quot; &quot;测试状态&quot; &quot;测试项目&quot; &quot;测试内容1&quot; &quot;测试内容2&quot;fi 保存后获取回调地址 到构建中设置回调 把之前脚本的回调地址粘贴到WebHooks中，注意！如果是在一台服务器中，用内网地址，别用外网地址，否则可能会连接超时导致触发不了！","tags":["笔记"],"categories":["其他"]},{"title":"JPOM搭建","path":"/2025/02/05/20250205/","content":"前言关于项目自动化部署，因为项目体量不大加上Jenkins维护插件版本太麻烦，所以没用Jenkins，也没用GitHub的action，因为action需要服务器开启ssh,谷歌云开启ssh比较麻烦，且不安全，对比后用了JPOM 服务器系统：Ubuntu 20.04.6 LTS 下载我这里是存储桶里有包，所以在存储桶里下载的,这里用的版本：2.11.11 12wget https://xxx.amazonaws.com/common/jpom-2/agent-2.11.11-release.zipwget https://xxx.amazonaws.com/common/jpom-2/server-2.11.11-release.zip Jpom 官方安装包下载地址 启动12sudo apt install openjdk-11-jdksudo apt install maven 12345678910111213#nodejs前端项目需要curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -sudo apt install -y nodejsnode -vnpm -v#如果上面的报错，换下面的方式curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bashsource ~/.bashrcnvm install nodenode -vnpm -v#如果是在非交互式环境（例如通过 JPOM、CI/CD 脚本或其他自动化工具）中执行 npm 命令，那么这些环境通常不会自动加载 ~/.bashrc。解决方法是在脚本的开头手动加载 nvmexport NVM_DIR=&quot;$HOME/.nvm&quot; &amp;&amp; [ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; \\. &quot;$NVM_DIR/nvm.sh&quot; &amp;&amp; npm -v &amp;&amp; npm i &amp;&amp; npm run build --verbose 服务端启动1234# 进入安装目录cd /xxxxx# 启动服务端bash ./bin/Server.sh start 插件启动1234# 进入安装目录cd /xxxxx# 启动插件端bash ./bin/Agent.sh start 官方文档 参考文档 其他如果启动失败，可以尝试在官方文档里搜索报错信息，我这里是java版本导致的报错，环境变量不存在。 需要删除不存在的环境变量：删掉UseFastAccessorMethods所在的那一行,插件修改Agent.sh 服务端是Server.sh 启动后，访问地址：http://ip:2122 ，登陆进去初始化账号密码 新增仓库选令牌导入（左侧菜单-在线构建-仓库信息，选择右边的令牌导入） 导入完成后选择左侧菜单-在线构建-构建列表 构建参数： 12mvn clean package -e/target/xxx.jar -e用来打印构建错误信息","tags":["笔记"],"categories":["其他"]},{"title":"自动识别项目所属环境标识","path":"/2025/02/05/2025020502/","content":"项目地址 把项目install 取得jar，执行以下代码手动安装jar 1mvn install:install-file -Dfile=/Users/edy/Documents/middleware-config-1.0.2.jar -DgroupId=com.yujian.middleware -DartifactId=middleware-config -Dversion=1.0.2 -Dpackaging=jar -DgeneratePom=true 参数解释mvn install:install-file —— 执行 Maven 的 install-file 目标，用于将 JAR 文件手动安装到本地 Maven 仓库。-Dfile=/Users/edy/Documents/middleware-config-1.0.2(1).jar指定 JAR 文件的路径（此处 middleware-config-1.0.2(1).jar 似乎是浏览器下载后自动加了 (1) 的文件名，建议去掉括号以免报错）。-DgroupId=com.yujian.middleware指定 groupId（通常是 JAR 依赖所属的组织或公司）。-DartifactId=middleware-config指定 artifactId（通常是项目名称）。-Dversion=1.0.2指定版本号（这里是 1.0.2）。-Dpackaging=jar指定打包类型（这里是 jar）。-DgeneratePom=true生成 POM 文件（如果该 JAR 没有 POM 文件，Maven 会自动生成） 项目入口文件改造 123456789101112131415161718192021package com.touchsmail;import com.yujian.middleware.config.env.MiddlewareEnv;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;/** * @author mac */@SpringBootApplication(exclude = DataSourceAutoConfiguration.class,scanBasePackages = &quot;com.touchsmail&quot;)public class MailApplication &#123; public static void main(String[] args) &#123; args = new String[] &#123;&quot;--spring.profiles.active=&quot; + MiddlewareEnv.getEnvName().toLowerCase()&#125;; SpringApplication.run(MailApplication.class, args); &#125;&#125; 在服务器以下位置标记环境 1/root/public/environment 示例 123456root@mail:/home/kevin# cd /root/public/root@mail:~/public# lsenvironmentroot@mail:~/public# cat environment env=PRODroot@mail:~/public# 查看服务器hostName 12root@touchs-test:/home/kevin# hostnametouchs-test 根据环境修改对应代码 Env枚举文件中，hostPrefixList对应hostName，ipRangeList对应服务启动机器的内网ip","tags":["笔记"],"categories":["Java"]},{"title":"数据库密码加解密中间件","path":"/2025/02/05/2025020503/","content":"项目地址 把项目install 取得jar，执行以下代码手动安装jar 1mvn install:install-file -Dfile=/Users/edy/Documents/middleware-commons-1.0.4.jar -DgroupId=com.yujian.middleware -DartifactId=middleware-commons -Dversion=1.0.4 -Dpackaging=jar -DgeneratePom=true 参数解释mvn install:install-file —— 执行 Maven 的 install-file 目标，用于将 JAR 文件手动安装到本地 Maven 仓库。-Dfile=/Users/edy/Documents/middleware-config-1.0.2(1).jar指定 JAR 文件的路径（此处 middleware-config-1.0.2(1).jar 似乎是浏览器下载后自动加了 (1) 的文件名，建议去掉括号以免报错）。-DgroupId=com.yujian.middleware指定 groupId（通常是 JAR 依赖所属的组织或公司）。-DartifactId=middleware-config指定 artifactId（通常是项目名称）。-Dversion=1.0.2指定版本号（这里是 1.0.2）。-Dpackaging=jar指定打包类型（这里是 jar）。-DgeneratePom=true生成 POM 文件（如果该 JAR 没有 POM 文件，Maven 会自动生成） 项目MybatisConfig配置文件改造 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119package com.touchsmail.common.conf;import com.alibaba.druid.pool.DruidDataSource;import com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceBuilder;import com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean;import com.touchsmail.common.dataSources.DataSourceType;import com.touchsmail.common.dataSources.DynamicDataSource;import com.yujian.middleware.commons.support.YjDBPasswordFactory;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.annotation.MapperScan;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.core.io.Resource;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import org.springframework.core.io.support.ResourcePatternResolver;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import org.springframework.transaction.PlatformTransactionManager;import java.io.IOException;import java.util.ArrayList;import java.util.Arrays;import java.util.HashMap;import java.util.List;import java.util.Map;import javax.sql.DataSource;/** * Mybatis多数据源配置 * 参考文章：https://www.cnblogs.com/geekdc/p/10963476.html * @ClassName: MybatisConfig * @author fuce * @date 2019-12-06 21:11 */@Configuration@MapperScan(basePackages = &#123;&quot;com.touchsmail.mapper&quot;,&quot;com.touchsmail.website.mapper&quot;,&quot;com.touchsmail.manager.mapper&quot;&#125;)public class MybatisConfig &#123; private static final Logger logger = LoggerFactory.getLogger(MybatisConfig.class); @Bean @ConfigurationProperties(&quot;spring.datasource.druid.master&quot;) public DruidDataSource masterDataSource() &#123; return DruidDataSourceBuilder.create().build(); &#125; @Bean @ConfigurationProperties(&quot;spring.datasource.druid.slave&quot;) @ConditionalOnProperty(prefix = &quot;spring.datasource.druid.slave&quot;, name = &quot;enabled&quot;, havingValue = &quot;true&quot;) public DataSource slaveDataSource() &#123; return DruidDataSourceBuilder.create().build(); &#125; @Bean(name = &quot;dynamicDataSource&quot;) @Primary public DynamicDataSource dataSource(DataSource masterDataSource, DataSource slaveDataSource) throws Exception &#123; Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); DruidDataSource source = (DruidDataSource) masterDataSource; YjDBPasswordFactory passwordFactory = new YjDBPasswordFactory(); passwordFactory.setPassword(source.getPassword()); source.setPassword(passwordFactory.getObject()); targetDataSources.put(DataSourceType.MASTER.name(), source); targetDataSources.put(DataSourceType.SLAVE.name(),slaveDataSource); return new DynamicDataSource(masterDataSource(), targetDataSources); &#125; @Bean public SqlSessionFactory sqlSessionFactory(DynamicDataSource dynamicDataSource) throws Exception &#123; //核心就是这个，替换原始的SqlSessionFactoryBean 用mybatisSqlSessionFactoryBean即可 MybatisSqlSessionFactoryBean factoryBean = new MybatisSqlSessionFactoryBean(); factoryBean.setDataSource(dynamicDataSource); // 设置mapper.xml的位置路径 factoryBean.setMapperLocations(resolveMapperLocations()); return factoryBean.getObject(); &#125; public Resource[] resolveMapperLocations() &#123; ResourcePatternResolver resourceResolver = new PathMatchingResourcePatternResolver(); List&lt;String&gt; mapperLocations = new ArrayList&lt;&gt;(); mapperLocations.add(&quot;classpath*:mybatis/*/*/*.xml&quot;); mapperLocations.add(&quot;classpath*:mybatis-plus/*.xml&quot;); List&lt;Resource&gt; resources = new ArrayList&lt;Resource&gt;(); if (mapperLocations != null) &#123; for (String mapperLocation : mapperLocations) &#123; try &#123; Resource[] mappers = resourceResolver.getResources(mapperLocation); resources.addAll(Arrays.asList(mappers)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return resources.toArray(new Resource[resources.size()]); &#125; /** * 配置@Transactional注解事务 * @param dynamicDataSource * @return * @author fuce * @Date 2019年12月7日 上午11:31:33 */ @Bean public PlatformTransactionManager transactionManager(DynamicDataSource dynamicDataSource)&#123; return new DataSourceTransactionManager(dynamicDataSource); &#125;&#125; 重点在这里 1234567891011 public DynamicDataSource dataSource(DataSource masterDataSource, DataSource slaveDataSource) throws Exception &#123; Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); DruidDataSource source = (DruidDataSource) masterDataSource; YjDBPasswordFactory passwordFactory = new YjDBPasswordFactory(); passwordFactory.setPassword(source.getPassword()); String dePass = passwordFactory.getObject(); source.setPassword(dePass); targetDataSources.put(DataSourceType.MASTER.name(), source); targetDataSources.put(DataSourceType.SLAVE.name(),slaveDataSource); return new DynamicDataSource(masterDataSource(), targetDataSources);&#125; 项目中的EncryptDBPasswordFactory文件，用于数据库密码加密、解密 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118package com.touchsmail.util;import org.springframework.beans.factory.FactoryBean;import javax.crypto.BadPaddingException;import javax.crypto.Cipher;import javax.crypto.IllegalBlockSizeException;import javax.crypto.NoSuchPaddingException;import javax.crypto.spec.SecretKeySpec;import java.math.BigInteger;import java.security.InvalidKeyException;import java.security.NoSuchAlgorithmException;/** * 用于数据库密码加密、解密，跟jboss4.0.5兼容 加解密代码源自于org.jboss.resource.security.SecureIdentityLoginModule * * @author cy */public class EncryptDBPasswordFactory implements FactoryBean&lt;String&gt; &#123; /** * 加密密码 */ private String password; /** * 加密 * * @param secret * @return * @throws NoSuchPaddingException * @throws NoSuchAlgorithmException * @throws InvalidKeyException * @throws BadPaddingException * @throws IllegalBlockSizeException */ private String encode(String secret, String privateKey) throws NoSuchPaddingException, NoSuchAlgorithmException, InvalidKeyException, BadPaddingException, IllegalBlockSizeException &#123; byte[] kbytes = privateKey.getBytes(); SecretKeySpec key = new SecretKeySpec(kbytes, &quot;Blowfish&quot;); Cipher cipher = Cipher.getInstance(&quot;Blowfish&quot;); cipher.init(Cipher.ENCRYPT_MODE, key); byte[] encoding = cipher.doFinal(secret.getBytes()); BigInteger n = new BigInteger(encoding); return n.toString(16); &#125; /** * 解密 * * @param secret * @return * @throws NoSuchPaddingException * @throws NoSuchAlgorithmException * @throws InvalidKeyException * @throws BadPaddingException * @throws IllegalBlockSizeException */ private char[] decode(String secret) throws NoSuchPaddingException, NoSuchAlgorithmException, InvalidKeyException, BadPaddingException, IllegalBlockSizeException &#123; byte[] kbytes = &quot;这里是盐&quot;.getBytes(); SecretKeySpec key = new SecretKeySpec(kbytes, &quot;Blowfish&quot;); BigInteger n = new BigInteger(secret, 16); byte[] encoding = n.toByteArray(); Cipher cipher = Cipher.getInstance(&quot;Blowfish&quot;); cipher.init(Cipher.DECRYPT_MODE, key); byte[] decode = cipher.doFinal(encoding); return new String(decode).toCharArray(); &#125; @Override public String getObject() throws Exception &#123; if (password != null) &#123; return String.valueOf(decode(password)); &#125; else &#123; return null; &#125; &#125; @Override public Class&lt;String&gt; getObjectType() &#123; return String.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125; /** * @param password */ public void setPassword(String password) &#123; this.password = password; &#125; public static void main(String[] args) throws InvalidKeyException, NoSuchAlgorithmException, NoSuchPaddingException, BadPaddingException, IllegalBlockSizeException &#123; EncryptDBPasswordFactory encrypt = new EncryptDBPasswordFactory(); String secret = &quot;&quot;; String secText = encrypt.encode(secret, &quot;&quot;); System.out.println(secText); System.out.println(encrypt.decode(secText)); &#125; public static String decodeA(String secret) throws InvalidKeyException, NoSuchPaddingException, NoSuchAlgorithmException, BadPaddingException, IllegalBlockSizeException &#123; EncryptDBPasswordFactory encrypt = new EncryptDBPasswordFactory(); return new String(encrypt.decode(secret)); &#125;&#125; 环境密钥路径：/root/private/dbsecretkey","tags":["笔记"],"categories":["Java"]},{"title":"java,spring日志配置文件","path":"/2024/12/27/20241227/","content":"logback-spring.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!-- scan：当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。 scanPeriod：设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒；当scan为true时，此属性生效。默认的时间间隔为1分钟。 debug：当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。--&gt;&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;10 seconds&quot; debug=&quot;false&quot;&gt; &lt;springProfile name=&quot;prod&quot;&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- 定义日志的根目录 --&gt; &lt;property name=&quot;log.path&quot; value=&quot;/data/apps/touchs/logs&quot;/&gt; &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot;/&gt; &lt;!-- 定义日志格式 --&gt; &lt;property name=&quot;CONSOLE_LOG_PATTERN&quot; value=&quot;%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr([%8.8t])&#123;faint&#125; %clr(%-30.30logger&#123;0&#125;)&#123;cyan&#125; %clr(%X&#123;requestId&#125;)&#123;faint&#125; %clr(%X&#123;userId&#125;)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&quot;/&gt; &lt;include resource=&quot;org/springframework/boot/logging/logback/console-appender.xml&quot;/&gt; &lt;!-- 2.2 level为 INFO 日志，时间滚动输出 --&gt; &lt;appender name=&quot;INFO_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/info.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/info-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录info级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;info&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.4 level为 ERROR 日志，时间滚动输出 --&gt; &lt;appender name=&quot;ERROR_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/error.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/error-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录ERROR级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;error&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;root level=&quot;info&quot;&gt; &lt;appender-ref ref=&quot;INFO_FILE&quot;/&gt; &lt;appender-ref ref=&quot;ERROR_FILE&quot;/&gt; &lt;/root&gt; &lt;/springProfile&gt; &lt;springProfile name=&quot;dev&quot;&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot;/&gt; &lt;!-- 定义日志格式 --&gt; &lt;property name=&quot;CONSOLE_LOG_PATTERN&quot; value=&quot;%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr([%8.8t])&#123;faint&#125; %clr(%-30.30logger&#123;0&#125;)&#123;cyan&#125; %clr(%X&#123;requestId&#125;)&#123;faint&#125; %clr(%X&#123;userId&#125;)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&quot;/&gt; &lt;include resource=&quot;org/springframework/boot/logging/logback/console-appender.xml&quot;/&gt; &lt;!--1. 输出到控制台--&gt; &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;Pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/Pattern&gt; &lt;!-- 设置字符集 --&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt; &lt;/root&gt; &lt;/springProfile&gt;&lt;/configuration&gt;","tags":["随笔"],"categories":["Java"]},{"title":"java,通过接口读取日志文件","path":"/2024/12/09/2024120902/","content":"前言nginx需要配置对sse的支持，否则访问不通 修改nginx配置1vim /etc/nginx/sites-available/default 123456789101112131415161718192021222324252627282930313233343536373839server &#123; listen 443 ssl; server_name 域名.后缀; client_max_body_size 30M; ssl_certificate /etc/letsencrypt/live/域名.后缀/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/域名.后缀/privkey.pem; # managed by Certbot # 默认的 location 配置，不影响其他请求 location / &#123; proxy_pass http://127.0.0.1:6001; # 代理到本地服务 proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; &#125; # 针对 SSE 请求的特殊配置 location /service/logs/realtime &#123; # 假设 SSE 请求是通过 /service/logs/realtime 路径处理的 proxy_pass http://127.0.0.1:6001; # 代理到本地服务 proxy_http_version 1.1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # SSE 关键优化 proxy_buffering off; # 禁用缓冲，确保数据流不中断 proxy_cache off; # 确保 Nginx 不缓存 SSE 响应 proxy_set_header Connection &#x27;&#x27;; # 避免 Nginx 添加 `Connection: close`，保持连接 chunked_transfer_encoding off; # 禁用 chunked 传输，SSE 不需要它 # 只针对 SSE 请求设置的超时 proxy_read_timeout 3600s; # 设置为较长时间（例如 3600 秒 = 1 小时） proxy_send_timeout 3600s; # 设置为较长时间 send_timeout 3600s; # 设置 Nginx 向客户端发送响应的超时时间 &#125;&#125; 检查nginx配置1sudo nginx -t 123root@touchs-test:/home/kevin# sudo nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful 重新加载nginx配置不会中断现有连接 1nginx -s reload 服务端配置文件yml123server-log: enabled: true # 设置为true开启日志读取功能 filePath: /Users/edy/Documents/console.log # 日志文件路径 LogReaderProperties1234567891011import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;import lombok.Data;@Data@Component@ConfigurationProperties(prefix = &quot;server-log&quot;)public class LogReaderProperties &#123; private String filePath; private boolean enabled = false;&#125; 方式一（不建议）这种处理可能会抛异常：User limit of inotify instances reached or too many open files 结构关系：1234controller -tools -LogReaderProperties -SystemLogController SystemLogController123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291package com.touchsmail.controller.tools.log;import com.touchsmail.util.StringUtils;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.web.bind.annotation.*;import org.springframework.http.ResponseEntity;import org.springframework.format.annotation.DateTimeFormat;import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;import java.io.*;import java.nio.charset.StandardCharsets;import java.nio.file.*;import java.util.*;import java.time.*;import java.time.format.*;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicLong;import javax.annotation.PreDestroy;import javax.annotation.Resource;@RestController@RequestMapping(&quot;/service/logs&quot;)public class SystemLogController &#123; // private static final String LOG_FILE_PATH = &quot;/Users/edy/Documents/console.log&quot;; private static final DateTimeFormatter DATE_FORMAT = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;); private final ExecutorService executor = Executors.newCachedThreadPool(); @Resource private LogReaderProperties properties; // 增加响应头，处理中文乱码 private HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(HttpHeaders.CONTENT_ENCODING, &quot;UTF-8&quot;); headers.set(HttpHeaders.CONTENT_TYPE, &quot;text/plain;charset=UTF-8&quot;); return headers; &#125; private void checkEnabled() &#123; if (!properties.isEnabled()) &#123; throw new IllegalStateException(&quot;log not open!&quot;); &#125; &#125; private void checkFileExists() &#123; if (StringUtils.isBlank(properties.getFilePath()) || !Files.exists(Paths.get(properties.getFilePath()))) &#123; throw new IllegalStateException(&quot;log file does not exist!&quot;); &#125; &#125; @GetMapping(&quot;/&quot;) public ResponseEntity&lt;String&gt; explain() &#123; checkEnabled(); checkFileExists(); final String content = &quot;// 读取全部日志 &quot; + &quot;GET http://localhost:6001/service/logs/all &quot; + &quot; &quot; + &quot;// 读取最新10条日志 &quot; + &quot;GET http://localhost:6001/service/logs/latest?lines=10 &quot; + &quot; &quot; + &quot;// 读取指定时间范围的日志 &quot; + &quot;GET http://localhost:6001/service/logs/time?startTime=2024-12-01 00:00:00&amp;endTime=2024-12-31 00:00:00 &quot; + &quot; &quot; + &quot;// 流式读取日志 &quot; + &quot;GET http://localhost:6001/service/logs/stream?bufferSize=100&quot;+ &quot;// 流式追踪最新日志 &quot; + &quot;GET http://localhost:6001/service/logs/realtime&quot;; return new ResponseEntity&lt;&gt;(content, getHeaders(), HttpStatus.OK); &#125; @GetMapping(&quot;/all&quot;) public ResponseEntity&lt;String&gt; readAllLogs() &#123; checkEnabled(); checkFileExists(); try &#123; String content = new String(Files.readAllBytes(Paths.get(properties.getFilePath())), StandardCharsets.UTF_8); return new ResponseEntity&lt;&gt;(content, getHeaders(), HttpStatus.OK); &#125; catch (IOException e) &#123; return new ResponseEntity&lt;&gt;(&quot;读取日志文件失败: &quot; + e.getMessage(), getHeaders(), HttpStatus.INTERNAL_SERVER_ERROR); &#125; &#125; @GetMapping(&quot;/latest&quot;) public ResponseEntity&lt;String&gt; readLatestLogs(@RequestParam(defaultValue = &quot;10&quot;) int lines) &#123; try &#123; checkEnabled(); checkFileExists(); List&lt;String&gt; allLines = Files.readAllLines(Paths.get(properties.getFilePath()), StandardCharsets.UTF_8); int startIndex = Math.max(0, allLines.size() - lines); List&lt;String&gt; latestLines = allLines.subList(startIndex, allLines.size()); StringBuilder result = new StringBuilder(); for (String line : latestLines) &#123; result.append(line).append(&quot; &quot;); &#125; return new ResponseEntity&lt;&gt;(result.toString(), getHeaders(), HttpStatus.OK); &#125; catch (IOException e) &#123; return new ResponseEntity&lt;&gt;(&quot;读取日志文件失败: &quot; + e.getMessage(), getHeaders(), HttpStatus.INTERNAL_SERVER_ERROR); &#125; &#125; @GetMapping(&quot;/time&quot;) public ResponseEntity&lt;String&gt; readLogsByTimeRange( @RequestParam @DateTimeFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;) LocalDateTime startTime, @RequestParam @DateTimeFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;) LocalDateTime endTime) &#123; try &#123; checkEnabled(); checkFileExists(); List&lt;String&gt; allLines = Files.readAllLines(Paths.get(properties.getFilePath()), StandardCharsets.UTF_8); StringBuilder result = new StringBuilder(); for (String line : allLines) &#123; try &#123; String timeStr = line.substring(0, 19); LocalDateTime logTime = LocalDateTime.parse(timeStr, DATE_FORMAT); if ((logTime.isEqual(startTime) || logTime.isAfter(startTime)) &amp;&amp; (logTime.isEqual(endTime) || logTime.isBefore(endTime))) &#123; result.append(line).append(&quot; &quot;); &#125; &#125; catch (Exception e) &#123; // Skip malformed log entries continue; &#125; &#125; return new ResponseEntity&lt;&gt;(result.toString(), getHeaders(), HttpStatus.OK); &#125; catch (IOException e) &#123; return new ResponseEntity&lt;&gt;(&quot;读取日志文件失败: &quot; + e.getMessage(), getHeaders(), HttpStatus.INTERNAL_SERVER_ERROR); &#125; &#125; @GetMapping(&quot;/stream&quot;) public ResponseEntity&lt;String&gt; streamLog(@RequestParam(defaultValue = &quot;100&quot;) int maxLines) &#123; try &#123; checkEnabled(); checkFileExists(); List&lt;String&gt; lines = new ArrayList&lt;&gt;(); try (BufferedReader reader = new BufferedReader( new InputStreamReader(new FileInputStream(properties.getFilePath()), StandardCharsets.UTF_8))) &#123; String line; while ((line = reader.readLine()) != null) &#123; lines.add(line); if (lines.size() &gt; maxLines) &#123; lines.remove(0); &#125; &#125; &#125; StringBuilder result = new StringBuilder(); for (String line : lines) &#123; result.append(line).append(&quot; &quot;); &#125; return new ResponseEntity&lt;&gt;(result.toString(), getHeaders(), HttpStatus.OK); &#125; catch (IOException e) &#123; return new ResponseEntity&lt;&gt;(&quot;读取日志文件失败: &quot; + e.getMessage(), getHeaders(), HttpStatus.INTERNAL_SERVER_ERROR); &#125; &#125; /** * 实时读取日志文件内容并推送给客户端 * * @param initialLines 初次读取日志的行数（可选，默认为 0，不读取初始内容，直接开始实时监控和推送新增日志） * @param filePath 日志文件路径，不传就用配置文件中的 * @return SseEmitter 用于推送实时日志内容 */ @GetMapping(&quot;/realtime&quot;) public SseEmitter streamLogRealtime(@RequestParam(defaultValue = &quot;0&quot;) int initialLines, @RequestParam(required = false) String filePath) &#123;// checkEnabled(); SseEmitter emitter = new SseEmitter(Long.MAX_VALUE); Path logFilePath = (filePath != null &amp;&amp; !filePath.isEmpty()) ? Paths.get(filePath) : Paths.get(properties.getFilePath()); if (!Files.exists(logFilePath)) &#123; throw new RuntimeException(&quot;Log file not found: &quot; + filePath); &#125; executor.execute(() -&gt; &#123; try &#123; WatchService watchService = FileSystems.getDefault().newWatchService(); logFilePath.getParent().register(watchService, StandardWatchEventKinds.ENTRY_MODIFY, StandardWatchEventKinds.ENTRY_DELETE); AtomicLong filePointer = new AtomicLong(Files.size(logFilePath)); // 读取最后 N 行日志 if (initialLines &gt; 0) &#123; List&lt;String&gt; lastLines = readLastLines(logFilePath, initialLines); for (String line : lastLines) &#123; emitter.send(SseEmitter.event().data(line)); &#125; &#125; ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1); scheduler.scheduleAtFixedRate(() -&gt; &#123; try &#123; long newSize = Files.size(logFilePath); if (newSize &gt; filePointer.get()) &#123; // 使用 UTF-8 读取文件内容，避免乱码 try (RandomAccessFile file = new RandomAccessFile(logFilePath.toFile(), &quot;r&quot;); InputStreamReader isr = new InputStreamReader(new FileInputStream(file.getFD()), StandardCharsets.UTF_8); BufferedReader reader = new BufferedReader(isr)) &#123; file.seek(filePointer.get()); // 移动到上次读取的位置 String line; while ((line = reader.readLine()) != null) &#123; emitter.send(SseEmitter.event().data(line)); // 发送 UTF-8 正确编码的日志 &#125; filePointer.set(file.getFilePointer()); // 更新文件指针 &#125; &#125; &#125; catch (IOException e) &#123; emitter.completeWithError(e); &#125; &#125;, 0, 1, TimeUnit.SECONDS); while (true) &#123; WatchKey key = watchService.take(); boolean fileDeleted = false; for (WatchEvent&lt;?&gt; event : key.pollEvents()) &#123; Path changed = (Path) event.context(); if (changed.endsWith(logFilePath.getFileName())) &#123; if (event.kind() == StandardWatchEventKinds.ENTRY_DELETE) &#123; fileDeleted = true; &#125; &#125; &#125; key.reset(); if (fileDeleted) &#123; emitter.send(SseEmitter.event().data(&quot;Log file deleted. Stopping log streaming.&quot;)); emitter.complete(); scheduler.shutdown(); break; &#125; &#125; &#125; catch (IOException | InterruptedException e) &#123; emitter.completeWithError(e); &#125; &#125;); return emitter; &#125; /** * 读取文件的最后 n 行 * * @param filePath 文件路径 * @param lines 需要读取的行数 * @return 最后 n 行的内容列表 */ private List&lt;String&gt; readLastLines(Path filePath, int lines) throws IOException &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); // 使用 BufferedReader 以 UTF-8 编码读取文件 try (BufferedReader reader = Files.newBufferedReader(filePath, StandardCharsets.UTF_8)) &#123; // 获取文件的所有行 List&lt;String&gt; allLines = Files.readAllLines(filePath, StandardCharsets.UTF_8); // 从末尾读取最后 lines 行 int start = Math.max(allLines.size() - lines, 0); for (int i = start; i &lt; allLines.size(); i++) &#123; result.add(allLines.get(i)); &#125; &#125; return result; &#125; /** * 在类销毁时关闭线程池 */ @PreDestroy public void shutdownExecutor() &#123; executor.shutdown(); &#125;&#125; 调用示例：123456789101112131415161718192021//调用说明GET http://localhost:8080/service/logs/// 读取全部日志GET http://localhost:8080/service/logs/all// 读取最新10条日志GET http://localhost:8080/service/logs/latest?lines=10// 读取指定时间范围的日志GET http://localhost:8080/service/logs/time?startTime=2024-12-01 00:00:00&amp;endTime=2024-12-30 00:00:00// 流式读取日志GET http://localhost:8080/service/logs/stream?bufferSize=100// 流式追踪最新日志GET [http://localhost:8080/service/logs/stream?bufferSize=100](http://localhost:6001/service/logs/realtime? initialLines=&#123;&#123;$random.integer(100)&#125;&#125;&amp; filePath=&#123;&#123;$random.alphanumeric(8)&#125;&#125;) 方式二（推荐）结构关系：12345controller -tools -LogReaderProperties -LogStreamingController -LogStreamingService LogStreamingController12345678910111213141516171819202122232425package com.touchsmail.controller.tools.log;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;@RestController@RequestMapping(&quot;/service/logs&quot;)public class LogStreamingController &#123; private final LogStreamingService logStreamingService; public LogStreamingController(LogStreamingService logStreamingService) &#123; this.logStreamingService = logStreamingService; &#125; @GetMapping(&quot;/realtime&quot;) public SseEmitter streamLogRealtime(@RequestParam(defaultValue = &quot;0&quot;) int initialLines, @RequestParam(required = false) String filePath) &#123; return logStreamingService.streamLogRealtime(initialLines, filePath); &#125;&#125; LogStreamingService123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140package com.touchsmail.controller.tools.log;import org.springframework.stereotype.Service;import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;import javax.annotation.Resource;import java.io.*;import java.nio.charset.StandardCharsets;import java.nio.file.*;import java.util.List;import java.util.concurrent.*;import java.util.concurrent.atomic.AtomicLong;@Servicepublic class LogStreamingService &#123; private final ExecutorService executor = Executors.newCachedThreadPool(); private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(2); private final CopyOnWriteArrayList&lt;SseEmitter&gt; emitters = new CopyOnWriteArrayList&lt;&gt;(); private final WatchService watchService; private final ConcurrentHashMap&lt;Path, AtomicLong&gt; filePointers = new ConcurrentHashMap&lt;&gt;(); @Resource private LogReaderProperties properties; public LogStreamingService() throws IOException &#123; this.watchService = FileSystems.getDefault().newWatchService(); startFileWatcher(); &#125; public SseEmitter streamLogRealtime(int initialLines, String filePath) &#123; if (!properties.isEnabled()) &#123; throw new IllegalStateException(&quot;log not open!&quot;); &#125; Path logFilePath = (filePath != null &amp;&amp; !filePath.isEmpty()) ? Paths.get(filePath) : Paths.get(properties.getFilePath()); if (!Files.exists(logFilePath)) &#123; throw new RuntimeException(&quot;Log file not found: &quot; + logFilePath); &#125; SseEmitter emitter = new SseEmitter(0L); emitters.add(emitter); executor.execute(() -&gt; sendInitialLines(emitter, logFilePath, initialLines)); AtomicLong filePointer = filePointers.computeIfAbsent(logFilePath, path -&gt; new AtomicLong(getFileSize(path))); scheduler.scheduleAtFixedRate(() -&gt; &#123; try &#123; readNewLines(emitter, logFilePath, filePointer); &#125; catch (IOException e) &#123; emitter.completeWithError(e); &#125; &#125;, 0, 1, TimeUnit.SECONDS); // Schedule a heart beat every 30 seconds scheduler.scheduleAtFixedRate(() -&gt; &#123; try &#123; emitter.send(SseEmitter.event().data(&quot;heartbeat&quot;)); &#125; catch (IOException e) &#123; emitter.completeWithError(e); &#125; &#125;, 0, 30, TimeUnit.SECONDS); emitter.onCompletion(() -&gt; emitters.remove(emitter)); emitter.onTimeout(() -&gt; emitters.remove(emitter)); return emitter; &#125; private void sendInitialLines(SseEmitter emitter, Path logFilePath, int initialLines) &#123; try &#123; List&lt;String&gt; lastLines = readLastLines(logFilePath, initialLines); for (String line : lastLines) &#123; emitter.send(SseEmitter.event().data(line)); &#125; &#125; catch (IOException e) &#123; emitter.completeWithError(e); &#125; &#125; private void readNewLines(SseEmitter emitter, Path logFilePath, AtomicLong filePointer) throws IOException &#123; long newSize = Files.size(logFilePath); if (newSize &gt; filePointer.get()) &#123; try (RandomAccessFile file = new RandomAccessFile(logFilePath.toFile(), &quot;r&quot;); InputStreamReader isr = new InputStreamReader(new FileInputStream(file.getFD()), StandardCharsets.UTF_8); BufferedReader reader = new BufferedReader(isr)) &#123; file.seek(filePointer.get()); String line; while ((line = reader.readLine()) != null) &#123; emitter.send(SseEmitter.event().data(line)); &#125; filePointer.set(file.getFilePointer()); &#125; &#125; &#125; private List&lt;String&gt; readLastLines(Path path, int n) throws IOException &#123; List&lt;String&gt; lines = Files.readAllLines(path, StandardCharsets.UTF_8); return lines.subList(Math.max(lines.size() - n, 0), lines.size()); &#125; private long getFileSize(Path path) &#123; try &#123; return Files.exists(path) ? Files.size(path) : 0; &#125; catch (IOException e) &#123; return 0; &#125; &#125; private void startFileWatcher() &#123; executor.execute(() -&gt; &#123; while (true) &#123; try &#123; WatchKey key = watchService.take(); for (WatchEvent&lt;?&gt; event : key.pollEvents()) &#123; if (event.kind() == StandardWatchEventKinds.ENTRY_DELETE) &#123; Path deletedFile = (Path) event.context(); emitters.forEach(emitter -&gt; &#123; try &#123; emitter.send(SseEmitter.event().data(&quot;Log file deleted: &quot; + deletedFile)); emitter.complete(); &#125; catch (IOException ignored) &#123; &#125; &#125;); emitters.clear(); &#125; &#125; key.reset(); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); break; &#125; &#125; &#125;); &#125;&#125; 前端结构1234567src -views -serviceTable -serviceTable.less -serviceTable.tsx-EventBus.ts-useEventBus.tsx 前端代码不全，仅供参考，缺少全局状态路由通知 EventBus.ts12345678910111213141516171819202122232425262728293031type Listener = (...args: any[]) =&gt; void;class EventBus &#123; private events: &#123; [event: string]: Listener[] &#125;; constructor() &#123; this.events = &#123;&#125;; &#125; // 注册事件监听器 on(event: string, listener: Listener): void &#123; if (!this.events[event]) &#123; this.events[event] = []; &#125; this.events[event].push(listener); &#125; // 移除事件监听器 off(event: string, listener: Listener): void &#123; if (!this.events[event]) return; this.events[event] = this.events[event].filter((l) =&gt; l !== listener); &#125; // 触发事件 emit(event: string, ...args: any[]): void &#123; if (!this.events[event]) return; this.events[event].forEach((listener) =&gt; listener(...args)); &#125;&#125;export const eventBus = new EventBus(); useEventBus.tsx1234567891011121314151617181920212223import &#123; useEffect &#125; from &#x27;react&#x27;;import &#123;eventBus&#125; from &#x27;./EventBus&#x27;; // 注意：不需要加 .tsx 后缀// 定义事件回调函数的类型type EventCallback = (data: any) =&gt; void;// 自定义 Hook: 用于订阅和发布事件export const useEventBus = (event: string, callback: EventCallback): void =&gt; &#123; useEffect(() =&gt; &#123; // 订阅事件 eventBus.on(event, callback); // 组件卸载时移除事件监听器 return () =&gt; &#123; eventBus.off(event, callback); &#125;; &#125;, [event, callback]); // 依赖项：事件和回调函数&#125;;// 发布事件的函数export const publishEvent = (event: string, data: any): void =&gt; &#123; eventBus.emit(event, data);&#125;; serviceTable.less1234567891011121314151617181920212223242526272829303132333435363738394041424344.msgBox &#123;\twidth: 100%;\theight: calc(100vh - 150px);\toverflow: auto;\tbackground-color: #1e1e1e; /* VS Code 深色背景 */\tcolor: #d4d4d4; /* VS Code 默认字体颜色 */\tpadding: 20px 10px;\tlist-style-type: none;\tfont-family: monospace;\tfont-size: 14px;\tline-height: 1.4;\ttransition: all 0.3s ease;&#125;.msgBox.fullscreen &#123;\theight: 100vh; /* 全屏时撑满视口 */\tpadding: 24px 16px; /* 适当调整内边距 */\tfont-size: 16px; /* 放大字体方便阅读 */\tline-height: 1.5;&#125;.msgBox li &#123;\tmargin-bottom: 10px;\tfont-size: 18px;\tline-height: 26px;&#125;.msgBox li .li-item &#123;\twhite-space: pre-wrap; /* 自动换行，保留空格 */\tword-break: break-word; /* 单词内断行 */\t// padding-left: 1em; /* 缩进效果 */\tpadding-top: 2px;\tpadding-bottom: 2px;\ttext-indent: 0;&#125;.log-pre &#123; margin: 0; white-space: pre-wrap; font-family: monospace; font-size: 14px; line-height: 1.3; color: #d4d4d4;&#125; serviceTable.tsx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330import React, &#123; useEffect, useState, useRef &#125; from &quot;react&quot;;import &#123; Button, Input, InputNumber, Select &#125; from &quot;antd&quot;;import screenfull from &quot;screenfull&quot;;import &#123; useTranslation &#125; from &quot;react-i18next&quot;;import &#123; useEventBus &#125; from &quot;@/useEventBus&quot;; // 你自己的事件总线钩子import &quot;./serviceTable.less&quot;;const baseURL = import.meta.env.VITE_API_URL;const predefinedPaths = [\t&#123; value: &quot;/data/apps/ai/logs/run.log&quot;, name: &quot;AI日志&quot; &#125;,];const ServiceTable: React.FC = () =&gt; &#123;\tconst &#123; t &#125; = useTranslation();\tconst divRef = useRef&lt;HTMLUListElement | null&gt;(null);\tconst [filePath, setFilePath] = useState&lt;string&gt;(&quot;&quot;);\tconst [logs, setLogs] = useState&lt;string[][]&gt;([]);\tconst [initialLines, setInitialLines] = useState&lt;number&gt;(100);\tconst [btnLoading, setBtnLoading] = useState&lt;boolean&gt;(false);\tconst [isConnect, setIsConnect] = useState&lt;boolean&gt;(false);\tconst [isFullscreen, setIsFullscreen] = useState&lt;boolean&gt;(false);\tconst token = localStorage.getItem(&quot;admin_token&quot;) || &quot;&quot;;\t// SSE 控制相关 refs 和计数器\tconst abortControllerRef = useRef&lt;AbortController | null&gt;(null);\tconst reconnectTimeoutRef = useRef&lt;NodeJS.Timeout | null&gt;(null);\tconst retryCountRef = useRef&lt;number&gt;(0);\tconst maxRetries = 3;\t// 事件总线监听示例，收到特定事件时清理状态\tuseEventBus(&quot;message&quot;, (data: any) =&gt; &#123; if (data &amp;&amp; data !== &quot;log/serviceTable&quot;) &#123; reset(); setLogs([]); setInitialLines(100); setFilePath(&quot;&quot;); &#125;\t&#125;);\t// 全屏状态监听\tuseEffect(() =&gt; &#123; if (!screenfull.isEnabled) return; const onChange = () =&gt; &#123; setIsFullscreen(screenfull.isFullscreen); &#125;; screenfull.on(&quot;change&quot;, onChange); return () =&gt; &#123; screenfull.off(&quot;change&quot;, onChange); &#125;;\t&#125;, []);\t// 组件卸载时清理\tuseEffect(() =&gt; &#123; return () =&gt; &#123; if (abortControllerRef.current) &#123; abortControllerRef.current.abort(); abortControllerRef.current = null; &#125; if (reconnectTimeoutRef.current) &#123; clearTimeout(reconnectTimeoutRef.current); reconnectTimeoutRef.current = null; &#125; setIsConnect(false); setLogs([]); setFilePath(&quot;&quot;); setInitialLines(100); &#125;;\t&#125;, []);\tuseEffect(() =&gt; &#123; const handleKeyDown = (e: KeyboardEvent) =&gt; &#123; if (e.key === &quot;Enter&quot;) &#123; setLogs((prev) =&gt; [...prev, [&quot; &quot;]]); // 插入空行 setTimeout(() =&gt; &#123; if (divRef.current) &#123; divRef.current.scrollTop = divRef.current.scrollHeight; &#125; &#125;, 100); &#125; &#125;; window.addEventListener(&quot;keydown&quot;, handleKeyDown); return () =&gt; &#123; window.removeEventListener(&quot;keydown&quot;, handleKeyDown); &#125;;\t&#125;, []);\t// 连接 SSE\tconst connectToSSE = async () =&gt; &#123; // 中止旧请求 if (abortControllerRef.current) &#123; abortControllerRef.current.abort(); &#125; abortControllerRef.current = new AbortController(); const url = `$&#123;baseURL&#125;/service/logs/realtime?filePath=$&#123;encodeURIComponent( filePath )&#125;&amp;initialLines=$&#123;initialLines&#125;`; try &#123; const response = await fetch(url, &#123; method: &quot;GET&quot;, headers: &#123; Authorization: token, &quot;Content-Type&quot;: &quot;application/json&quot;, &#125;, signal: abortControllerRef.current.signal, &#125;); setBtnLoading(false); if (!response.ok) &#123; throw new Error(`HTTP error! status: $&#123;response.status&#125;`); &#125; if (!response.body) &#123; throw new Error(&quot;Response body is not a readable stream&quot;); &#125; setIsConnect(true); retryCountRef.current = 0; // 重连计数清零 const reader = response.body.getReader(); const decoder = new TextDecoder(&quot;utf-8&quot;); let done = false; while (!done) &#123; const result = await reader.read(); done = result.done ?? false; if (done) &#123; console.log(&quot;SSE stream closed&quot;); attemptReconnect(); break; &#125; const chunk = decoder.decode(result.value, &#123; stream: true &#125;); const messages = formatLog(chunk); setLogs((prev) =&gt; [...prev, messages]); setTimeout(() =&gt; &#123; if (divRef.current) &#123; divRef.current.scrollTop = divRef.current.scrollHeight; &#125; &#125;, 100); &#125; &#125; catch (error: any) &#123; setBtnLoading(false); if (error.name === &quot;AbortError&quot;) &#123; console.log(&quot;SSE request was aborted&quot;); &#125; else &#123; console.error(&quot;SSE error:&quot;, error); attemptReconnect(); &#125; &#125;\t&#125;;\t// 格式化日志字符串为字符串数组\tconst formatLog = (logString: string): string[] =&gt; &#123; const cleaned = logString .split(&quot;data:&quot;) .map( (entry) =&gt; entry .replace(/\\r /g, &quot; &quot;) // 标准化换行符 .replace(/ &#123;1,&#125;/g, &quot; &quot;) // 连续换行 → 仅保留1个 ) .filter( (entry) =&gt; entry.trim() !== &quot;&quot; &amp;&amp; !entry.trim().startsWith(&quot;heartbeat&quot;) ); return cleaned;\t&#125;;\t// 重连逻辑\tconst attemptReconnect = () =&gt; &#123; if (retryCountRef.current &gt;= maxRetries) &#123; console.warn(&quot;最大重连次数已达，停止重连&quot;); setIsConnect(false); return; &#125; if (reconnectTimeoutRef.current) &#123; clearTimeout(reconnectTimeoutRef.current); &#125; reconnectTimeoutRef.current = setTimeout(() =&gt; &#123; if (!abortControllerRef.current?.signal.aborted) &#123; retryCountRef.current += 1; console.log(`重连尝试第 $&#123;retryCountRef.current&#125; 次`); connectToSSE(); &#125; &#125;, 2000);\t&#125;;\t// 断开连接\tconst reset = () =&gt; &#123; setBtnLoading(false); if (abortControllerRef.current) &#123; abortControllerRef.current.abort(); abortControllerRef.current = null; &#125; setIsConnect(false); if (reconnectTimeoutRef.current) &#123; clearTimeout(reconnectTimeoutRef.current); reconnectTimeoutRef.current = null; &#125;\t&#125;;\t// 输入数字变化处理\tconst onChangeInitialLines = (value: number | null) =&gt; &#123; if (value !== null) setInitialLines(value);\t&#125;;\t// 全屏切换\tconst toggleFullscreen = () =&gt; &#123; if (!screenfull.isEnabled || !divRef.current) return; if (screenfull.isFullscreen) &#123; screenfull.exit(); &#125; else &#123; screenfull.request(divRef.current); &#125;\t&#125;;\treturn ( &lt;div&gt; &lt;div style=&#123;&#123; marginBottom: 12 &#125;&#125;&gt; &lt;span style=&#123;&#123; marginRight: 10 &#125;&#125;&gt; &lt;span&gt;&#123;t(&quot;first_latest&quot;)&#125;：&lt;/span&gt; &lt;InputNumber style=&#123;&#123; width: 200, marginRight: 8 &#125;&#125; placeholder=&#123;t(&quot;initial_content&quot;)&#125; min=&#123;0&#125; value=&#123;initialLines&#125; parser=&#123;(value: any) =&gt; value ? value.replace(/\\D/g, &quot;&quot;) : &quot;&quot; &#125; formatter=&#123;(value: any) =&gt; value ? value.replace(/\\B(?=(\\d&#123;3&#125;)+(?!\\d))/g, &quot;,&quot;) : &quot;&quot; &#125; onChange=&#123;onChangeInitialLines&#125; /&gt; &lt;/span&gt; &lt;Input placeholder=&#123;t(&quot;log_file&quot;)&#125; value=&#123;filePath&#125; onChange=&#123;(e) =&gt; setFilePath(e.target.value)&#125; style=&#123;&#123; width: 300, marginRight: 8 &#125;&#125; disabled=&#123;isConnect&#125; /&gt; &lt;Select showSearch allowClear style=&#123;&#123; width: 300, marginRight: 8 &#125;&#125; placeholder=&#123;t(&quot;select_log_file&quot;)&#125; value=&#123;filePath || undefined&#125; onChange=&#123;(value) =&gt; setFilePath(value)&#125; onSearch=&#123;(value) =&gt; setFilePath(value)&#125; options=&#123;predefinedPaths.map((path) =&gt; (&#123; label: path.name, value: path.value, &#125;))&#125; filterOption=&#123;false&#125; disabled=&#123;isConnect&#125; /&gt; &lt;Button disabled=&#123;isConnect&#125; loading=&#123;btnLoading&#125; type=&quot;primary&quot; onClick=&#123;() =&gt; &#123; setBtnLoading(true); setLogs([]); connectToSSE(); &#125;&#125; style=&#123;&#123; marginLeft: 8 &#125;&#125; &gt; &#123;t(&quot;connect&quot;)&#125; &lt;/Button&gt; &lt;Button disabled=&#123;!isConnect&#125; type=&quot;primary&quot; onClick=&#123;reset&#125; style=&#123;&#123; marginLeft: 8 &#125;&#125; &gt; &#123;t(&quot;disconnect&quot;)&#125; &lt;/Button&gt; &lt;Button type=&quot;primary&quot; onClick=&#123;toggleFullscreen&#125; style=&#123;&#123; marginLeft: 8 &#125;&#125; &gt; &#123;isFullscreen ? t(&quot;exit_fullscreen&quot;) : t(&quot;fullscreen&quot;)&#125; &lt;/Button&gt; &lt;/div&gt; &lt;ul className=&#123;`msgBox $&#123;isFullscreen ? &quot;fullscreen&quot; : &quot;&quot;&#125;`&#125; ref=&#123;divRef&#125; &gt; &#123;logs.map((msg, index) =&gt; &#123; if (!Array.isArray(msg)) return null; return ( &lt;li key=&#123;index&#125;&gt; &lt;pre className=&quot;log-pre&quot;&gt;&#123;msg.join(&quot; &quot;)&#125;&lt;/pre&gt; &lt;/li&gt; ); &#125;)&#125; &lt;/ul&gt; &lt;/div&gt;\t);&#125;;export default ServiceTable;","tags":["随笔"],"categories":["Java"]},{"title":"linux，jar脚本","path":"/2024/12/09/20241209/","content":"123456789101112131415161718192021222324252627#!/bin/bashAPP=$1;PORT=$2;APPS_BASE=&quot;/data/apps&quot;SHELL_FOLDER=$(dirname $(readlink -f &quot;$0&quot;))if [ -z &quot;$APP&quot; ]; then echo &quot;no app&quot;; exit 1;fiif [ -z &quot;$PORT&quot; ]; then echo &quot;no port&quot;; exit 1;fiecho &quot;$APP use port $PORT&quot;mkdir -p $APPS_BASE/$APP/binmkdir -p $APPS_BASE/$APP/logscp $SHELL_FOLDER/jar-start.sh $APPS_BASE/$APP/$APP-jar-start.shsed -i &quot;s/APP=noapp;/APP=$APP;/g&quot; $APPS_BASE/$APP/$APP-jar-start.shsed -i &quot;s/PORT=noport;/PORT=$PORT;/g&quot; $APPS_BASE/$APP/$APP-jar-start.shecho &quot;$APPS_BASE/$APP/$APP-jar-start.sh initialized!&quot; sudo sh init-jar-app.sh 项目名称 端口执行后 会生成 /data/apps/项目名称 这个目录cd进去这个目录 把jar包丢到bin里面 ，然后返回上级目录 执行 项目名称-jar-start.sh这个脚本","tags":["随笔"],"categories":["Java"]},{"title":"开发规范","path":"/2024/12/02/20241202/","content":"前端项目命名全部采用kebab-case命名，字母小写，以短横分隔单词，示例：my-project-name目录命名全部采用kebab-case命名，字母小写，以短横分隔单词，有复数结构时，要采用复数命名法，缩写不用复数，示例：scripts / styles / components / images / assets / views / utils / custom-themes / layout / img / doc / api / router文件命名全部采用kebab-case命名，字母小写，以短横分隔单词，示例：render-dom.js / home.css / home-banner.png 扩展名: 用 .tsx 作为组件扩展名。 文件名: 用大驼峰作为文件名，如：ReservationCard.tsx。 参数命名: React 组件用大驼峰，组件的实例用小驼峰。 eslint: react/jsx-pascal-case组件命名: 文件名作为组件名。例如：ReservationCard.jsx 应该用 ReservationCard 作为参数名。 然而，对于一个文件夹里的跟组件，应该用 index.jsx 作为文件名，同时用文件夹名作为组件名高阶组件HOC命名: 用高阶组件名和传入的组件名组合作为生成的组件的 displayName。 举个例子，一个高阶组件 withFoo()， 当传入一个组件 Bar 应该生成一个新的组件，他的 displayName 属性是 withFoo(Bar)。 命名严禁拼音和英文混合方式，更不允许直接使用中文，使用有意义且规范的缩写，避免望文不知义除了使用语义化标签，一个网页还需要遵守一定的结构和顺序，自上而下，从左到右，保持一定的顺序 1234567891011&lt;div class=&quot;app-container&quot;&gt; &lt;!-- header --&gt; &lt;div class=&quot;header-container&quot;&gt;&lt;/div&gt; &lt;!-- main --&gt; &lt;div class=&quot;main-container&quot;&gt; &lt;div class=&quot;left-box&quot;&gt;&lt;/div&gt; &lt;div class=&quot;content-box&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;!-- footer --&gt; &lt;div class=&quot;footer-container&quot;&gt;&lt;/div&gt; &lt;/div&gt; 后端Java，项目包名：com.touchsmailsql名称:touchsmail 命名数据库表名规范:模块名称_表名，比如第三方模块的ai配置表名字:third_party_ai_config项目命名全部采用小写方式， 以中划线分隔，例如：third-party表名对应包下的包的命名规范controller：Controller集合facade：调用Service的逻辑集合，要包含接口和实现类，实现类用@Component注入service：MyBatis-Plus的Service，里边不要写任何代码，只用于被facade调用。mapper：MyBatis-Plus的Mapper，被service调用。如果要写SQL，facade直接去调即可。entity：MyBatis-Plus的DAO（数据库对象）。bo：入参实体类vo：返回值实体类dto:传输constant：常量。比如：枚举类、Interface常量类helper：业务工具，比如：组装实体类的字段schedule：定时任务，比如：xxl-job的定时任务mq：mq消费者strategy：策略模式（假如用到策略模式的话）。其他设计模式也一样，单独写一个包，以设计模式的名字命名。common 目录需要依照项目进行特定的修改，示例 123456789src |-- common |-- |--- anno 通用注解，比如权限，登录等等|-- |--- constant 通用常量，比如 ResponseCodeConst|-- |--- domain 全局的 javabean，比如 BaseEntity,PageParamDTO 等|-- |--- exception 全局异常，如 BusinessException|-- |--- json json 类库，如 LongJsonDeserializer，LongJsonSerializer|-- |--- swagger swagger 文档|-- |--- validator 适合各个项目的通用 validator，如 CheckEnum，CheckBigDecimal 等 config 目录依照项目进行特定的修改，示例 123456src |-- config 项目的所有配置信息|-- |--- MvcConfig mvc的相关配置，如interceptor,filter等|-- |--- DataSourceConfig 数据库连接池的配置|-- |--- MybatisConfig mybatis的配置|-- |--- .... 其他 dao层方法命名规范 获取单个对象的方法用 get 做前缀。 获取多个对象的方法用 list 做前缀。 获取统计值的方法用 count 做前缀。 插入的方法用 save/insert 做前缀。 删除的方法用 remove/delete 做前缀。 修改的方法用 update 做前缀。 注释TODO描述已知待改进、待补充的修改点FIXME 用来描述已知缺陷函数注释参考： 123456/**xxx方法用来干啥的@param 参数1，是啥@return 参数2，是啥*/ 其他数据库里,时间日期统一存储时间戳，全局用1个静态工具函数来转为具体日期时间无论是 controller，service，manager，dao 亦或是其他的代码，每个方法最多 3 个参数，如果超出 3 个参数的话，要封装成 javabean 对象要用枚举来表示类型，不要用数字。比如：有三种支付方式：微信、支付宝、银行卡，则这样定义枚举： 123456789101112131415161718192021package com.example.pay; public enum PayType &#123; ALIPAY(&quot;支付宝支付&quot;), WECHAT_PAY(&quot;微信支付&quot;), BANK_CARD_PAY(&quot;银行卡支付&quot;) ; /** * 描述 */ private final String description; PayType(String description) &#123; this.description = description; &#125; public String getDescription() &#123; return description; &#125;&#125; controller只充当路由的角色，只允许使用@Valid 注解做简单的校验，不做任何的业务逻辑操作，不做任何的参数、业务校验，不做任何的数据组合、拼装、赋值等操作只能在 controller 层获取当前请求用户，并传递给 service 层接口路径驼峰命名接口路径前面统一带/ 公共代码推送： feat: 新功能 fix: 修补bug docs: 文档 style: 格式 refactor: 重构 chore: 构建过程或辅助工具的变动 revert: 撤销，版本回退 perf: 性能优化 test：测试 improvement: 改进 例如：新增用户登陆 feat:UserLogin不确定的功能测试开发，自己新建1个分支，开发测试没问题后再合并回去，然后删除测试用的分支提交前应该先编译一次，防止出现编译都报错的情况提交前检查代码是否格式化，是否符合代码规范，无用的包引入、变量是否清除等配置文件按环境区分，使用环境变量来切换线上环境尽量打错误级别的日志","tags":["其他"],"categories":["其他"]},{"title":"cenos7.6 yum报错","path":"/2024/10/10/20241010/","content":"Could not resolve host: mirrorlist.centos.org; 未知的错误 解决方案：更换镜像源 123wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo#或者curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo","tags":["报错"],"categories":["Linux"]},{"title":"cenos7.6 安装宝塔","path":"/2024/10/10/2024101002/","content":"1yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh 中途需要输入y回车确认安装","tags":["笔记"],"categories":["Linux"]},{"title":"win11安装多个版本的node","path":"/2024/09/23/20240923/","content":"在做项目开发过程中，有时会因为node版本过高或太低，导致报错；如何在同一个系统中安装多个版本的node呢，那就是使用nvm进行管理 安装前须知之前有node环境的需卸载干净,卸载完后检测系统中是否还存在nodejs，cmd,node -v nvm安装安装包下载地址： https://github.com/coreybutler/nvm-windows/releases 确认是否安装成功 cmd 运行 nvm 到此nvm已经安装成功，下面完成下载镜像的配置，打开nvm文件夹下的settings.txt文件，在最后添加以下代码（不改，下载node可能会报错） 12345node_mirror: https://npm.taobao.org/mirrors/node/npm_mirror: https://npm.taobao.org/mirrors/npm/ 如果后续安装node的时候报错 Could not retrieve https://npm.taobao.org/mirrors/node/index.json.” 则可能是npm.taobao.org失效了，改成npmmirror.com，以下完整文件可参考 1234567root: D:\\Users\\Administrator\\AppData\\Roaming vmpath: D:\\Program Files odejsnode_mirror: https://npmmirror.com/mirrors/node/npm_mirror: https://npmmirror.com/mirrors/npm/ 配置环境变量这里nvm安装完成，接下来配置环境变量，不配置的话，nvm安装使用了node版本，cmd运行node命令可能报不存在 1.打开nvm文件夹，就是上面修改配置文件的那个文件夹，我这里的是 D:\\Users\\Administrator\\AppData\\Roaming vm 2.在nvm下面建一个文件夹nodejs，这个nodejs文件夹下面不要放任何东西，保持为空即可。 3.打开控制面板—高级系统设置—高级–环境变量，将红色圈圈部分变量值设置为刚才nodejs文件夹所在位置 4.设置好之后请务必关掉终端后，再打开，总之一定要重新进cmd 5.如果还是报node命令不存在，则重新nvm use [your node version]。 nvm使用1234567891011nvm -h // 查看所有命令；nvm list // 查看当前安装的nodeJS的版本；这里有星号标注的说明是当前使用的nodeJS版本nvm install v11.15.0 // 指定安装v11.15.0 的nodeJS；nvm use v11.15.0 // 指定使用某版本的nodeJS；nvm uninstall 11.15.0 // 卸载指定版本的nodeJS；","tags":["笔记"],"categories":["Node"]},{"title":"java流式输出接口","path":"/2024/09/14/20240914/","content":"Controller1234567891011121314151617181920212223242526272829303132333435package com.ioo.system.refactor_report.controller;import com.ioo.system.refactor_report.service.OldDateImportService;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;import javax.annotation.Resource;/** * @Project：astoa-admin * @Package：com.ioo.system.refactor_report.controller * @Author：xen * @name：OldDateImportController * @Date：2024/9/14/0014 14:01 */@RestController@RequestMapping(&quot;/v2/report/DateImport&quot;)public class OldDateImportController&#123; @Resource private OldDateImportService dateImportService; @GetMapping() public SseEmitter streamSse() &#123; SseEmitter emitter = new SseEmitter(Long.MAX_VALUE); Thread streamThread = new Thread(() -&gt; dateImportService.main(emitter)); streamThread.start(); return emitter; &#125;&#125; Service12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.ioo.system.refactor_report.service;import lombok.extern.slf4j.Slf4j;import org.springframework.stereotype.Service;import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;import java.io.IOException;/** * @Project：astoa-admin * @Package：com.ioo.system.refactor_report.service * @Author：xen * @name：OldDateImportService * @Date：2024/8/1/0001 18:20 */@Slf4j@Servicepublic class OldDateImportService &#123; public void main(SseEmitter emitter) &#123; try &#123; templateImport(emitter); &#125; catch (Exception e) &#123; Thread.currentThread().interrupt(); log.error(e.getMessage()); &#125; finally &#123; emitter.complete(); &#125; &#125; private void sendDataToEmitter(SseEmitter emitter, String data) &#123; try &#123; emitter.send(SseEmitter.event().data(data)); &#125; catch (IOException e) &#123; emitter.completeWithError(e); &#125; &#125; private void templateImport(SseEmitter emitter) &#123; sendDataToEmitter(emitter, &quot;模板导入开始&quot;); sendDataToEmitter(emitter, &quot;模板导入结束&quot;); &#125; private void instanceImport(SseEmitter emitter) &#123; sendDataToEmitter(emitter, &quot;实例导入开始&quot;); sendDataToEmitter(emitter, &quot;实例导入结束&quot;); &#125; private void contentTemplateImport(SseEmitter emitter) &#123; sendDataToEmitter(emitter, &quot;实例导入开始&quot;); sendDataToEmitter(emitter, &quot;实例导入结束&quot;); &#125;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"R","path":"/2024/09/03/20240903/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118package com.scrm.common.core.web.domain;import java.io.Serializable;import com.scrm.common.constant.HttpStatus;/** * 响应信息主体 * * @author ruoyi */public class R&lt;T&gt; implements Serializable&#123; private static final long serialVersionUID = 1L; /** 成功 */ public static final int SUCCESS = HttpStatus.SUCCESS; /** 失败 */ public static final int FAIL = HttpStatus.ERROR; private int code; private String msg; private T data; public static &lt;T&gt; R&lt;T&gt; ok() &#123; return restResult(null, SUCCESS, &quot;操作成功&quot;); &#125; public static &lt;T&gt; R&lt;T&gt; ok(T data) &#123; return restResult(data, SUCCESS, &quot;操作成功&quot;); &#125; public static &lt;T&gt; R&lt;T&gt; ok(T data, String msg) &#123; return restResult(data, SUCCESS, msg); &#125; public static &lt;T&gt; R&lt;T&gt; fail() &#123; return restResult(null, FAIL, &quot;操作失败&quot;); &#125; public static &lt;T&gt; R&lt;T&gt; fail(String msg) &#123; return restResult(null, FAIL, msg); &#125; public static &lt;T&gt; R&lt;T&gt; fail(T data) &#123; return restResult(data, FAIL, &quot;操作失败&quot;); &#125; public static &lt;T&gt; R&lt;T&gt; fail(T data, String msg) &#123; return restResult(data, FAIL, msg); &#125; public static &lt;T&gt; R&lt;T&gt; fail(int code, String msg) &#123; return restResult(null, code, msg); &#125; private static &lt;T&gt; R&lt;T&gt; restResult(T data, int code, String msg) &#123; R&lt;T&gt; apiResult = new R&lt;&gt;(); apiResult.setCode(code); apiResult.setData(data); apiResult.setMsg(msg); return apiResult; &#125; public int getCode() &#123; return code; &#125; public void setCode(int code) &#123; this.code = code; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; public T getData() &#123; return data; &#125; public void setData(T data) &#123; this.data = data; &#125; public static &lt;T&gt; Boolean isError(R&lt;T&gt; ret) &#123; return !isSuccess(ret); &#125; public static &lt;T&gt; Boolean isSuccess(R&lt;T&gt; ret) &#123; return R.SUCCESS == ret.getCode(); &#125;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"使用Github-Action持续部署Springboot或vue","path":"/2024/08/27/20240827/","content":"案例一GitHub Actions 是 GitHub 提供的一项持续集成 (CI) 和持续部署 (CD) 服务。它允许你在代码仓库中定义和运行自动化的工作流程，以响应存储库中的事件或调度。GitHub Actions 可以用于构建、测试、打包和部署项目，也可以执行其他自动化任务。 第一步需要先配置 secrets，保证我们的服务器信息不暴露 GitHub Actions 中的 secrets 和 variables 都是用于存储和访问敏感信息或配置的机制 因为我的服务器用的宝塔面板环境，加上构建出来的包和文件并不是很大，所以使用的方式是先在 github action 的环境构建打包，然后将包发送到目标服务器。你也可以在 github action 里让目标服务器执行命令去做 git，构建，部署，启动等等相关的 Springboot123456789101112131415161718192021222324252627282930313233name: Java CI with Mavenon: push: branches: [ &quot;master&quot; ]jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up JDK 17 uses: actions/setup-java@v3 with: java-version: &#x27;17&#x27; distribution: &#x27;temurin&#x27; cache: maven - name: Build with Maven run: mvn -B package --file pom.xml - name: copy jar uses: cross-the-world/ssh-scp-ssh-pipelines@latest with: host: $&#123;&#123; secrets.HOST &#125;&#125; user: $&#123;&#123; secrets.USERNAME &#125;&#125; pass: $&#123;&#123; secrets.PASSWORD &#125;&#125; port: 22 scp: | ./target/springboot.jar =&gt; /home/ last_ssh: | JAR_; PID=$(ps aux | grep &quot;$JAR_NAME&quot; | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27;); if [ -n &quot;$PID&quot; ]; then kill -9 $PID &amp;&amp; echo &quot;进程 $PID 已被杀死&quot;; else echo &quot;未找到与 $JAR_NAME 相关的进程&quot;; fi /usr/bin/java -jar -Xmx1024M -Xms256M /home/springboot.jar &amp; Vue1234567891011121314151617181920212223242526272829303132333435363738name: Deploy to Serveron: push: branches: [ &quot;master&quot; ]jobs: deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-node@v3 with: node-version: 16 - name: Install dependencies run: yarn - name: Build project run: yarn generate - name: zip dist run: zip -r dist.zip dist/ # 部署到服务器 - name: Deploy 🚀 uses: cross-the-world/ssh-scp-ssh-pipelines@latest with: host: $&#123;&#123; secrets.HOST &#125;&#125; user: $&#123;&#123; secrets.USERNAME &#125;&#125; pass: $&#123;&#123; secrets.PASSWORD &#125;&#125; port: 22 scp: | &#x27;./dist.zip&#x27; =&gt; /home last_ssh: | cd /home/ rm -rf dist/ || true unzip dist.zip 常见的 GitHub Actions YAML 语法和关键概念GitHub Actions 使用 YAML 文件来定义工作流程。以下是一些常见的 GitHub Actions YAML 语法和关键概念： 工作流程（Workflow）的定义：12345678910111213name: My Workflowon: push: branches: - mainjobs: my_job: runs-on: ubuntu-latest steps: - name: Checkout Repository uses: actions/checkout@v2 # 其他步骤... name: 工作流程的名称。 on: 触发工作流程的事件，例如 push 到特定分支。 jobs: 包含一个或多个任务的部分。 任务（Job）的定义：1234567my_job: runs-on: ubuntu-latest steps: - name: Step 1 run: echo &quot;Hello, World!&quot; # 其他步骤... runs-on: 指定任务运行的操作系统和环境。 steps: 包含一个或多个步骤的列表。 步骤（Steps）的定义：123456789steps: - name: Step 1 run: echo &quot;Hello, World!&quot; - name: Step 2 uses: actions/setup-node@v3 with: node-version: &#x27;14&#x27; # 其他步骤... name: 步骤的名称。 run: 执行的命令或脚本。 uses: 使用的动作（可以是内置动作或自定义动作）。 with: 传递给动作的参数。 触发器（Trigger）的定义：12345678on: push: branches: - main pull_request: branches: - feature/* on: 触发工作流程的事件。 push: 代码推送事件。 pull_request: 合并请求事件。 环境变量（Environment Variables）的定义：12345678jobs: my_job: runs-on: ubuntu-latest env: MY_VARIABLE: my_value steps: # 步骤... env: 定义任务运行时的环境变量。 Secrets 和 Variables使用 Secrets：GitHub Actions 的 secrets 是用于存储敏感信息，例如 API 密钥、访问令牌等。这些 secrets 可以被工作流程中的步骤引用，但它们是加密的，并且只有在运行工作流程时才会暴露给步骤。 在 GitHub 存储库中创建 secret： 转到 GitHub 存储库的页面。 在存储库顶部导航栏中，点击 “Settings”。 在左侧边栏中，选择 “Secrets”。 点击 “New repository secret”，然后输入 secret 名称和值。 在工作流程中使用 secret： 1234567jobs: my_job: runs-on: ubuntu-latest steps: - name: Use secret run: echo $&#123;&#123; secrets.MY_SECRET &#125;&#125; 这里 MY_SECRET 是你创建的 secret 的名称，可以在步骤中使用 $&#123;&#123; secrets.MY_SECRET &#125;&#125; 引用它。 使用 Variables：GitHub Actions 的 variables 是由 GitHub 提供的一组默认环境变量，同时你也可以定义自己的环境变量。这些变量可以在工作流程的任何步骤中使用。 在工作流程中使用 GitHub 提供的 variables： 1234567jobs: my_job: runs-on: ubuntu-latest steps: - name: Use GitHub-provided variable run: echo $&#123;&#123; github.event_name &#125;&#125; 这里的 github.event_name 是 GitHub 提供的一个默认变量，表示触发工作流程的事件的名称。 在工作流程中定义自己的 variables： 123456789jobs: my_job: runs-on: ubuntu-latest env: MY_VARIABLE: my_value steps: - name: Use custom variable run: echo $MY_VARIABLE 在 env 部分定义自己的环境变量，然后在步骤中使用 $MY_VARIABLE 引用它。 注意：GitHub Actions 中的环境变量（包括 secrets 和 variables）在步骤中的引用方式使用 $&#123;&#123; ... &#125;&#125; 语法。此外，secrets 只能在工作流程的同一存储库中使用，而 variables 则可以在不同存储库的工作流程中共享。 案例二传统的部署方式是更新代码 -&gt; 本地构建 -&gt; 上传服务器发布；而现代化的部署方式是 CI/CD(持续集成 / 持续部署) CI/CD 服务有很多： Jenkins Gitlab CI Github Actions Travis CI Circle CI … 开始前需要准备 Linux 服务器；把本地代码提交 GitHub 远程仓库。 然后生成配置 GitHub Actions Token 生成 Token：https://github.com/settings/tokens 或者可以点击，头像 -&gt; Settings -&gt; Developer settings -&gt; Personal access tokens -&gt; Generate new Token Token 名称填写Token，Select scopes勾选 repo，然后滚动到网页最下面点击提交按钮。生成了 Token，复制保存（该 Token 只显示一次，忘记了就再生成） 配置到项目的 Secrets 中：进入项目 -&gt; Settings -&gt; Secrets -&gt; New secret Name：建议和刚才生成 Token 保持一致 Value：为刚才生成的 Token 除了配置 Token，还要配置服务器的 HOST、USERNAME、PASSWORD、PORT，这些配置在 GitHub 把项目部署到服务器的时候使用到 这里 GitHun 的配置已经完成，接下要配置 GitHub Actions 执行脚本 在项目根目录创建.githun/workflows目录 在workflows目录创建main.yml文件，文件内容如下，这是 GitHub Actions 执行识别的文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364name: Publish And Deploy Demo # 自动部署的名称on: push: tags: # 当我们提交代码为tag 是以&#x27;v&#x27;开头的时候才会触发自动部署到服务端 如 git push tag v0.1.0 - &#x27;v*&#x27;jobs: build-and-deploy: runs-on: ubuntu-latest # 运行环境，告诉它运行在什么环境 steps: # 步骤 # 第一步：下载源码（CI/CD拉取代码到自己的本地） - name: Checkout uses: actions/checkout@master # 第二步：打包构建 - name: Build uses: actions/setup-node@master - run: npm install # 安装第三方包 - run: npm run build # 打包 - run: tar -zcvf release.tgz .nuxt static nuxt.config.js package.json package-lock.json pm2.config.json # 把.nuxt、nuxt.config.js等文件，打包压缩为release.tgz # 第三步：发布 Release - name: Create Release # 创建Release，可以在仓库看到一个个版本 id: create_release uses: actions/create-release@master env: GITHUB_TOKEN: $&#123;&#123; secrets.TOKEN &#125;&#125; # 之前GitHub添加的Token with: tag_name: $&#123;&#123; github.ref &#125;&#125; # (tag)标签名称 release_name: Release $&#123;&#123; github.ref &#125;&#125; draft: false # 是否是草稿 prerelease: false # 是否是预发布 # 第四步：上传构建结果到 Release（把打包的tgz上传到Release） - name: Upload Release Asset id: upload-release-asset uses: actions/upload-release-asset@master env: GITHUB_TOKEN: $&#123;&#123; secrets.TOKEN &#125;&#125; with: upload_url: $&#123;&#123; steps.create_release.outputs.upload_url &#125;&#125; # 上传地址，通过创建Release获取到的 asset_path: ./release.tgz # 要上传文件 asset_name: release.tgz # 上传后的文件名 asset_content_type: application/x-tgz # 第五步：部署到服务器 - name: Deploy uses: appleboy/ssh-action@master # 使用ssh链接服务器 with: host: $&#123;&#123; secrets.HOST &#125;&#125; username: $&#123;&#123; secrets.USERNAME &#125;&#125; password: $&#123;&#123; secrets.PASSWORD &#125;&#125; port: $&#123;&#123; secrets.PORT &#125;&#125; script: | # 执行命令（运行到服务器）cd：要确保服务器有这个目录； wget：下载上一步的release到服务器； tar：解压； 安装依赖；启动服务 cd /root/realworld-nuxtjs wget https://github.com/YuYun95/realworld-nuxtjs/releases/latest/download/release.tgz -O release.tgz tar zxvf release.tgz npm install --production pm2 reload pm2.config.json 到此全部配置已经完成，把代码提交 GitHub 仓库 git add . git commit -m &quot;feat: 第一次发布部署&quot; git push(此时只是推送了提交记录，并不会触发自动化构建部署) git add . git tag v0.1.0(通过 tag 打版) git tag(查看版本) git push origin v0.1.0(把本地标签推送到远程仓库，会触发自动构建部署) 执行完上面的命令 GitHub Actions 将自动打包部署到服务器 可以点击项目仓库的 Actions 可以查看打包部署过程和结果，全部勾绿色为部署成功，浏览器输入服务器地址即可打开 案例三一、Github Actions 是什么？GitHub Actions 是 GitHub 提供的一项功能，用于自动化软件开发工作流程。它允许你在代码仓库中配置和运行自动化任务，以响应各种事件和操作。这些任务可以包括构建、测试、部署和其他 CI/CD（持续集成 / 持续部署）工作流程。 GitHub Actions 的核心概念是工作流程（Workflow）。工作流程是一系列由 GitHub Actions 执行的任务，这些任务根据预定义的触发器（例如推送代码、创建 Pull Request 等）自动触发执行。 GitHub Actions 可以用于自动化执行各种软件开发任务： 构建和测试代码。 部署应用程序到云服务或服务器。 自动化代码审查和测试覆盖率检查。 触发持续集成和持续部署流程。 二、Github 项目配置 按照截图的目录配置 SEVER_IP 和 SERVER_PASSWORD。 项目代码中，新建目录. github/workflows，其中新增文件 git-release.yml，目录和内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394name: Git Release CI# 指定在哪个分支，以及什么操作触发on: # 在 push 到 master 和 release/1.8.0 的时候触发 push: branches: [ &quot;master&quot;, &quot;release/1.8.0&quot; ] # 在对 master 分支实施 pull_request（Merge 其他分支到 master）时触发 pull_request: branches: [ &quot;master&quot; ]# 具体任务配置jobs: build: # 指定运行环境 runs-on: ubuntu-latest # 具体的步骤 steps: # checkout 代码到 Github Actions 运行容器中 - uses: actions/checkout@v3 # 获取当前时间，后边打包用 - name: Get Current Date id: date run: echo &quot;::set-output # 向容器安装 Java 21，为 SpringBoot 提供运行环境 - name: Set up JDK 21 uses: actions/setup-java@v3 with: java-version: &#x27;21&#x27; distribution: &#x27;adopt&#x27; # 获取 relase 分支，用于打包 - name: Get Branch Name id: get_branch_name run: echo &quot;::set-output name=branch_name::$(echo $line | grep &#x27;SNAPSHOT&#x27; pom.xml | awk &#x27;&#123;split($0,a,&quot;-&quot;); print a[1]&#125;&#x27;| awk &#x27;&#123;split($0,a,&quot;&gt;&quot;); print a[2]&#125;&#x27;)&quot; # 通过 maven 打包 - name: Build with Maven run: mvn -B package --file pom.xml # 向 github 创建 tag 以及 release - name: Create Release id: create_release uses: actions/create-release@v1 env: GITHUB_TOKEN: $&#123;&#123; secrets.GITHUB_TOKEN &#125;&#125; with: tag_name: $&#123;&#123; steps.get_branch_name.outputs.branch_name &#125;&#125;-$&#123;&#123; steps.date.outputs.date &#125;&#125; release_name: Release $&#123;&#123; steps.get_branch_name.outputs.branch_name &#125;&#125;-$&#123;&#123; steps.date.outputs.date &#125;&#125; draft: false prerelease: false # 向 Github 的 Release 上传 jar 包 - name: Upload Release Asset Jar id: upload-release-asset-jar uses: actions/upload-release-asset@v1 env: GITHUB_TOKEN: $&#123;&#123; secrets.GITHUB_TOKEN &#125;&#125; with: upload_url: $&#123;&#123; steps.create_release.outputs.upload_url &#125;&#125; asset_path: target/stock-and-fund-$&#123;&#123; steps.get_branch_name.outputs.branch_name &#125;&#125;-SNAPSHOT.jar asset_name: stock-and-fund-$&#123;&#123; steps.get_branch_name.outputs.branch_name &#125;&#125;-SNAPSHOT.jar asset_content_type: application/gzip # 向 Github 的 Release 上传 database 文件，如果你的项目没有可以删除这部分 - name: Upload Release Asset DB id: upload-release-asset-db uses: actions/upload-release-asset@v1 env: GITHUB_TOKEN: $&#123;&#123; secrets.GITHUB_TOKEN &#125;&#125; with: upload_url: $&#123;&#123; steps.create_release.outputs.upload_url &#125;&#125; asset_path: stock-and-fund.db asset_name: stock-and-fund.db asset_content_type: application/gzip # 把 jar 包上传到指定服务器，其中的 secrets.SERVER_IP，secrets.SERVER_PASSWORD 需要在该项目 Github 的 Setting 中配置 - name: copy file to server uses: appleboy/scp-action@v0.1.4 with: host: $&#123;&#123; secrets.SERVER_IP &#125;&#125; username: root password: $&#123;&#123; secrets.SERVER_PASSWORD &#125;&#125; port: 22 source: &#x27;target/stock-and-fund-$&#123;&#123; steps.get_branch_name.outputs.branch_name &#125;&#125;-SNAPSHOT.jar&#x27; target: &#x27;/opt/stock-and-fund/&#x27; # ssh 到指定服务器，执行部署命令，具体 deployment.sh 的代码可以去看我之前写的 docker 部署 - name: Deploy stock and fund uses: garygrossgarten/github-action-ssh@release with: command: | cd /opt/stock-and-fund/ rm -rf ./stock-and-fund-$&#123;&#123; steps.get_branch_name.outputs.branch_name &#125;&#125;-SNAPSHOT.jar mv target/stock-and-fund-$&#123;&#123; steps.get_branch_name.outputs.branch_name &#125;&#125;-SNAPSHOT.jar ./ ./deployment.sh host: $&#123;&#123; secrets.SERVER_IP &#125;&#125; username: root port: 22 password: $&#123;&#123; secrets.SERVER_PASSWORD &#125;&#125; 案例四一、自动化部署1.1 提交代码到 Github 1.2 设置服务器密钥、GitHub 私钥、DockerHub 账号secretvalueremarkDOCKER_HUB_ACCESS_TOKEN1234567890dockerhub 账号私钥DOCKER_HUB_USERNAMEbubaiwantongdockerhub 账号SERVER_HOST127.0.0.1服务器 IP 地址SERVER_PASSWORD1234567890服务器密码SERVER_PORT22服务器开放端口SERVER_PRIVATE_KEY1234567890服务器私钥SERVER_USERNAMEroot服务器账号TOKEN1234567890Github 的 Token 1.2.1 设置服务器密钥 1.2.2 设置 Github 私钥 1.2.3 设置 DockerHub 账号 1.3 新增工作流文件 maven.yml文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869name: Deploy with dockeron: push: # 分支 branches: [ &quot;master&quot; ] pull_request: branches: [ &quot;master&quot; ]jobs: compile: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Set up JDK 21 uses: actions/setup-java@v2 with: java-version: &#x27;21&#x27; distribution: &#x27;adopt&#x27; # maven缓存，不加的话每次都会去重新拉取，会影响速度 - name: Dependies Cache uses: actions/cache@v2 with: path: ~/.m2/repository key: $&#123;&#123; runner.os &#125;&#125;-maven-$&#123;&#123; hashFiles(&#x27;**/pom.xml&#x27;) &#125;&#125; restore-keys: | $&#123;&#123; runner.os &#125;&#125;-maven- # 编译打包 - name: Build with Maven run: | mvn package -Dmaven.test.skip=true # 登录Docker Hub - name: Login to Docker Hub uses: docker/login-action@v1 with: username: $&#123;&#123; secrets.DOCKER_HUB_USERNAME &#125;&#125; password: $&#123;&#123; secrets.DOCKER_HUB_ACCESS_TOKEN &#125;&#125; - name: Set up Docker Buildx id: buildx uses: docker/setup-buildx-action@v1 #build镜像并push到中央仓库中 - name: Build and push id: docker_build uses: docker/build-push-action@v2 with: context: ./ file: ./Dockerfile push: true tags: $&#123;&#123;secrets.DOCKER_HUB_USERNAME&#125;&#125;/back:latest #push后，用ssh连接服务器执行脚本 - name: SSH# uses: fifsky/ssh-action@master uses: appleboy/ssh-action@master with:# command: |# cd /develop/work/education-back-server# sh start.sh host: $&#123;&#123;secrets.SERVER_HOST&#125;&#125; username: $&#123;&#123;secrets.SERVER_USERNAME&#125;&#125; port: $&#123;&#123;secrets.SERVER_PORT &#125;&#125;# key: $&#123;&#123;secrets.SERVER_PRIVATE_KEY&#125;&#125; password: $&#123;&#123;secrets.SERVER_PASSWORD&#125;&#125; script: sh /develop/work/education-back-server/start.sh# sh start.sh 1.4 新增 Dockerfile 文件 Dockerfile文件 123456789101112131415161718192021222324252627#基础镜像FROM bubaiwantong/openjdk:21-jdk-alpine#安装字体RUN sed -i &#x27;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#x27; /etc/apk/repositories &amp;&amp; apk add --update ttf-dejavu fontconfig &amp;&amp; rm -rf /var/cache/apk/* &amp;&amp; mkfontscale &amp;&amp; mkfontdir &amp;&amp; fc-cacheRUN apk add --update ttf-dejavu fontconfig &amp;&amp; rm -rf /var/cache/apk/*#添加文件ADD education-back/target/back-0.0.1-SNAPSHOT.jar /usr/localRUN chmod u+x /usr/local/back-0.0.1-SNAPSHOT.jar#设置时区RUN rm -f /etc/localtime \\&amp;&amp; ln -sv /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\&amp;&amp; echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone#挂载目录到容器#VOLUME [&quot;/data&quot;]#环境变量设置#ENV #开放端口EXPOSE 8088#启动时执行的命令CMD [&quot;/bin/bash&quot;]#启动时执行的命令ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/usr/local/back-0.0.1-SNAPSHOT.jar&quot;] 1.5 编写服务器启动脚本start.sh文件 12345678910111213#!/bin/bashdocker pull bubaiwantong/back:latestdocker tag docker.io/bubaiwantong/back:latest back:latestdocker stop backdocker rm backdocker run --name back -p 8088:8088 -d back:latestdocker image prune - 2.7 开启自动化部署提交代码到 master，在 GitHub 中的 Actions 即可发现项目正在自动化部署 在浏览器地址栏打开[ 就可以发现自动化部署成功啦！","tags":["笔记"],"categories":["Java"]},{"title":"Idea试用过期后，无法进入主界面","path":"/2024/08/26/20240826/","content":"Idea试用过期后，无法进入主界面，这时候怎么办呢？试了网上有很多例子，但是都不成功。最后还是莫名其妙成功的，甚至都不知道是哪个方案导致的成功。我的步骤是方式二，无效方式三，无效方式一，刚开始删除\\Local\\JetBrains文件，系统提示被占用无法删除，然后就莫名其妙进入主界面了。 方式一 点击Evaluate按钮，就可以免费使用。 过了30天的试用期。重新试用30天。我们需要如下操作： 删除C:\\Users\\用户名\\AppData\\Local\\JetBrains文件 删除C:\\Users\\用户名\\AppData\\Roaming\\JetBrains文件 删除注册表中的JetBrains 找到注册表的文件方法如下： 1、按下键盘上的组合建【Win】+【R】，打开运行文件窗口。 2、然后在窗口中输入命令：【regedit】，然后点击确定。 3、然后到删除表中找到HKEY_CURRENT_USER/SOFTWARE/JavaSoft/Prefs/jetbrains删除 4、重新启动idea,重新免费使用30天试用期。 方式二Windows系统： 本地idea安装路径找到eval目录，将该目录下的idea212.evaluation.key删除即可。 路径：C:\\Users\\XXXX\\AppData\\Roaming\\JetBrains\\IntelliJIdea2021.2\\eval\\idea212.evaluation.key Mac系统：（m1） 同样找到idea安装目录，删除eval\\idea212.evaluation.key 路径：资源库/Application Support/JetBrains/IntelliJIdea2021.2\\eval\\idea212.evaluation.key 方式三代码一 123456789101112131415161718192021222324252627282930313233343536373839404142434445Windows Registry Editor Version 5.00[-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;7B8E9164-324D-4A2E-A46D-0165FB2000EC&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;7B8E9164-324D-4A2E-A46D-0165FB2000EC&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;7B8E9164-324D-4A2E-A46D-0165FB2000EC&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;7B8E9164-324D-4A2E-A46D-0165FB2000EC&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;6DDF00DB-1234-46EC-8356-27E7B2051192&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;6DDF00DB-1234-46EC-8356-27E7B2051192&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;6DDF00DB-1234-46EC-8356-27E7B2051192&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;6DDF00DB-1234-46EC-8356-27E7B2051192&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;D5B91409-A8CA-4973-9A0B-59F713D25671&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;D5B91409-A8CA-4973-9A0B-59F713D25671&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;D5B91409-A8CA-4973-9A0B-59F713D25671&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;D5B91409-A8CA-4973-9A0B-59F713D25671&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;5ED60779-4DE2-4E07-B862-974CA4FF2E9C&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;5ED60779-4DE2-4E07-B862-974CA4FF2E9C&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;5ED60779-4DE2-4E07-B862-974CA4FF2E9C&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;5ED60779-4DE2-4E07-B862-974CA4FF2E9C&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;07999AC3-058B-40BF-984F-69EB1E554CA7&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;07999AC3-058B-40BF-984F-69EB1E554CA7&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;07999AC3-058B-40BF-984F-69EB1E554CA7&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;07999AC3-058B-40BF-984F-69EB1E554CA7&#125;][HKEY_CURRENT_USER\\Software\\DownloadManager]&quot;FName&quot;=-&quot;LName&quot;=-&quot;Email&quot;=-&quot;Serial&quot;=-[HKEY_LOCAL_MACHINE\\Software\\Internet Download Manager]&quot;FName&quot;=-&quot;LName&quot;=-&quot;Email&quot;=-&quot;Serial&quot;=-[HKEY_LOCAL_MACHINE\\Software\\Wow6432Node\\Internet Download Manager]&quot;FName&quot;=-&quot;LName&quot;=-&quot;Email&quot;=-&quot;Serial&quot;=- 代码二 123456789101112131415161718192021222324252627282930313233343536373839404142434445Windows Registry Editor Version 5.00[-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;7B8E9164-324D-4A2E-A46D-0165FB2000EC&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;7B8E9164-324D-4A2E-A46D-0165FB2000EC&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;7B8E9164-324D-4A2E-A46D-0165FB2000EC&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;7B8E9164-324D-4A2E-A46D-0165FB2000EC&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;6DDF00DB-1234-46EC-8356-27E7B2051192&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;6DDF00DB-1234-46EC-8356-27E7B2051192&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;6DDF00DB-1234-46EC-8356-27E7B2051192&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;6DDF00DB-1234-46EC-8356-27E7B2051192&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;D5B91409-A8CA-4973-9A0B-59F713D25671&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;D5B91409-A8CA-4973-9A0B-59F713D25671&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;D5B91409-A8CA-4973-9A0B-59F713D25671&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;D5B91409-A8CA-4973-9A0B-59F713D25671&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;5ED60779-4DE2-4E07-B862-974CA4FF2E9C&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;5ED60779-4DE2-4E07-B862-974CA4FF2E9C&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;5ED60779-4DE2-4E07-B862-974CA4FF2E9C&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;5ED60779-4DE2-4E07-B862-974CA4FF2E9C&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\CLSID\\&#123;07999AC3-058B-40BF-984F-69EB1E554CA7&#125;][-HKEY_CURRENT_USER\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;07999AC3-058B-40BF-984F-69EB1E554CA7&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\CLSID\\&#123;07999AC3-058B-40BF-984F-69EB1E554CA7&#125;][-HKEY_LOCAL_MACHINE\\Software\\Classes\\Wow6432Node\\CLSID\\&#123;07999AC3-058B-40BF-984F-69EB1E554CA7&#125;][HKEY_CURRENT_USER\\Software\\DownloadManager]&quot;FName&quot;=-&quot;LName&quot;=-&quot;Email&quot;=-&quot;Serial&quot;=-[HKEY_LOCAL_MACHINE\\Software\\Internet Download Manager]&quot;FName&quot;=-&quot;LName&quot;=-&quot;Email&quot;=-&quot;Serial&quot;=-[HKEY_LOCAL_MACHINE\\Software\\Wow6432Node\\Internet Download Manager]&quot;FName&quot;=-&quot;LName&quot;=-&quot;Email&quot;=-&quot;Serial&quot;=- 两份代码是否有什么不同没有去对比，建议2个都试一下自行复制，在txt文件粘贴，另存为reg文件，然后双击运行，反正就是双击一次reg文件就多30天啦，重置试用期。这个方法最烦的是每次打开都会警告你要注册，或者时而弹窗警告，注意最后一行必须是空行，也就是代码最后，敲一下回车，再保存","tags":["笔记"],"categories":["其他"]},{"title":"一些注解","path":"/2024/08/19/20240819/","content":"Bean校验注解@NotBlank一般用来校验String类型不能为空 @NotNull一般用来校验Integer类型不能为空 @NotEmpty一般用来校验List类型不能为空 需在控制器中配合 @Valid 使用，例如 123@RepeatSubmit@PostMapping(value = &quot;/datasetsConfig&quot;)public R datasetsConfig(@RequestBody @Valid DatasetsConfigDTO dto) controller@RepeatSubmit 防止重复提交 @RepeatSubmit(interval = 60000, message = “请求过于频繁”) 限制频次 1234567@GetMapping(value = &quot;/getDocumentsSegments/&#123;datasetsId&#125;/&#123;documentId&#125;&quot;) public R&lt;DocumentsListSegmentsVO&gt; getDocumentsSegments(@PathVariable String datasetsId, @PathVariable String documentId, @RequestParam(value = &quot;limit&quot;, defaultValue = &quot;12&quot;) Integer limit, @RequestParam(value = &quot;keyword&quot;) String keyword, @RequestParam(value = &quot;enabled&quot;, defaultValue = &quot;all&quot;) String enabled) &#123; return R.ok(); &#125; 1234@PostMapping(value = &quot;/addDocumentsSegments/&#123;datasetsId&#125;/&#123;documentId&#125;&quot;) public R&lt;AddDocumentSegmentVO&gt; addDocumentsSegments(@PathVariable String datasetsId, @PathVariable String documentId, @RequestBody @Valid AddDocumentsSegmentsDTO dto) &#123; return R.ok(); &#125; 12345@Log(title = &quot;角色管理&quot;, businessType = BusinessType.UPDATE) @PutMapping(&quot;/setName&quot;) public AjaxResult editName(@RequestBody SysRoleP sysRoleP) &#123; return success(); &#125; 1234@DeleteMapping(&quot;/formGroup&quot;) public Object deleteFormGroup(@RequestParam Long id)&#123; return oaFormGroupsService.deleteFormGroup(id); &#125; 允许参数为空 12345@GetMapping(&quot;/info&quot;) public AjaxResult editOrReplenish(@RequestParam(value = &quot;instanceId&quot;) Long instanceId, @RequestParam(value = &quot;reportId&quot;, required = false) Long reportId) &#123; return R.ok(); &#125; sql@TableField(exist = false)private Long[] menuIds;","tags":["笔记"],"categories":["Java"]},{"title":"Java中JVM常用参数配置","path":"/2024/08/16/2024081602/","content":"前言 在实际开发和部署中一个合格的码农都会对 JVM 的一些参数做合理的配置，比如内存配置参数、GC 策略配置参数、日志配置参数、异常信息参数等，本文会列出一些常用的 JVM 参数以及通过一些例子演示配置后的效果。 PS：本文使用 JDK1.8 一、内存参数配置1234567891011121314151617181920212223242526272829303132333435363738394041424344// 设置JVM使Server模式，特点是启动速度较慢，但运行时性能和内存管理效率很高，适用于生产环境。在具有64位能力的JDK环境下默认启用该模式。-server // 设置元空间最大值， 默认是-1， 即不限制， 或者说只受限于本地内存大小,如果超过这个值会内存溢出。-XX:MaxMetaspaceSize=256m// 指定元空间触发Fullgc的初始阈值(元空间无固定初始大小)， 以字节为单位，默认是21M，达到该值就会触发full gc进行类型卸载， 同时收集器会对该值进行调整： 如果释放了大量的空间， 就适当降低该值； 如果释放了很少的空间， 那么在不超过-XX:MaxMetaspaceSize（如果设置了的话） 的情况下， 适当提高该值。这个跟早期jdk版本的-XX:PermSize参数意思不一样，-XX:PermSize代表永久代的初始容量。// 触发一次元空间Full GC后就会重新计算该值，建议设置成和最大内存一致-XX:MetaspaceSize=256m// 设置最大堆内存，默认是物理内存的1/4，内存的单位可以是m g，并且不区分大小写-Xmx2g 或者 -XX:MaxHeapSize=2048m// 设置初始值堆内存，默认是物理内存的1/64，内存的单位可以是m g，并且不区分大小写-Xms2g 或者 -XX:InitialHeapSize=2048m// 设置年轻代内存大小，默认和老年代1\\2，-XX:NewSize初始化年轻代大小 -XX:MaxNewSize最大年轻代大小-Xmn1g 或者 -XX:NewSize=1g -XX:MaxNewSize=1g// 设置每个线程的堆栈大小 默认是1024k，这个是最大内存并不是开启一个线程马上就会消耗这么多内存-Xss512k 或者 -XX:ThreadStackSize=512k// 年轻代占用堆比例（如果有配置-Xmn，那么会以-Xmn配置为准）// 默认 -XX:NewRatio=2新生代占1,老年代占2,年轻代占整个堆的1/3// 假如 -XX:NewRatio=4新生代占1,老年代占4,年轻代占整个堆的1/5 NewRatio值就是设置老年代的占比,剩下的1给新生代-XX:NewRatio=2 // 用来设置新生代中eden空间和from/to空间的比例.含义:-设置为8代表 eden使用80%的新生代内存 from和to各用10%，默认为8-XX:SurvivorRatio=8// 禁用Survivor区自适应策略默认是开启的，如果不关闭这个配置新生代eden区和s0 s1区会在gc后自动调整大小，如果设置了-XX:SurvivorRatio也只有在没有GC之前有效只要GC后就会重新动态计算-XX:-UseAdaptiveSizePolicy// 扩张堆内存的时机// 堆内存使用率大于70时扩张堆内存，如果最大堆内存=初始堆内存时该参数无效，默认值70-XX:MaxHeapFreeRatio=70// 缩小堆内存的时机// 堆内存使用率小于40时缩减堆内存，如果最大堆内存=初始堆内存时该参数无效，默认值40-XX:MinHeapFreeRatio=40// 字符串常量池hash桶大小 类似于HashTable，最小值1009 默认60013 不可动态扩容-XX:StringTableSize=60013// 设置直接内存大小，NIO（Non-blocking I/O）中通过ByteBuffer等对象分配的堆外内存// 默认情况下，直接内存的大小可能会与Java堆的最大值 (-Xmx) 相同-XX:MaxDirectMemorySize=512m 二、垃圾收集器配置1234567891011121314151617181920212223// 配置使用Serial单线程垃圾收集器，虚拟机运行在Client模式下的默认值// 新生代使用Serial 老年代则使用SerialOld-XX:+UseSerialGC// 配置使用ParNew垃圾收集器// 新生代使用ParNew 老年代则使用Serial Old-XX:+UseParNewGC// 配置使用Parallel Scavenge垃圾收集器，虚拟机运行在Server模式下的默认值// 新生代使用Parallel Scavenge 老年代使用Parallel Old收集器-XX:+UseParallelGC// 配置使用Parallel Old垃圾收集器// 新生代使用Parallel Scavenge 老年代使用Parallel Old收集器-XX:+UseParallelOldGC// 配置使用CMS垃圾收集器// 新生代使用ParNew 老年代使用CMS+Serial Old收集器-XX:+UseConcMarkSweepGC// 配置使用G1垃圾收集器-XX:+UseG1GC 可以通过jinfo -flags 进程号查看对应 Java 程序启动参数，我本地使用的 JDK1.8 默认使用的ParallelGC 三、GC 策略配置3.1、基础通用配置12345678910111213141516171819202122232425// GC停顿时间，垃圾收集器会尝试用各种手段达到这个时间，比如减小年轻代-XX:MaxGCPauseMillis // 新生代晋升老年代阈值 默认是15 不同回收算法不同-XX:MaxTenuringThreshold=15// 对象动态年龄判断默认50% 当一批对象大小&gt;=survivor区的50%时这批对象会直接放入老年代-XX:TargetSurvivorRatio=50// 默认值是0没有限制 大于这个值的参数直接在老年代分配// 这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存复制‐XX:PretenureSizeThreshold=1m// 忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+DisableExplicitGC // 内存页的大小-XX:LargePageSizeInBytes=128m // 设定GMT区域，避免CentOS坑爹的时区设置-Duser.timezone=GMT+8// FullGC 前执行MinorGC 默认是开启的-XX:+ScavengeBeforeFullGC 3.2、Parallel 和 Parallel Old 常用参数配置123456789// 调整垃圾回收的时间和总时间的占比 公式 1/(1+ratio) ratio默认是99，100分钟运行时间默认不能超过1分钟的GC时间，ratio一般设置为19-XX:GCTimeRatio=99// GC最大暂停毫秒数 默认是200毫秒 和-XX:+GCTimeRatio有冲突，堆内存小回收速度才会快，而-XX:+GCTimeRatio需要保证一定时间内GC时间不能超过一个临界值需要增加内存才能减小GC时间比，需要找到一个两个参数的合理值-XX:MaxGCPauseMillis=200ms// 设置垃圾回收线程数量 默认是CUP内核数量-XX:ParallelGCThreads=4 3.3、CMS 常用参数配置1234567891011121314151617181920212223242526272829303132// GC最大暂停毫秒数 默认是200毫秒-XX:MaxGCPauseMillis=200ms// 为了加快此阶段处理速度，减少停顿时间，可以开启初始标记并行化-XX:+CMSParallelInitialMarkEnabled// CMS并行线程数量，并行线程用于执行 CMS 垃圾回收器的并行阶段，如初始标记阶段和重新标记阶段// 默认值为系统的逻辑处理器数量减1，目的是为了保留一个处理器用于应用程序线程-XX:ParallelCMSThreads=3// CMS并发线程数量，并发线程用于执行 CMS 垃圾回收器的并发阶段，如初始标记阶段、并发标记阶段和并发清理阶段。// 默认值为系统的逻辑处理器数量减1，目的是为了保留一个处理器用于应用程序线程-XX:ConcGCThreads=3// 执行CMS的内存占比 percent=80 当我的老年代内存达到80%触发垃圾回收 默认是92% 应为CMS采用标记清除需要给浮动垃圾（在最后一步并发清除时其它没有被标记的垃圾遗留）预留空间 -XX:CMSInitiatingOccupancyFraction=percent// 该参数需要配合XX:CMSInitiatingOccupancyFraction使用，只使用设定的回收阈值(-XX:CMSInitiatingOccupancyFraction设 定的值)，如果不指定，JVM仅在第一次使用设定值，后续则会自动调整-XX:+UseCMSInitiatingOccupancyOnly // 重新标记阶段前提前进行一次新生代GC，因为重新标记也会判断新生代对象是否引用老年代对象，有些时候新生代对象已经没有被GC root对象引用但是还没有GC时，重新标记会扫描到新生代对象并且保留新生代对象引用的老年代对象，默认关闭false-XX:CMSScavengeBeforeRemark=true// 执行完Full GC后对内存空间进行压缩整理 默认开启-XX:+UseCMSCompactAtFullGollection// 设置在执行多少次Full GC后对内存空间进行压缩整理 默认0次，只要触发Full GC就会进行内存压缩-XX:CMSFullGCsBeforeCompaction=0// 垃圾回收时是否同时卸载不用的class信息，默认关闭-XX:+CMSClassUnloadingEnabled 3.4、G1 常用参数配置123456789101112131415161718192021222324252627282930313233// 指定分区大小(1MB~32MB，且必须是2的N次幂)，不设置默认会根据堆大小分配// 堆内存为1G默认1024个1MB分区、堆内存为2G默认2048个1MB分区、堆内存为4G默认2048个2MB分区、堆内存为4G默认2048个2MB分区、堆内存为6G默认6144个1MB分区、堆内存为8G默认2048个4MB分区、以此类推-XX:G1HeapRegionSize=2m// 目标暂停时间(默认200ms) -XX:MaxGCPauseMillis=200ms// 新生代内存初始空间(默认整堆5%) // PS: 因为JDK版本问题，在启动时可能会出现 &quot;Error: VM option &#x27;G1NewSizePercent&#x27; is experimental and must be enabled via -XX:+UnlockExperimentalVMOptions.&quot;// 如果出现上述问题，在启动参数中添加-XX:+UnlockExperimentalVMOptions即可-XX:G1NewSizePercent=5// 新生代内存最大空间 (默认整堆60%) -XX:G1MaxNewSizePercent=60// Survivor区的填充容量(默认50%)，Survivor区域里的一批对象(年龄1+年龄2+年龄n的多个 年龄对象)总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代 -XX:TargetSurvivorRatio=50// 最大年龄阈值(默认15) -XX:MaxTenuringThreshold=15// 老年代占用空间达到整堆内存阈值(默认45%)，则执行新生代和老年代的混合收集(MixedGC) -XX:InitiatingHeapOccupancyPercent=45// region中的存活对象低于这个值时才会回收该region，如果超过这个值，存活对象过多，回收的的意义不大(默认65%)。 -XX:G1MixedGCLiveThresholdPercent=65// 在一次回收过程中指定做几次筛选回收(默认8次)，在最后一个筛选回收阶段可以回收一会，然后暂停回收，恢复系统运行，一会再开始回收，这样可以让系统不至于单次停顿时间过长。 -XX:G1MixedGCCountTarget=8// gc过程中空出来的region是否充足阈值，在混合回收的时候，对Region回收都是基于复制算法进行的，都是把要回收的Region里的存活对象放入其他Region，然后这个Region中的垃圾对象全部清理掉，这样的话在回收过程就会不断空出来新的Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立即停止混合回收，意味着本次混合回收就结束了(默认5%)。-XX:G1HeapWastePercent=5 四、GC 日志配置1234567891011121314151617181920212223242526272829// 设置日志目录和日志名称-Xloggc:/data/logs/gc-%t.log// 开启滚动生成日志 默认关闭-XX:+UseGCLogFileRotation// 滚动GC日志文件数，默认0不滚动，保留最多5个日志文件-XX:NumberOfGCLogFiles=5// GC文件滚动大小，需开启UseGCLogFileRotation，每个文件最大为20MB-XX:GCLogFileSize=20M // 在进行GC的前后打印出堆的信息-XX:+PrintHeapAtGC // 打印新生代晋升详情-XX:+PrintTenuringDistribution// 打印字符串常量池堆信息-XX:+PrintStringTableStatistics// 打印GC信息-verbose:gc // 打印GC详细信息 -XX:+PrintGCDetails// 输出GC的时间戳（以基准时间的形式）-XX:+PrintGCTimeStamps// 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）-XX:+PrintGCDateStamps // 打印当前JVM参数信息 建议在每个程序中都添加上-XX:+PrintCommandLineFlags// 产生GC的原因(默认开启)-XX:+PrintGCCause 五、dump 日志参数配置5.1、OutOfMemory 异常时生成 dump 文件1234567// 默认关闭// 可以通过jinfo -flag [+|-]HeapDumpOnOutOfMemoryError &lt;pid&gt; 或 jinfo -flag HeapDumpOnOutOfMemoryError=&lt;value&gt; &lt;pid&gt; 来动态开启或设置值-XX:+HeapDumpOnOutOfMemoryError// 设置文件存储路径// 当HeapDumpOnOutOfMemoryError开启的时候，dump文件的保存路径，默认为工作目录下的，可以通过配置指定保存路径-XX:HeapDumpPath=/data/dump/jvm.hprof 5.2、发生 Full GC 时生成 dump 文件不推荐开启会增加整体停顿时间 1234567// 在Full GC前dump-XX:+HeapDumpBeforeFullGC// 在Full GC后dump-XX:+HeapDumpAfterFullGC// 设置Dump保存的路径-XX:HeapDumpPath=/data/dump/jvm.hprof 六、其它参数配置1234567// JVM自身故障导致进程奔溃时，会有一个日志文件生成，它包含了导致crash的重要信息，通过分析文件来查找crash原因-XX:ErrorFile=/data/logs/error.log// JDK1.6开始，默认server模式下开启了这个参数，意为当jvm检测到程序在重复抛一个异常// 在执行若干次后会将异常吞掉，这里的若干次在jdk1.7测得是20707。即执行20707次后，stackTrace 长度会为0。有时这不利于我们排错，通过指定OmitStackTraceInFastThrow，可禁用这功能-XX:-OmitStackTraceInFastThrow 七、配置示例需要配置的参数信息 123456789101112131415161718192021// 配置新生代使用Parallel Scavenge 老年代将会使用Parallel Old收集器-XX:+UseParallelOldGC// 配置元空间最大内存和初始内存-XX:MaxMetaspaceSize=256m -XX:MetaspaceSize=256m// 配置最大堆内存、初始内存、新生代占用内存-Xmx512m -Xms512m -Xmn256m// 配置关闭动态调整新生代eden和from to大小比例-XX:-UseAdaptiveSizePolicy// 配置忽略手动调用GC和时区-XX:+DisableExplicitGC -Duser.timezone=GMT+8// 配置开启记录OOM Dump信息和存储地址-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./jvm.hprof// 配置打印当前JVM参数信息-XX:+PrintCommandLineFlags// 配置开启GC日志输出-verbose:gc -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCDateStamps -Xloggc:./gc-%t.log// 配置关闭重复多次抛同一个异常不输出-XX:-OmitStackTraceInFastThrow// 配置JVM自身故障导致宕机时日志输出目录-XX:ErrorFile=./error.log 7.1、在 IDEA 中配置 JVM 参数 配置参数（注意文件的输出目录，我这里会直接输出在当前目录） 1234567891011-XX:+UseParallelOldGC-XX:MaxMetaspaceSize=256m -XX:MetaspaceSize=256m-Xmx20m -Xms20m -Xmn10m-XX:-UseAdaptiveSizePolicy-XX:+DisableExplicitGC -Duser.timezone=GMT+8-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./jvm.hprof-XX:+PrintCommandLineFlags-verbose:gc -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCDateStamps -Xloggc:./gc-%t.log-XX:-OmitStackTraceInFastThrow-XX:ErrorFile=./error.log 配置流程 7.2、通过 Java -jar 启动配置123# 应用配置示例nohup java -XX:+UseParallelOldGC -XX:MaxMetaspaceSize=256m -XX:MetaspaceSize=256m -Xmx512m -Xms512m -Xmn256m -XX:-UseAdaptiveSizePolicy -XX:+DisableExplicitGC -Duser.timezone=GMT+8 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./jvm.hprof -XX:+PrintCommandLineFlags -verbose:gc -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCDateStamps -Xloggc:./gc-%t.log -XX:-OmitStackTraceInFastThrow -XX:ErrorFile=./error.log -jar app.jar &gt; app.log 2&gt;&amp;1 &amp;","tags":["笔记"],"categories":["Java"]},{"title":"java -jar 常用命令","path":"/2024/08/16/20240816/","content":"简单启动1、上传jar包到linux系统你想要放的位置 2、运行jar包在linux系统中运行jar包主要有以下几种方式。 一、java -jar XXX.jar 最基本的jar包执行方式，但是当我们用ctrl+c中断或者关闭窗口时，程序也会中断执行。 二、java -jar XXX.jar &amp; &amp;代表在后台运行，使用ctrl+c不会中断程序的运行，但是关闭窗口会中断程序的运行。 三、nohup java -jar XXX.jar &amp; 使用这种方式运行的程序日志会输出到当前目录下的nohup.out文件，使用ctrl+c中断或者关闭窗口都不会中断程序的执行。 四、nohup java -jar XXX.jar &gt;temp.out &amp; temp.out的意思是将日志输出重定向到temp.out文件，使用ctrl+c中断或者关闭窗口都不会中断程序的执行。 3、停止jar包运行3.1、查看当前应用进程号方式1：根据应用端口得到进程号 1netstat -nlp | grep :9001 可能报错找不到命令 1yum -y install net-tools #安装 方式2：根据java程序得到相应的进程号 1ps -ef | grep java 方式3：和方式1一样 1netstat -ntulp | grep 9001 3.2、结束此jar包的进程kill -9 进程号 1kill -9 23118 4、端口netstat -ntlp //查看当前所有tcp端口netstat -ntulp | grep 80 //查看所有80端口使用情况 5.查看日志 123456789101112# 查看文件的后10行tail -10 /etc/passwd 或 tail -n 10 /etc/passwd # 不停地去读/var/log/messages文件最新的内容，这样有实时监视的效果，用Ctrl＋c来终止！tail -f /var/log/messages # 显示文件 notes.log 的内容，从第 20 行至文件末尾:tail +20 notes.log# 显示文件 notes.log 的最后 10 个字符:tail -c 10 notes.log 更多Linux命令参考 指定配置Windos1、指定端口 1java -jar springboot.jar --server.port=8181 2、指定配置文件 1java -jar springboot.jar --spring.profiles.active=dev 3、同时指定端口与配置文件 1java -jar springboot.jar --server.port=8181--spring.profiles.active=dev Linux1、后台服务方式启动 1nohup java -jar springboot.jar --server.port=8181 &gt;outlog.log 2&gt;&amp;1 &amp; 2、加载服务器配置文件 application-dev.yml 1nohup java -Dserver.port=8086 -Dspring.config.additional-location=./application-dev.yml -jar ./springboot.jar&gt; nohup.out 2&gt;&amp;1 &amp; java -jar 运行 jar 包基础参数配置1、默认运行命令 1java -jar XXX.jar 2、指定 jvm 运行内存大小参数 1java -Xms256m -Xmx512m -jar xxx.jar 3、指定 port 端口 1java -jar xxx.jar --server.port=8085 4、指定配置文件 1java -jar xxx.jar --spring.profiles.active=pro 1nohup java -Dspring.profiles.active=pro -jar /www/scrm/run/scrm/scrm-admin.jar &gt;&gt; /www/scrm/logs/scrm/server.log &amp; 注：pro 就是 springboot 项目的配置环境，一般我们会有 dev、test、pro 等， 当我们忘记或者怕打包忘记改回来的时候可以在启动参数里面配置指定使用的配置环境。 5.看日志 123tail -f /www/scrm/logs/scrm/server.logtail -f /www/scrm/logs/scrm/server.log | grep -v CurrencyServicecat /www/scrm/logs/scrm/server.log 6.创建脚本文件 restart.sh 1234567891011121314151617181920212223242526272829303132333435#!/bin/bashpkg=&#x27;scrm-admin.jar&#x27;echo &quot; ==================== 启动$pkg【开始】 ==================== &quot;#rm -rf ./logspid=`ps -aux | grep $pkg |grep -v grep |awk &#x27;&#123;print $2&#125;&#x27;`if test -z &quot;$pid&quot;then echo &quot;原有$pkg进程没有启动&quot;else echo &quot;杀死原有$pkg进程【$pid】&quot; kill -9 $pidfinohup java -Dspring.profiles.active=pro -jar /www/scrm/run/scrm/scrm-admin.jar &gt;&gt; /www/scrm/logs/scrm/server.log &amp;pid=`ps -aux | grep $pkg |grep -v grep |awk &#x27;&#123;print $2&#125;&#x27;`echo &quot;$pkg 已启动 【$pid】&quot;echo &quot; ==================== 启动$pkg【结束】==================== &quot;#tail -n100 -f ./nohup.outtail -f /www/scrm/logs/scrm/server.log | grep -v CurrencyService 重启可直接执行 sh /www/scrm/run/scrm/restart.sh","tags":["笔记"],"categories":["Java"]},{"title":"DateUtil1","path":"/2024/08/15/2024081502/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659package com.ioo.system.utils;import cn.hutool.core.collection.CollectionUtil;import cn.hutool.core.util.ObjectUtil;import com.ioo.system.constant.CommonConstant;import com.ioo.system.web.report_statistic.controller.vo.ReportDateVO;import java.text.DateFormat;import java.text.ParseException;import java.text.SimpleDateFormat;import java.time.LocalDate;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;import java.time.temporal.ChronoUnit;import java.time.temporal.IsoFields;import java.util.*;/** * @Project：iootools2 * @Package：com.ioo.system.utils * @Author：xl * @name：SysDateUtil * @Date：2024/3/13 17:39 */public class SysDateUtil &#123; public static long targetDate(Date target) &#123; Calendar calendar = Calendar.getInstance(); calendar.setTime(target); LocalDate today = LocalDate.now(); // 获取当前日期 LocalDate targetDate = LocalDate.of(calendar.get(Calendar.YEAR), calendar.get(Calendar.MONTH) + 1, calendar.get(Calendar.DAY_OF_MONTH));// 月份是从0开始的，所以需要+1 long daysBetween = ChronoUnit.DAYS.between(today.atStartOfDay(), targetDate.atStartOfDay()); return daysBetween; &#125; //字符串日期排序 public static List&lt;String&gt; datesSort(List&lt;String&gt; dates) &#123; if (CollectionUtil.isEmpty(dates)) return dates; SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); dates.sort((d1, d2) -&gt; &#123; try &#123; Date date1 = dateFormat.parse(d1); Date date2 = dateFormat.parse(d2); return date1.compareTo(date2); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;); return dates; &#125; //找出2个日期中的每一天 public static List&lt;String&gt; findDates(String beginTime, String endTime) throws ParseException &#123; List&lt;String&gt; allDate = new ArrayList(); SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date dBegin = sdf.parse(beginTime); Date dEnd = sdf.parse(endTime); allDate.add(sdf.format(dBegin)); Calendar calBegin = Calendar.getInstance(); // 使用给定的 Date 设置此 Calendar 的时间 calBegin.setTime(dBegin); Calendar calEnd = Calendar.getInstance(); // 使用给定的 Date 设置此 Calendar 的时间 calEnd.setTime(dEnd); // 测试此日期是否在指定日期之后 while (dEnd.after(calBegin.getTime())) &#123; // 根据日历的规则，为给定的日历字段添加或减去指定的时间量 calBegin.add(Calendar.DAY_OF_MONTH, 1); allDate.add(sdf.format(calBegin.getTime())); &#125; return allDate; &#125; //找出2个日期中的每一天 public static List&lt;String&gt; findDates(Date beginTime, Date endTime) throws ParseException &#123; return findDates(dateToString(beginTime, &quot;yyyy-MM-dd&quot;), dateToString(endTime, &quot;yyyy-MM-dd&quot;)); &#125; //计算2个日期相差的天数 public static int getDateSpanToDays(String startDateStr, String endDateStr) &#123; DateFormat dft = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); int days = 0; try &#123; Date star = dft.parse(startDateStr);//开始时间 Date endDay = dft.parse(endDateStr);//结束时间 if (!date1Less(star, endDay)) return days; Long starTime = star.getTime(); Long endTime = endDay.getTime(); Long num = endTime - starTime;//时间戳相差的毫秒数 days = Math.toIntExact(num / 24 / 60 / 60 / 1000); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return days; &#125; public static List&lt;Date&gt; getDateSpan(String startDateStr, String endDateStr) &#123; SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date startDate = null; Date endDate = null; try &#123; startDate = dateFormat.parse(startDateStr); endDate = dateFormat.parse(endDateStr); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; Calendar calendar = Calendar.getInstance(); calendar.setTime(startDate); List&lt;Date&gt; datesInRange = new ArrayList&lt;&gt;(); while (calendar.getTime().before(endDate) || calendar.getTime().equals(endDate)) &#123; Date currentDate = calendar.getTime(); datesInRange.add(currentDate); calendar.add(Calendar.DATE, 1); &#125; for (Date date : datesInRange) &#123; System.out.println(dateFormat.format(date)); &#125; return datesInRange; &#125; public static ReportDateVO getWeeks(String dt) &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); LocalDate date2 = LocalDate.parse(dt, formatter); int year = date2.getYear(); int month = date2.getMonthValue(); int day = date2.getDayOfMonth(); // 指定日期 LocalDate date = LocalDate.of(year, month, day); // 获取当前年份的第几周 int weekOfYear = date.get(IsoFields.WEEK_OF_WEEK_BASED_YEAR); List&lt;String&gt; strings = weekToDayFormate(year, weekOfYear); ReportDateVO build = ReportDateVO.builder().title(year + &quot;年第&quot; + weekOfYear + &quot;周&quot;).year(year).startDate(stringToDateToYMD(strings.get(0))).endDate(stringToDateToYMD(strings.get(1))) .start(strings.get(0)) .end(strings.get(1)) .weekNum((weekOfYear)).build(); return build; &#125; public static String replyEndTimeToAutoRemindSubmitTime(String replyEndTime, String autoRemindTime) &#123; if (ObjectUtil.isEmpty(autoRemindTime) || ObjectUtil.isEmpty(replyEndTime)) return &quot;&quot;; String[] split = autoRemindTime.split(&quot;,&quot;); if (split.length != 2) return &quot;&quot;; String[] split1 = split[1].split(&quot;:&quot;); if (split1.length != 2) return &quot;&quot;; int day = Integer.parseInt(split[0]); int hours = Integer.parseInt(split1[0]); int min = Integer.parseInt(split1[1]); return stringDateSubtract(replyEndTime, day, hours, min); &#125; public static String stringDateSubtract(String dateString, int day, int hours, int min) &#123;// String dateString = &quot;2022-01-02 03:30:00&quot;; dateString += &quot;:00&quot;; // 定义日期时间格式 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;); // 将字符串日期时间转换为 LocalDateTime 对象 LocalDateTime date = LocalDateTime.parse(dateString, formatter); // 执行减法运算 date = date.minusDays(day); date = date.minusHours(hours); date = date.minusMinutes(min); return date.format(formatter); &#125; public static String stringDateToString(String dateString) &#123; SimpleDateFormat originalFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); SimpleDateFormat targetFormat = new SimpleDateFormat(&quot;yyyy年MM月dd日&quot;); String formattedDate = dateString; try &#123; Date date = originalFormat.parse(dateString); formattedDate = targetFormat.format(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return formattedDate; &#125; public static Long stringDateToTimestamp(String dateString) &#123; long timestamp = -999l; try &#123; SimpleDateFormat formatter = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); Date date = formatter.parse(dateString); timestamp = date.getTime(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return timestamp; &#125; public static String timeDistance(Date endDate, Date startTime) &#123; long nd = 1000 * 24 * 60 * 60; long nh = 1000 * 60 * 60; long nm = 1000 * 60; // long ns = 1000; // 获得两个时间的毫秒时间差异 long diff = endDate.getTime() - startTime.getTime(); // 计算差多少天 long day = diff / nd; // 计算差多少小时 long hour = diff % nd / nh; // 计算差多少分钟 long min = diff % nd % nh / nm; // 计算差多少秒//输出结果 // long sec = diff % nd % nh % nm / ns; return (day &gt; 0L ? day + &quot;天&quot; : &quot;&quot;) + (hour &gt; 0L ? hour + &quot;小时&quot; : &quot;&quot;) + min + &quot;分钟&quot;; &#125; public static ReportDateVO getMonths(String dt) &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); LocalDate date2 = LocalDate.parse(dt, formatter); int year = date2.getYear(); int month = date2.getMonthValue(); String firstDay = getFirstDay(year, month, &quot;yyyy-MM-dd&quot;); String lastDay = getLastDay(year, month, &quot;yyyy-MM-dd&quot;); ReportDateVO build = ReportDateVO.builder().title(year + &quot;年第&quot; + month + &quot;月&quot;).year(year).startDate(stringToDateToYMD(firstDay, &quot;yyyy-MM-dd&quot;)).endDate(stringToDateToYMD(lastDay, &quot;yyyy-MM-dd&quot;)) .start(firstDay) .end(lastDay) .month(month).build(); return build; &#125; public static ReportDateVO getDays(String dt) &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); LocalDate date2 = LocalDate.parse(dt, formatter); int year = date2.getYear(); int month = date2.getMonthValue(); int dayOfMonth = date2.getDayOfMonth(); String firstDay = getFirstDay(year, month, &quot;yyyy-MM-dd&quot;); String lastDay = getLastDay(year, month, &quot;yyyy-MM-dd&quot;); ReportDateVO build = ReportDateVO.builder().title(dt).year(year).day(dayOfMonth).startDate(stringToDateToYMD(firstDay, &quot;yyyy-MM-dd&quot;)).endDate(stringToDateToYMD(lastDay, &quot;yyyy-MM-dd&quot;)) .start(firstDay) .end(lastDay) .month(month).build(); return build; &#125; public static Boolean date1Less(String date1, String date2) &#123; Date d1 = stringToDateToYMD(date1, &quot;yyyy-MM-dd&quot;); Date d2 = stringToDateToYMD(date2, &quot;yyyy-MM-dd&quot;); return (d1.compareTo(d2)) &lt;= 0; &#125; public static Boolean date1LessByHM(String date1, String date2) &#123; Date d1 = stringToDateToYMD(date1, &quot;yyyy-MM-dd HH:mm&quot;); Date d2 = stringToDateToYMD(date2, &quot;yyyy-MM-dd HH:mm&quot;); return (d1.compareTo(d2)) &lt;= 0; &#125; public static Boolean date1Less(Date date1, Date date2) &#123; return (date1.compareTo(date2)) &lt;= 0; &#125; public static Date stringToDateToYMD(String date) &#123; SimpleDateFormat format = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); Date parse = new Date(); try &#123; parse = format.parse(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return parse; &#125; public static Date stringToDateToYMDHMS(String date) &#123; SimpleDateFormat format = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date parse = new Date(); try &#123; parse = format.parse(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return parse; &#125; public static Date stringToDateToYMD(String date, String ft) &#123; SimpleDateFormat format = new SimpleDateFormat(ft); Date parse = new Date(); try &#123; parse = format.parse(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return parse; &#125; //判断日期是否是今天 public static Boolean isToday(Date date) &#123; Calendar calendar = Calendar.getInstance(); calendar.setTime(date); Calendar today = Calendar.getInstance(); return today.get(Calendar.YEAR) == calendar.get(Calendar.YEAR) &amp;&amp; today.get(Calendar.MONTH) == calendar.get(Calendar.MONTH) &amp;&amp; today.get(Calendar.DAY_OF_MONTH) == calendar.get(Calendar.DAY_OF_MONTH); &#125; public static Date stringToDateHMS(String date) &#123; SimpleDateFormat format = new SimpleDateFormat(&quot;yyyy-MM-dd h:m&quot;); Date parse = new Date(); try &#123; parse = format.parse(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return parse; &#125; public static String dateToString(Date date) &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); return sdf.format(date); &#125; public static String dateToString(Date date, String ft) &#123; SimpleDateFormat sdf = new SimpleDateFormat(ft); return sdf.format(date); &#125; //修改日期的时间部分 public static Date setDt(Date time, int h, int min) &#123; Calendar cal = Calendar.getInstance(); cal.setTime(time); cal.set(Calendar.HOUR_OF_DAY, h); //时 cal.set(Calendar.MINUTE, min); //分 cal.set(Calendar.SECOND, 0); //秒 cal.set(Calendar.MILLISECOND, 0); //毫秒 return cal.getTime(); &#125; // 获取指定年的开始天数和结束天数 public static List&lt;Date&gt; getFirstDayAndLastDayOfTheSpecifiedYear(int year) &#123; Calendar calendar = Calendar.getInstance(); // 设置某年的开始时间 calendar.set(year, Calendar.JANUARY, 1, 0, 0, 0); calendar.set(Calendar.MILLISECOND, 0); Date startTime = calendar.getTime(); // 设置某年的结束时间 calendar.set(year, Calendar.DECEMBER, 31, 23, 59, 59); calendar.set(Calendar.MILLISECOND, 999); Date endTime = calendar.getTime(); // 设置返回信息,返回样式根据需求自行格式化 List&lt;Date&gt; years = new ArrayList&lt;&gt;(); years.add(setDt(startTime, 0, 0)); years.add(setDt(endTime, 23, 59)); return years; &#125; // 获取指定年指定月的开始天数和结束天数 public static List&lt;Date&gt; getFirstDayAndLastDayOfTheSpecifiedMonth(int year, int month) &#123; // 获取当前分区的日历信息(这里可以使用参数指定时区) Calendar calendar = Calendar.getInstance(); // 设置年 calendar.set(Calendar.YEAR, year); // 设置月，月份从0开始 calendar.set(Calendar.MONTH, month - 1); // 设置为指定月的第一天 calendar.set(Calendar.DAY_OF_MONTH, 1); // 获取指定月第一天的时间 Date start = calendar.getTime(); // 设置日历天数为当前月实际天数的最大值，即指定月份的最后一天 calendar.set(Calendar.DATE, calendar.getActualMaximum(Calendar.DATE)); // 获取最后一天的时间 Date end = calendar.getTime(); // 设置返回信息,返回样式根据需求自行格式化 List&lt;Date&gt; months = new ArrayList&lt;&gt;(); months.add(setDt(start, 0, 0)); months.add(setDt(end, 23, 59)); return months; &#125; //获取当前月份的开始和结束时间 public static List&lt;Date&gt; getCurMonth() &#123; List&lt;Date&gt; month = new ArrayList&lt;&gt;(); // 获取当前日期 Date currentDate = new Date(); // 创建Calendar实例 Calendar calendar = Calendar.getInstance(); // 设置日期为当前日期 calendar.setTime(currentDate); // 将日期设置为该月的第一天 calendar.set(Calendar.DAY_OF_MONTH, 1); // 获取本月的开始时间 Date startTime = calendar.getTime(); // 将日期设置为该月的最后一天 calendar.set(Calendar.DAY_OF_MONTH, calendar.getActualMaximum(Calendar.DAY_OF_MONTH)); // 获取本月的结束时间 Date endTime = calendar.getTime(); month.add(setDt(startTime, 0, 0)); month.add(setDt(endTime, 23, 59)); return month; &#125; //获取当前时间的年月日 public static String getCurrentDate() &#123; Date currentDate = new Date(); SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); String formattedDate = dateFormat.format(currentDate); return formattedDate; &#125; //获取当前时间的年月日时分秒 public static String getCurrentDateHMS() &#123; Date currentDate = new Date(); SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); String formattedDate = dateFormat.format(currentDate); return formattedDate; &#125; //获取N天前的年月日 public static String getDateSpan() &#123; LocalDate today = LocalDate.now(); // 获取当前日期 LocalDate oneHundredEightyDaysAgo = today.minusDays(CommonConstant.WEEK_DATE_SPAN); // 当前日期减去365天 // 格式化日期为年月日 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); String formattedDate = oneHundredEightyDaysAgo.format(formatter); return formattedDate; &#125; // 计算两个时间中所有的月份 public static List&lt;String&gt; getMonths(String startDate, String endDate) throws ParseException &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date parse = sdf.parse(startDate); Date parse2 = sdf.parse(endDate); List&lt;String&gt; dateList = new ArrayList&lt;&gt;(); Calendar startC = Calendar.getInstance(); startC.setTime(parse); //转为周一 int year = startC.get(Calendar.YEAR); int month = startC.get(Calendar.MONTH); startC.set(year, month, 1, 0, 0, 0); Calendar endC = Calendar.getInstance(); endC.setTime(parse2); int weekYear2 = endC.get(Calendar.YEAR); int weekOfYear2 = endC.get(Calendar.WEEK_OF_YEAR); endC.setWeekDate(weekYear2, weekOfYear2, Calendar.SUNDAY); while (true) &#123; int tempMonth = startC.get(Calendar.MONTH); String date = startC.getWeekYear() + &quot;-&quot; + ((tempMonth + 1) &lt;= 9 ? &quot;0&quot; + (tempMonth + 1) : tempMonth + 1); dateList.add(date); //下一个月&lt;结束日期 startC.set(Calendar.MONTH, tempMonth + 1); if (startC.getTimeInMillis() &gt;= endC.getTimeInMillis()) &#123; break; &#125; &#125; return dateList; &#125; private static Long dateScaleplate(Calendar calendar) &#123; int year = calendar.get(Calendar.YEAR); // 获取月份（月份是从0开始的，因此需要+1）// int month = calendar.get(Calendar.MONTH) + 1;// int day = calendar.get(Calendar.DAY_OF_MONTH); int weekNum = calendar.get(Calendar.WEEK_OF_YEAR); String dt = year + &quot;&quot; + weekNum; return Long.parseLong(dt); &#125; // 计算两个时间内 所有的周数 public static List&lt;ReportDateVO&gt; getWeeks(String startDate, String endDate) throws ParseException &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date parse = sdf.parse(startDate); Date parse2 = sdf.parse(endDate); List&lt;ReportDateVO&gt; dateList = new ArrayList&lt;&gt;(); Calendar startC = Calendar.getInstance(); startC.setFirstDayOfWeek(Calendar.MONDAY); startC.setTime(parse); Long startCurrentWeek = dateScaleplate(startC); //转为周一 int weekYear = startC.get(Calendar.YEAR); int weekOfYear = startC.get(Calendar.WEEK_OF_YEAR); startC.setWeekDate(weekYear, weekOfYear, Calendar.MONDAY); Calendar endC = Calendar.getInstance(); endC.setFirstDayOfWeek(Calendar.MONDAY); endC.setTime(parse2); Long endWeek = dateScaleplate(endC); int weekYear2 = endC.get(Calendar.YEAR); int weekOfYear2 = endC.get(Calendar.WEEK_OF_YEAR); endC.setWeekDate(weekYear2, weekOfYear2, Calendar.SUNDAY); while (true) &#123; int weekNum = startC.get(Calendar.WEEK_OF_YEAR); ReportDateVO build = ReportDateVO.builder().title(startC.getWeekYear() + &quot;年第&quot; + (weekNum &gt; 9 ? weekNum : &quot;0&quot; + weekNum) + &quot;周&quot;).year(startC.getWeekYear()) .weekNum((weekNum &gt; 9 ? weekNum : Integer.valueOf(&quot;0&quot; + weekNum))).build(); dateList.add(build);// if (c1.getTimeInMillis() &gt;= c2.getTimeInMillis()) &#123;// System.out.println(&quot;22-c1:&quot;+cdt1+&quot;-c2:&quot;+cdt2);// break;// &#125; if (startCurrentWeek &gt;= endWeek) &#123; break; &#125; //增加7天 startC.setTimeInMillis(startC.getTimeInMillis() + 1000 * 60 * 60 * 24 * 7); startCurrentWeek = dateScaleplate(startC); &#125; return dateList; &#125; /** * 根据年月获取月初第一天日期 * * @param year * @param month * @return */ public static String getFirstDay(int year, int month, String format) &#123; Calendar calendar = Calendar.getInstance(); calendar.set(Calendar.YEAR, year); calendar.set(Calendar.MONTH, month - 1); calendar.set(Calendar.DAY_OF_MONTH, 1); calendar.set(Calendar.HOUR_OF_DAY, 0); //时 calendar.set(Calendar.MINUTE, 0); //分 calendar.set(Calendar.SECOND, 0); //秒 calendar.set(Calendar.MILLISECOND, 0); //毫秒// TimeZone timeZone = TimeZone.getTimeZone(&quot;UTC&quot;);// calendar.setTimeZone(timeZone); Date startDate = calendar.getTime(); SimpleDateFormat sdf = new SimpleDateFormat(format); String formattedStartDate = sdf.format(startDate); return formattedStartDate; &#125; /** * 根据年月获取月末最后一天日期 * * @param year * @param month * @return */ public static String getLastDay(int year, int month, String format) &#123; Calendar calendar = Calendar.getInstance(); calendar.set(Calendar.YEAR, year); calendar.set(Calendar.MONTH, month); calendar.set(Calendar.DAY_OF_MONTH, 1); calendar.add(Calendar.DAY_OF_MONTH, -1); calendar.set(Calendar.HOUR_OF_DAY, 23); //时 calendar.set(Calendar.MINUTE, 59); //分 calendar.set(Calendar.SECOND, 59); //秒 calendar.set(Calendar.MILLISECOND, 0); //毫秒// TimeZone timeZone = TimeZone.getTimeZone(&quot;UTC&quot;);// calendar.setTimeZone(timeZone); Date endDate = calendar.getTime(); SimpleDateFormat sdf = new SimpleDateFormat(format); String formattedEndDate = sdf.format(endDate); return formattedEndDate; &#125; // 根据year年的第week周，查询本周的起止时间 public static List&lt;String&gt; weekToDayFormate(int year, int week) &#123; Calendar calendar = Calendar.getInstance(); // ①.设置该年份的开始日期：第一个月的第一天 calendar.set(year, 0, 1); List&lt;String&gt; dateList = new ArrayList&lt;&gt;(); // ②.计算出第一周还剩几天：+1是因为1号是1天 int dayOfWeek = 7 - calendar.get(Calendar.DAY_OF_WEEK) + 1; // ③.周数减去第一周再减去要得到的周 week = week - 2; // ④.计算起止日期 calendar.add(Calendar.DAY_OF_YEAR, week * 7 + dayOfWeek); calendar.add(Calendar.DAY_OF_YEAR, 1); TimeZone timeZone = TimeZone.getTimeZone(&quot;GMT+8&quot;); calendar.setTimeZone(timeZone); dateList.add(new SimpleDateFormat(&quot;yyyy-MM-dd 00:00:00&quot;).format(calendar.getTime()));// System.out.println(&quot;开始日期：&quot; + new SimpleDateFormat(&quot;yyyy-MM-dd&quot;).format(calendar.getTime())); calendar.add(Calendar.DAY_OF_YEAR, 6);// calendar.set(Calendar.HOUR_OF_DAY, 23); //时// calendar.set(Calendar.MINUTE, 59); //分// calendar.set(Calendar.SECOND, 59); //秒// calendar.set(Calendar.MILLISECOND, 0); //毫秒 dateList.add(new SimpleDateFormat(&quot;yyyy-MM-dd 23:59:59&quot;).format(calendar.getTime()));// System.out.println(&quot;结束日期：&quot; + new SimpleDateFormat(&quot;yyyy-MM-dd&quot;).format(calendar.getTime())); return dateList; &#125; public static List&lt;String&gt; weekToDayFormate2(int year, int week) &#123; List&lt;String&gt; dateList = new ArrayList&lt;&gt;(); Calendar calendar = Calendar.getInstance(); calendar.set(year, 0, 1); int dayOfWeek = 7 - calendar.get(Calendar.DAY_OF_WEEK) + 1;//算出第一周还剩几天 +1是因为1号是1天 week = week - 2;//周数减去第一周再减去要得到的周 calendar.add(Calendar.DAY_OF_YEAR, week * 7 + dayOfWeek); dateList.add(new SimpleDateFormat(&quot;yyyy-MM-dd 00:00:00&quot;).format(calendar.getTime())); calendar.add(Calendar.DAY_OF_YEAR, 6); dateList.add(new SimpleDateFormat(&quot;yyyy-MM-dd 23:59:59&quot;).format(calendar.getTime())); return dateList; &#125; // 计算两个时间内所有日期 public static List&lt;String&gt; getDays(String date1, String date2) throws ParseException &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); Long startTime = sdf.parse(date1).getTime(); Long endTime = sdf.parse(date2).getTime(); List&lt;String&gt; dateList = new ArrayList&lt;String&gt;(); Long oneDay = 1000 * 60 * 60 * 24l; Long time = startTime; while (time &lt;= endTime) &#123; Date d = new Date(time); DateFormat df = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); String date = df.format(d); dateList.add(date); time += oneDay; &#125; return dateList; &#125;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"DateTimeUtil-未验证，可能不准或者报错","path":"/2024/08/15/2024081503/","content":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037103810391040104110421043104410451046104710481049105010511052105310541055105610571058105910601061106210631064106510661067106810691070107110721073107410751076107710781079108010811082108310841085108610871088108910901091109210931094109510961097109810991100110111021103110411051106110711081109111011111112111311141115111611171118111911201121112211231124112511261127112811291130113111321133113411351136113711381139114011411142114311441145114611471148114911501151115211531154115511561157115811591160116111621163116411651166116711681169117011711172117311741175117611771178117911801181118211831184118511861187118811891190119111921193119411951196119711981199120012011202120312041205120612071208120912101211121212131214121512161217121812191220122112221223122412251226122712281229123012311232123312341235123612371238123912401241124212431244124512461247124812491250125112521253125412551256125712581259126012611262126312641265126612671268126912701271127212731274127512761277127812791280128112821283128412851286128712881289129012911292129312941295129612971298129913001301130213031304130513061307130813091310131113121313131413151316131713181319132013211322132313241325132613271328132913301331133213331334133513361337133813391340134113421343134413451346134713481349135013511352135313541355135613571358135913601361136213631364136513661367136813691370137113721373137413751376137713781379138013811382138313841385138613871388138913901391139213931394139513961397139813991400140114021403140414051406140714081409141014111412141314141415141614171418141914201421142214231424142514261427142814291430143114321433143414351436143714381439144014411442144314441445144614471448144914501451145214531454145514561457145814591460146114621463146414651466146714681469147014711472147314741475147614771478147914801481148214831484148514861487148814891490149114921493149414951496149714981499150015011502150315041505150615071508150915101511151215131514151515161517151815191520152115221523152415251526152715281529153015311532153315341535153615371538153915401541154215431544154515461547154815491550155115521553155415551556155715581559156015611562156315641565156615671568156915701571157215731574157515761577157815791580158115821583158415851586158715881589159015911592159315941595159615971598159916001601160216031604160516061607160816091610161116121613161416151616161716181619162016211622162316241625162616271628162916301631163216331634package com.ioo.system.refactor_report.utils;import cn.hutool.core.date.DateUtil;import com.ioo.system.constant.CommonConstant;import com.ioo.system.enums.ReplyCycle;import com.ioo.system.refactor_report.controller.dto.ReportHMMDTO;import com.ioo.system.refactor_report.controller.vo.ReportDateVO;import com.ioo.system.refactor_report.controller.vo.ReportTemplateVO;import org.apache.logging.log4j.util.Strings;import java.text.ParseException;import java.text.SimpleDateFormat;import java.time.*;import java.time.format.DateTimeFormatter;import java.time.format.DateTimeParseException;import java.time.temporal.*;import java.util.*;/** * @Project：astoa-admin * @Package：com.ioo.system.refactor_report.utils * @Author：xen * @name：DateTimeUtil * @Date：2024/8/1/0001 18:06 */public class DateTimeUtil &#123; /** * 将 日期时间字符串补全 * * @param dateTimeStr 日期时间字符串 * @return 转换后的日期字符串 */ public static String complementStrDate(String dateTimeStr) &#123; if (!dateTimeStr.matches(&quot;\\\\d&#123;4&#125;-\\\\d&#123;2&#125;-\\\\d&#123;2&#125; \\\\d&#123;2&#125;:\\\\d&#123;2&#125;:\\\\d&#123;2&#125;&quot;)) dateTimeStr = dateTimeStr + &quot;:00&quot;; return dateTimeStr; &#125; /** * 将 日期时间字符串转换为特定格式的字符串。 * * @param dateTimeStr 日期时间字符串 * @param ft 格式，默认 yyyy-MM-dd HH:mm:ss * @return 转换后的日期字符串 */ public static String formatToFt(String dateTimeStr, String ft) &#123; // 定义原始格式 DateTimeFormatter inputFormatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;); // 定义目标格式 DateTimeFormatter outputFormatter = DateTimeFormatter.ofPattern(ft); try &#123; // 解析字符串为 LocalDateTime 对象 LocalDateTime dateTime = LocalDateTime.parse(dateTimeStr, inputFormatter); // 格式化为 &quot;MM月dd日&quot; 格式的字符串 return dateTime.format(outputFormatter); &#125; catch (Exception e) &#123; // 处理异常，例如格式不匹配 System.err.println(&quot;Error parsing date: &quot; + e.getMessage()); return null; &#125; &#125; /** * 将时间戳转换为指定时区的 yyyy-MM-dd HH:mm:ss 格式的字符串。 * * @param timestamp 时间戳，单位为毫秒 * @param zoneId 时区ID，例如 &quot;Asia/Shanghai&quot; * @param ft 格式，默认 yyyy-MM-dd HH:mm:ss * @return 格式化的日期时间字符串 */ public static String formatTimestamp(long timestamp, String zoneId, String ft) &#123; if (Strings.isBlank(ft)) ft = &quot;yyyy-MM-dd HH:mm:ss&quot;; // 将时间戳转换为Instant对象 Instant instant = Instant.ofEpochMilli(timestamp); // 在指定时区创建ZonedDateTime对象 ZonedDateTime zonedDateTime = instant.atZone(ZoneId.of(zoneId)); // 定义日期时间格式 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(ft); // 格式化日期时间 return zonedDateTime.format(formatter); &#125; /** * 将给定的日期时间字符串从 &quot;yyyy-MM-dd HH:mm:ss&quot; 格式转换为 &quot;X月X日&quot; 格式。 * * @param dateTimeStr 日期时间字符串 * @return 转换后的日期字符串，格式为 &quot;X月X日&quot; */ public static String formatToMonthDay(String dateTimeStr) &#123; // 日期时间格式 DateTimeFormatter inputFormatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;); // 月和日的格式 DateTimeFormatter outputFormatter = DateTimeFormatter.ofPattern(&quot;MMMMdd日&quot;, Locale.CHINA); // 解析输入的日期时间字符串 LocalDateTime dateTime = LocalDateTime.parse(dateTimeStr, inputFormatter); // 格式化为 &quot;X月X日&quot; return dateTime.format(outputFormatter); &#125; /** * 根据给定的时间戳和时区ID，返回格式为YYYYMMDD的整数。 * * @param timestamp 时间戳，以毫秒为单位 * @param zoneId 时区ID，例如 &quot;GMT+8&quot; 或 &quot;America/New_York&quot; * @return 年月日的整数，例如 20240814 */ public static int getYyyyMmDdFromTimestamp(long timestamp, String zoneId) &#123; // 将时间戳转换为ZonedDateTime ZonedDateTime zonedDateTime = Instant.ofEpochMilli(timestamp).atZone(ZoneId.of(zoneId)); // 获取年、月、日并格式化为YYYYMMDD return zonedDateTime.getYear() * 10000 + zonedDateTime.getMonthValue() * 100 + zonedDateTime.getDayOfMonth(); &#125; /** * 根据给定的时间戳和时区ID，返回格式为YYYYWww的整数，表示年和周数。 * * @param timestamp 时间戳，以毫秒为单位 * @param zoneId 时区ID，例如 &quot;Asia/Shanghai&quot; 或 &quot;GMT&quot; * @return 年和周数的整数，例如 202418 表示2024年第18周 */ public static int getYearWeekFromTimestamp(long timestamp, String zoneId) &#123; // 将时间戳转换为ZonedDateTime ZonedDateTime zonedDateTime = Instant.ofEpochMilli(timestamp).atZone(ZoneId.of(zoneId)); // 获取年份和周数 int year = zonedDateTime.getYear(); int weekOfYear = zonedDateTime.get(IsoFields.WEEK_OF_WEEK_BASED_YEAR); // 格式化为YYYYWww return year * 100 + weekOfYear; &#125; /** * 根据给定的时间戳和时区ID，返回格式为YYYYMM的整数。 * * @param timestamp 时间戳，以毫秒为单位 * @param zoneId 时区ID，例如 &quot;Asia/Shanghai&quot; 或 &quot;GMT&quot; * @return 年月的整数，例如 202408 表示2024年8月 */ public static int getYyyyMmFromTimestamp(long timestamp, String zoneId) &#123; // 将时间戳转换为ZonedDateTime ZonedDateTime zonedDateTime = Instant.ofEpochMilli(timestamp).atZone(ZoneId.of(zoneId)); // 使用DateTimeFormatter格式化日期为YYYYMM DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyyMM&quot;); String formattedDate = zonedDateTime.format(formatter); // 将格式化的字符串转换为整数 return Integer.parseInt(formattedDate); &#125; /** * @param temVO * @Description: 校验模板的开始时间是否小于结束时间, 不重复类型直接返回true跳过校验 * @return: java.lang.Boolean * @Author: xl * @Date: 2024/8/15/0015 11:37 */ public static Boolean startEndTimeCheck(ReportTemplateVO temVO) &#123; if (ReplyCycle.DAY.getType().equals(temVO.getReplyCycle())) &#123; if (temVO.getDay().getIsNext()) return true; return DateTimeUtil.compareTimeStrings(temVO.getDay().getBeginTime(), temVO.getDay().getEndTime()) &lt; 0; &#125; else if (ReplyCycle.WEEK.getType().equals(temVO.getReplyCycle())) &#123; if (temVO.getWeek().getIsNext() || temVO.getWeek().getEndWeekDay() &gt; temVO.getWeek().getBeginWeekDay()) return true; if (temVO.getWeek().getBeginWeekDay() &gt; temVO.getWeek().getEndWeekDay()) return false; return DateTimeUtil.compareTimeStrings(temVO.getWeek().getBeginTime(), temVO.getWeek().getEndTime()) &lt; 0; &#125; else if (ReplyCycle.MONTH.getType().equals(temVO.getReplyCycle())) &#123; if (!validateReportDays(temVO.getMonth().getBeginMonthDay(), temVO.getMonth().getEndMonthDay())) return false; return DateTimeUtil.compareTimeStrings(temVO.getMonth().getBeginTime(), temVO.getMonth().getEndTime()) &lt; 0; &#125; else return ReplyCycle.UNCYCLE.getType().equals(temVO.getReplyCycle()); &#125; /** * @param temVO * @Description: 校验模板的结束时间是否大于下个实例的开始时间, 不重复类型直接返回true跳过校验 * @return: java.lang.Boolean * @Author: xl * @Date: 2024/8/16/0016 14:51 */ public static Boolean endStartTimeCheck(ReportTemplateVO temVO) &#123; if (ReplyCycle.DAY.getType().equals(temVO.getReplyCycle())) &#123; if (!temVO.getDay().getIsNext()) return true; return DateTimeUtil.compareTimeStrings(temVO.getDay().getEndTime(), temVO.getDay().getBeginTime()) &lt; 0; &#125; else if (ReplyCycle.WEEK.getType().equals(temVO.getReplyCycle())) &#123; if (!temVO.getWeek().getIsNext() || temVO.getWeek().getEndWeekDay() &lt; temVO.getWeek().getBeginWeekDay()) return true; if (temVO.getWeek().getEndWeekDay() &gt; temVO.getWeek().getBeginWeekDay()) return false; return DateTimeUtil.compareTimeStrings(temVO.getWeek().getEndTime(), temVO.getWeek().getBeginTime()) &lt; 0; &#125; return true; &#125; /** * 校验月报的开始节点和结束节点是否有效。 * * @param startDay 月报的开始节点，表示每月的第几天。 * @param endDayBeforeEndOfMonth 月报的结束节点，表示每月截止前的倒数第几天。 * @return 如果结束节点大于开始节点，返回true；否则返回false。 */ public static boolean validateReportDays(int startDay, int endDayBeforeEndOfMonth) &#123; // 假设每个月都是28天.按最少的来算 int daysInMonth = 28; // 计算结束节点的具体日期 int endDay = daysInMonth - endDayBeforeEndOfMonth; // 校验开始节点和结束节点 return endDay &gt; startDay; &#125; /** * 比较两个时间字符串的大小。 * * @param time1 第一个时间字符串，格式为&quot;HH时mm分&quot; * @param time2 第二个时间字符串，格式为&quot;HH时mm分&quot; * @return 如果time1在time2之前返回负数，如果time1和time2相同返回0，如果time1在time2之后返回正数 */ public static int compareTimeStrings(String time1, String time2) &#123; // 定义时间格式 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;HH:mm&quot;); // 解析时间字符串 LocalTime timeParsed1 = LocalTime.parse(time1, formatter); LocalTime timeParsed2 = LocalTime.parse(time2, formatter); // 比较时间 return timeParsed1.compareTo(timeParsed2); &#125; /** * 解析时间字符串并返回小时、分钟和秒。 * * @param timeString 时间字符串，格式应为 &quot;HH:mm&quot; * @return 一个包含小时、分钟和秒的对象 * @throws IllegalArgumentException 如果时间字符串格式不正确或无效 */ public static ReportHMMDTO parseTimeString(String timeString) &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;HH:mm&quot;); try &#123; LocalTime localTime = LocalTime.parse(timeString, formatter); return ReportHMMDTO.builder() .hour(localTime.getHour()) .minute(localTime.getMinute()) .second(localTime.getSecond()) .build(); &#125; catch (DateTimeParseException e) &#123; throw new IllegalArgumentException(&quot;Invalid time format&quot;, e); &#125; &#125; /** * 根据指定的时区获取当前日期和时间的字符串表示。 * * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 格式化的日期和时间字符串，格式为 &quot;yyyy-MM-dd HH:mm:ss&quot; */ public static String getCurrentDateTimeByTimeZone(String timeZone, String ft) &#123; // 创建DateTimeFormatter对象，用于格式化日期和时间 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(ft); // 获取当前时间的ZonedDateTime对象，并转换为指定的时区 ZonedDateTime zonedDateTime = ZonedDateTime.now(ZoneId.of(timeZone)); // 使用DateTimeFormatter格式化日期和时间 return formatter.format(zonedDateTime); &#125; /** * 根据特定时区和相对天数获取日期，返回yyyy-MM-dd格式的字符串日期。 * * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @param daysFromNow 相对今天的天数，0表示今天，1表示明天，以此类推 * @return 格式化的日期字符串 */ public static String getDateByDaysFromNow(String timeZone, int daysFromNow) &#123; // 创建DateTimeFormatter对象，用于格式化日期 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); // 获取特定时区的ZonedDateTime对象 ZonedDateTime zonedDateTime = ZonedDateTime.now(ZoneId.of(timeZone)); // 根据相对天数计算目标日期 ZonedDateTime targetDate = zonedDateTime.plus(daysFromNow, ChronoUnit.DAYS); // 使用DateTimeFormatter格式化日期 return targetDate.format(formatter); &#125; /** * 根据指定的时区获取当前日期，返回java.util.Date对象。 * * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 返回一个java.util.Date对象，表示指定时区的当前日期和时间 * String timeZone = &quot;Asia/Shanghai&quot;; * Date currentDate = getCurrentDateByTimeZone(timeZone); * SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); * System.out.println(&quot;Current date and time in &quot; + timeZone + &quot; is: &quot; + sdf.format(currentDate)); */ public static Date getCurrentDateByTimeZone(String timeZone, String ft) &#123; // 创建一个SimpleDateFormat对象，用于格式化日期 SimpleDateFormat sdf = new SimpleDateFormat(ft); // 设置时区 sdf.setTimeZone(TimeZone.getTimeZone(timeZone)); // 获取当前时间的Date对象 Date currentDate = new Date(); // 格式化当前日期为指定时区的字符串 String formattedDate = sdf.format(currentDate); // 使用相同的SimpleDateFormat和时区来解析格式化的字符串，得到一个新的Date对象 Date dateByTimeZone = null; try &#123; dateByTimeZone = sdf.parse(formattedDate); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return dateByTimeZone; &#125; public static Date getCurrentDateByTimeZone(String timeZone) &#123; return getCurrentDateByTimeZone(timeZone, &quot;yyyy-MM-dd HH:mm:ss&quot;); &#125; /** * 获取指定时区的当前日期所在的周数 * * @param zoneId 时区ID * @return 当前日期所在的周数 * int tokyoWeekInYear = DateTimeUtils.getCurrentWeekOfYear(&quot;Asia/Tokyo&quot;); * int nyWeekInYear = DateTimeUtils.getCurrentWeekOfYear(&quot;America/New_York&quot;); */ public static int getCurrentWeekOfYear(String zoneId) &#123; // 获取指定时区的当前日期 LocalDate localDate = LocalDate.now(ZoneId.of(zoneId)); // 获取当前日期所在的周数 return localDate.get(WeekFields.of(Locale.getDefault()).weekOfYear()); &#125; /** * 根据给定的时间戳和时区，获取该时间戳在对应时区下的一年中的第几周。 * * @param timestamp 时间戳（毫秒） * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 一年中的周数 */ public static int getWeekOfYear(long timestamp, String timeZone) &#123; // 将时间戳转换为ZonedDateTime对象，并指定时区 ZonedDateTime zonedDateTime = ZonedDateTime.ofInstant( java.time.Instant.ofEpochMilli(timestamp), ZoneId.of(timeZone) ); // 获取该日期是一年中的第几天 long dayOfYear = zonedDateTime.get(ChronoField.DAY_OF_YEAR); // 计算该日期是第几周 // 一周的开始被认为是周一，因此，如果dayOfYear小于周的中间（例如，如果一周从周日开始，则是4），则为前一周 int weekOfYear = (int) ((dayOfYear + 3) / 7); return weekOfYear; &#125; /** * 根据给定的时间戳和时区，获取该时间戳在对应时区下的月份。 * * @param timestamp 时间戳（毫秒） * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 月份（1-12） */ public static int getMonth(long timestamp, String timeZone) &#123; // 将时间戳转换为ZonedDateTime对象，并指定时区 ZonedDateTime zonedDateTime = ZonedDateTime.ofInstant( java.time.Instant.ofEpochMilli(timestamp), ZoneId.of(timeZone) ); // 获取月份 return zonedDateTime.get(ChronoField.MONTH_OF_YEAR); &#125; /** * 根据指定的时区获取当前年份。 * * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; 或 &quot;UTC&quot; * @return 当前年份的整数值 * String timeZone = &quot;Asia/Shanghai&quot;; * int currentYear = getCurrentYear(timeZone); */ public static int getCurrentYear(String timeZone) &#123; // 获取当前时间的ZonedDateTime对象，并转换为指定的时区 ZonedDateTime now = ZonedDateTime.now(ZoneId.of(timeZone)); // 获取当前年份 return now.getYear(); &#125; /** * 根据指定的时区获取当前月份。 * * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; 或 &quot;UTC&quot; * @return 当前月份 * String timeZone = &quot;Asia/Shanghai&quot;; * String currentMonth = getCurrentMonth(timeZone); */ public static int getCurrentMonth(String timeZone) &#123; // 获取当前时间的ZonedDateTime对象，并转换为指定的时区 ZonedDateTime now = ZonedDateTime.now(ZoneId.of(timeZone)); // 获取当前月份，返回Month枚举 Month currentMonth = now.getMonth(); // 返回月份的名称 return currentMonth.getValue(); &#125; /** * 根据指定的时区获取今天是几号。 * * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; 或 &quot;UTC&quot; * @return 今天是几号 * String timeZone = &quot;Asia/Shanghai&quot;; * int dayOfMonth = getDayOfMonth(timeZone); */ public static int getDayOfMonth(String timeZone) &#123; // 获取当前时间的ZonedDateTime对象，并转换为指定的时区 ZonedDateTime now = ZonedDateTime.now(ZoneId.of(timeZone)); // 获取今天的日期 return now.get(ChronoField.DAY_OF_MONTH); &#125; /** * 根据指定的时区获取今天是周几，返回值为1（周一）到7（周日）。 * * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; 或 &quot;UTC&quot; * @return 今天是周几的整数表示 * String timeZone = &quot;Asia/Shanghai&quot;; * int dayOfWeekInt = getTodayDayOfWeekAsInt(timeZone); */ public static int getTodayDayOfWeekAsInt(String timeZone) &#123; // 获取当前时间的ZonedDateTime对象，并转换为指定的时区 ZonedDateTime now = ZonedDateTime.now(ZoneId.of(timeZone)); // 获取今天是星期几，返回DayOfWeek枚举 DayOfWeek dayOfWeek = now.getDayOfWeek(); // 返回星期几的整数表示，根据DayOfWeek的getValue方法 return dayOfWeek.getValue(); &#125; /** * 根据特定时区和yyyy-MM-dd格式的字符串日期，获取该时区下该日期是周几。 * * @param dateString 日期字符串，格式为 &quot;yyyy-MM-dd&quot; * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 星期几的整数值，1代表周一，2代表周二，...，7代表周日 */ public static int getDayOfWeek(String dateString, String timeZone) &#123; // 创建日期时间格式器// DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); // 使用ZonedDateTime解析日期字符串，并指定时区// ZonedDateTime zonedDateTime = ZonedDateTime.parse(dateString, formatter)// .withZoneSameInstant(ZoneId.of(timeZone));//// // 获取星期几的整数值// int dayOfWeekValue = zonedDateTime.get(ChronoField.DAY_OF_WEEK); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); ZonedDateTime zonedDateTime = ZonedDateTime.of( LocalDate.parse(dateString, formatter), LocalTime.of(0, 0), ZoneId.of(timeZone) ); return zonedDateTime.get(ChronoField.DAY_OF_WEEK); &#125; /** * 根据特定时区和未来N天后的特定时间（X时X分X秒），计算时间戳。 * * @param days 未来天数 * @param hour 小时（0-23） * @param minute 分钟（0-59） * @param second 秒（0-59） * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 时间戳（毫秒） */ public static long getFutureTimestamp(int days, int hour, int minute, int second, String timeZone) &#123;// // 获取当前时间的ZonedDateTime对象，并转换为指定的时区// ZonedDateTime now = ZonedDateTime.now(ZoneId.of(timeZone));//// // 添加N天// ZonedDateTime futureDate = now.plusDays(days);//// // 设置时间为X时X分X秒// LocalDateTime specificTime = futureDate.toLocalDateTime()// .withHour(hour)// .withMinute(minute)// .withSecond(second);//// // 转换回ZonedDateTime，并获取时间戳// return specificTime.atZone(ZoneId.of(timeZone)).toInstant().toEpochMilli(); ZoneId zone = ZoneId.of(timeZone); LocalDate today = LocalDate.now(zone); LocalDateTime future = LocalDateTime.of(today.plusDays(days), LocalTime.of(hour, minute, second)); ZonedDateTime zonedFuture = ZonedDateTime.of(future, zone); return zonedFuture.toInstant().toEpochMilli(); &#125; /** * 根据指定的时区获取明天 X时X分X秒的时间戳。 * * @param hour 小时 * @param minute 分钟 * @param second 秒 * @param timeZone 时区ID * @return 时间戳（毫秒） * int hour = 13; * int minute = 45; * int second = 30; * String timeZone = &quot;Asia/Shanghai&quot;; * long timestamp = getTomorrowTimestamp(hour, minute, second, timeZone); */ public static long getTomorrowTimestamp(int hour, int minute, int second, String timeZone) &#123; // 获取当前时间的ZonedDateTime对象，并转换为指定的时区 ZonedDateTime now = ZonedDateTime.now(ZoneId.of(timeZone)); // 找到明天的日期 ZonedDateTime tomorrow = now.plusDays(1); // 设置时间为明天的X时X分X秒 ZonedDateTime specificDateTime = tomorrow.withHour(hour) .withMinute(minute) .withSecond(second); // 返回时间戳 return specificDateTime.toInstant().toEpochMilli(); &#125; /** * 根据指定的时区、年、月、日、时、分、秒获取时间戳。 * * @param year 年份 * @param month 月份（1-12） * @param day 日（1-31，根据月份不同） * @param hour 小时（0-23） * @param minute 分钟（0-59） * @param second 秒（0-59） * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 时间戳（毫秒） * int year = 2024; * int month = 7; // 注意月份从1开始计数 * int day = 24; * int hour = 12; * int minute = 30; * int second = 25; * String timeZone = &quot;Asia/Shanghai&quot;; * long timestamp = getTimestamp(year, month, day, hour, minute, second, timeZone); */ public static long getTimestampByYMDHMS(int year, int month, int day, int hour, int minute, int second, String timeZone) &#123; // 创建DateTimeFormatter对象 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;); // 构建日期时间字符串 String dateTimeString = String.format(&quot;%d-%02d-%02d %02d:%02d:%02d&quot;, year, month, day, hour, minute, second); // 解析日期时间字符串为ZonedDateTime对象，并转换为指定的时区 ZonedDateTime zonedDateTime = ZonedDateTime.parse(dateTimeString, formatter) .withZoneSameInstant(ZoneId.of(timeZone)); // 转换为时间戳 return zonedDateTime.toInstant().toEpochMilli(); &#125; /** * 根据指定的时区获取本月第X天 X时X分X秒的时间戳。 * * @param dayOfMonth 本月的第几天（例如，1表示本月第一天） * @param hour 小时（0-23） * @param minute 分钟（0-59） * @param second 秒（0-59） * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 时间戳（毫秒） */ public static long getTimestampOfSpecificDayOfMonth(int dayOfMonth, int hour, int minute, int second, String timeZone) &#123; // 获取当前时间的ZonedDateTime对象，并转换为指定的时区 ZonedDateTime zonedDateTime = ZonedDateTime.now(ZoneId.of(timeZone)); // 找到本月的第一天 ZonedDateTime firstDayOfMonth = zonedDateTime.with(TemporalAdjusters.firstDayOfMonth()); // 计算目标日期 ZonedDateTime specificDayOfMonth = firstDayOfMonth.plusDays(dayOfMonth - 1); // 设置时间为X时X分X秒 ZonedDateTime specificDateTime = specificDayOfMonth.withHour(hour) .withMinute(minute) .withSecond(second); // 返回时间戳 return specificDateTime.toInstant().toEpochMilli(); &#125; /** * 根据指定的时区获取N月后第X天 X时X分X秒的时间戳。 * * @param monthLater N个月后，0代表本月，1代表下个月，以此类推 * @param dayOfMonth 月份中的第几天 * @param hour 小时 * @param minute 分钟 * @param second 秒 * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 时间戳（毫秒） */ public static long getTimestampOfSpecificDayInMonth(int monthLater, int dayOfMonth, int hour, int minute, int second, String timeZone) &#123; // 获取当前时间的ZonedDateTime对象，并转换为指定的时区 ZonedDateTime zonedDateTime = ZonedDateTime.now(ZoneId.of(timeZone)); // 计算N个月后的第一天 ZonedDateTime firstDayOfTargetMonth = zonedDateTime .with(TemporalAdjusters.firstDayOfNextMonth()) .plusMonths(monthLater - 1); // 减1是因为firstDayOfNextMonth已经增加了一个月 // 计算目标日期：N月后的第X天 ZonedDateTime specificDay = firstDayOfTargetMonth.withDayOfMonth(dayOfMonth); // 设置时间为X时X分X秒 ZonedDateTime specificDateTime = specificDay.withHour(hour) .withMinute(minute) .withSecond(second); // 返回时间戳 return specificDateTime.toInstant().toEpochMilli(); &#125; /** * 根据指定的时区获取本月倒数第X天 X时X分X秒的时间戳。 * * @param dayIndexFromEnd 本月的倒数第几天（例如，0表示月底最后一天） * @param hour 小时 * @param minute 分钟 * @param second 秒 * @param timeZone 时区ID * @return 时间戳（毫秒） * int dayIndexFromEnd = 2; // 本月倒数第2天 * int hour = 15; * int minute = 30; * int second = 25; * String timeZone = &quot;Asia/Shanghai&quot;; * long timestamp = getLastOfMonthTimestamp(dayIndexFromEnd, hour, minute, second, timeZone); */ public static long getLastOfMonthTimestamp(int dayIndexFromEnd, int hour, int minute, int second, String timeZone) &#123; // 获取本月的最后一天 LocalDate lastDayOfMonth = LocalDate.now(ZoneId.of(timeZone)) .with(TemporalAdjusters.lastDayOfMonth()); // 计算目标日期（本月倒数第X天） LocalDate targetDay = lastDayOfMonth.minusDays(dayIndexFromEnd); // 创建目标日期和时间的LocalDateTime对象 LocalDateTime specificDateTime = LocalDateTime.of(targetDay.getYear(), targetDay.getMonth(), targetDay.getDayOfMonth(), hour, minute, second); // 转换为特定时区的ZonedDateTime对象 ZonedDateTime zonedDateTime = specificDateTime.atZone(ZoneId.of(timeZone)); // 返回时间戳 return zonedDateTime.toInstant().toEpochMilli(); &#125; /** * 根据指定的时区获取下周周X X时X分X秒的时间戳。 * * @param dayOfWeek 下周的星期几（例如，MONDAY为1，SUNDAY为7） * @param hour 小时（0-23） * @param minute 分钟（0-59） * @param second 秒（0-59） * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 时间戳（毫秒） * int dayOfWeek = 2; // 星期二（DayOfWeek.MONDAY 为 1，以此类推） * int hour = 15; * int minute = 30; * int second = 25; * String timeZone = &quot;Asia/Shanghai&quot;; * long timestamp = getTimestampNextWeekDay(dayOfWeek, hour, minute, second, timeZone); */ public static long getTimestampNextWeekDay(int dayOfWeek, int hour, int minute, int second, String timeZone) &#123; // 获取当前时间的ZonedDateTime对象，并转换为指定的时区 ZonedDateTime now = ZonedDateTime.now(ZoneId.of(timeZone)); // 找到下周对应的星期几的日期 ZonedDateTime nextWeekDay = now.with(TemporalAdjusters.nextOrSame(DayOfWeek.of(dayOfWeek))); // 设置时间为X时X分X秒 ZonedDateTime specificDateTime = nextWeekDay.withHour(hour) .withMinute(minute) .withSecond(second); // 返回时间戳 return specificDateTime.toInstant().toEpochMilli(); &#125; /** * 根据指定的时区获取本周周X X时X分X秒的时间戳。 * * @param dayOfWeekIndex 星期几的索引（1=周一，2=周二，...，7=周日） * @param hour 小时 * @param minute 分钟 * @param second 秒 * @param timeZone 时区ID * @return 时间戳（毫秒） * int dayOfWeekIndex = 3; // 周三（ISO标准，1=周一，...，7=周日） * int hour = 12; * int minute = 30; * int second = 0; * String timeZone = &quot;Asia/Shanghai&quot;; * long timestamp = getThisWeekTimestamp(dayOfWeekIndex, hour, minute, second, timeZone); */ public static long getThisWeekTimestamp(int dayOfWeekIndex, int hour, int minute, int second, String timeZone) &#123; // 获取当前时间的本地日期时间对象，并设置为本周一的00:00:00 LocalDateTime startOfWeek = LocalDateTime.now(ZoneId.of(timeZone)) .with(TemporalAdjusters.previousOrSame(DayOfWeek.MONDAY)) .withHour(0) .withMinute(0) .withSecond(0) .withNano(0); // 计算目标星期几的日期时间对象 DayOfWeek targetDayOfWeek = DayOfWeek.of(dayOfWeekIndex); LocalDateTime targetDateTime = startOfWeek.with(TemporalAdjusters.nextOrSame(targetDayOfWeek)) .withHour(hour) .withMinute(minute) .withSecond(second); // 转换为特定时区的ZonedDateTime对象 ZonedDateTime zonedDateTime = targetDateTime.atZone(ZoneId.of(timeZone)); // 返回时间戳 return zonedDateTime.toInstant().toEpochMilli(); &#125; /** * 获取指定时区N周后的周X X时X分X秒的时间戳。 * * @param timeZoneStr 时区字符串，如 &quot;Asia/Shanghai&quot; * @param weeks 周数 * @param dayOfWeek 星期几，1表示周一，7表示周日 * @param hourOfDay 小时，24小时制 * @param minuteOfHour 分钟 * @param secondOfMinute 秒 * @return 时间戳 */ public static long getTimeStampInTimeZone(int weeks, int dayOfWeek, int hourOfDay, int minuteOfHour, int secondOfMinute, String timeZoneStr) &#123; // 使用系统默认时区的当前时间 LocalDateTime now = LocalDateTime.now(); // 转换为指定时区的ZonedDateTime ZonedDateTime zonedDateTime = now.atZone(ZoneId.of(timeZoneStr)); //已过的日期和未过的日期，如果不处理一下结果会相差1个星期// if (weeks &lt; 1 &amp;&amp; getDayOfWeekAsInt(timeZoneStr) &lt; dayOfWeek)// if (weeks &lt; 1 &amp;&amp; getDayOfWeekAsInt(timeZoneStr) &gt;= dayOfWeek)// weeks++; if (getDayOfWeekAsInt(timeZoneStr) &lt; dayOfWeek) weeks--;// weeks--; // 根据weeks的值来决定是使用当前时间还是增加相应的周数// if (weeks &gt; 0) &#123; // 如果weeks大于0，计算N周后的日期 zonedDateTime = zonedDateTime.plusWeeks(weeks);// &#125; // 调整到周X的指定时间 zonedDateTime = zonedDateTime.with(TemporalAdjusters.ofDateAdjuster(date -&gt; &#123; // 找到当前周或未来周的指定星期几 DayOfWeek targetDayOfWeek = DayOfWeek.of(dayOfWeek); DayOfWeek currentDayOfWeek = date.getDayOfWeek(); if (currentDayOfWeek.getValue() &gt;= targetDayOfWeek.getValue()) &#123; // 如果当前是目标星期或之后，直接调整到目标星期 return date.with(targetDayOfWeek); &#125; else &#123; // 如果当前是目标星期之前，需要调整到下一周的目标星期 return date.plusWeeks(1).with(targetDayOfWeek); &#125; &#125;)) .withHour(hourOfDay) .withMinute(minuteOfHour) .withSecond(secondOfMinute) .with(ChronoField.NANO_OF_SECOND, 0); // 确保纳秒为0 // 返回时间戳 return zonedDateTime.toInstant().toEpochMilli(); &#125; /** * 获取指定时区今天是周几的工具函数。 * * @param timeZoneId 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 返回今天是周几的整数，1代表周一，7代表周日 */ public static int getDayOfWeekAsInt(String timeZoneId) &#123; // 获取当前时间，并指定时区 ZonedDateTime zonedDateTime = ZonedDateTime.now(java.time.ZoneId.of(timeZoneId)); // 获取今天是周几 DayOfWeek dayOfWeek = zonedDateTime.getDayOfWeek(); // 将DayOfWeek转换为整数 return dayOfWeek.getValue(); &#125; /** * 根据指定的年份、周数、星期几、小时、分钟和秒以及时区获取时间戳。 * * @param year 年份 * @param weekOfYear 一年中的周数（例如第1周） * @param dayOfWeek 星期几（1=星期一，...，7=星期日） * @param hour 小时 * @param minute 分钟 * @param second 秒 * @param timeZone 时区ID，例如 &quot;Asia/Shanghai&quot; * @return 时间戳（毫秒） */ public static long getTimestamp(int year, int weekOfYear, int dayOfWeek, int hour, int minute, int second, String timeZone) &#123; // 定义周的第一天为星期一 WeekFields weekFields = WeekFields.of(Locale.getDefault()); DayOfWeek firstDayOfWeek = weekFields.getFirstDayOfWeek(); // 计算年初的日期 LocalDateTime startOfYear = LocalDateTime.of(year, 1, 1, 0, 0); int currentWeek = startOfYear.get(weekFields.weekOfYear()); // 找到年初的第一个星期的第一天 LocalDateTime firstWeekStartDate = startOfYear.with(TemporalAdjusters.previousOrSame(firstDayOfWeek)); // 计算目标日期 long daysToAdd = (weekOfYear - 1) * 7 + (dayOfWeek - firstDayOfWeek.getValue()); LocalDateTime targetDateTime = firstWeekStartDate.plusDays(daysToAdd) .withHour(hour) .withMinute(minute) .withSecond(second); // 转换为特定时区的时间戳 ZonedDateTime zonedDateTime = targetDateTime.atZone(ZoneId.of(timeZone)); return zonedDateTime.toInstant().toEpochMilli(); &#125; /** * 根据给定的时间戳和时区，转换为java.util.Date格式的日期。 * * @param timestamp 时间戳（毫秒） * @param timeZone 时区ID * @return java.util.Date对象 * long timestamp = System.currentTimeMillis(); // 假设当前时间戳 * String timeZone = &quot;Asia/Shanghai&quot;; * Date date = convertToDateTime(timestamp, timeZone); */ public static Date convertToDateTime(long timestamp, String timeZone) &#123;// // 创建一个Date对象，该对象将时间戳设置为给定的时间戳// Date date = new Date(timestamp);//// // 设置时区// TimeZone tz = TimeZone.getTimeZone(timeZone);//// // 将Date对象转换为特定时区的日期//// return new Date(date.getTime() - tz.getRawOffset());// // 将时间戳转换为Instant对象// Instant instant = Instant.ofEpochMilli(timestamp);//// // 根据时区创建ZonedDateTime对象// ZonedDateTime zonedDateTime = instant.atZone(ZoneId.of(timeZone));//// // 将ZonedDateTime对象转换为java.util.Date// return Date.from(zonedDateTime.toInstant());// // 将时间戳转换为Instant对象// Instant instant = Instant.ofEpochMilli(timestamp);//// // 根据时区创建ZonedDateTime对象,并考虑夏令时的影响// TimeZone tz = TimeZone.getTimeZone(timeZone);// ZonedDateTime zonedDateTime = ZonedDateTime.ofInstant(instant, tz.toZoneId());//// return Date.from(zonedDateTime.toInstant()); // 设置时区 TimeZone.setDefault(TimeZone.getTimeZone(timeZone)); // 使用 Hutool 将时间戳转换为 java.util.Date return DateUtil.date(timestamp); &#125; /** * 获取当前时间戳。 * * @return java.util.Date对象 */ public static Long getCurrentTimestamp() &#123; // 获取当前时间戳 return System.currentTimeMillis(); &#125; /** * 获取当前北京时间，并以Date对象格式返回。 * * @return 当前北京时间的Date对象 */ public static Date getCurrentBeijingTime() &#123; // 设置时区为亚洲/上海，代表北京时间 TimeZone timeZone = TimeZone.getTimeZone(&quot;Asia/Shanghai&quot;); // 获取当前时间的毫秒数（自1970年1月1日00:00:00 GMT以来） long currentTimeMillis = System.currentTimeMillis(); return new Date(currentTimeMillis); &#125; /** * 根据给定的Date对象和时区，转换为时间戳。 * * @param date java.util.Date对象 * @param timeZone 时区 * @return 时间戳（毫秒） * Date date = new Date(); // 假设当前时间 * TimeZone timeZone = TimeZone.getTimeZone(&quot;Asia/Shanghai&quot;); * long timestamp = convertToDateTimestamp(date, timeZone); */ public static long convertToDateTimestamp(Date date, TimeZone timeZone) &#123; // 将Date对象转换为特定时区的时间戳 long timestamp = date.getTime(); // 如果需要转换到不同的时区，可以调整时间戳 // 以下代码将时间戳从默认时区转换到指定的时区 long offset = timeZone.getRawOffset() - date.getTimezoneOffset() * 1000; return timestamp + offset; &#125; /** * 根据给定的日期和时区字符串转换为时间戳。 * * @param date 需要转换的日期 * @param timeZoneId 时区的字符串表示，例如 &quot;Asia/Shanghai&quot; * @return 转换后的时间戳 */ public static long convertDateToTimestamp(Date date, String timeZoneId) &#123; // 设置时区 TimeZone timeZone = TimeZone.getTimeZone(timeZoneId); // 将日期转换为毫秒值（时间戳） long timestamp = date.getTime(); // 根据时区调整时间戳 long adjustedTimestamp = timestamp + (timeZone.getRawOffset() - TimeZone.getDefault().getRawOffset()); return adjustedTimestamp; &#125; /** * 根据给定的日期字符串和时区，转换为时间戳。 * * @param dateString 日期字符串 * @param timeZone 时区，例如 &quot;Asia/Shanghai&quot; 或 &quot;GMT&quot; * @param dateFormat 日期格式，例如 &quot;yyyy-MM-dd HH:mm:ss&quot; * @return 时间戳（毫秒） * String dateString = &quot;2024-07-24 00:00:00&quot;; * String timeZone = &quot;CST&quot;; // 例如，中国标准时间 * String dateFormat = &quot;yyyy-MM-dd HH:mm:ss&quot;; * long timestamp = convertToDateTimestamp(dateString, timeZone, dateFormat);* */ public static long convertToDateTimestamp(String dateString, String timeZone, String dateFormat) &#123; SimpleDateFormat formatter = new SimpleDateFormat(dateFormat); formatter.setTimeZone(TimeZone.getTimeZone(timeZone)); try &#123; Date date = formatter.parse(dateString); return date.getTime(); &#125; catch (ParseException e) &#123; if (dateFormat.equals(&quot;yyyy-MM-dd HH:mm:ss&quot;)) return convertToDateTimestamp(dateString, timeZone, &quot;yyyy-MM-dd HH:mm&quot;); e.printStackTrace(); return -1; &#125; &#125; /** * @param dt 格式 * @Description: 封装汇报时间ReportDateVO * @return: com.ioo.system.web.report_statistic.controller.vo.ReportDateVO * @Author: xl * @Date: 2024/8/8/0008 18:12 */ public static ReportDateVO getDays(String dt) &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); LocalDate date2 = LocalDate.parse(dt, formatter); int year = date2.getYear(); int month = date2.getMonthValue(); int dayOfMonth = date2.getDayOfMonth(); String firstDay = getFirstDay(year, month, &quot;yyyy-MM-dd&quot;); String lastDay = getLastDay(year, month, &quot;yyyy-MM-dd&quot;); ReportDateVO build = ReportDateVO.builder().title(dt).year(year).day(dayOfMonth).startDate(stringToDateToYMD(firstDay, &quot;yyyy-MM-dd&quot;)).endDate(stringToDateToYMD(lastDay, &quot;yyyy-MM-dd&quot;)) .start(firstDay) .end(lastDay) .month(month).build(); return build; &#125; /** * @param dt 格式 * @Description: 封装汇报时间ReportDateVO * @return: com.ioo.system.web.report_statistic.controller.vo.ReportDateVO * @Author: xl * @Date: 2024/8/8/0008 18:14 */ public static ReportDateVO getWeeks(String dt) &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); LocalDate date2 = LocalDate.parse(dt, formatter); int year = date2.getYear(); int month = date2.getMonthValue(); int day = date2.getDayOfMonth(); // 指定日期 LocalDate date = LocalDate.of(year, month, day); // 获取当前年份的第几周 int weekOfYear = date.get(IsoFields.WEEK_OF_WEEK_BASED_YEAR); List&lt;String&gt; strings = weekToDayFormate(year, weekOfYear); ReportDateVO build = ReportDateVO.builder().title(year + &quot;年第&quot; + weekOfYear + &quot;周&quot;).year(year).startDate(stringToDateToYMD(strings.get(0))).endDate(stringToDateToYMD(strings.get(1))) .start(strings.get(0)) .end(strings.get(1)) .weekNum((weekOfYear)).build(); return build; &#125; /** * @param startDate * @param endDate * @Description: 计算两个时间内 所有的周数 * @return: java.util.List&lt;com.ioo.system.refactor_report.controller.vo.ReportDateVO&gt; * @Author: xl * @Date: 2024/8/22/0022 15:49 */ public static List&lt;ReportDateVO&gt; getWeeks(String startDate, String endDate) throws ParseException &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date parse = sdf.parse(startDate); Date parse2 = sdf.parse(endDate); List&lt;ReportDateVO&gt; dateList = new ArrayList&lt;&gt;(); Calendar startC = Calendar.getInstance(); startC.setFirstDayOfWeek(Calendar.MONDAY); startC.setTime(parse); Long startCurrentWeek = dateScaleplate(startC); //转为周一 int weekYear = startC.get(Calendar.YEAR); int weekOfYear = startC.get(Calendar.WEEK_OF_YEAR); startC.setWeekDate(weekYear, weekOfYear, Calendar.MONDAY); Calendar endC = Calendar.getInstance(); endC.setFirstDayOfWeek(Calendar.MONDAY); endC.setTime(parse2); Long endWeek = dateScaleplate(endC); int weekYear2 = endC.get(Calendar.YEAR); int weekOfYear2 = endC.get(Calendar.WEEK_OF_YEAR); endC.setWeekDate(weekYear2, weekOfYear2, Calendar.SUNDAY); while (true) &#123; int weekNum = startC.get(Calendar.WEEK_OF_YEAR); ReportDateVO build = ReportDateVO.builder().title(startC.getWeekYear() + &quot;年第&quot; + (weekNum &gt; 9 ? weekNum : &quot;0&quot; + weekNum) + &quot;周&quot;).year(startC.getWeekYear()) .weekNum((weekNum &gt; 9 ? weekNum : Integer.valueOf(&quot;0&quot; + weekNum))).build(); dateList.add(build);// if (c1.getTimeInMillis() &gt;= c2.getTimeInMillis()) &#123;// System.out.println(&quot;22-c1:&quot;+cdt1+&quot;-c2:&quot;+cdt2);// break;// &#125; if (startCurrentWeek &gt;= endWeek) &#123; break; &#125; //增加7天 startC.setTimeInMillis(startC.getTimeInMillis() + 1000 * 60 * 60 * 24 * 7); startCurrentWeek = dateScaleplate(startC); &#125; return dateList; &#125; private static Long dateScaleplate(Calendar calendar) &#123; int year = calendar.get(Calendar.YEAR); // 获取月份（月份是从0开始的，因此需要+1）// int month = calendar.get(Calendar.MONTH) + 1;// int day = calendar.get(Calendar.DAY_OF_MONTH); int weekNum = calendar.get(Calendar.WEEK_OF_YEAR); String dt = year + &quot;&quot; + weekNum; return Long.parseLong(dt); &#125; /** * @param dt 格式 * @Description: 封装汇报时间ReportDateVO * @return: com.ioo.system.web.report_statistic.controller.vo.ReportDateVO * @Author: xl * @Date: 2024/8/8/0008 18:14 */ public static ReportDateVO getMonths(String dt) &#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); LocalDate date2 = LocalDate.parse(dt, formatter); int year = date2.getYear(); int month = date2.getMonthValue(); String firstDay = getFirstDay(year, month, &quot;yyyy-MM-dd&quot;); String lastDay = getLastDay(year, month, &quot;yyyy-MM-dd&quot;); ReportDateVO build = ReportDateVO.builder().title(year + &quot;年第&quot; + month + &quot;月&quot;).year(year).startDate(stringToDateToYMD(firstDay, &quot;yyyy-MM-dd&quot;)).endDate(stringToDateToYMD(lastDay, &quot;yyyy-MM-dd&quot;)) .start(firstDay) .end(lastDay) .month(month).build(); return build; &#125; /** * @param time 日期时间 * @param h 目标小时 * @param min 目标分钟 * @Description: 修改日期的时间部分 * @return: java.util.Date * @Author: xl * @Date: 2024/8/8/0008 18:15 */ public static Date setDt(Date time, int h, int min) &#123; Calendar cal = Calendar.getInstance(); cal.setTime(time); cal.set(Calendar.HOUR_OF_DAY, h); //时 cal.set(Calendar.MINUTE, min); //分 cal.set(Calendar.SECOND, 0); //秒 cal.set(Calendar.MILLISECOND, 0); //毫秒 return cal.getTime(); &#125; /** * @param year 哪一年 * @Description: 获取指定年的开始日期和结束日期 * @return: java.util.List&lt;java.util.Date&gt; * @Author: xl * @Date: 2024/8/8/0008 18:15 */ public static List&lt;Date&gt; getFirstDayAndLastDayOfTheSpecifiedYear(int year) &#123; Calendar calendar = Calendar.getInstance(); // 设置某年的开始时间 calendar.set(year, Calendar.JANUARY, 1, 0, 0, 0); calendar.set(Calendar.MILLISECOND, 0); Date startTime = calendar.getTime(); // 设置某年的结束时间 calendar.set(year, Calendar.DECEMBER, 31, 23, 59, 59); calendar.set(Calendar.MILLISECOND, 999); Date endTime = calendar.getTime(); // 设置返回信息,返回样式根据需求自行格式化 List&lt;Date&gt; years = new ArrayList&lt;&gt;(); years.add(setDt(startTime, 0, 0)); years.add(setDt(endTime, 23, 59)); return years; &#125; /** * @param year 哪一年 * @param month 哪个月 * @Description: 获取指定年指定月的开始日期和结束日期 * @return: java.util.List&lt;java.util.Date&gt; * @Author: xl * @Date: 2024/8/8/0008 18:16 */ public static List&lt;Date&gt; getFirstDayAndLastDayOfTheSpecifiedMonth(int year, int month) &#123; // 获取当前分区的日历信息(这里可以使用参数指定时区) Calendar calendar = Calendar.getInstance(); // 设置年 calendar.set(Calendar.YEAR, year); // 设置月，月份从0开始 calendar.set(Calendar.MONTH, month - 1); // 设置为指定月的第一天 calendar.set(Calendar.DAY_OF_MONTH, 1); // 获取指定月第一天的时间 Date start = calendar.getTime(); // 设置日历天数为当前月实际天数的最大值，即指定月份的最后一天 calendar.set(Calendar.DATE, calendar.getActualMaximum(Calendar.DATE)); // 获取最后一天的时间 Date end = calendar.getTime(); // 设置返回信息,返回样式根据需求自行格式化 List&lt;Date&gt; months = new ArrayList&lt;&gt;(); months.add(setDt(start, 0, 0)); months.add(setDt(end, 23, 59)); return months; &#125; /** * @param * @Description: 获取当前月份的开始和结束时间 * @return: java.util.List&lt;java.util.Date&gt; * @Author: xl * @Date: 2024/8/8/0008 18:16 */ public static List&lt;Date&gt; getCurMonth() &#123; List&lt;Date&gt; month = new ArrayList&lt;&gt;(); // 获取当前日期 Date currentDate = new Date(); // 创建Calendar实例 Calendar calendar = Calendar.getInstance(); // 设置日期为当前日期 calendar.setTime(currentDate); // 将日期设置为该月的第一天 calendar.set(Calendar.DAY_OF_MONTH, 1); // 获取本月的开始时间 Date startTime = calendar.getTime(); // 将日期设置为该月的最后一天 calendar.set(Calendar.DAY_OF_MONTH, calendar.getActualMaximum(Calendar.DAY_OF_MONTH)); // 获取本月的结束时间 Date endTime = calendar.getTime(); month.add(setDt(startTime, 0, 0)); month.add(setDt(endTime, 23, 59)); return month; &#125; /** * @param * @Description: 获取当前时间的年月日 * @return: java.lang.String * @Author: xl * @Date: 2024/8/8/0008 18:16 */ public static String getCurrentDate() &#123; Date currentDate = new Date(); SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); String formattedDate = dateFormat.format(currentDate); return formattedDate; &#125; /** * @param * @Description: 获取当前时间的年月日时分秒 * @return: java.lang.String * @Author: xl * @Date: 2024/8/8/0008 18:16 */ public static String getCurrentDateHMS() &#123; Date currentDate = new Date(); SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); String formattedDate = dateFormat.format(currentDate); return formattedDate; &#125; /** * @param * @Description: 获取N天前的年月日 * @return: java.lang.String * @Author: xl * @Date: 2024/8/8/0008 18:17 */ public static String getDateSpan() &#123; LocalDate today = LocalDate.now(); // 获取当前日期 LocalDate oneHundredEightyDaysAgo = today.minusDays(CommonConstant.WEEK_DATE_SPAN); // 当前日期减去365天 // 格式化日期为年月日 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); String formattedDate = oneHundredEightyDaysAgo.format(formatter); return formattedDate; &#125; /** * @param startDate * @param endDate * @Description: 计算两个日期中所有的月份 * @return: java.util.List&lt;java.lang.String&gt; * @Author: xl * @Date: 2024/8/8/0008 18:17 */ public static List&lt;String&gt; getMonths(String startDate, String endDate) throws ParseException &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date parse = sdf.parse(startDate); Date parse2 = sdf.parse(endDate); List&lt;String&gt; dateList = new ArrayList&lt;&gt;(); Calendar startC = Calendar.getInstance(); startC.setTime(parse); //转为周一 int year = startC.get(Calendar.YEAR); int month = startC.get(Calendar.MONTH); startC.set(year, month, 1, 0, 0, 0); Calendar endC = Calendar.getInstance(); endC.setTime(parse2); int weekYear2 = endC.get(Calendar.YEAR); int weekOfYear2 = endC.get(Calendar.WEEK_OF_YEAR); endC.setWeekDate(weekYear2, weekOfYear2, Calendar.SUNDAY); while (true) &#123; int tempMonth = startC.get(Calendar.MONTH); String date = startC.getWeekYear() + &quot;-&quot; + ((tempMonth + 1) &lt;= 9 ? &quot;0&quot; + (tempMonth + 1) : tempMonth + 1); dateList.add(date); //下一个月&lt;结束日期 startC.set(Calendar.MONTH, tempMonth + 1); if (startC.getTimeInMillis() &gt;= endC.getTimeInMillis()) &#123; break; &#125; &#125; return dateList; &#125; /** * @param year 年份 * @param month 月份 * @param format 格式 * @Description: 根据年月获取月末最后一天日期 * @return: java.lang.String * @Author: xl * @Date: 2024/8/8/0008 18:17 */ public static String getLastDay(int year, int month, String format) &#123; Calendar calendar = Calendar.getInstance(); calendar.set(Calendar.YEAR, year); calendar.set(Calendar.MONTH, month); calendar.set(Calendar.DAY_OF_MONTH, 1); calendar.add(Calendar.DAY_OF_MONTH, -1); calendar.set(Calendar.HOUR_OF_DAY, 23); //时 calendar.set(Calendar.MINUTE, 59); //分 calendar.set(Calendar.SECOND, 59); //秒 calendar.set(Calendar.MILLISECOND, 0); //毫秒// TimeZone timeZone = TimeZone.getTimeZone(&quot;UTC&quot;);// calendar.setTimeZone(timeZone); Date endDate = calendar.getTime(); SimpleDateFormat sdf = new SimpleDateFormat(format); String formattedEndDate = sdf.format(endDate); return formattedEndDate; &#125; /** * @param year 年份 * @param month 月份 * @param format 格式 * @Description: 根据年月获取月末最后一天日期 * @return: java.lang.String * @Author: xl * @Date: 2024/8/8/0008 18:18 */ public static String getFirstDay(int year, int month, String format) &#123; Calendar calendar = Calendar.getInstance(); calendar.set(Calendar.YEAR, year); calendar.set(Calendar.MONTH, month - 1); calendar.set(Calendar.DAY_OF_MONTH, 1); calendar.set(Calendar.HOUR_OF_DAY, 0); //时 calendar.set(Calendar.MINUTE, 0); //分 calendar.set(Calendar.SECOND, 0); //秒 calendar.set(Calendar.MILLISECOND, 0); //毫秒// TimeZone timeZone = TimeZone.getTimeZone(&quot;UTC&quot;);// calendar.setTimeZone(timeZone); Date startDate = calendar.getTime(); SimpleDateFormat sdf = new SimpleDateFormat(format); String formattedStartDate = sdf.format(startDate); return formattedStartDate; &#125; public static String dateToString(Date date, String ft) &#123; SimpleDateFormat sdf = new SimpleDateFormat(ft); return sdf.format(date); &#125; /** * 根据给定的日期字符串，返回 &quot;XX年第XX周&quot; 格式化的字符串。 * * @param dateString 日期字符串 * @param ft 日期字符串的格式 * @return 格式化的周字符串，例如 &quot;2024年第35周&quot; */ public static String formatToYearWeek(String dateString, String ft) &#123; if (Strings.isBlank(ft)) ft = &quot;yyyy-MM-dd HH:mm:ss&quot;; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(ft); try &#123; // 解析日期字符串 LocalDate date = LocalDate.parse(dateString, formatter); // 获取年份和周数 int year = date.getYear(); int week = date.get(IsoFields.WEEK_OF_WEEK_BASED_YEAR); // 格式化为 &quot;XX年第XX周&quot; 格式的字符串 return String.format(&quot;%d年第%d周&quot;, year, week); &#125; catch (Exception e) &#123; // 处理异常，例如格式不匹配 System.err.println(&quot;Error parsing date: &quot; + e.getMessage()); return null; &#125; &#125; /** * 根据给定的Date对象，返回格式化的字符串，格式为 &quot;XX年第XX周&quot;。 * * @param date java.util.Date对象 * @return 格式化的字符串，例如 &quot;2023年第47周&quot; */ public static String formatDateToYearAndWeek(Date date) &#123; if (date == null) &#123; throw new IllegalArgumentException(&quot;日期对象不能为空&quot;); &#125; Calendar calendar = Calendar.getInstance(); calendar.setTime(date); // 获取年份 int year = calendar.get(Calendar.YEAR); // 获取一年中的第几周 int weekOfYear = calendar.get(Calendar.WEEK_OF_YEAR); // 格式化为 &quot;XX年第XX周&quot; return String.format(&quot;%d年第%d周&quot;, year, weekOfYear); &#125; /** * 根据给定的日期字符串，返回 &quot;XX年XX月&quot; 格式化的字符串。 * * @param dateString 日期字符串 * @param ft 日期字符串的格式 * @return 格式化的年月字符串，例如 &quot;2024年08月&quot; */ public static String formatToYearMonth(String dateString, String ft) &#123; if (Strings.isBlank(ft)) ft = &quot;yyyy-MM-dd HH:mm:ss&quot;; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(ft); try &#123; // 解析日期字符串 LocalDate date = LocalDate.parse(dateString, formatter); // 定义输出格式 DateTimeFormatter outputFormatter = DateTimeFormatter.ofPattern(&quot;yyyy年MM月&quot;); // 格式化日期 return date.format(outputFormatter); &#125; catch (Exception e) &#123; // 处理异常，例如格式不匹配 System.err.println(&quot;Error parsing date: &quot; + e.getMessage()); return null; &#125; &#125; /** * 根据给定的Date对象，返回格式化的字符串，格式为 &quot;XX年XX月&quot;。 * * @param date java.util.Date对象 * @return 格式化的字符串，例如 &quot;2023年11月&quot; */ public static String formatDateToYearAndMonth(Date date) &#123; if (date == null) &#123; throw new IllegalArgumentException(&quot;日期对象不能为空&quot;); &#125; // 创建SimpleDateFormat对象，设置日期格式 SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy年MM月&quot;); // 格式化日期 return dateFormat.format(date); &#125; /** * @param date 字符串日期 * @Description: 字符串转日期格式- yyyy-MM-dd HH:mm:ss * @return: java.util.Date * @Author: xl * @Date: 2024/8/8/0008 18:18 */ public static Date stringToDateToYMD(String date) &#123; SimpleDateFormat format = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); Date parse = new Date(); try &#123; parse = format.parse(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return parse; &#125; /** * @param date 字符串日期 * @param ft 日期格式 * @Description: 字符串转日期格式 * @return: java.util.Date * @Author: xl * @Date: 2024/8/8/0008 18:19 */ public static Date stringToDateToYMD(String date, String ft) &#123; SimpleDateFormat format = new SimpleDateFormat(ft); Date parse = new Date(); try &#123; parse = format.parse(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return parse; &#125; /** * @param year 年份 * @param week 周数 * @Description: 根据某年的某周，查询本周的起止时间 * @return: java.util.List&lt;java.lang.String&gt; * @Author: xl * @Date: 2024/8/8/0008 18:19 */ public static List&lt;String&gt; weekToDayFormate(int year, int week) &#123; Calendar calendar = Calendar.getInstance(); // ①.设置该年份的开始日期：第一个月的第一天 calendar.set(year, 0, 1); List&lt;String&gt; dateList = new ArrayList&lt;&gt;(); // ②.计算出第一周还剩几天：+1是因为1号是1天 int dayOfWeek = 7 - calendar.get(Calendar.DAY_OF_WEEK) + 1; // ③.周数减去第一周再减去要得到的周 week = week - 2; // ④.计算起止日期 calendar.add(Calendar.DAY_OF_YEAR, week * 7 + dayOfWeek); calendar.add(Calendar.DAY_OF_YEAR, 1); TimeZone timeZone = TimeZone.getTimeZone(&quot;GMT+8&quot;); calendar.setTimeZone(timeZone); dateList.add(new SimpleDateFormat(&quot;yyyy-MM-dd 00:00:00&quot;).format(calendar.getTime())); calendar.add(Calendar.DAY_OF_YEAR, 6);// calendar.set(Calendar.HOUR_OF_DAY, 23); //时// calendar.set(Calendar.MINUTE, 59); //分// calendar.set(Calendar.SECOND, 59); //秒// calendar.set(Calendar.MILLISECOND, 0); //毫秒 dateList.add(new SimpleDateFormat(&quot;yyyy-MM-dd 23:59:59&quot;).format(calendar.getTime())); return dateList; &#125; /** * @param endDate 截止日期 * @param startTime 开始日期 * @Description: 计算2个日期差 * @return: java.lang.String * @Author: xl * @Date: 2024/8/8/0008 18:20 */ public static String timeDistance(Date endDate, Date startTime) &#123; long nd = 1000 * 24 * 60 * 60; long nh = 1000 * 60 * 60; long nm = 1000 * 60; // long ns = 1000; // 获得两个时间的毫秒时间差异 long diff = endDate.getTime() - startTime.getTime(); // 计算差多少天 long day = diff / nd; // 计算差多少小时 long hour = diff % nd / nh; // 计算差多少分钟 long min = diff % nd % nh / nm; // 计算差多少秒//输出结果 // long sec = diff % nd % nh % nm / ns; return (day &gt; 0L ? day + &quot;天&quot; : &quot;&quot;) + (hour &gt; 0L ? hour + &quot;小时&quot; : &quot;&quot;) + min + &quot;分钟&quot;; &#125; /** * @param dateString 字符串日期 * @Description: 字符串日期转yyyy年MM月dd日格式的字符串日期 * @return: java.lang.String * @Author: xl * @Date: 2024/8/8/0008 18:21 */ public static String stringDateToString(String dateString) &#123; SimpleDateFormat originalFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); SimpleDateFormat targetFormat = new SimpleDateFormat(&quot;yyyy年MM月dd日&quot;); String formattedDate = dateString; try &#123; Date date = originalFormat.parse(dateString); formattedDate = targetFormat.format(date); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return formattedDate; &#125; /** * @param dateString 字符串日期 * @Description: 字符串日期转时间戳 * @return: java.lang.Long * @Author: xl * @Date: 2024/8/8/0008 18:22 */ public static Long stringDateToTimestamp(String dateString) &#123; long timestamp = -999l; try &#123; SimpleDateFormat formatter = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); Date date = formatter.parse(dateString); timestamp = date.getTime(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return timestamp; &#125;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"节点框架","path":"/2024/08/15/20240815/","content":"节点框架cloudflare 参考","tags":["笔记"],"categories":["其他"]},{"title":"java 8 流(Stream)操作两个集合求并集，交集，补集","path":"/2024/08/14/20240814/","content":"一、基础的数据类型 如 String两个集合123456789101112List&lt;String&gt; A = new ArrayList&lt;&gt;();A.add(&quot;1&quot;);A.add(&quot;2&quot;);A.add(&quot;3&quot;);A.add(&quot;4&quot;);List&lt;String&gt; B = new ArrayList&lt;&gt;();B.add(&quot;3&quot;);B.add(&quot;4&quot;);B.add(&quot;5&quot;);B.add(&quot;6&quot;);B.add(&quot;7&quot;); 1. 求并集1234A.addAll(B);List&lt;String&gt; AuB = A.stream().distinct().collect(Collectors.toList());System.out.println(&quot;并集：&quot; + AuB); 输出结果： 并集：[1, 2, 3, 4, 5, 6, 7] 2. 求交集123List&lt;String&gt; AnB = A.stream().filter(B::contains).collect(Collectors.toList());System.out.println(&quot;交集：&quot; + AnB); 注：B::contains = s -&gt; B.contains(s) 高版本IDEA会提示转换输出结果 交集：[3, 4] 3. 求差集123List&lt;String&gt; difference = A.stream().filter(s -&gt; !B.contains(s)).collect(Collectors.toList());System.out.println(&quot;A中B的补集：&quot; + difference); 注：差集：A - B；学名就叫做 A中B的补集输出结果 A 中 B 的补集：[1, 2] 二、自定义的类型（以单条属性为标准）求交集并集是以 username 为标准 12345678910import lombok.AllArgsConstructor;import lombok.Data;@Data@AllArgsConstructorpublic class UserInfo &#123; private String username; private Integer age;&#125; 两个集合12345678List&lt;UserInfo&gt; A = new ArrayList&lt;&gt;();A.add(new UserInfo(&quot;赵&quot;, 1));A.add(new UserInfo(&quot;杜&quot;, 2));List&lt;UserInfo&gt; B = new ArrayList&lt;&gt;();B.add(new UserInfo(&quot;杜&quot;, 2));B.add(new UserInfo(&quot;周&quot;, 3)); 1. 求并集12345678910111213// 求并集A.addAll(B);// 获取两集合相加并根据username去重后的集合，并按照number进行排序List&lt;UserInfo&gt; AuB = A.stream().collect(Collectors.collectingAndThen( Collectors.toCollection( () -&gt; new TreeSet&lt;&gt;( Comparator.comparing(UserInfo::getUsername) ) ), ArrayList::new)).stream().sorted(Comparator.comparing(UserInfo::getNumber)).collect(Collectors.toList());System.out.println(&quot;并集：&quot;);AuB.forEach(System.out::println); 输出结果： 并集：UserInfo(username = 赵, number=1)UserInfo(username = 杜, number=2)UserInfo(username = 周, number=3) 2. 求交集1234567// 求交集List&lt;UserInfo&gt; AnB = A.stream().filter(userInfo -&gt; B.stream().map(UserInfo::getUsername).collect(Collectors.toList()).contains(userInfo.getUsername())).collect(Collectors.toList());System.out.println(&quot;交集：&quot;);AnB.forEach(System.out::println); 输出结果 交集：UserInfo(username = 杜, number=2) 3. 求差集1234567// 求差集List&lt;UserInfo&gt; difference = A.stream().filter(userInfo -&gt; !B.stream().map(UserInfo::getUsername).collect(Collectors.toList()).contains(userInfo.getUsername())).collect(Collectors.toList());System.out.println(&quot;A中B的补集：&quot;);difference.forEach(System.out::println); 注：差集：A - B；学名就叫做 A中B的补集输出结果 A 中 B 的补集：UserInfo(username = 赵, number=1) 二、自定义的类型（以多条属性为标准）求差集123456789101112// 大集合List&lt;PmRuleConfigParams&gt; prpallParams = new ArrayList&lt;&gt;();// 小集合List&lt;PmRuleConfigParams&gt; pmParams = new ArrayList&lt;&gt;();// 求差集List&lt;PmRuleConfigParams&gt; dif = prpallParams.stream.filter( //把集合转成以ruleCode-paramCode为key的map ruleParams -&gt; !pmParams.stream().collect(Collectors.toMap(params -&gt; params.getRuleCode() + &quot;-&quot; + params.getParamCode(), value -&gt; value)) //判断该key是否存在 .containsKey(ruleParams.getRuleCode() + &quot;-&quot; + ruleParams.getParamCode())).collect(Collectors.toList()) 单属性的原理是把一个集合转化成一个完全由该属性组成的 List，从而判断该属性是否存在，多条属性则是转成一个 map，标准属性作为 key，判断 key 存不存在","tags":["笔记"],"categories":["Java"]},{"title":"Java折叠代码块","path":"/2024/08/06/20240806/","content":"折叠代码块C#中用 #region和#endregion java中用 //region和//endregion ，还可以加标题，即 //region xxx","tags":["笔记"],"categories":["Java"]},{"title":"Linux 常用命令","path":"/2024/08/05/20240805/","content":"1、cd - 切换当前目录这是一个最基本，也是最常用的命令，它用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径。 12345cd /root # 切换到目录/rootcd ./path # 切换到当前目录下的path目录中，“.”表示当前目录 cd ../path # 切换到上层目录中的path目录中，“..”表示上一层目录 2、ls - 查看文件与目录这也是一个非常有用的查看文件与目录的命令，它的参数非常多，下面就列出一些常用的参数： -l ：列出长数据串，包含文件的属性与权限数据等 -a ：列出全部的文件，连同隐藏文件（开头为. 的文件）一起列出来（常用） -d ：仅列出目录本身，而不是列出目录的文件数据 -h ：将文件容量以较易读的方式（GB，kB 等）列出来 -R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来 注：这些参数也可以组合使用 12345678ls -l # 以长数据串的形式列出当前目录下的数据文件和目录 ls -al # 以长数据串的形式列出当前目录下的数据文件和目录及隐藏文件(常用)ls -lR # 以长数据串的形式列出当前目录下的所有文件 ls -aR # 列出当前目录所有文件，包括子目录ls -al --block-size=m # 查看文件大小，其中k,m,g表示单位 相关命令： 如果想展示树形结构，可使用 tree 命令 12345678910111213# 使用yum install tree命令先安装treetree # 树形展示当前目录下所有子文件和目录，该命令不显示中文tree -N # 中文展示tree -N -L 2 # 遍历两级菜单tree /home --charset=gbk -L 2 # 设定中文编码# -a显示所有文件，-C文件与目录清单加上颜色，-L 2遍历两级菜单tree -aC -L 2 -I 命令允许你使用正则匹配来排除掉你不想看到的文件夹。 1234567tree -I &quot;node_modules&quot;# 也可以使用`|`同时排除掉多个文件夹# 最后一个使用到正则匹配，这样以`test_`开头的文件夹都不会被显示出来。tree -I &quot;node_modules|cache|test_*&quot; 3、grep - 分析一行内容过滤筛选分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工等，下面就列出一些常用的参数： -a ：将 binary 文件以 text 文件的方式查找数据 -c ：计算找到‘查找字符串’的次数 -i ：忽略大小写的区别，即把大小写视为相同 -v ：反向选择，即显示出没有‘查找字符串’内容的那一行 1234567891011# 把ls -l的输出中包含字母file（不区分大小写）的内容输出 ls -l | grep -i file # 取出文件/etc/passwd中包含root的行，并把找到的关键字加上颜色 grep --color=auto &#x27;root&#x27; /etc/passwd# 当我们需要过滤多个文件时，也很管用# 查看以smart开头的目录下面以smart开头的properties配置文件是否包含kafkagrep --color=auto &#x27;kafka&#x27; smart*/smart*.properties 4、cat - 查看文本文件的内容该命令用于查看文本文件的内容，后接要查看的文件名，通常可用管道与 more 和 less 一起使用，从而可以一页页地查看数据，下面就列出一些常用的参数： -n ：由 1 开始对所有输出的行数编号。 -b ：和 -n 相似，只不过对于空白行不编号。 123456789101112131415161718192021222324252627282930313233343536cat text | less # 查看text文件中的内容,这条命令也可以使用less text来代替 cat /etc/redhat-release # 查看操作系统版本号cat /proc/version # 查看操作系统版本cat /etc/os-release # 查看操作系统版本号cat /etc/*release* # 查看操作系统版本号,这个命令比较好使# 总核数 = 物理CPU个数 X 每颗物理CPU的核数 # 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数cat /proc/cpuinfo # 查看CPU信息# 查看物理CPU个数cat /proc/cpuinfo | grep &quot;physical id&quot;| sort| uniq| wc -l# 查看每个物理CPU中core的个数(即核数)cat /proc/cpuinfo | grep &quot;cpu cores&quot;| uniq# 查看逻辑CPU的个数cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l# 查看CPU信息（型号）cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -ccat /proc/meminfo # 查看内存信息# 查看所有用户帐号的信息，包括用户名和密码# passwd文件由许多条记录组成，每条记录占一行，记录了一个用户帐号的所有信息。# 每条记录由7个字段组成，字段间用冒号“:”隔开，其格式如下：# username:password:User ID:Group ID:comment:home directory:shellcat /etc/passwd cat /etc/resolv.conf # 查看DNS# 过滤有error的行，并输出行号cat -n app.log | grep &#x27;error&#x27;# 清空 /etc/test.txt 文档内容cat /dev/null &gt; /etc/test.txt 5、tail/tailf - 从尾部查看文本文件的内容用于从文件尾部查看文件的内容，有一个常用的参数 -f 常用于查阅正在改变的日志文件。tail -f filename 会把 filename 文件里的最尾部的内容显示在屏幕上，并且不断刷新，只要 filename 更新就可以看到最新的文件内容。 常用参数如下： -f：循环读取 -c &lt;数目&gt;：显示的字节数 -n &lt;行数&gt;：显示文件的尾部 n 行内容 12345678910111213# 查看文件的后10行tail -10 /etc/passwd 或 tail -n 10 /etc/passwd # 不停地去读/var/log/messages文件最新的内容，这样有实时监视的效果，用Ctrl＋c来终止！tail -f /var/log/messages # 显示文件 notes.log 的内容，从第 20 行至文件末尾:tail +20 notes.log# 显示文件 notes.log 的最后 10 个字符:tail -c 10 notes.log tailf 等同于 tail -f -n 10，与 tail -f 不同的是，如果文件不增长，它不会去访问磁盘文件，所以 tailf 特别适合那些便携机上跟踪日志文件，因为它减少了磁盘访问，可以省电。 6、find - 查找文件一个查找文件的命令，相对而言，它的使用也相对较为复杂，参数也比较多，所以在这里将给把它们分类列出。 1234567891011121314151617181920212223242526272829303132333435363738# 命令格式find [PATH] [option] [action] # 与时间有关的参数： -mtime n : n为数字，意思为在n天之前的“一天内”被更改过的文件-mtime +n : 列出在n天之前（不含n天本身）被更改过的文件名-mtime -n : 列出在n天之内（含n天本身）被更改过的文件名-newer file : 列出比file还要新的文件名# 例如： find /root -mtime 0 # 在当前root目录下查找今天之内有改动的文件 find /root -newer xxx # 在当前root目录下查找比file还要新的文件名# 与用户或用户组名有关的参数： -user name : 列出文件所有者为name的文件 -group name : 列出文件所属用户组为name的文件 -uid n : 列出文件所有者为用户ID为n的文件 -gid n : 列出文件所属用户组为用户组ID为n的文件# 例如： find /home/liguodong -user liguodong # 在目录/home/liguodong 中找出所有者为liguodong的文件 # 与文件权限及名称有关的参数： -name filename ：找出文件名为filename的文件 -size [+-]SIZE ：找出比SIZE还要大（+）或小（-）的文件 -tpye TYPE ：查找文件的类型为TYPE的文件，TYPE的值主要有：一般文件（f)、设备文件（b、c）、 目录（d）、连接文件（l）、socket（s）、FIFO管道文件（p）； -perm mode ：查找文件权限刚好等于mode的文件，mode用数字表示，如0755； -perm -mode ：查找文件权限必须要全部包括mode权限的文件，mode用数字表示 -perm +mode ：查找文件权限包含任一mode的权限的文件，mode用数字表示 # 例如： find / -name passwd # 查找文件名为passwd的文件 find . -perm 0755 # 查找当前目录中文件权限的0755的文件, 第一个0，表示十进制 find . -size +1k # 查找当前目录中大于1KB的文件，注意c表示byte find . -size +1024c # 查找当前目录中大于1KB的文件 7、locate - 查找文件用于查找符合条件的文档，他会去保存文档和目录名称的数据库内，查找合乎范本样式条件的文档或目录。当我们不知道某个文件放哪里了，能够通过他快速定位到文件目录，这是一条非常有用的命令。 1234567# 查找eureka-server-xxx.jar文件的位置locate &#x27;eureka-server-xxx.jar&#x27;# 查询包含passwd的目录或文档locate passwd locate 与 find 的不同: find 是去硬盘找，locate 只在 / var/lib/slocate 资料库中找。locate 的速度比 find 快，它并不是真的查找，而是查数据库，一般文件数据库在 / var/lib/slocate/slocate.db 中，所以 locate 的查找并不是实时的，而是以数据库的更新为准，一般是系统自己维护，也可以手工升级数据库 ，命令为： 123locate -u 8、cp - 复制文件该命令用于复制文件，它还可以把多个文件一次性地复制到一个目录下，它的常用参数如下： -a ：将文件的特性一起复制 -p ：连同文件的属性一起复制，而非使用默认方式，与 - a 相似，常用于备份 -i ：若目标文件已经存在时，在覆盖时会先询问操作的进行 -r ：递归持续复制，用于目录的复制行为 -u ：目标文件与源文件有差异时才会复制 1234cp -a file1 file2 # 连同文件的所有特性把文件file1复制成文件file2 cp file1 file2 file3 dir #把文件file1、file2、file3复制到目录dir中 9、scp - 远程复制文件该命令用于Linux之间复制文件和目录。 scp 是 linux 系统下基于 ssh 登陆进行安全的远程文件拷贝命令。scp 是加密的。 123456789# 命令格式scp [可选参数] file_source file_targetscp local_file remote_username@remote_ip:remote_folder scp local_file remote_username@remote_ip:remote_file scp local_file remote_ip:remote_folder scp local_file remote_ip:remote_file 下面就列出一些常用的参数： -p：保留原文件的修改时间，访问时间和访问权限。 -q： 不显示传输进度条。 -r： 递归复制整个目录。 -v：详细方式显示输出。 12345678910111213# 从本地服务器复制到远程服务器# 复制文件scp /home/space/music/1.mp3 root@www.runoob.com:/home/root/others/music # 复制文件夹scp -r /home/space/music/ root@www.runoob.com:/home/root/others/ # 从远程服务器复制到本地服务器# 复制文件scp root@www.runoob.com:/home/root/others/music /home/space/music/1.mp3 # 复制文件夹scp -r www.runoob.com:/home/root/others/ /home/space/music/ 10、vim - 编辑文件该命令主要用于文本编辑，它接一个文件名作为参数，如果文件存在就打开，如果文件不存在就以该文件名创建一个文件。vim 是一个非常好用的文本编辑器，它里面有很多非常好用的命令，在这里不再多说。 123vim demo.txt # 编辑demo.txt文件 11、mv - 移动目录文件该命令用于移动文件、目录或更名，move 之意，它的常用参数如下： -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 -i ：若目标文件已经存在，就会询问是否覆盖 -u ：若目标文件已经存在，且比目标文件新，才会更新 注： 该命令可以把一个文件或多个文件一次移动一个文件夹中，但是最后一个目标文件一定要是 “目录”。 123456mv file1 file2 file3 dir # 把文件file1、file2、file3移动到目录dir中 mv file1 file2 # 把文件file1重命名为file2mv xxdir/ tempdir # 把目录xxdir下的所有文件和目录移动到temp目录下,包含xxdir目录mv xxdir/* tempdir # 把目录xxdir下的所有文件和目录移动到temp目录下,不包含xxdir目录 12、rm - 删除目录文件该命令用于删除文件或目录，remove 之意，它的常用参数如下： -f ：就是 force 的意思，忽略不存在的文件，不会出现警告消息 -i ：互动模式，在删除前会询问用户是否操作 -r ：递归删除，最常用于目录删除，它是一个非常危险的参数 1234rm -i file # 删除文件file，在删除之前会询问是否进行该操作 rm -rf dir # 强制删除目录dir中的所有文件 ** 避免 rm -rf *** 1234cd $&#123;log_path&#125;rm -rf * 上面的命名，先进入到日志目录，然后把日志都删除。看上去没有任何问题。但是，当目录不存在时，悲剧就发生了。 ps：偷偷告诉你一个小故事，我之前就犯过这种错误，不过好在是自己学习虚拟机上面。如果实现线上生产环境，就不是故事了，而是事故了。 上诉问题有四种方法进行规避： 第一、命令替换，在生产环境把 rm -rf 命令替换为 mv，再写个定时 shell 定期清理。模拟了回收站的功能。 第二、收拢权限，帐号权限的分离，线上分配 work 帐号，只能够删除 / home/work/logs / 目录，无法删除根目录。大公司一般线上权限管理比较规范，小公司就未必了，搞不好所有的小伙伴都有权限在线上乱搞。 第三、使用 &amp;&amp; ，可以通过 “&amp;&amp;”，将 1234cd $&#123;log_path&#125;rm -rf * 合并成一个语句 123cd $&#123;log_path&#125; &amp;&amp; rm -rf * 当前半句执行失败的时候，后半句不再执行。 第四、判断目录是否存在，制定编码规范，对目录进行操作之前，要先判断目录是否存在。靠人的自觉来保证规范的执行，总感觉有些不太靠谱。当然，规范是有必要的。 13、ln - 连接这是一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接。当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在其它的目录下用 ln 命令链接它就可以，不必重复的占用磁盘空间。 而链接又可分为两种 : 硬链接 (hard link) 与软链接(symbolic link)，硬链接的意思是一个档案可以有多个名称，而软链接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。硬链接是存在同一个文件系统中，而软链接却可以跨越不同的文件系统。不论是硬链接或软链接都不会将原本的档案复制一份，只会占用非常少量的磁碟空间。 它的常用参数如下： -f : 链接时先将与 dist 同档名的档案删除 -i : 在删除与 dist 同档名的档案时先进行询问 -n : 在进行软链接时，将 dist 视为一般的档案 -s : 进行软链接 (symbolic link) -v : 在连结之前显示其档名 -b : 将在链接时会被覆写或删除的档案进行备份 1234567891011121314151617# 创建软链接在/usr/bin/目录下freeswitch文件，# 如果 /usr/local/freeswitch/bin/freeswitch丢失，/usr/bin/freeswitch将失效ln -sf /usr/local/freeswitch/bin/freeswitch /usr/bin/# 删除软链接,和删除普通的文件是一眼的，删除都是使用rm来进行操作rm -rf 软链接名称# 下面我们来创建test_chk目录的软链接ln -s test_chk test_chk_ln#软链接创建好了，我们来看看怎么删除它# 正确的删除方式（删除软链接，但不删除实际数据）rm -rf ./test_chk_ln# 错误的删除方式rm -rf ./test_chk_ln/ (这样就会把原来test_chk下的内容删除) 软链接与硬链接的区别： 软链接： 软链接，以路径的形式存在。类似于 Windows 操作系统中的快捷方式 软链接可以 跨文件系统 ，硬链接不可以 软链接可以对一个不存在的文件名进行链接 软链接可以对目录进行链接 硬链接： 硬链接，以文件副本的形式存在。但不占用实际空间。 不允许给目录创建硬链接 硬链接只有在同一个文件系统中才能创建 14、chmod - 修改文件权限chmod 用于管理文件或目录的权限，文件或目录权限的控制分别以读取 ®、写入 (w)、执行 (x)3 种，一般的用法如下： 123chmod [-R] abc 文件或目录 参数说明如下： -R：进行递归的持续更改，即连同子目录下的所有文件都会更改 abc : a,b,c 各为一个数字，分别表示 User、Group、及 Other 的权限。 该命令有两种用法。一种是包含字母和操作符表达式的文字设定法； u 表示该文件的拥有者，g 表示与该文件的拥有者属于同一个群体 (group) 者，o 表示其他以外的人，a 表示这三者皆是。 表示增加权限、- 表示取消权限、= 表示唯一设定权限。 r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该文件是个子目录或者该文件已经被设定过为可执行。 另一种是包含数字的数字设定法。其中 4 表示读，2 表示写，1 表示可执行，因此 7 表示读写可执行，5 表示读可执行 12345678910chmod g+w file # 向file的文件权限中加入用户组可写权限 # 文件 file1.txt 设为所有人皆可读取 :chmod ugo+r file1.txt chmod 755 file # 把file的文件权限改变为-rxwr-xr-x chmod a=rwx file 等价于 chmod 777 filechmod ug=rwx,o=x file 等价于 chmod 771 file 15、chgrp - 修改文件所属用户组该命令用于改变文件所属用户组，它的使用非常简单，它的基本用法如下： 123chgrp [-R] dirname/filename 参数说明如下： -R ：进行递归的持续对所有文件和子目录更改 1234# 递归地把dir目录下中的所有文件和子目录下所有文件的用户组修改为users chgrp users -R ./dir 16、chown - 修改文件所属用户、用户组该命令用于改变文件的所有者，与 chgrp 命令的使用方法相同，只是修改的文件属性不同 123456# 将文件 file1.txt 的拥有者设为 runoob，用户组组 runoobgroup :chown runoob:runoobgroup file1.txt# 将目前目录下的所有文件与子目录的拥有者皆设为 runoob，群体的使用者 runoobgroup:chown -R runoob:runoobgroup * 17、sz/rz - 文件上传下载这是 Linux/Unix 同 Windows 进行 ZModem 文件传输的命令行工具。windows 端需要支持 ZModem 的 telnet/ssh 客户端（比如 SecureCRT、XShell） sz：将选定的文件发送到本地机器 rz：运行该命令会弹出一个文件选择窗口，从本地选择文件上传到 Linux 服务器 1234567891011121314# 安装yum install lrzsz# 从本地上传文件到服务器：rz# 从服务器下载一个文件到本地： sz filename # 从服务器下载多个文件到本地： sz filename1 filename2### 下载dir目录下的所有文件，不包含dir下的文件夹： # sz dir/* 18、yum - 包安装卸载Linux 包管理器 ，解决依赖问题，方便快捷 1234567yum install &lt;package_name&gt; -y # 安装包yum search &lt;package_name&gt; # 搜索包名yum search all # 查询所有yum remove &lt;package_name&gt; -y # 删除包(不建议用，yum可以解决依赖问题，删除会删除所有包依赖)yum update # 安装所有软件到最新版本 19、curl - 与服务器之间传输数据curl 是一个非常实用的、用来与服务器之间传输数据的工具；支持的协议包括 (DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMTP, SMTPS, TELNET and TFTP)，curl 设计为无用户交互下完成工作；curl 提供了一大堆非常有用的功能，包括代理访问、用户认证、ftp 上传下载、HTTP POST、SSL 连接、cookie 支持、断点续传等。 12345678910111213141516171819202122# 下载页面curl -o index.html http://aiezu.com# 下载并显示进度条curl -# -o centos6.8.iso http://mirrors.aliyun.com/centos/6.8/isos/x86_64/CentOS.iso# 继续完成上次终止的未完成的下载curl -# -o centos6.8.iso -C - http://mirrors.aliyun.com/centos/6.8/isos/x86_64/CentOS.iso# 访问一个网页curl https://www.baidu.com# http请求，带上用户名和密码curl -u xxx:xxx http://10.250.xxx.xxx:5400/xxx/health# http post请求curl http://xxx.xxx.xxx/shorturl -X POST -d &#x27;&#123;&quot;originalUrl&quot;:&quot;xxx&quot;,&quot;expire&quot;:7776000,&quot;app&quot;:&quot;xxx&quot;&#125;&#x27; --header &quot;Content-Type: application/json&quot; 20、wget - 文件下载一个下载文件的工具，，我们经常要下载一些软件或从远程服务器恢复备份到本地服务器。wget 支持 HTTP，HTTPS 和 FTP 协议，可以使用 HTTP 代理。 12345678910111213# 使用wget下载单个文件wget http://www.linuxde.net/testfile.zip# 下载并以不同的文件名保存wget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080# 使用wget断点续传wget -c http://www.linuxde.net/testfile.zip# wget限速下载wget --limit-rate=300k http://www.linuxde.net/testfile.zip 21、ps - 查看进程运行情况该命令用于将某个时间点的进程运行情况选取下来并输出，它的常用参数如下： -a ： 显示除控制进程与无端进程外的所有进程 -d ：显示除控制进程外的所有进程 -e ：显示所有进程 -g ：显示会话或组 ID 在 grplist 列表中的进程 -p ：显示 PID 在 pidlist 列表中的进程 -s ：显示会话 ID 在 sesslist 列表中的进程 -t ：显示终端 ID 在 ttylist 列表中的进程 -u ：显示有效用户 ID 在 userlist 列表中的进程 -x ：以用户为中心组织进程状态信息显示 -M ：显示进程的安全信息 -f ：显示完整格式的输出 -j ：显示任务信息 -l ：显示长列表 -o ：仅显示由 format 指定的列 -y ：不要显示进程标记 -L ：显示进程中的线程 其实我们只要记住 ps 一般使用的命令参数搭配即可，它们并不多，如下： 12345678ps aux # 查看系统所有的进程数据 ps ax # 查看不与终端（terminal）有关的所有进程 ps -lA # 查看系统所有的进程数据 ps axjf # 查看连同一部分进程树状态 ps –ef # 显示所有信息，连同命令行 ps -ef | grep xxx # 过滤池包含xxx的行 22、top - 查看系统的整体运行情况实时动态地查看系统的整体运行情况，是一个综合了多方信息监测系统性能和运行信息的实用工具。通过 top 命令所提供的互动式界面，用热键可以管理。它的常用参数如下： -b：以批处理模式操作； -c：显示完整的命令； -i &lt;时间&gt;：设置间隔时间； -u &lt;用户名&gt;：指定用户名； -p &lt;进程号&gt;：指定进程； -n &lt;次数&gt;：循环显示的次数。 top 交互命令如下： h：显示帮助画面，给出一些简短的命令总结说明； k：终止一个进程； i：忽略闲置和僵死进程，这是一个开关式命令； q：退出程序； r：重新安排一个进程的优先级别； S：切换到累计模式； s：改变两次刷新之间的延迟时间（单位为 s），如果有小数，就换算成 ms。输入 0 值则系统将不断刷新，默认值是 5s； f 或者 F：从当前显示中添加或者删除项目； o 或者 O：改变显示项目的顺序； l：切换显示平均负载和启动时间信息； m：切换显示内存信息； t：切换显示进程和 CPU 状态信息； c：切换显示命令名称和完整命令行； M：根据驻留内存大小进行排序； P：根据 CPU 使用百分比大小进行排序； T：根据时间 / 累计时间进行排序；w：将当前设置写入~/.toprc 文件中。 12345top # 显示系统中进程的资源占用状况top -c # 显示系统中进程的资源占用状况，并显示完整的命令top -u xxx # 查看xxx用户的进程的资源占用状况 相关命令：iotop、htop 23、kill - 根据进程 ID 杀死进程该命令用于向某个工作（%jobnumber）或者是某个 PID（数字）传送一个信号，它通常与 ps 和 jobs 命令一起使用，它的基本语法如下： 123kill -signal PID signal 的常用参数如下： 1：SIGHUP，启动被终止的进程 2：SIGINT，相当于输入 ctrl+c，中断一个程序的进行 9：SIGKILL，强制中断一个进程的进行 15：SIGTERM，以正常的结束进程方式来终止进程 17：SIGSTOP，相当于输入 ctrl+z，暂停一个进程的进行 注： 最前面的数字为信号的代号，使用时可以用代号代替相应的信号。 12345678# 以正常的结束进程方式来终于第一个后台工作，可用jobs命令查看后台中的第一个工作进程 kill -SIGTERM %1 # 重新改动进程ID为PID的进程，PID可用ps命令通过管道命令加上grep命令进行筛选获得 kill -SIGHUP PID# 强制杀死进程号为1112的进程kill -9 1112 kill -15 PID 和 kill -9 PID 的区别 kill -9 PID 是操作系统从内核级别强制杀死一个进程。 kill -15 PID 可以理解为操作系统发送一个通知告诉应用主动关闭。效果是正常退出进程，退出前可以被阻塞或回调处理。并且它是 Linux 缺省的程序中断信号。 尽量使用 kill -15 PID 而不要使用 kill -9 PID。 kill -9 PID 没有给进程留下善后的机会： 关闭 socket 链接 清理临时文件 将自己将要被销毁的消息通知给子进程 重置自己的终止状态 一些磁盘操作多的程序更是不要使用 kill -9 PID，会导致数据的丢失，如 ES，kafka 等。 批量杀死进程 (ps/grep/awk/kill)123ps aux|grep server|grep -v grep | awk &#x27;&#123;print $2&#125;&#x27;|xargs kill -9 说明： 管道符”|” 用来隔开两个命令，管道符左边命令的输出会作为管道符右边命令的输入。 awk 的作用是输出某一列，{print $2} 就是输出第二列，如上即是 pid 这一列。 “xargs kill -9” 中的 xargs 命令是用来把前面命令的输出结果作为”kill -9″命令的参数，并执行该命令。”kill -9″会强行杀掉指定进程。 24、killall - 杀死指定名字的进程用于杀死指定名字的进程，向一个命令启动的进程发送一个信号，它的一般语法如下： 123killall [-iIe] [command name] 它的参数如下： -i ：交互式的意思，若需要删除时，会询问用户 -e ：表示后面接的 command name 要一致，但 command name 不能超过 15 个字符 -I ：命令名称忽略大小写 123killall -SIGHUP syslogd # 重新启动syslogd 25、file - 辨识文件类型该命令用于辨识文件类型，因为在 Linux 下文件的类型并不是以后缀为分的，所以这个命令对我们来说就很有用了，它的用法非常简单，基本语法如下： 123file filename 查看 test 文件格式： 123file ./test 26、tar - 对文件压缩解压缩该命令用于对文件进行打包，默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序（如 gzip 和 bzip 等）进行压缩和解压。它的常用参数如下： -c ：新建打包文件 -t ：查看打包文件的内容含有哪些文件名 -x ：解打包或解压缩的功能，可以搭配 - C（大写）指定解压的目录 -j ：通过 bzip2 的支持进行压缩 / 解压缩 -z ：通过 gzip 的支持进行压缩 / 解压缩 -v ：在压缩 / 解压缩过程中，将正在处理的文件名显示出来 -f filename ：filename 为要处理的文件 -C dir ：指定压缩 / 解压缩的目录 dir 注意：-c,-t,-x 不能同时出现在同一条命令中 通常我们只需要记住下面几条命令即可： 123456789101112# 压缩tar -jcv -f filename.tar.bz2 要被处理的文件或目录名称 # 查询tar -jtv -f filename.tar.bz2 # 解压tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录 # 注：上面文件名并不定要以后缀tar.bz2结尾，这里主要是为了说明使用的压缩程序为bzip2# 解压elasticsearch-5.5.2.tar.gztar -zxvf elasticsearch-5.5.2.tar.gz 27、zip/unzip/gzip/gunzip - 对文件压缩解压缩用于压缩、解压缩文件，zip 压缩的后文件是 *.zip ，而 gzip 压缩后的文件 *.gz，相应的解压缩命令则是 gunzip 和 unzip。 1234567891011121314151617181920212223242526272829303132# 将 /home/html/ 这个目录下所有文件和文件夹打包为当前目录下的 html.zip：zip -q -r html.zip /home/htmlzip -r MiniGPT-4.zip ./MiniGPT-4/# 如果在我们在 /home/html 目录下，可以执行以下命令：zip -q -r html.zip *# 从压缩文件 cp.zip 中删除文件 a.czip -dv cp.zip a.c# 将当前目录下的所有文件和文件夹全部压缩成myfile.zip文件,-r表示递归压缩子目录下所有文件zip -r myfile.zip ./*# 把myfile.zip文件解压到 /home/bunny/# -o:不提示的情况下覆盖文件# -d:-d /home/bunny 指明将文件解压缩到/home/bunny目录下unzip -o -d /home/bunny myfile.zip# 它会将文件压缩为文件 test.txt.gz，原来的文件则没有了，解压缩也一样 gzip test.txt # 它会将文件解压缩为文件 test.txt，原来的文件则没有了，为了保留原有的文件，# 我们可以加上 -c 选项并利用 linux 的重定向 gunzip test.txt.gz # 这样不但可以将原有的文件保留，而且可以将压缩包放到任何目录中，解压缩也一样 gzip -c test.txt &gt; /root/test.gz# 解压缩gunzip -c /root/test.gz &gt; ./test.txt 28、adduser/useradd/userdel - 增加删除用户adduser/useradd 为创建用户命令，使用权限：系统管理员，root 用户。常用参数说明如下： -c comment：加上备注文字。备注文字会保存在通常是 /etc/passwd）的备注栏位中。 -d home_dir：设定使用者的根目录为 home_dir ，预设值为预设的 home 后面加上使用者帐号 -e expire_date：设定此帐号的使用期限（格式为 YYYY-MM-DD），预设值为永久有效 -f inactive_time：帐号过期几日后永久停权。当值为 0 时帐号则立刻被停权。而当值为 - 1 时则关闭此功能，预设值为 - 1 -g &lt;群组&gt;：指定用户所属的群组。 -r ：建立一个系统的帐号，这个帐号的 UID 会有限制 (/etc/login.defs) 1234567891011121314# 添加一个一般用户useradd kk # 添加用户kk# 为添加的用户指定相应的用户组useradd -g root kk # 添加用户kk，并指定用户所在的组为root用户组# 创建一个系统用户useradd -r kk # 创建一个系统用户kk# 为新添加的用户指定/home目录useradd -d /home/myf kk //新添加用户kk，其home目录为/home/myf# 当用户名kk登录主机时，系统进入的默认目录为/home/myf 用户删除命令：userdel，语法如下: 123userdel [login ID] 删除用户 kk: 123userdel kk 29、passwd - 修改用户密码更改使用者的密码，常用参数如下： -d：删除密码 -l：停止账号使用 -S：显示密码信息 -u：启用已被停止的账户 -x：设置密码的有效期 -g：修改群组密码 -i：过期后停止用户账号 12345678910# 修改用户密码passwd runoob # 设置runoob用户的密码# 显示账号密码信息passwd -S runoob# 删除用户密码passwd -d lx138 30、time - 测算一个命令的执行时间该命令用于测算一个命令的执行时间。就像平时输入命令一样，不过在命令的前面加入一个 time 即可。 在程序或命令运行结束后，在最后输出了三个时间，它们分别是： user：用户 CPU 时间，命令执行完成花费的用户 CPU 时间，即命令在用户态中执行时间总和； system：系统 CPU 时间，命令执行完成花费的系统 CPU 时间，即命令在核心态中执行时间总和； real：实际时间，从 command 命令行开始执行到运行终止的消逝时间； 1234time ./process.sh # 查看process.sh脚本执行时间time ps aux # 查看ps aux命令的执行时间 31、free - 显示内存的使用情况显示内存的使用情况，包括实体内存，虚拟的交换文件内存，共享内存区段，以及系统核心使用的缓冲区等。 参数说明： -b：以 Byte 为单位显示内存使用情况。 -k：以 KB 为单位显示内存使用情况。 -m ：以 MB 为单位显示内存使用情况。 -g ：以 GB 为单位显示内存使用情况。 -o ：不显示缓冲区调节列。 -s &lt;间隔秒数&gt;：持续观察内存使用状况。 -t：显示内存总和列。 12345678910# 显示内存使用情况free # 显示内存使用信息# 以总和的形式显示内存的使用信息free -gt # 以总和的形式查询内存的使用信息,以GB为单位# 周期性的查询内存使用信息free -g -s 10 # 每10s执行一次命令,以GB为单位 32、crontab - 定时任务用来定时的去跑一些脚本或者程序，linux 内置的 cron 进程能帮我们实现这些需求，精确到分，设计秒的我们一般自己写脚本。 相关配置文件说明： /var/spool/cron / 目录下存放的是每个用户包括 root 的 crontab 任务，每个任务以创建者的名字命名 /etc/crontab 这个文件负责调度各种管理和维护任务。 /etc/cron.d/ 这个目录用来存放任何要执行的 crontab 文件或脚本。 我们还可以把脚本放在 / etc/cron.hourly、/etc/cron.daily、/etc/cron.weekly、/etc/cron.monthly 目录中，让它每小时 / 天 / 星期、月执行一次。 常用参数说明： -u ：省略该参数，表示操作当前用户的 crontab -e：编辑某个用户的 crontab 文件内容。如果不指定用户，则表示编辑当前用户的 crontab 文件。 -l：显示某个用户的 crontab 文件内容，如果不指定用户，则表示显示当前用户的 crontab 文件内容。 -r：从 / var/spool/cron 目录中删除某个用户的 crontab 文件，如果不指定用户，则默认删除当前用户的 crontab 文件。 -i：在删除用户的 crontab 文件时给确认提示 注意：-r，-i 尽量不要执行 常见操作命令如下： 1234567891011121314crontab -e # 编辑定时任务* * * * * sh /opt/lampp/test.sh # 每分钟执行一次test.sh，crontab使用crontab -l # 查看定时任务* * * * * sh /opt/lampp/test.sh# 重启定时任务进程crondservice crond reload# 查看日志# /var/log/cron只会记录是否执行了某些计划的脚本sudo tail -100f /var/log/cron 定时任务配置实例如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed# 每1分钟执行一次myCommand* * * * * myCommand# 每小时的第3和第15分钟执行3,15 * * * * myCommand# 在上午8点到11点的第3和第15分钟执行3,15 8-11 * * * myCommand# 每隔两天的上午8点到11点的第3和第15分钟执行3,15 8-11 */2 * * myCommand# 每周一上午8点到11点的第3和第15分钟执行3,15 8-11 * * 1 myCommand# 每晚的21:30重启smb30 21 * * * /etc/init.d/smb restart# 每月1、10、22日的4 : 45重启smb45 4 1,10,22 * * /etc/init.d/smb restart# 每周六、周日的1 : 10重启smb10 1 * * 6,0 /etc/init.d/smb restart# 每天18 : 00至23 : 00之间每隔30分钟重启smb0,30 18-23 * * * /etc/init.d/smb restart# 每星期六的晚上11 : 00 pm重启smb0 23 * * 6 /etc/init.d/smb restart# 每一小时重启smb* */1 * * * /etc/init.d/smb restart# 晚上11点到早上7点之间，每隔一小时重启smb* 23-7/1 * * * /etc/init.d/smb restart","tags":["笔记"],"categories":["Linux"]},{"title":"java内部类","path":"/2024/08/02/2024080205/","content":"在学习内部类之前，我们先了解一下，类的五大成员是哪些? 属性、方法、构造器、代码块、内部类 内部类就是在一个类或方法中定义的类。内部类又分为成员内部类，静态内部类，匿名内部类和局部内部类。 1、成员内部类成员内部类是定义在类的内部，作为类的成员的类。 1234567891011121314151617public class Outer &#123; private Inner inner=null; private double r; String b; public Inner getInnerInstance()&#123;//用于返回一个内部类对象 if (inner==null) inner=new Inner(); return inner; &#125; private class Inner&#123;//成员内部类,用private修饰，只能外部类的内部访问 final static int t=1;//成员内部类不能定义静态成员，final修饰的除外 public void draw()&#123; System.out.println(&quot;绘制一个圆，半径为&quot;+r); &#125; &#125;&#125; 特点如下： 内部类可以直接访问外部类的所有成员（成员变量和成员方法），包括 private 和 static 所修饰的。但是外部类不能直接访问内部类成员，需要通过预先创建的内部类对象去访问。 成员内部类可以使用权限修饰符（private、default、protected、public）任意进行修饰。 成员内部类是默认包含了一个指向外部类对象的引用。要创建成员内部类对象，必须先创建一个外部类对象。 成员内部类对象创建方法： 1234567//第一种方式Outer outer=new Outer();Outer.Inner inner=outer.new Inner();//第二种方式Outer.Inner inner1=outer.getInnerInstance();//在外部类提供一个方法，返回一个内部类对象 当成员内部类拥有和外部类同名的成员变量或者方法时，会发生隐藏现象，即默认情况下访问的是成员内部类的成员。如果要访问外部类的同名成员，需要以下面的形式进行访问： 外部类. this. 成员变量 / 成员方法 外部类的静态成员不能访问内部类，内部类不可以定义静态成员（final 修饰的除外），比如静态方法、静态属性和静态代码块。 2、静态内部类使用 static 修饰的成员内部类我们称之为静态内部类。 123456789101112131415161718192021public class Test &#123; public static void main(String[] args) &#123; Outer.Inner inner=new Outer.Inner();//静态内部类可以被其他类直接访问和实例化，而不需要先实例化外部类。 inner.draw(); &#125;&#125; class Outer &#123; int t=0; static String desc=&quot;123&quot;; static class Inner&#123; static int x=10; &#123; System.out.println(&quot;这里是静态内部类的代码块&quot;); &#125; public static void draw()&#123; System.out.println(&quot;t的值:&quot;);//这里会编译报错 System.out.println(&quot;desc的值：&quot;+desc); &#125; &#125;&#125; 特点如下： 静态内部类可以访问外部类的静态成员，不能访问非静态成员，内部类还可以定义静态成员。 静态内部类是 4 种类中唯一一个不依赖于外部类对象的引用的内部类，静态内部类可以被其他类直接访问和实例化，不需要先实例化外部类。 3、匿名内部类匿名内部类没有显式的类名, 通常在创建对象的时候定义，可以直接在表达式中使用，不需要单独声明一个命名的类。在 jdk8 新特性中可以使用 Lambda 表达式替代。 123456789101112131415public class Test &#123; public static void main(String[] args) &#123; Calculator calculator=new Calculator() &#123;// 创建一个匿名内部类实现Calculator接口 @Override public int calculate(int a, int b) &#123; return a + b; &#125; &#125;; System.out.println(calculator.calculate(2,3)); &#125;&#125;interface Calculator &#123; int calculate(int a, int b);&#125; 匿名内部类可以出现在任何允许表达式出现的地方，比如方法参数、变量初始化、方法返回值等。定义格式： new 父类构造器（参数列表）或 实现接口（）{// 匿名内部类的类体部分} _特点_： 匿名内部类可以访问外部类所有的变量和方法，不能在匿名内部类中修改外部局部变量。 匿名内部类默认包含了外部类对象的引用。 使用匿名内部类还有个前提条件：必须继承一个父类或实现一个接口 匿名内部类只能使用一次，它通常用来简化代码编写。 注：匿名内部类是唯一一种没有构造器的类。匿名内部类用于继承其他类或是实现接口，并不需要增加额外的方法，只是对继承方法的实现或是重写。 使用 Lambda 进行替换Lambda 表达式并不能取代所有的匿名内部类，能够使用 Lambda 的依据是必须有相应的函数接口（函数接口，是指内部只有一个抽象方法的接口）。 1. 无参函数的简写如果需要新建一个线程, 匿名内部类写法： 1234567new Thread(new Runnable()&#123;// 接口名\t@Override\tpublic void run()&#123;// 方法名 System.out.println(&quot;Thread run()&quot;);\t&#125;&#125;).start(); Lambda 表达式简化写法： 123456789new Thread( () -&gt; &#123; // 省略接口名和方法名 System.out.print(&quot;Hello&quot;); System.out.println(&quot;Jack&quot;); &#125; ).start(); //如果函数体只有一行语句，花括号直接去掉，留下那一行语句，比如() -&gt; System.out.println(&quot;Thread run()&quot;) 2. 带参数函数的简写如果要给一个字符串列表通过自定义比较器，按照字符串长度进行排序, 匿名内部类写法： 12345678910List&lt;String&gt; list = Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;); Collections.sort(list, new Comparator&lt;String&gt;()&#123;// 接口名 @Override public int compare(String s1, String s2)&#123;// 方法名 if(s1 == null) return -1; if(s2 == null) return 1; return s1.length()-s2.length(); &#125; &#125;); Lambda 表达式简化写法： 123456List&lt;String&gt; list = Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;);Collections.sort(list, (s1, s2) -&gt;&#123;// 省略参数表的类型 if(s1 == null) return -1; if(s2 == null) return 1; return s1.length()-s2.length(); &#125;); 自定义函数接口自定义函数接口，只需要编写一个只有一个抽象方法的接口即可。 12345678910111213141516171819// 自定义函数接口@FunctionalInterface //这个注解是可选的，但加上该标注编译器会帮你检查接口是否符合函数接口规范。interface MyInterface&lt;T&gt;&#123; void doSomething(T t);&#125;class Test&lt;T&gt;&#123; private List&lt;T&gt; list; public void myForEach(MyInterface&lt;T&gt; myInterface)&#123; for (T t:list) &#123; myInterface.doSomething(t); &#125; &#125; public static void main(String[] args) &#123; Test test=new Test(); test.list= Arrays.asList(12,13,14,15,16,17); test.myForEach(str-&gt;System.out.println(str));// 使用自定义函数接口书写Lambda表达式 &#125;&#125; *需要注意的是:* lambda 表达式隐含了 return 关键字，所以在单个的表达式中，我们无需显式的写 return 关键字，但是当表达式是一个语句集合的时候，则需要显式添加 return，并用花括号 { } 将多个表达式包围起来，下面看几个例子： 1234567891011//返回给定字符串的长度，隐含return语句(String s) -&gt; s.length() // 始终返回42的无参方法() -&gt; 42 // 包含多行表达式，则用花括号括起来(int x, int y) -&gt; &#123; int z = x * y; return x + z;&#125; 4、局部内部类局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内。作用域指的是方法里的代码块（如 if/else 语句块、for 循环块、while 循环块等）。 12345678910111213141516class Outer&#123; public void test()&#123; int x=20; class Inner&#123; //在方法内定义 public void print()&#123; System.out.println(&quot;我今年&quot;+x); &#125; &#125; new Inner().print(); // 局部内部类必须在方法内部实例化，然后return出去或者直接调用其方法。 &#125; public static void main(String[] args) &#123; Outer outer = new Outer(); outer.test(); &#125;&#125; 特点如下： 局部内部类不能有访问权限修饰符，且不能被定义为 static。 内部类可以直接访问外部类的所有成员（成员变量和成员方法）。 局部内部类默认包含了外部类对象的引用 局部内部类也可以使用 Outer.this 语法制定访问外部类成员 5、内部类作用 可以实现多重继承。（最大的优点） 内部类提供了更好的封装，除了该外围类，其他类都不能访问。 内部类拥有外围类的所有元素的访问权限。 在单个外围类中，可以让多个内部类以不同的方式实现同一个接口，或者继承同一个类。 成员内部类实现多继承： 123456789101112131415161718192021222324252627282930313233343536class Father &#123; public int eat()&#123; return 10; &#125;&#125;class Mother &#123; public int fly()&#123; return 20; &#125;&#125; class Son &#123; class Father_1 extends Father&#123; public int eat()&#123; return super.eat() + 10; &#125; &#125; class Mother_1 extends Mother&#123; public int fly()&#123; return super.fly() - 7; &#125; &#125; public int geteat()&#123; return new Father_1().eat(); &#125; public int getfly()&#123; return new Mother_1().fly(); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; Son son = new Son(); System.out.println( son.geteat()); System.out.println( son.getfly()); &#125;&#125; 其他快速创建参考12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Data@Builder@AllArgsConstructor@NoArgsConstructorpublic class ReportTemplateDO &#123; private RefactorReportTemplate template; private InstanceInfo instanceInfo; private ConfigInfo configInfo; public InstanceInfo getInstanceInfoByTemplate(RefactorReportTemplate template) &#123; return instanceInfo; &#125; public ConfigInfo getConfigInfoByTemplate(RefactorReportTemplate template) &#123; return configInfo; &#125; @Data @AllArgsConstructor @NoArgsConstructor public static class ConfigInfo &#123; private PeopleConfig peopleConfig; private WriteConfig writeConfig; &#125; @Data @AllArgsConstructor @NoArgsConstructor public static class PeopleConfig &#123; &#125; @Data @AllArgsConstructor @NoArgsConstructor public static class WriteConfig &#123; &#125; @Data @AllArgsConstructor @NoArgsConstructor public static class InstanceInfo &#123; &#125;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"java 中的 dto、dao、vo、bo、do、po、pojo_dto dao区别","path":"/2024/08/02/2024080203/","content":"一、如何认识 pojo POJO（Plain Old Java Object）是指普通的 Java 对象，它是一个简单的 Java 类，通常没有实现特定的接口或继承特定的类。POJO 对象的设计原则是简单、普通、纯粹的 Java 对象，不依赖于特定的框架或技术。 POJO 对象通常用于封装数据，它可以包含一些私有字段（属性）和公共的 getter 和 setter 方法，用于对属性进行读写操作。POJO 对象通常不包含业务逻辑，主要用于传输数据、数据存储和数据交换。 在 Java 开发中，POJO 对象被广泛应用于各种场景，例如： 数据传输：POJO 对象用于在不同层之间传输数据，如在业务逻辑层（Service 层）和表示层（Presentation 层）之间传输数据。 数据存储：POJO 对象用于封装数据库中的数据，通常用于与数据库进行交互的 ORM（对象关系映射）操作。 数据交换：POJO 对象用于与外部系统进行数据交换，如与其他服务进行 RESTful API 调用、与消息队列进行数据传输等。 单元测试：由于 POJO 对象通常不依赖于外部环境，因此在单元测试中往往可以更加方便地创建和操作 POJO 对象。 二、分别解释 dto、dao、vo、bo、do、po1.DTO Data Transfer Object：数据传输对象，DTO 用于在不同层之间传输数据，它通常用于将业务逻辑层（Service 层）的数据传输给表示层（Presentation 层）或持久化层（Persistence 层）。DTO 对象通常包含业务领域的数据，但不包含业务逻辑。 2.dao Data Access Objects：数据访问对象, DAO 用于封装数据访问逻辑，它负责与数据库进行交互，执行 CRUD（创建、读取、更新、删除）操作。DAO 对象通常封装了数据库访问的细节，使业务逻辑层能够更加简洁地操作数据。 3.vo Value Object：值对象，VO 也是用于数据传输的对象，类似于 DTO，但 VO 通常更加专注于视图层的数据展示。VO 对象通常包含了在前端页面展示所需的数据。屏蔽掉密码、创建时间、状态等敏感信息 4.bo Business Object：业务对象层，BO 用于封装业务逻辑，它通常包含了一系列的业务方法，用于实现业务规则和业务流程。BO 对象通常会调用 DAO 对象来实现数据的持久化和访问。 5.doDomain Object： 领域对象，通常用于表示业务领域中的实体或业务对象。DO 对象通常包含了业务逻辑和数据，是业务逻辑的实体表示。在某些情况下，DO 对象可能与 PO 对象相似，但它们的用途和含义不同。DO 对象通常用于表示业务领域中的复杂业务逻辑和业务实体。 6.po Persistant Object ：持久对象，通常用于表示与数据库中的表（或文档）相映射的 Java 对象。PO 对象的属性对应数据库表的字段，每个 PO 对象通常表示数据库中的一条记录。PO 对象通常用于 ORM（对象关系映射）框架中，如 Hibernate、MyBatis 等。 三、补充 这些对象在 Java 开发中常用于不同的层次和场景，有助于将数据、业务逻辑和持久化操作进行有效地分离和组织。在实际应用中，根据具体的需求和设计理念，可以选择合适的对象模型来实现业务功能。 一般开发过程中，还存在 entity、model、bean 等对象 Entity: 指的是 java 实体，在软件开发中，实体通常用于表示现实世界中的具体对象或概念，如用户、订单、产品等。在 JPA（Java Persistence API）或 ORM（对象关系映射）框架中，实体通常指的是与数据库表相对应的 Java 对象，用于表示数据库中的一条记录。实体对象通常包含与数据库表字段对应的属性，以及对应的 getter 和 setter 方法。 Model（模型）： 模型通常用于表示数据的抽象或规范，它可以是一种设计模式、数据结构或规则。在 MVC（Model-View-Controller）架构中，模型用于表示应用程序的业务逻辑和数据。在这种情况下，Model 对象通常用于封装业务逻辑、处理数据操作和传递数据给视图（View）层。Model 对象可以是实体对象、DTO（数据传输对象）或其他业务对象。 Bean（Java Bean）： Java Bean 是一种符合特定规范的 Java 类，它通常包含私有的属性、公共的无参构造方法、getter 和 setter 方法，并且可以序列化。Java Bean 通常用于封装数据和行为，是一种可重用、可扩展的组件。Bean 可以用于表示实体对象、业务对象、数据传输对象等，它们通常是轻量级的、不包含业务逻辑的数据对象。","tags":["笔记"],"categories":["Java"]},{"title":"Java 中常用的 23 种设计模式详解1","path":"/2024/08/02/2024080201/","content":"设计模式是软件开发中的最佳实践，帮助开发者在面对复杂设计问题时提供有效的解决方案。GoF（Gang of Four）在其经典著作《设计模式：可复用面向对象软件的基础》中定义了 23 种设计模式。。本文将详细介绍 23 种经典设计模式，包括创建型模式、结构型模式和行为型模式，提供每种模式的定义、原理、优点、Java 示例代码以及详细注释。 一、创建型模式（Creational Patterns）创建型模式关注于对象的创建，提供了更灵活的对象创建方式。 1.1 单例模式（Singleton Pattern）定义：确保一个类只有一个实例，并提供一个全局访问点。 原理：通过私有化构造函数和提供一个静态方法来获取实例。 优点： 控制实例数量：保证只有一个实例。 提供全局访问点：方便在全局范围内访问该实例。 Java 示例： 1234567891011121314151617// 单例类public class Singleton &#123; // 唯一实例 private static Singleton instance; // 私有构造函数，防止外部实例化 private Singleton() &#123;&#125; // 提供全局访问点 public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); // 懒汉式加载 &#125; return instance; &#125;&#125; 1.2 原型模式（Prototype Pattern）定义：通过复制现有的实例来创建新实例，而不是通过构造函数。 原理：实现 Cloneable 接口并重写 clone() 方法来复制对象。 优点： 减少创建新对象的开销：通过复制现有对象创建新对象。 动态配置对象：可以在运行时配置对象状态。 Java 示例： 1234567891011121314151617181920212223242526272829303132// 原型接口public interface Prototype extends Cloneable &#123; Prototype clone();&#125;// 具体原型类public class ConcretePrototype implements Prototype &#123; private String data; public ConcretePrototype(String data) &#123; this.data = data; &#125; @Override public Prototype clone() &#123; return new ConcretePrototype(data); &#125; public String getData() &#123; return data; &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; ConcretePrototype prototype = new ConcretePrototype(&quot;Prototype Data&quot;); ConcretePrototype clonedPrototype = (ConcretePrototype) prototype.clone(); System.out.println(clonedPrototype.getData()); &#125;&#125; 1.3 建造者模式（Builder Pattern）定义：使用多个简单的对象一步一步构建一个复杂的对象。 原理：定义一个建造者接口和具体建造者类，通过建造者类来创建复杂对象。 优点： 解耦：将复杂对象的构建与表示解耦。 灵活性：可以根据需要创建不同表示的复杂对象。 Java 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// 产品类public class Product &#123; private String partA; private String partB; // 构造函数 public Product(String partA, String partB) &#123; this.partA = partA; this.partB = partB; &#125; @Override public String toString() &#123; return &quot;Product [partA=&quot; + partA + &quot;, partB=&quot; + partB + &quot;]&quot;; &#125;&#125;// 建造者接口public interface Builder &#123; void buildPartA(); void buildPartB(); Product getResult();&#125;// 具体建造者类public class ConcreteBuilder implements Builder &#123; private String partA; private String partB; @Override public void buildPartA() &#123; partA = &quot;Part A&quot;; &#125; @Override public void buildPartB() &#123; partB = &quot;Part B&quot;; &#125; @Override public Product getResult() &#123; return new Product(partA, partB); &#125;&#125;// 指导者类public class Director &#123; private Builder builder; public Director(Builder builder) &#123; this.builder = builder; &#125; public void construct() &#123; builder.buildPartA(); builder.buildPartB(); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Builder builder = new ConcreteBuilder(); Director director = new Director(builder); director.construct(); Product product = builder.getResult(); System.out.println(product); &#125;&#125; 1.4 工厂方法模式（Factory Method Pattern）定义：定义一个创建对象的接口，但由子类决定实例化哪个类。 原理：将对象的创建逻辑放在子类中，而不是在客户端代码中。 优点： 灵活性：可以在运行时决定创建对象的类型。 符合开闭原则：对扩展开放，对修改关闭。 Java 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 产品接口public interface Product &#123; void operation();&#125;// 具体产品Apublic class ConcreteProductA implements Product &#123; @Override public void operation() &#123; System.out.println(&quot;ConcreteProductA operation&quot;); &#125;&#125;// 具体产品Bpublic class ConcreteProductB implements Product &#123; @Override public void operation() &#123; System.out.println(&quot;ConcreteProductB operation&quot;); &#125;&#125;// 工厂接口public abstract class Creator &#123; public abstract Product factoryMethod();&#125;// 具体工厂Apublic class ConcreteCreatorA extends Creator &#123; @Override public Product factoryMethod() &#123; return new ConcreteProductA(); &#125;&#125;// 具体工厂Bpublic class ConcreteCreatorB extends Creator &#123; @Override public Product factoryMethod() &#123; return new ConcreteProductB(); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Creator creator = new ConcreteCreatorA(); Product product = creator.factoryMethod(); product.operation(); &#125;&#125; 1.5 抽象工厂模式（Abstract Factory Pattern）定义：提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。 原理：通过定义多个工厂接口，每个接口负责创建一组相关的对象。 优点： 一致性：确保创建的一系列对象具有一致性。 扩展性：易于扩展产品系列，而不影响现有代码。 Java 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485// 产品A接口public interface ProductA &#123; void operationA();&#125;// 产品B接口public interface ProductB &#123; void operationB();&#125;// 具体产品A1public class ConcreteProductA1 implements ProductA &#123; @Override public void operationA() &#123; System.out.println(&quot;ConcreteProductA1 operationA&quot;); &#125;&#125;// 具体产品B1public class ConcreteProductB1 implements ProductB &#123; @Override public void operationB() &#123; System.out.println(&quot;ConcreteProductB1 operationB&quot;); &#125;&#125;// 具体产品A2public class ConcreteProductA2 implements ProductA &#123; @Override public void operationA() &#123; System.out.println(&quot;ConcreteProductA2 operationA&quot;); &#125;&#125;// 具体产品B2public class ConcreteProductB2 implements ProductB &#123; @Override public void operationB() &#123; System.out.println(&quot;ConcreteProductB2 operationB&quot;); &#125;&#125;// 抽象工厂接口public interface AbstractFactory &#123; ProductA createProductA(); ProductB createProductB();&#125;// 具体工厂1public class ConcreteFactory1 implements AbstractFactory &#123; @Override public ProductA createProductA() &#123; return new ConcreteProductA1(); &#125; @Override public ProductB createProductB() &#123; return new ConcreteProductB1(); &#125;&#125;// 具体工厂2public class ConcreteFactory2 implements AbstractFactory &#123; @Override public ProductA createProductA() &#123; return new ConcreteProductA2(); &#125; @Override public ProductB createProductB() &#123; return new ConcreteProductB2(); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; AbstractFactory factory = new ConcreteFactory1(); ProductA productA = factory.createProductA(); ProductB productB = factory.createProductB(); productA.operationA(); productB.operationB(); &#125;&#125; 二、结构型模式（Structural Patterns）结构型模式关注如何将类或对象组合成更大的结构，以便更好地实现功能。 2.1 适配器模式（Adapter Pattern）定义：将一个类的接口转换成客户希望的另一个接口。适配器模式使得原本接口不兼容的类可以合作。 原理：通过引入一个适配器类，将目标接口转换为适配者接口。 优点： 接口兼容：使得接口不兼容的类可以协作。 复用性：可以复用现有的类。 Java 示例： 1234567891011121314151617181920212223242526272829303132333435// 目标接口public interface Target &#123; void request();&#125;// 适配者类public class Adaptee &#123; public void specificRequest() &#123; System.out.println(&quot;SpecificRequest&quot;); &#125;&#125;// 适配器类public class Adapter implements Target &#123; private Adaptee adaptee; public Adapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; @Override public void request() &#123; adaptee.specificRequest(); // 适配方法 &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Adaptee adaptee = new Adaptee(); Target target = new Adapter(adaptee); target.request(); // 通过适配器调用 &#125;&#125; 2.2 桥接模式（Bridge Pattern）定义：将抽象部分与实现部分分离，使它们可以独立地变化。 原理：通过定义抽象类和实现类，将它们的变化解耦。 优点： 解耦：抽象和实现的解耦，使得它们可以独立变化。 灵活性：可以独立地扩展抽象和实现。 Java 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 实现接口public interface Implementor &#123; void operation();&#125;// 具体实现Apublic class ConcreteImplementorA implements Implementor &#123; @Override public void operation() &#123; System.out.println(&quot;ConcreteImplementorA operation&quot;); &#125;&#125;// 具体实现Bpublic class ConcreteImplementorB implements Implementor &#123; @Override public void operation() &#123; System.out.println(&quot;ConcreteImplementorB operation&quot;); &#125;&#125;// 抽象类public abstract class Abstraction &#123; protected Implementor implementor; public Abstraction(Implementor implementor) &#123; this.implementor = implementor; &#125; public abstract void operation();&#125;// 扩展抽象类public class RefinedAbstraction extends Abstraction &#123; public RefinedAbstraction(Implementor implementor) &#123; super(implementor); &#125; @Override public void operation() &#123; implementor.operation(); // 委托给实现类 &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Implementor implementorA = new ConcreteImplementorA(); Abstraction abstraction = new RefinedAbstraction(implementorA); abstraction.operation(); Implementor implementorB = new ConcreteImplementorB(); abstraction = new RefinedAbstraction(implementorB); abstraction.operation(); &#125;&#125; 2.3 组合模式（Composite Pattern）定义：将对象组合成树形结构以表示部分 - 整体层次结构，使得客户端对单个对象和组合对象的使用具有一致性。 原理：通过定义一个组件接口，将叶子节点和容器节点统一处理。 优点： 一致性：对单个对象和组合对象的一致性操作。 简化客户端代码：客户端代码可以统一处理叶子节点和容器节点。 Java 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.util.ArrayList;import java.util.List;// 组件接口public interface Component &#123; void operation();&#125;// 叶子节点public class Leaf implements Component &#123; @Override public void operation() &#123; System.out.println(&quot;Leaf operation&quot;); &#125;&#125;// 容器节点public class Composite implements Component &#123; private List&lt;Component&gt; children = new ArrayList&lt;&gt;(); public void add(Component component) &#123; children.add(component); &#125; public void remove(Component component) &#123; children.remove(component); &#125; @Override public void operation() &#123; for (Component child : children) &#123; child.operation(); &#125; &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Composite root = new Composite(); Component leaf1 = new Leaf(); Component leaf2 = new Leaf(); root.add(leaf1); root.add(leaf2); root.operation(); // 统一调用 &#125;&#125; 2.4 装饰器模式（Decorator Pattern）定义：动态地给一个对象添加一些额外的职责。装饰器模式提供了比继承更灵活的扩展功能的方式。 原理：通过定义装饰器类来扩展被装饰对象的功能。 优点： 灵活性：可以动态地扩展对象的功能。 避免子类爆炸：通过装饰器而不是继承来扩展功能。 Java 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 组件接口public interface Component &#123; void operation();&#125;// 具体组件public class ConcreteComponent implements Component &#123; @Override public void operation() &#123; System.out.println(&quot;ConcreteComponent operation&quot;); &#125;&#125;// 装饰器抽象类public abstract class Decorator implements Component &#123; protected Component component; public Decorator(Component component) &#123; this.component = component; &#125; @Override public void operation() &#123; component.operation(); &#125;&#125;// 具体装饰器public class ConcreteDecorator extends Decorator &#123; public ConcreteDecorator(Component component) &#123; super(component); &#125; @Override public void operation() &#123; super.operation(); addedBehavior(); &#125; private void addedBehavior() &#123; System.out.println(&quot;ConcreteDecorator addedBehavior&quot;); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Component component = new ConcreteComponent(); Component decorator = new ConcreteDecorator(component); decorator.operation(); // 执行装饰后的操作 &#125;&#125; 2.5 外观模式（Facade Pattern）定义：为子系统中的一组接口提供一个一致的界面，使得子系统更容易使用。 原理：通过定义一个外观类来封装子系统的复杂性，提供简化的接口。 优点： 简化使用：提供简单的接口来访问复杂的子系统。 解耦：将客户端与子系统解耦。 Java 示例： 1234567891011121314151617181920212223242526272829303132333435363738// 子系统类Apublic class SubsystemA &#123; public void operationA() &#123; System.out.println(&quot;SubsystemA operationA&quot;); &#125;&#125;// 子系统类Bpublic class SubsystemB &#123; public void operationB() &#123; System.out.println(&quot;SubsystemB operationB&quot;); &#125;&#125;// 外观类public class Facade &#123; private SubsystemA subsystemA; private SubsystemB subsystemB; public Facade() &#123; subsystemA = new SubsystemA(); subsystemB = new SubsystemB(); &#125; public void operation() &#123; subsystemA.operationA(); subsystemB.operationB(); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Facade facade = new Facade(); facade.operation(); // 通过外观类调用子系统 &#125;&#125; 2.6 享元模式（Flyweight Pattern）定义：运用共享技术有效地支持大量细粒度的对象。 原理：通过将对象的共享部分与独享部分分开，将共享部分提取出来。 优点： 节省内存：通过共享来减少内存使用。 提高性能：减少对象创建和管理的开销。 Java 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.util.HashMap;import java.util.Map;// 享元接口public interface Flyweight &#123; void operation(String extrinsicState);&#125;// 具体享元类public class ConcreteFlyweight implements Flyweight &#123; private String intrinsicState; public ConcreteFlyweight(String intrinsicState) &#123; this.intrinsicState = intrinsicState; &#125; @Override public void operation(String extrinsicState) &#123; System.out.println(&quot;Intrinsic State: &quot; + intrinsicState + &quot;, Extrinsic State: &quot; + extrinsicState); &#125;&#125;// 享元工厂public class FlyweightFactory &#123; private Map&lt;String, Flyweight&gt; flyweights = new HashMap&lt;&gt;(); public Flyweight getFlyweight(String key) &#123; Flyweight flyweight = flyweights.get(key); if (flyweight == null) &#123; flyweight = new ConcreteFlyweight(key); flyweights.put(key, flyweight); &#125; return flyweight; &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; FlyweightFactory factory = new FlyweightFactory(); Flyweight flyweight1 = factory.getFlyweight(&quot;A&quot;); Flyweight flyweight2 = factory.getFlyweight(&quot;B&quot;); flyweight1.operation(&quot;1&quot;); flyweight2.operation(&quot;2&quot;); &#125;&#125; 2.7 代理模式（Proxy Pattern）定义：为其他对象提供一种代理以控制对这个对象的访问。 原理：通过定义代理类来控制对真实对象的访问。 优点： 控制访问：可以在代理中实现对真实对象的控制。 增强功能：可以在代理中增加额外的功能，如延迟加载。 Java 示例： 12345678910111213141516171819202122232425262728293031323334// 抽象主题接口public interface Subject &#123; void request();&#125;// 真实主题类public class RealSubject implements Subject &#123; @Override public void request() &#123; System.out.println(&quot;RealSubject request&quot;); &#125;&#125;// 代理类public class Proxy implements Subject &#123; private RealSubject realSubject; @Override public void request() &#123; if (realSubject == null) &#123; realSubject = new RealSubject(); &#125; realSubject.request(); // 代理控制对真实主题的访问 &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Subject proxy = new Proxy(); proxy.request(); // 通过代理访问真实主题 &#125;&#125; 三、行为型模式（Behavioral Patterns）行为型模式关注对象之间的沟通和职责分配。 3.1 责任链模式（Chain of Responsibility Pattern）定义：使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递请求，直到有一个对象处理它为止。 原理：通过定义处理请求的链，并逐步将请求传递给链中的各个对象，直到找到合适的处理者。 优点： 解耦：发送者和接收者解耦。 灵活性：可以动态地添加或修改处理者。 Java 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 处理者接口public abstract class Handler &#123; protected Handler nextHandler; public void setNextHandler(Handler nextHandler) &#123; this.nextHandler = nextHandler; &#125; public abstract void handleRequest(String request);&#125;// 具体处理者Apublic class ConcreteHandlerA extends Handler &#123; @Override public void handleRequest(String request) &#123; if (request.equals(&quot;A&quot;)) &#123; System.out.println(&quot;Handler A handling request A&quot;); &#125; else if (nextHandler != null) &#123; nextHandler.handleRequest(request); &#125; &#125;&#125;// 具体处理者Bpublic class ConcreteHandlerB extends Handler &#123; @Override public void handleRequest(String request) &#123; if (request.equals(&quot;B&quot;)) &#123; System.out.println(&quot;Handler B handling request B&quot;); &#125; else if (nextHandler != null) &#123; nextHandler.handleRequest(request); &#125; &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Handler handlerA = new ConcreteHandlerA(); Handler handlerB = new ConcreteHandlerB(); handlerA.setNextHandler(handlerB); handlerA.handleRequest(&quot;A&quot;); // 处理请求A handlerA.handleRequest(&quot;B&quot;); // 处理请求B handlerA.handleRequest(&quot;C&quot;); // 无处理者 &#125;&#125; 3.2 命令模式（Command Pattern）定义：将请求封装成一个对象，从而使你能够用不同的请求对客户进行参数化、队列化请求、以及支持可撤销操作。 原理：通过定义命令接口和具体命令类，将请求封装为对象，并将其传递给调用者。 优点： 解耦：发送者和接收者解耦。 灵活性：可以动态地创建、撤销请求。 Java 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 命令接口public interface Command &#123; void execute();&#125;// 具体命令类public class ConcreteCommand implements Command &#123; private Receiver receiver; public ConcreteCommand(Receiver receiver) &#123; this.receiver = receiver; &#125; @Override public void execute() &#123; receiver.action(); // 将请求委托给接收者 &#125;&#125;// 接收者类public class Receiver &#123; public void action() &#123; System.out.println(&quot;Receiver action&quot;); &#125;&#125;// 调用者类public class Invoker &#123; private Command command; public void setCommand(Command command) &#123; this.command = command; &#125; public void invoke() &#123; command.execute(); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Receiver receiver = new Receiver(); Command command = new ConcreteCommand(receiver); Invoker invoker = new Invoker(); invoker.setCommand(command); invoker.invoke(); // 执行命令 &#125;&#125; 3.3 迭代器模式（Iterator Pattern）定义：提供一种方法访问一个容器对象中各个元素，而又不暴露该对象的内部表示。 原理：通过定义迭代器接口和具体迭代器类来遍历集合对象中的元素。 优点： 简化访问：提供统一的访问方式。 解耦：容器和迭代器解耦。 Java 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.util.ArrayList;import java.util.List;// 迭代器接口public interface Iterator &#123; boolean hasNext(); Object next();&#125;// 具体迭代器类public class ConcreteIterator implements Iterator &#123; private List&lt;Object&gt; items; private int position; public ConcreteIterator(List&lt;Object&gt; items) &#123; this.items = items; &#125; @Override public boolean hasNext() &#123; return position &lt; items.size(); &#125; @Override public Object next() &#123; return items.get(position++); &#125;&#125;// 聚合类public class Aggregate &#123; private List&lt;Object&gt; items = new ArrayList&lt;&gt;(); public void add(Object item) &#123; items.add(item); &#125; public Iterator iterator() &#123; return new ConcreteIterator(items); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Aggregate aggregate = new Aggregate(); aggregate.add(&quot;Item 1&quot;); aggregate.add(&quot;Item 2&quot;); Iterator iterator = aggregate.iterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; &#125;&#125; 3.4 中介者模式（Mediator Pattern）定义：定义一个对象来封装一组对象之间的交互，使得对象之间的耦合松散，从而使得它们可以独立地改变。 原理：通过定义中介者接口和具体中介者类来协调对象之间的交互。 优点： 降低耦合：将对象间的交互集中在中介者中。 易于维护：中介者可以集中处理复杂的交互逻辑。 Java 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// 中介者接口public interface Mediator &#123; void notify(Component sender, String event);&#125;// 具体中介者类public class ConcreteMediator implements Mediator &#123; private ComponentA componentA; private ComponentB componentB; public void setComponentA(ComponentA componentA) &#123; this.componentA = componentA; &#125; public void setComponentB(ComponentB componentB) &#123; this.componentB = componentB; &#125; @Override public void notify(Component sender, String event) &#123; if (sender == componentA) &#123; componentB.handleEvent(event); &#125; else if (sender == componentB) &#123; componentA.handleEvent(event); &#125; &#125;&#125;// 组件接口public abstract class Component &#123; protected Mediator mediator; public Component(Mediator mediator) &#123; this.mediator = mediator; &#125; public abstract void handleEvent(String event);&#125;// 具体组件Apublic class ComponentA extends Component &#123; public ComponentA(Mediator mediator) &#123; super(mediator); &#125; @Override public void handleEvent(String event) &#123; System.out.println(&quot;ComponentA handling event: &quot; + event); &#125; public void triggerEvent(String event) &#123; mediator.notify(this, event); &#125;&#125;// 具体组件Bpublic class ComponentB extends Component &#123; public ComponentB(Mediator mediator) &#123; super(mediator); &#125; @Override public void handleEvent(String event) &#123; System.out.println(&quot;ComponentB handling event: &quot; + event); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; ConcreteMediator mediator = new ConcreteMediator(); ComponentA componentA = new ComponentA(mediator); ComponentB componentB = new ComponentB(mediator); mediator.setComponentA(componentA); mediator.setComponentB(componentB); componentA.triggerEvent(&quot;Event A&quot;); componentB.handleEvent(&quot;Event B&quot;); &#125;&#125; 3.5 备忘录模式（Memento Pattern）定义：在不暴露对象内部状态的情况下，捕获一个对象的内部状态，并在该对象外部保存这个状态。可以在以后将对象恢复到保存的状态。 原理：通过定义备忘录类来保存对象的状态，并通过发起人类和恢复者类来实现状态的恢复。 优点： 状态恢复：可以在需要的时候恢复对象的状态。 封装性：不暴露对象的内部状态。 Java 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// 备忘录类public class Memento &#123; private String state; public Memento(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125;&#125;// 发起人类public class Originator &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public Memento saveStateToMemento() &#123; return new Memento(state); &#125; public void getStateFromMemento(Memento memento) &#123; state = memento.getState(); &#125;&#125;// 管理者类public class Caretaker &#123; private Memento memento; public void saveMemento(Memento memento) &#123; this.memento = memento; &#125; public Memento retrieveMemento() &#123; return memento; &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Originator originator = new Originator(); Caretaker caretaker = new Caretaker(); originator.setState(&quot;State1&quot;); caretaker.saveMemento(originator.saveStateToMemento()); originator.setState(&quot;State2&quot;); System.out.println(&quot;Current State: &quot; + originator.getState()); originator.getStateFromMemento(caretaker.retrieveMemento()); System.out.println(&quot;Restored State: &quot; + originator.getState()); &#125;&#125; 3.6 解释器模式（Interpreter Pattern）定义：给定一个语言，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子。 原理：通过定义解释器类和表达式类，将文法规则和解释逻辑分开。 优点： 易于扩展：可以通过增加新的终结符和非终结符来扩展语法。 灵活性：可以定义复杂的语言规则。 Java 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.util.HashMap;import java.util.Map;// 表达式接口public interface Expression &#123; int interpret(Map&lt;String, Integer&gt; context);&#125;// 终结符表达式public class NumberExpression implements Expression &#123; private int number; public NumberExpression(int number) &#123; this.number = number; &#125; @Override public int interpret(Map&lt;String, Integer&gt; context) &#123; return number; &#125;&#125;// 非终结符表达式public class PlusExpression implements Expression &#123; private Expression left; private Expression right; public PlusExpression(Expression left, Expression right) &#123; this.left = left; this.right = right; &#125; @Override public int interpret(Map&lt;String, Integer&gt; context) &#123; return left.interpret(context) + right.interpret(context); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Expression expression = new PlusExpression(new NumberExpression(5), new NumberExpression(3)); Map&lt;String, Integer&gt; context = new HashMap&lt;&gt;(); int result = expression.interpret(context); System.out.println(&quot;Result: &quot; + result); // 输出结果 8 &#125;&#125; 3.7 状态模式（State Pattern）定义：允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类。 原理：通过定义状态接口和具体状态类，将对象的状态和行为分开，使得状态改变时可以改变行为。 优点： 状态独立：每个状态都有自己的行为。 易于扩展：可以增加新的状态而不改变现有代码。 Java 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 状态接口public interface State &#123; void handle(Context context);&#125;// 具体状态Apublic class ConcreteStateA implements State &#123; @Override public void handle(Context context) &#123; System.out.println(&quot;Handling state A&quot;); context.setState(new ConcreteStateB()); // 切换到状态B &#125;&#125;// 具体状态Bpublic class ConcreteStateB implements State &#123; @Override public void handle(Context context) &#123; System.out.println(&quot;Handling state B&quot;); context.setState(new ConcreteStateA()); // 切换到状态A &#125;&#125;// 上下文类public class Context &#123; private State state; public Context(State state) &#123; this.state = state; &#125; public void setState(State state) &#123; this.state = state; &#125; public void request() &#123; state.handle(this); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Context context = new Context(new ConcreteStateA()); context.request(); // 处理状态A context.request(); // 处理状态B &#125;&#125; 3.8 策略模式（Strategy Pattern）定义：定义一系列算法，将每一个算法封装起来，并使它们可以相互替换。策略模式让算法独立于使用它的客户而独立变化。 原理：通过定义策略接口和具体策略类，将算法封装为对象，并在运行时选择使用。 优点： 灵活性：可以动态选择算法。 易于扩展：可以新增策略而不影响现有代码。 Java 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 策略接口public interface Strategy &#123; void execute();&#125;// 具体策略Apublic class ConcreteStrategyA implements Strategy &#123; @Override public void execute() &#123; System.out.println(&quot;Executing strategy A&quot;); &#125;&#125;// 具体策略Bpublic class ConcreteStrategyB implements Strategy &#123; @Override public void execute() &#123; System.out.println(&quot;Executing strategy B&quot;); &#125;&#125;// 上下文类public class Context &#123; private Strategy strategy; public void setStrategy(Strategy strategy) &#123; this.strategy = strategy; &#125; public void executeStrategy() &#123; strategy.execute(); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; Context context = new Context(); context.setStrategy(new ConcreteStrategyA()); context.executeStrategy(); // 执行策略A context.setStrategy(new ConcreteStrategyB()); context.executeStrategy(); // 执行策略B &#125;&#125; 3.9 模板方法模式（Template Method Pattern）定义：定义一个操作中的算法的骨架，将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下重新定义算法中的某些步骤。 原理：通过定义模板方法在父类中，并将一些步骤的实现延迟到子类中。 优点： 复用性：将公共算法逻辑放在父类中。 灵活性：子类可以改变某些步骤的实现而不改变算法结构。 Java 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// 抽象类public abstract class AbstractClass &#123; // 模板方法 public final void templateMethod() &#123; step1(); step2(); step3(); &#125; // 具体步骤1 private void step1() &#123; System.out.println(&quot;Step 1&quot;); &#125; // 具体步骤2，留给子类实现 protected abstract void step2(); // 具体步骤3 private void step3() &#123; System.out.println(&quot;Step 3&quot;); &#125;&#125;// 具体类Apublic class ConcreteClassA extends AbstractClass &#123; @Override protected void step2() &#123; System.out.println(&quot;ConcreteClassA Step 2&quot;); &#125;&#125;// 具体类Bpublic class ConcreteClassB extends AbstractClass &#123; @Override protected void step2() &#123; System.out.println(&quot;ConcreteClassB Step 2&quot;); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; AbstractClass concreteClassA = new ConcreteClassA(); concreteClassA.templateMethod(); // 执行具体类A的模板方法 AbstractClass concreteClassB = new ConcreteClassB(); concreteClassB.templateMethod(); // 执行具体类B的模板方法 &#125;&#125; 3.10 访问者模式（Visitor Pattern）定义：表示一个作用于某对象结构中的各元素的操作，它可以在不改变元素类的前提下定义作用于这些元素的新操作。 原理：通过定义访问者接口和具体访问者类，将操作和对象结构分离，使得可以在不改变对象结构的情况下增加新的操作。 优点： 扩展性：可以在不改变对象结构的情况下增加新的操作。 操作集中：操作被集中在访问者中，使得相关操作更易于维护。 Java 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586import java.util.ArrayList;import java.util.List;// 访问者接口public interface Visitor &#123; void visit(ConcreteElementA elementA); void visit(ConcreteElementB elementB);&#125;// 具体访问者Apublic class ConcreteVisitorA implements Visitor &#123; @Override public void visit(ConcreteElementA elementA) &#123; System.out.println(&quot;Visitor A visiting Element A&quot;); &#125; @Override public void visit(ConcreteElementB elementB) &#123; System.out.println(&quot;Visitor A visiting Element B&quot;); &#125;&#125;// 具体访问者Bpublic class ConcreteVisitorB implements Visitor &#123; @Override public void visit(ConcreteElementA elementA) &#123; System.out.println(&quot;Visitor B visiting Element A&quot;); &#125; @Override public void visit(ConcreteElementB elementB) &#123; System.out.println(&quot;Visitor B visiting Element B&quot;); &#125;&#125;// 元素接口public interface Element &#123; void accept(Visitor visitor);&#125;// 具体元素Apublic class ConcreteElementA implements Element &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125;&#125;// 具体元素Bpublic class ConcreteElementB implements Element &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125;&#125;// 对象结构public class ObjectStructure &#123; private List&lt;Element&gt; elements = new ArrayList&lt;&gt;(); public void addElement(Element element) &#123; elements.add(element); &#125; public void accept(Visitor visitor) &#123; for (Element element : elements) &#123; element.accept(visitor); &#125; &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; ObjectStructure structure = new ObjectStructure(); structure.addElement(new ConcreteElementA()); structure.addElement(new ConcreteElementB()); Visitor visitorA = new ConcreteVisitorA(); structure.accept(visitorA); // Visitor A visiting elements Visitor visitorB = new ConcreteVisitorB(); structure.accept(visitorB); // Visitor B visiting elements &#125;&#125; 3.11 观察者模式（Observer Pattern）定义：定义对象之间的一对多依赖，使得当一个对象改变状态时，所有依赖于它的对象都得到通知并被自动更新。 原理：通过定义观察者接口和被观察者类来实现一对多的通知机制。 优点： 解耦：观察者和被观察者之间的解耦。 动态更新：自动更新所有观察者。 Java 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.util.ArrayList;import java.util.List;// 观察者接口public interface Observer &#123; void update(String message);&#125;// 被观察者接口public interface Subject &#123; void addObserver(Observer observer); void removeObserver(Observer observer); void notifyObservers(String message);&#125;// 具体被观察者public class ConcreteSubject implements Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); @Override public void addObserver(Observer observer) &#123; observers.add(observer); &#125; @Override public void removeObserver(Observer observer) &#123; observers.remove(observer); &#125; @Override public void notifyObservers(String message) &#123; for (Observer observer : observers) &#123; observer.update(message); &#125; &#125;&#125;// 具体观察者public class ConcreteObserver implements Observer &#123; private String name; public ConcreteObserver(String name) &#123; this.name = name; &#125; @Override public void update(String message) &#123; System.out.println(name + &quot; received: &quot; + message); &#125;&#125;// 客户端代码public class Client &#123; public static void main(String[] args) &#123; ConcreteSubject subject = new ConcreteSubject(); Observer observer1 = new ConcreteObserver(&quot;Observer1&quot;); Observer observer2 = new ConcreteObserver(&quot;Observer2&quot;); subject.addObserver(observer1); subject.addObserver(observer2); subject.notifyObservers(&quot;Hello Observers!&quot;); &#125;&#125; 这些设计模式是解决常见设计问题的通用方案。每种模式都有其独特的应用场景和优点，通过合理运用这些模式，可以使软件系统更加灵活、可维护和可扩展。","tags":["笔记"],"categories":["Java"]},{"title":"Java 中常用的 23 种设计模式详解2","path":"/2024/08/02/2024080202/","content":"设计模式是在软件设计中反复出现的问题的通用解决方案。它们是经过多次验证和应用的指导原则，旨在帮助软件开发人员解决特定类型的问题，提高代码的可维护性、可扩展性和重用性。 设计模式是一种抽象化的思维方式，可以帮助开发人员更好地组织和设计他们的代码。它们提供了一种通用的框架，可以用于解决各种不同的软件设计问题。设计模式不是完整的代码，而是一种描述问题和解决方案之间关系的模板。 设计模式并不是一成不变的法则，而是根据不同的问题和情境来决定是否使用以及如何使用。了解和应用设计模式可以帮助开发人员更好地组织代码，提高代码的可读性和可维护性，同时也有助于促进团队之间的合作和沟通。 设计模式的分类 创建型模式（Creational）：关注对象的实例化过程，包括了如何实例化对象、隐藏对象的创建细节等。常见的创建型模式有单例模式、工厂模式、抽象工厂模式等。 结构型模式（Structural）：关注对象之间的组合方式，以达到构建更大结构的目标。这些模式帮助你定义对象之间的关系，从而实现更大的结构。常见的结构型模式有适配器模式、装饰器模式、代理模式等。 行为型模式（Behavioral）：关注对象之间的通信方式，以及如何合作共同完成任务。这些模式涉及到对象之间的交互、责任分配等。常见的行为型模式有观察者模式、策略模式、命令模式等。 设计模式的基本要素 模式名称：每个设计模式都有一个简洁的名称，用于描述问题、解决方案和效果。这个名称有助于在交流中快速指代模式。 问题：描述了在什么情况下应该考虑使用特定的设计模式。问题部分阐述了该模式试图解决的具体设计难题。 解决方案：解决方案部分提供了一个详细的设计指南，描述了如何组织类、对象以及它们之间的关系，以解决特定问题。这包括了每个角色的职责、协作方式等。 效果：描述了模式应用的效果及使用模式应权衡的问题。 种设计模式概览 设计模式间的关系 设计模式代码示例仓库地址23 种设计模式 JAVA 实现 设计模式详解1. 工厂方法模式（Factory Method）问题： 在软件设计中，我们经常遇到需要创建不同类型对象的情况。但是，如果直接在代码中实例化对象，会使代码紧密耦合在一起，难以维护和扩展。此外，如果对象的创建方式需要变化，那么就需要在整个代码中进行大量的修改。工厂方法模式旨在解决这个问题。 解决方案： 工厂方法模式提供了一个创建对象的接口，但是将具体的对象创建延迟到子类中。这样，客户端代码不需要知道要创建的具体对象的类，只需要通过工厂方法来创建对象。这使得客户端代码与具体对象的创建解耦，提高了代码的灵活性和可维护性。 在工厂方法模式中，通常会定义一个抽象工厂类，其中包含一个创建对象的抽象方法，而具体的对象创建则由具体的子类实现。这样，每个具体的子类都可以根据需要创建不同类型的对象，而客户端代码只需要通过抽象工厂类来调用工厂方法，而不需要关心具体的对象创建细节。 效果： 工厂方法模式的优点包括： 松耦合：客户端代码与具体对象的创建解耦，使得系统更具弹性和可维护性。 扩展性：通过添加新的具体工厂和产品子类，可以很容易地扩展系统以支持新的对象类型。 封装性：将对象的创建集中在工厂类中，封装了对象的创建细节，使得客户端代码更简洁。 然而，工厂方法模式也可能引入一些额外的复杂性，因为需要定义多个工厂类和产品类的层次结构。这可能会导致系统中类的数量增加。在选择使用工厂方法模式时，需要根据具体情况进行权衡。 工厂方法模式在实际应用中非常常见，例如，图形库可以使用工厂方法模式来创建不同类型的图形对象，数据库访问框架可以使用工厂方法模式来创建不同类型的数据库连接等。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// 首先，我们需要定义一个图形接口interface Shape &#123; void draw();&#125;// 然后，我们实现两个具体的图形类，分别是 Circle（圆形）和 Rectangle（矩形）class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Drawing a circle&quot;); &#125;&#125;class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Drawing a rectangle&quot;); &#125;&#125;// 接下来，我们创建一个抽象工厂类 ShapeFactory// 它定义了一个抽象的工厂方法 createShape，子类将实现这个方法来创建具体的图形对象abstract class ShapeFactory &#123; abstract Shape createShape();&#125;// 然后，我们创建两个具体的工厂类，分别是 CircleFactory 和 RectangleFactory// 它们分别实现了 ShapeFactory 并重写了 createShape 方法来返回相应的图形对象class CircleFactory extends ShapeFactory &#123; @Override Shape createShape() &#123; return new Circle(); &#125;&#125;class RectangleFactory extends ShapeFactory &#123; @Override Shape createShape() &#123; return new Rectangle(); &#125;&#125;// 我们可以使用这些工厂类来创建图形对象public class FactoryMethodExample &#123; public static void main(String[] args) &#123; ShapeFactory circleFactory = new CircleFactory(); Shape circle = circleFactory.createShape(); circle.draw(); ShapeFactory rectangleFactory = new RectangleFactory(); Shape rectangle = rectangleFactory.createShape(); rectangle.draw(); &#125;&#125; 2. 抽象工厂模式（Abstract Factory）问题： 在某些情况下，需要创建一系列相关或相互依赖的对象，这些对象属于一组相关的产品族。同时，系统需要保证这些产品族之间的一致性。如果直接在代码中创建这些对象，会使得代码与具体产品的细节紧密耦合，不利于后续的扩展和维护。 解决方案： 抽象工厂模式提供了一个接口，用于创建一系列相关或相互依赖的对象。通过使用抽象工厂接口及其具体实现，可以将对象的创建与客户端代码分离，从而实现系统的松耦合。抽象工厂模式涉及多个角色： 抽象工厂（Abstract Factory）：声明了一组用于创建不同产品的抽象方法。具体的工厂类必须实现这些方法来创建具体的产品对象。 具体工厂（Concrete Factory）：实现抽象工厂接口，负责创建特定种类的产品对象。 抽象产品（Abstract Product）：定义了产品的通用接口，具体产品必须实现这个接口。 具体产品（Concrete Product）：实现抽象产品接口，是抽象工厂创建的实际对象。 效果： 抽象工厂模式的使用可以带来以下效果： 产品族一致性：抽象工厂确保创建的产品是一组相关的产品族，保证了这些产品之间的一致性。 松耦合：客户端代码不需要直接依赖于具体产品，只需要通过抽象工厂接口创建产品，从而降低了代码的耦合度。 可扩展性：增加新的产品族或产品变得相对容易，只需要添加新的具体工厂和产品类即可，不需要修改现有代码。 限制：抽象工厂模式要求系统中的每个产品族都必须有一个对应的具体工厂，这可能增加了系统的复杂性。 抽象工厂模式适用于需要创建一系列相关产品并保证它们之间一致性的情况，例如图形界面库中的 UI 元素，不同操作系统下的界面组件等。通过使用抽象工厂模式，可以更好地管理和组织这些产品的创建过程。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394// 抽象产品接口：操作系统interface OperatingSystem &#123; void run();&#125;// 具体产品：Windows操作系统class WindowsOS implements OperatingSystem &#123; @Override public void run() &#123; System.out.println(&quot;Running Windows OS&quot;); &#125;&#125;// 具体产品：Linux操作系统class LinuxOS implements OperatingSystem &#123; @Override public void run() &#123; System.out.println(&quot;Running Linux OS&quot;); &#125;&#125;// 抽象产品接口：应用程序interface Application &#123; void open();&#125;// 具体产品：Word应用程序class WordApplication implements Application &#123; @Override public void open() &#123; System.out.println(&quot;Opening Word Application&quot;); &#125;&#125;// 具体产品：Excel应用程序class ExcelApplication implements Application &#123; @Override public void open() &#123; System.out.println(&quot;Opening Excel Application&quot;); &#125;&#125;// 抽象工厂接口interface SoftwareFactory &#123; OperatingSystem createOperatingSystem(); Application createApplication();&#125;// 具体工厂：Windows工厂class WindowsFactory implements SoftwareFactory &#123; @Override public OperatingSystem createOperatingSystem() &#123; return new WindowsOS(); &#125; @Override public Application createApplication() &#123; return new ExcelApplication(); &#125;&#125;// 具体工厂：Linux工厂class LinuxFactory implements SoftwareFactory &#123; @Override public OperatingSystem createOperatingSystem() &#123; return new LinuxOS(); &#125; @Override public Application createApplication() &#123; return new WordApplication(); &#125;&#125;// 在这个示例中，抽象工厂模式通过SoftwareFactory接口和其实现类来创建不同类型的操作系统和应用程序。// 客户端代码可以根据需要选择不同的工厂实例来创建不同的产品组合。public class Client &#123; public static void main(String[] args) &#123; SoftwareFactory windowsFactory = new WindowsFactory(); OperatingSystem windowsOS = windowsFactory.createOperatingSystem(); Application windowsApp = windowsFactory.createApplication(); windowsOS.run(); windowsApp.open(); SoftwareFactory linuxFactory = new LinuxFactory(); OperatingSystem linuxOS = linuxFactory.createOperatingSystem(); Application linuxApp = linuxFactory.createApplication(); linuxOS.run(); linuxApp.open(); &#125;&#125; 3. 建造者模式（Builder）问题： 在某些情况下，一个对象的创建过程非常复杂，涉及多个步骤，每个步骤都可能有不同的实现方式。如果将所有创建逻辑放在一个类中，会导致该类变得庞大且难以维护。此外，如果需要创建不同的变体对象，就需要在该类中添加更多的逻辑，使得代码变得混乱。 解决方案： 建造者模式提供了一种将一个复杂对象的构建过程与其表示分离的方法。它将对象的构建过程封装在一个独立的 “建造者” 类中，由该类负责逐步构建对象。这样，可以根据需要创建不同的建造者来构建不同的对象变体。通常，建造者模式涉及以下角色： 产品（Product）：表示正在构建的复杂对象。建造者模式的目标是构建这个产品。 抽象建造者（Abstract Builder）：定义了构建产品的步骤和方法，但没有具体的实现。不同的具体建造者可以实现不同的构建步骤，从而创建不同的产品变体。 具体建造者（Concrete Builder）：实现了抽象建造者定义的方法，完成了产品的构建过程。每个具体建造者负责构建特定的产品变体。 指导者（Director）：负责控制建造的过程。它通过将客户端与具体建造者分离，确保产品的构建是按照一定顺序和规则进行的。 效果： 建造者模式的效果包括： 分离构建过程和表示：通过建造者模式，可以将复杂对象的构建过程与其最终表示分离，使得构建过程更加清晰可控。 支持不同的表示：通过使用不同的具体建造者，可以创建不同的产品表示，而不改变客户端的代码。 更好的可扩展性：如果需要添加新的产品变体，只需创建一个新的具体建造者即可，而无需修改已有的代码。 隐藏产品的内部结构：客户端只需与抽象建造者和指导者交互，无需关心产品的内部构建细节。 总之，建造者模式适用于需要构建复杂对象，且构建过程涉及多个步骤或变体的情况。通过将构建过程分解为可重用的步骤，建造者模式提供了一种结构化的方法来创建对象。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120// 首先，我们定义房屋类 House，它具有多个属性，如地基、结构、屋顶和装修。class House &#123; private String foundation; private String structure; private String roof; private String interior; public void setFoundation(String foundation) &#123; this.foundation = foundation; &#125; public void setStructure(String structure) &#123; this.structure = structure; &#125; public void setRoof(String roof) &#123; this.roof = roof; &#125; public void setInterior(String interior) &#123; this.interior = interior; &#125; @Override public String toString() &#123; return &quot;House [foundation=&quot; + foundation + &quot;, structure=&quot; + structure + &quot;, roof=&quot; + roof + &quot;, interior=&quot; + interior + &quot;]&quot;; &#125;&#125;// 然后，我们创建一个抽象建造者类 HouseBuilder，它定义了构建房屋的方法。abstract class HouseBuilder &#123; protected House house = new House(); public abstract void buildFoundation(); public abstract void buildStructure(); public abstract void buildRoof(); public abstract void buildInterior(); public House getHouse() &#123; return house; &#125;&#125;// 接下来，我们创建两个具体的建造者类 ConcreteHouseBuilder 和 LuxuryHouseBuilder// 分别实现了不同类型房屋的构建过程。// 具体建造者类 - 普通房屋class ConcreteHouseBuilder extends HouseBuilder &#123; @Override public void buildFoundation() &#123; house.setFoundation(&quot;Standard Foundation&quot;); &#125; @Override public void buildStructure() &#123; house.setStructure(&quot;Standard Structure&quot;); &#125; @Override public void buildRoof() &#123; house.setRoof(&quot;Standard Roof&quot;); &#125; @Override public void buildInterior() &#123; house.setInterior(&quot;Standard Interior&quot;); &#125;&#125;// 具体建造者类 - 豪华房屋class LuxuryHouseBuilder extends HouseBuilder &#123; @Override public void buildFoundation() &#123; house.setFoundation(&quot;Strong Foundation&quot;); &#125; @Override public void buildStructure() &#123; house.setStructure(&quot;Reinforced Structure&quot;); &#125; @Override public void buildRoof() &#123; house.setRoof(&quot;Elegant Roof&quot;); &#125; @Override public void buildInterior() &#123; house.setInterior(&quot;Luxury Interior&quot;); &#125;&#125;// 最后，我们创建指导者类 Director，它协调建造过程并返回构建的房屋对象。class Director &#123; private HouseBuilder builder; public Director(HouseBuilder builder) &#123; this.builder = builder; &#125; public House constructHouse() &#123; builder.buildFoundation(); builder.buildStructure(); builder.buildRoof(); builder.buildInterior(); return builder.getHouse(); &#125;&#125;// 这个示例演示了如何使用建造者模式创建不同类型的房屋，每种房屋类型的建造过程都由相应的具体建造者类负责实现，而指导者类负责协调建造过程。public class BuilderPatternExample &#123; public static void main(String[] args) &#123; HouseBuilder concreteBuilder = new ConcreteHouseBuilder(); Director director1 = new Director(concreteBuilder); House concreteHouse = director1.constructHouse(); System.out.println(&quot;Concrete House: &quot; + concreteHouse); HouseBuilder luxuryBuilder = new LuxuryHouseBuilder(); Director director2 = new Director(luxuryBuilder); House luxuryHouse = director2.constructHouse(); System.out.println(&quot;Luxury House: &quot; + luxuryHouse); &#125;&#125; 4. 原型模式（Prototype）问题： 在某些情况下，需要创建对象的副本，但复制一个对象的成本可能很高，或者希望避免与对象的具体类耦合。例如，当创建对象的过程较为复杂，或者对象包含大量共享的状态时，使用常规的创建方法可能会导致性能下降。 解决方案： 原型模式的解决方案是通过复制现有对象来创建新对象，而不是从头开始构建。这允许我们以更高效的方式创建新对象，同时避免了与对象类的直接耦合。核心概念是在原型对象的基础上进行克隆，使得新对象具有与原型相同的初始状态。 在原型模式中，通常会有以下几个角色： 抽象原型（Prototype）：声明克隆方法，作为所有具体原型的基类或接口。 具体原型（Concrete Prototype）：实现克隆方法，从自身创建一个副本。 客户端（Client）：使用原型对象的客户端代码，在需要新对象时通过克隆现有对象来创建新实例。 效果： 原型模式的应用可以带来以下效果： 减少对象创建的成本：避免了复杂对象的重复初始化过程，提高了创建对象的效率。 避免与具体类耦合：客户端可以通过克隆方法创建新对象，而无需知道具体类的细节，降低了耦合度。 灵活性增加：可以在运行时动态地添加或删除原型，适应不同的对象创建需求。 支持动态配置：可以通过克隆来定制对象的不同配置，而无需修改其代码。 然而，也需要注意一些限制，如： 深克隆问题：原型模式默认进行浅克隆，即复制对象本身和其引用。如果对象内部包含其他对象的引用，可能需要实现深克隆来复制整个对象结构。 克隆方法的实现：某些对象可能不容易进行克隆，特别是涉及到文件、网络连接等资源的情况。 总之，原型模式是一种在需要创建对象副本时非常有用的设计模式，它提供了一种灵活且高效的方法来处理对象的复制需求。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243// 创建一个实现 Cloneable 接口的原型类class Shape implements Cloneable &#123; private String type; public Shape(String type) &#123; this.type = type; &#125; public String getType() &#123; return type; &#125; public void setType(String type) &#123; this.type = type; &#125; @Override public Shape clone() &#123; try &#123; return (Shape) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; return null; &#125; &#125;&#125;// 测试原型模式public class PrototypeExample &#123; public static void main(String[] args) &#123; // 创建原型对象 Shape circle = new Shape(&quot;Circle&quot;); // 克隆原型对象来创建新对象 Shape clonedCircle = circle.clone(); clonedCircle.setType(&quot;Cloned Circle&quot;); // 输出原型对象和克隆对象的类型 System.out.println(&quot;Original Shape Type: &quot; + circle.getType()); System.out.println(&quot;Cloned Shape Type: &quot; + clonedCircle.getType()); &#125;&#125; 5. 单例模式（Singleton）问题： 在某些情况下，需要确保一个类只有一个实例，并且需要一个全局访问点来访问这个实例。例如，在一个应用程序中，一个配置管理器类需要保持一致的配置数据，以避免不同部分之间的配置冲突。 解决方案： 单例模式通过确保一个类只能创建一个实例，并提供一个静态方法或静态属性来访问这个实例。通常，单例类会将自己的构造函数声明为私有，以防止外部代码直接创建实例。通过一个静态方法，单例类可以控制在运行时只能获得同一个实例。 效果： 单例模式的应用可以确保在整个应用程序中只有一个实例存在，从而节省了资源和内存。它也可以提供一个全局的访问点，使得代码中的各个部分都可以方便地获取这个实例。然而，过度使用单例模式可能导致全局状态的难以控制，以及模块之间的紧耦合。在多线程环境下需要小心处理，以确保线程安全。 总之，单例模式是一种常用的设计模式，适用于需要全局唯一实例的场景。它的核心思想在于通过限制类的实例化来控制对象的数量，从而保证全局唯一性。 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738public class Singleton &#123; // 私有静态成员变量，用于保存单例实例 private static Singleton instance; // 私有构造方法，防止外部实例化 private Singleton() &#123; // 初始化操作 &#125; // 公共静态方法，用于获取单例实例 public static Singleton getInstance() &#123; if (instance == null) &#123; // 如果实例为空，则创建一个新实例 instance = new Singleton(); &#125; return instance; &#125; // 其他成员方法 public void showMessage() &#123; System.out.println(&quot;Hello, I am a Singleton!&quot;); &#125;&#125;// 这个示例演示了如何创建一个简单的单例模式// 但请注意，这个实现并不是线程安全的。// 在多线程环境中，可能会出现多个线程同时访问getInstance()方法，导致创建多个实例的情况。// 为了实现线程安全的单例模式，可以使用双重检查锁定或其他同步机制。public class Main &#123; public static void main(String[] args) &#123; // 获取单例实例 Singleton singleton = Singleton.getInstance(); // 调用成员方法 singleton.showMessage(); &#125;&#125; 6. 适配器模式（Adapter）问题： 当你有两个不兼容的接口（即类或对象），但需要它们能够一起工作时，适配器模式可以解决这个问题。例如，你可能有一个已存在的类库或组件，但其接口与你的代码不匹配，你希望能够无缝地将它们集成在一起。 解决方案： 适配器模式通过引入一个适配器类来充当中间人，将一个接口转换成另一个接口，使得两个不兼容的对象能够协同工作。适配器类包含一个对不兼容接口的引用，并实现了你期望的目标接口。这样，当你需要使用目标接口的时候，可以通过适配器来调用原本不兼容的类的方法。 效果： 适配器模式的应用可以使得现有的代码与新代码能够无缝协同工作，从而提高了代码的可重用性。它允许你将不同系统、库或组件整合在一起，而无需对现有代码进行大量修改。然而，适配器模式也可能引入一些复杂性，因为你需要维护适配器类和处理不同接口之间的映射关系。 总的来说，适配器模式是一种很有用的模式，特别适合在集成不同组件或类时，解决接口不匹配的问题，从而保持代码的灵活性和可维护性。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142// 已存在的LegacyRectangle类class LegacyRectangle &#123; public void display(int x1, int y1, int x2, int y2) &#123; System.out.println(&quot;LegacyRectangle: Point1(&quot; + x1 + &quot;, &quot; + y1 + &quot;), Point2(&quot; + x2 + &quot;, &quot; + y2 + &quot;)&quot;); &#125;&#125;// 统一的Shape接口interface Shape &#123; void draw(int x, int y, int width, int height);&#125;// 适配器类，将LegacyRectangle适配到Shape接口上class RectangleAdapter implements Shape &#123; private LegacyRectangle legacyRectangle; public RectangleAdapter(LegacyRectangle legacyRectangle) &#123; this.legacyRectangle = legacyRectangle; &#125; @Override public void draw(int x, int y, int width, int height) &#123; int x1 = x; int y1 = y; int x2 = x + width; int y2 = y + height; legacyRectangle.display(x1, y1, x2, y2); &#125;&#125;// 在这个示例中，LegacyRectangle是已经存在的类，而RectangleAdapter是适配器类，用于将LegacyRectangle适配到Shape接口上。// 客户端代码通过使用适配器来画一个矩形，实际上是在调用了LegacyRectangle的display方法，但是通过适配器，它符合了Shape接口的标准。public class AdapterPatternExample &#123; public static void main(String[] args) &#123; LegacyRectangle legacyRectangle = new LegacyRectangle(); Shape shapeAdapter = new RectangleAdapter(legacyRectangle); shapeAdapter.draw(10, 20, 50, 30); &#125;&#125; 7. 桥接模式（Bridge）问题： 在软件设计中，有时候你会遇到一个类有多个变化维度（例如抽象和具体的实现）。如果使用继承来处理这些变化，将会导致类层次结构的急剧增加，难以管理和维护。此外，继承会将抽象部分和具体部分紧密耦合，不利于独立地进行扩展和变化。 解决方案： 桥接模式通过将抽象部分和具体部分分离，使它们可以独立地变化。在桥接模式中，通过创建一个桥接接口（或抽象类），其中包含一个指向具体实现的引用，将抽象部分和具体部分连接起来。这样，抽象部分和具体部分可以独立地进行扩展，而不会相互影响。这种方式也被称为 “组合优于继承”。 效果： 桥接模式的应用能够提供更好的灵活性和可扩展性。它允许抽象部分和具体部分独立变化，避免了类层次结构的爆炸式增长。这样可以更容易地添加新的抽象部分和具体部分，而不会影响到彼此。然而，使用桥接模式可能会引入一些复杂性，因为你需要管理更多的类和对象。 总之，桥接模式是一种有助于解耦抽象和实现，提供更灵活、可扩展设计的设计模式。它适用于那些需要处理多个变化维度的情况，同时又希望保持代码的清晰结构和可维护性。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// 实现部分 - 颜色接口interface Color &#123; void applyColor();&#125;class Red implements Color &#123; public void applyColor() &#123; System.out.println(&quot;Applying red color&quot;); &#125;&#125;class Blue implements Color &#123; public void applyColor() &#123; System.out.println(&quot;Applying blue color&quot;); &#125;&#125;// 抽象部分 - 形状类abstract class Shape &#123; protected Color color; public Shape(Color color) &#123; this.color = color; &#125; abstract void draw();&#125;class Circle extends Shape &#123; public Circle(Color color) &#123; super(color); &#125; public void draw() &#123; System.out.print(&quot;Drawing a circle. &quot;); color.applyColor(); &#125;&#125;class Square extends Shape &#123; public Square(Color color) &#123; super(color); &#125; public void draw() &#123; System.out.print(&quot;Drawing a square. &quot;); color.applyColor(); &#125;&#125;// 在这个示例中，Color 接口代表颜色的实现部分，Red 和 Blue 分别是实现了颜色接口的具体颜色类。// Shape 是形状的抽象部分，具有一个颜色引用，而 Circle 和 Square 是继承自 Shape 的具体形状类。// 这种设计允许我们在不改变形状或颜色的情况下，独立地对它们进行扩展和变化。public class BridgePatternExample &#123; public static void main(String[] args) &#123; Color redColor = new Red(); Color blueColor = new Blue(); Shape redCircle = new Circle(redColor); Shape blueSquare = new Square(blueColor); redCircle.draw(); blueSquare.draw(); &#125;&#125; 8. 组合模式（Composite）问题： 在某些情况下，我们需要处理一组对象，这些对象之间具有整体 - 部分的关系。我们希望能够以一致的方式处理单个对象和对象组合，而不需要对它们进行特殊处理。 解决方案： 组合模式的解决方案是将对象组合成树状结构，其中树的节点可以是单个对象或对象组合。这样，无论是操作单个对象还是对象组合，都可以使用统一的方式进行操作。组合模式通过定义一个共同的抽象类或接口来表示单个对象和对象组合，从而实现了透明的处理。 在组合模式中，通常有两种主要角色： 组件（Component）： 这是一个抽象类或接口，定义了单个对象和对象组合共同的操作。它可以有一些默认实现，也可以有抽象方法需要在具体子类中实现。 叶子（Leaf）： 继承自组件，表示单个对象。它没有子对象。 复合（Composite）： 继承自组件，表示对象组合。它包含了一组子对象，这些子对象可以是叶子，也可以是复合。 效果： 组合模式的优点包括： 透明性： 使用组合模式，客户端可以一致地对待单个对象和对象组合，无需关心具体对象的类型。 简化客户端代码： 客户端不需要判断操作的对象是单个对象还是对象组合，从而简化了客户端的代码。 灵活性： 可以很方便地添加新的叶子或复合对象，扩展性较好。 然而，组合模式也可能带来一些限制和权衡，如： 不适合所有情况： 并非所有情况都适合使用组合模式。在一些情况下，可能会引入不必要的复杂性。 可能限制操作： 组合模式可能会限制某些特定对象的操作，因为共同的抽象接口可能无法涵盖所有可能的操作。 综上所述，组合模式适用于处理对象的整体 - 部分关系，并且能够提供一种统一、透明的方式来处理这些对象，从而提高代码的可维护性和扩展性。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// 组件接口interface FileSystemComponent &#123; void displayInfo();&#125;// 叶子节点class File implements FileSystemComponent &#123; private String name; public File(String name) &#123; this.name = name; &#125; public void displayInfo() &#123; System.out.println(&quot;File: &quot; + name); &#125;&#125;// 容器节点class Directory implements FileSystemComponent &#123; private String name; private List&lt;FileSystemComponent&gt; components; public Directory(String name) &#123; this.name = name; components = new ArrayList&lt;&gt;(); &#125; public void addComponent(FileSystemComponent component) &#123; components.add(component); &#125; public void displayInfo() &#123; System.out.println(&quot;Directory: &quot; + name); for (FileSystemComponent component : components) &#123; component.displayInfo(); &#125; &#125;&#125;// 在这个示例中，FileSystemComponent 是组合模式的组件接口，File 是叶子节点类，而 Directory 是容器节点类。// 通过使用这些类，我们可以构建一个具有层次结构的文件系统。// 注意：这只是一个简单的示例，真实的组合模式可能涉及更复杂的场景和更多的功能。public class CompositePatternExample &#123; public static void main(String[] args) &#123; // 创建文件和文件夹 File file1 = new File(&quot;file1.txt&quot;); File file2 = new File(&quot;file2.txt&quot;); Directory subDirectory = new Directory(&quot;Subdirectory&quot;); subDirectory.addComponent(file1); subDirectory.addComponent(file2); Directory rootDirectory = new Directory(&quot;Root&quot;); rootDirectory.addComponent(subDirectory); // 展示文件系统结构 rootDirectory.displayInfo(); &#125;&#125; 9. 装饰模式（Decorator）问题： 在某些情况下，我们需要在不修改现有对象结构的情况下，动态地添加功能或责任。继承在这种情况下可能会导致类爆炸问题，而且修改现有类可能会影响到其他部分的代码。 解决方案： 装饰模式提供了一种在运行时动态地为对象添加新功能的方法，通过创建一个装饰类来包装原始类。装饰类具有与原始类相同的接口，它内部包含一个指向原始对象的引用，并且可以根据需要包装额外的功能。这样，你可以通过组合不同的装饰类来构建出具有不同功能组合的对象。 效果： 装饰模式的优点包括避免了类爆炸问题，因为你可以通过组合少量的装饰类来实现各种功能组合。它也使得功能的增加和修改更加灵活，不会影响到其他部分的代码。然而，装饰模式可能会导致增加很多小型的类，从而增加了代码的复杂性。 在装饰模式中，通常涉及以下角色： 组件（Component）：定义了一个抽象的接口，可以是具体对象或装饰器所共有的接口。 具体组件（Concrete Component）：实现了组件接口，是被装饰的原始对象。 装饰器（Decorator）：持有一个指向组件对象的引用，并实现了组件的接口。它可以包含额外的功能，也可以将请求传递给组件对象。 具体装饰器（Concrete Decorator）：扩展了装饰器类，通过添加额外的功能来装饰具体组件。 通过这种方式，装饰模式允许你将功能嵌套地堆叠在一起，以实现各种不同的功能组合，同时保持代码的灵活性和可维护性。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// 首先定义一个咖啡接口interface Coffee &#123; double cost(); String description();&#125;// 实现基本的咖啡类class SimpleCoffee implements Coffee &#123; @Override public double cost() &#123; return 2.0; &#125; @Override public String description() &#123; return &quot;Simple Coffee&quot;; &#125;&#125;// 创建装饰器抽象类abstract class CoffeeDecorator implements Coffee &#123; protected Coffee decoratedCoffee; public CoffeeDecorator(Coffee coffee) &#123; this.decoratedCoffee = coffee; &#125; @Override public double cost() &#123; return decoratedCoffee.cost(); &#125; @Override public String description() &#123; return decoratedCoffee.description(); &#125;&#125;// 实现具体的装饰器类class MilkDecorator extends CoffeeDecorator &#123; public MilkDecorator(Coffee coffee) &#123; super(coffee); &#125; @Override public double cost() &#123; return super.cost() + 1.0; &#125; @Override public String description() &#123; return super.description() + &quot;, with Milk&quot;; &#125;&#125;class SugarDecorator extends CoffeeDecorator &#123; public SugarDecorator(Coffee coffee) &#123; super(coffee); &#125; @Override public double cost() &#123; return super.cost() + 0.5; &#125; @Override public String description() &#123; return super.description() + &quot;, with Sugar&quot;; &#125;&#125;// 在这个示例中，Coffee 接口定义了基本的咖啡功能。SimpleCoffee 类实现了基本的咖啡。// CoffeeDecorator 是装饰器的抽象类，它维护一个被装饰的咖啡对象。// MilkDecorator 和 SugarDecorator 分别实现了具体的装饰器，通过在原始咖啡上添加新的功能。public class DecoratorPatternExample &#123; public static void main(String[] args) &#123; Coffee simpleCoffee = new SimpleCoffee(); System.out.println(&quot;Cost: $&quot; + simpleCoffee.cost() + &quot;, Description: &quot; + simpleCoffee.description()); Coffee milkCoffee = new MilkDecorator(simpleCoffee); System.out.println(&quot;Cost: $&quot; + milkCoffee.cost() + &quot;, Description: &quot; + milkCoffee.description()); Coffee sugarMilkCoffee = new SugarDecorator(milkCoffee); System.out.println(&quot;Cost: $&quot; + sugarMilkCoffee.cost() + &quot;, Description: &quot; + sugarMilkCoffee.description()); &#125;&#125; 10. 外观模式（Facade）问题： 在软件开发中，系统可能变得非常复杂，包含多个子系统和各种交互。这些子系统之间的依赖关系和调用可能变得混乱，导致系统难以理解、扩展和维护。在这种情况下，我们需要一种方法来提供一个简单的接口，将复杂的子系统调用和依赖关系进行封装，使客户端能够更轻松地与系统进行交互。 解决方案： 外观模式通过引入一个外观类（Facade），将复杂的子系统接口进行封装，为客户端提供一个简单的高层接口。外观类充当了客户端与子系统之间的中间人，处理客户端的请求并将其转发给适当的子系统。外观模式并不在系统中添加新功能，它只是提供了一个更简洁的接口，以简化客户端的操作。 效果： 外观模式的应用可以带来以下效果： 简化接口：客户端只需要与外观类交互，无需了解底层子系统的复杂性。 降低耦合：外观模式将客户端与子系统解耦，使得系统的变化不会影响客户端代码。 提高可维护性：由于外观模式将子系统封装起来，修改子系统的实现不会影响客户端代码，从而提高了系统的可维护性。 支持松散耦合：外观模式可以帮助系统中的不同模块之间实现松散耦合，从而支持模块的独立开发和测试。 总之，外观模式通过提供一个简化的接口，将复杂的子系统封装起来，帮助提高系统的可用性、可维护性和灵活性。它在处理复杂系统的同时，使客户端代码更加清晰和易于理解。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// 子系统：音响class StereoSystem &#123; public void turnOn() &#123; System.out.println(&quot;Stereo System is turned on&quot;); &#125; public void turnOff() &#123; System.out.println(&quot;Stereo System is turned off&quot;); &#125;&#125;// 子系统：投影仪class Projector &#123; public void turnOn() &#123; System.out.println(&quot;Projector is turned on&quot;); &#125; public void turnOff() &#123; System.out.println(&quot;Projector is turned off&quot;); &#125;&#125;// 子系统：灯光控制class LightsControl &#123; public void turnOn() &#123; System.out.println(&quot;Lights are turned on&quot;); &#125; public void turnOff() &#123; System.out.println(&quot;Lights are turned off&quot;); &#125;&#125;// 外观类：家庭影院外观class HomeTheaterFacade &#123; private StereoSystem stereo; private Projector projector; private LightsControl lights; public HomeTheaterFacade() &#123; stereo = new StereoSystem(); projector = new Projector(); lights = new LightsControl(); &#125; public void watchMovie() &#123; System.out.println(&quot;Getting ready to watch a movie...&quot;); lights.turnOff(); projector.turnOn(); stereo.turnOn(); &#125; public void endMovie() &#123; System.out.println(&quot;Ending the movie...&quot;); stereo.turnOff(); projector.turnOff(); lights.turnOn(); &#125;&#125;// HomeTheaterFacade充当了一个外观类，封装了音响、投影仪和灯光控制等子系统的复杂操作，以便客户端可以通过简单的调用来完成观影过程。// 这样，客户端不需要了解各个子系统的具体操作，只需通过外观类的方法来控制整个家庭影院系统的行为。public class FacadeExample &#123; public static void main(String[] args) &#123; HomeTheaterFacade homeTheater = new HomeTheaterFacade(); // 准备观影 homeTheater.watchMovie(); // 结束观影 homeTheater.endMovie(); &#125;&#125; 11. 享元模式（Flyweight）问题： 在某些情况下，一个应用程序可能需要大量相似对象，而这些对象的大部分属性是相同的。在这种情况下，创建大量相似对象会占用大量的内存和系统资源，导致系统性能下降。 解决方案： 享元模式的解决方案是共享对象的状态，以减少内存和资源的消耗。它将对象分为两部分：内部状态（Intrinsic State）和外部状态（Extrinsic State）。内部状态是对象共享的部分，而外部状态是每个对象特有的部分。 享元模式通过一个享元工厂（Flyweight Factory）来管理和创建共享对象。当需要一个对象时，工厂会检查是否已经有相同内部状态的对象存在，如果存在则返回已有的对象，否则创建一个新的对象并将其添加到内部对象池中。 效果： 优点：享元模式可以显著减少内存消耗，因为共享对象的内部状态只有一份。这可以在需要大量相似对象的情况下节省内存。同时，由于共享对象已经存在于池中，创建时间和性能开销也会降低。 权衡：享元模式引入了内部状态和外部状态的区分，这可能增加了系统的复杂性。此外，对内部状态的共享需要考虑线程安全性。 限制：享元模式适用于对象的内部状态相对稳定，而外部状态会变化的情况。如果一个对象的状态完全相同，那么不需要使用享元模式。 可能的后果：通过减少对象的创建和内存占用，系统性能可能会得到提升。但在一些情况下，过度使用享元模式可能会引入不必要的复杂性，因此需要根据具体情况进行权衡。 享元模式在需要大量相似对象的场景中非常有用，例如文字处理软件中的字符对象、图像处理软件中的像素对象等。它可以显著提高系统的性能和资源利用率。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 享元接口interface Shape &#123; void draw(int x, int y);&#125;// 具体享元类class Circle implements Shape &#123; private Color color; public Circle(Color color) &#123; this.color = color; &#125; @Override public void draw(int x, int y) &#123; System.out.println(&quot;Drawing a &quot; + color + &quot; circle at (&quot; + x + &quot;,&quot; + y + &quot;)&quot;); &#125;&#125;// 享元工厂类class ShapeFactory &#123; private static final Map&lt;Color, Shape&gt; circleMap = new HashMap&lt;&gt;(); public static Shape getCircle(Color color) &#123; Shape circle = circleMap.get(color); if (circle == null) &#123; circle = new Circle(color); circleMap.put(color, circle); &#125; return circle; &#125;&#125;// 在这个示例中，我们定义了一个Shape接口和一个具体的Circle类来表示享元对象。// ShapeFactory类负责管理共享的对象池，并通过getCircle方法返回共享的或新创建的圆形对象。// 在main函数中，我们随机选择不同的颜色，并使用ShapeFactory获取对应的圆形对象，然后调用draw方法绘制它们。public class FlyweightPatternExample &#123; public static void main(String[] args) &#123; Color[] colors = &#123;Color.RED, Color.GREEN, Color.BLUE, Color.YELLOW&#125;; for (int i = 0; i &lt; 20; i++) &#123; Color randomColor = colors[(int) (Math.random() * colors.length)]; Shape circle = ShapeFactory.getCircle(randomColor); circle.draw((int) (Math.random() * 100), (int) (Math.random() * 100)); &#125; &#125;&#125; 12. 代理模式（Proxy）问题： 在某些情况下，我们希望通过一个中间代理来控制对某个对象的访问。这可能是因为原始对象的创建或访问涉及复杂的逻辑，或者我们想要在访问原始对象之前或之后执行一些操作。 解决方案： 代理模式提供了一个代理对象，它充当了原始对象的替代品，以控制对原始对象的访问。代理对象与原始对象实现相同的接口，使得客户端可以无缝地切换和使用。代理对象可以对客户端的请求进行拦截、修改或增强，然后将请求传递给原始对象。 效果： 代理模式的应用可以带来多种效果： 远程代理（Remote Proxy）： 代理对象可以隐藏原始对象存在于远程服务器上的事实，使得客户端可以透明地访问远程对象。这对于分布式系统非常有用。 虚拟代理（Virtual Proxy）： 当创建原始对象需要大量资源时，代理对象可以充当一个轻量级的替代品，延迟原始对象的实际创建和初始化，从而提高性能。 保护代理（Protection Proxy）： 代理对象可以控制对原始对象的访问权限，确保只有具有特定权限的客户端可以访问原始对象。 缓存代理（Cache Proxy）： 代理对象可以缓存原始对象的结果，以便在后续相同请求时能够直接返回缓存的结果，减少重复计算。 日志记录代理（Logging Proxy）： 代理对象可以在访问原始对象之前或之后记录日志，用于调试、监控或审计。 总之，代理模式允许我们在不改变原始对象的情况下，通过引入代理对象来添加额外的控制和功能。这有助于提高代码的可维护性、可扩展性和灵活性。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 图像接口interface Image &#123; void display();&#125;// 真实图像类class RealImage implements Image &#123; private String filename; public RealImage(String filename) &#123; this.filename = filename; loadImageFromDisk(); &#125; private void loadImageFromDisk() &#123; System.out.println(&quot;Loading image from disk: &quot; + filename); &#125; public void display() &#123; System.out.println(&quot;Displaying image: &quot; + filename); &#125;&#125;// 代理图像类class ProxyImage implements Image &#123; private RealImage realImage; private String filename; public ProxyImage(String filename) &#123; this.filename = filename; &#125; public void display() &#123; if (realImage == null) &#123; realImage = new RealImage(filename); &#125; realImage.display(); &#125;&#125;// 在这个示例中，Image接口定义了display方法，RealImage是实际的图像加载类，而ProxyImage是代理图像类。// 当ProxyImage的display方法被调用时，它会在需要时创建一个RealImage实例，并调用其display方法。public class ProxyPatternExample &#123; public static void main(String[] args) &#123; Image image = new ProxyImage(&quot;sample.jpg&quot;); // 图像未加载，直到调用display()方法 image.display(); // 图像已加载，无需再次创建 image.display(); &#125;&#125; 13. 解释器模式（Interpreter）问题： 在某些情况下，你可能需要解释和处理一种特定语言或表达式。这可能涉及到解析、分析和执行这些语言或表达式，但在每个具体情况下，解释的方式都可能不同。 解决方案： 解释器模式通过定义一种语言文法的表示，并提供一种解释器来解释这种语言的语句。这样，你可以将语句表示为抽象语法树，然后通过解释器逐步执行和解释这个语法树。 抽象表达式（Abstract Expression）：定义了一个抽象的解释方法，所有的具体表达式都需要实现这个接口。 终结符表达式（Terminal Expression）：实现了抽象表达式接口，用于表示语言中的终结符（最小的语法单元）。 非终结符表达式（Non-terminal Expression）：实现了抽象表达式接口，用于表示语言中的非终结符，通常由多个终结符和 / 或其他非终结符组成的组合。 上下文（Context）：包含了需要被解释的信息，通常包括输入的语句和解释器。 解释器（Interpreter）：包含了解释器模式的主要逻辑，它通过递归的方式对抽象语法树进行解释，实现了语言中各种语句的解释和执行。 效果： 解释器模式的使用可以使你更容易地实现特定语言的解释和执行，尤其在处理自定义的领域特定语言（DSL）时非常有用。然而，解释器模式可能导致类的数量增加，因为每个语法规则都需要一个相应的表达式类。此外，解释器模式可能会对性能产生影响，特别是在处理复杂语法时。 总之，解释器模式适用于需要解释和处理特定语言或表达式的情况，它通过将语句表示为抽象语法树并提供解释器来执行解释。这有助于实现定制的语言处理逻辑。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// 表达式接口interface Expression &#123; int interpret();&#125;// 数字表达式类class NumberExpression implements Expression &#123; private int value; public NumberExpression(int value) &#123; this.value = value; &#125; @Override public int interpret() &#123; return value; &#125;&#125;// 加法表达式类class AddExpression implements Expression &#123; private Expression leftOperand; private Expression rightOperand; public AddExpression(Expression leftOperand, Expression rightOperand) &#123; this.leftOperand = leftOperand; this.rightOperand = rightOperand; &#125; @Override public int interpret() &#123; return leftOperand.interpret() + rightOperand.interpret(); &#125;&#125;// 减法表达式类class SubtractExpression implements Expression &#123; private Expression leftOperand; private Expression rightOperand; public SubtractExpression(Expression leftOperand, Expression rightOperand) &#123; this.leftOperand = leftOperand; this.rightOperand = rightOperand; &#125; @Override public int interpret() &#123; return leftOperand.interpret() - rightOperand.interpret(); &#125;&#125;// 在这个示例中，我们构建了一个简单的数学表达式解释器，用于解释并计算基本的加法和减法表达式。// 这展示了解释器模式如何工作，将表达式解释成实际的结果。// 在实际应用中，解释器模式可以用于更复杂的领域，如编程语言解释器或规则引擎。public class InterpreterPatternExample &#123; public static void main(String[] args) &#123; // 构建表达式：2 + (3 - 1) Expression expression = new AddExpression( new NumberExpression(2), new SubtractExpression( new NumberExpression(3), new NumberExpression(1) ) ); // 解释并计算表达式的值 int result = expression.interpret(); System.out.println(&quot;Result: &quot; + result); // 输出: Result: 4 &#125;&#125; 14. 模板方法模式（Template Method）问题： 当你在设计一个类或一组类时，发现有一些算法的结构是固定的，但其中的某些步骤可能会因应用情境或子类的不同而变化。你希望将这个算法的核心结构固定下来，但留出一些灵活性来允许特定步骤的定制。 解决方案： 模板方法模式通过定义一个抽象的父类，其中包含了算法的核心结构，但某些步骤使用抽象方法或受保护的虚拟方法来表示，这些方法由子类来实现。这使得子类可以根据需要重写特定的步骤，而核心算法结构保持不变。父类中的模板方法调用这些步骤，确保算法的整体流程一致。 效果： 模板方法模式的效果包括： 代码复用： 核心算法结构在父类中定义，可以被多个子类共享，避免了重复的代码。 灵活性： 子类可以通过实现特定的步骤来定制算法的行为，而不需要改变算法的整体结构。 可维护性： 将算法的核心结构集中在一个地方，易于维护和修改。 代码一致性： 所有子类共享相同的算法模板，确保了算法的一致性。 示例： 想象你正在设计一个咖啡和茶的准备流程。虽然两者的基本步骤相似（烧水、冲泡、添加调味品等），但是每种饮料的具体步骤略有不同。你可以使用模板方法模式来创建一个饮料准备的抽象类，其中包含烧水、冲泡和倒入杯中等通用步骤，但将冲泡的细节留给子类来实现（如茶类和咖啡类）。 这样，你就能在不改变整体流程的情况下，让不同的饮料类定制它们的冲泡过程。这遵循了模板方法模式的思想，将共享的算法结构与可变的部分分离，以便实现代码的重用和灵活性。 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 模板类abstract class AbstractClass &#123; // 模板方法，定义算法的骨架 public void templateMethod() &#123; step1(); step2(); step3(); &#125; // 基本方法，子类需要实现 abstract void step1(); abstract void step2(); abstract void step3();&#125;// 具体子类实现class ConcreteClass extends AbstractClass &#123; @Override void step1() &#123; System.out.println(&quot;ConcreteClass: Step 1&quot;); &#125; @Override void step2() &#123; System.out.println(&quot;ConcreteClass: Step 2&quot;); &#125; @Override void step3() &#123; System.out.println(&quot;ConcreteClass: Step 3&quot;); &#125;&#125;// 在上面的示例中，AbstractClass 是模板类，定义了一个包含三个步骤的模板方法 templateMethod// 这些步骤由抽象方法 step1、step2 和 step3 构成。ConcreteClass 是具体子类，继承自 AbstractClass，它实现了基本方法来完成每个步骤的具体行为。// 在 main 方法中，我们创建了一个 ConcreteClass 实例并调用了 templateMethod，这会按照模板的结构执行具体的步骤。public class TemplateMethodExample &#123; public static void main(String[] args) &#123; AbstractClass template = new ConcreteClass(); template.templateMethod(); &#125;&#125; 15. 责任链模式（Chain of Responsibility）问题： 在某些情况下，一个请求需要在多个对象之间传递，每个对象都可能处理该请求或将其传递给下一个对象。在这种情况下，需要避免将发送者与接收者之间的耦合，以及确定请求的处理方式。问题在于如何设计一个机制，使得多个对象都有机会处理请求，而且可以根据需要动态地改变它们之间的顺序和职责。 解决方案： 责任链模式提供了一种通过一系列处理对象来处理请求的方法。每个处理对象都包含一个对下一个处理对象的引用，形成一个链式结构。当一个请求到达时，它首先被传递给链中的第一个处理对象，如果该对象不能处理该请求，它会将请求传递给下一个处理对象，依此类推，直到找到能够处理请求的对象为止。 责任链模式的解决方案包括以下关键点： 定义一个抽象处理者（Handler）类，该类包含一个对下一个处理者的引用，并声明一个处理请求的方法。 具体的处理者类继承自抽象处理者类，实现处理请求的方法。在该方法中，处理者可以决定是否处理请求，如果不能处理，则将请求传递给下一个处理者。 客户端创建一个处理链，将处理者按照一定的顺序连接起来。 效果： 责任链模式的应用可以带来多个效果： 降低耦合度：发送者不需要知道哪个对象会处理请求，只需将请求发送到链的起始点。 灵活性：可以根据需要动态地改变处理链中处理者的顺序，以及每个处理者的职责。 可扩展性：可以很容易地添加新的处理者，而不会影响现有代码。 可维护性：每个处理者关注单一的责任，使得代码更易于理解和维护。 然而，责任链模式也有一些潜在的限制，比如可能导致请求无法被处理或者处理链太长而导致性能问题。因此，在使用责任链模式时需要谨慎权衡权衡利弊。 总之，责任链模式是一种有助于将请求与处理者解耦，并支持动态调整处理顺序和职责的设计模式。 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// 首先，我们需要创建一个表示请求的类 ReimbursementRequestpublic class ReimbursementRequest &#123; private double amount; private String description; public ReimbursementRequest(double amount, String description) &#123; this.amount = amount; this.description = description; &#125; public double getAmount() &#123; return amount; &#125; public String getDescription() &#123; return description; &#125;&#125;// 然后，创建一个抽象处理者类 ReimbursementHandlerpublic abstract class ReimbursementHandler &#123; protected ReimbursementHandler successor; public void setSuccessor(ReimbursementHandler successor) &#123; this.successor = successor; &#125; public abstract void handleRequest(ReimbursementRequest request);&#125;// 接下来，实现具体的处理者类：经理、部门主管和财务部门处理者。public class ManagerHandler extends ReimbursementHandler &#123; @Override public void handleRequest(ReimbursementRequest request) &#123; if (request.getAmount() &lt;= 1000) &#123; System.out.println(&quot;经理处理报销请求：&quot; + request.getDescription()); &#125; else if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125;public class DepartmentHeadHandler extends ReimbursementHandler &#123; @Override public void handleRequest(ReimbursementRequest request) &#123; if (request.getAmount() &lt;= 5000) &#123; System.out.println(&quot;部门主管处理报销请求：&quot; + request.getDescription()); &#125; else if (successor != null) &#123; successor.handleRequest(request); &#125; &#125;&#125;public class FinanceHandler extends ReimbursementHandler &#123; @Override public void handleRequest(ReimbursementRequest request) &#123; System.out.println(&quot;财务部门处理报销请求：&quot; + request.getDescription()); &#125;&#125;// 在这个示例中，报销请求会依次被经理、部门主管和财务部门处理。根据报销金额的不同，请求会被传递到适当的处理者。public class Main &#123; public static void main(String[] args) &#123; ReimbursementHandler manager = new ManagerHandler(); ReimbursementHandler departmentHead = new DepartmentHeadHandler(); ReimbursementHandler finance = new FinanceHandler(); manager.setSuccessor(departmentHead); departmentHead.setSuccessor(finance); ReimbursementRequest request1 = new ReimbursementRequest(800, &quot;购买办公用品&quot;); ReimbursementRequest request2 = new ReimbursementRequest(3000, &quot;参加培训&quot;); ReimbursementRequest request3 = new ReimbursementRequest(10000, &quot;举办团建活动&quot;); manager.handleRequest(request1); manager.handleRequest(request2); manager.handleRequest(request3); &#125;&#125; 16. 命令模式（Command）问题： 在某些情况下，你希望将请求发送者与接收者解耦，从而允许您以不同的方式组织和处理请求。例如，您可能希望将请求排队、记录、撤消或重做，而无需修改发送者和接收者之间的代码。 解决方案： 命令模式提供了一种将请求封装成对象的方法，使得请求的发送者与请求的接收者之间不直接耦合。这通过引入以下角色实现： 命令（Command）：抽象命令类，定义了执行命令的接口。它通常包含一个执行方法，以及可能的其他方法（例如，撤消）。 具体命令（Concrete Command）：实现了抽象命令类的具体子类，将一个接收者与一个动作绑定。它实现了执行方法，该方法调用接收者的特定操作。 接收者（Receiver）：执行实际工作的类。命令模式将命令传递给接收者，由接收者执行实际的操作。 调用者 / 请求者（Invoker）：负责将命令传递给合适的接收者并触发命令的执行。它并不关心具体的命令细节。 客户端（Client）：创建命令对象、接收者对象以及调用者对象，并将它们组织起来以实现特定的操作流程。 效果： 命令模式的效果在于解耦命令的发送者和接收者，从而支持更灵活的代码组织。它允许您轻松地添加新的命令，排队命令，记录命令历史，甚至实现撤消和重做功能。然而，命令模式也可能引入一些复杂性，因为您需要为每个操作创建一个具体命令类。 总的来说，命令模式在需要解耦请求发送者和接收者，并支持灵活的命令处理时非常有用。它在菜单系统、GUI 操作、多级撤销等场景中得到广泛应用。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// 命令接口interface Command &#123; void execute();&#125;// 具体命令：控制电灯打开class LightOnCommand implements Command &#123; private Light light; public LightOnCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.turnOn(); &#125;&#125;// 具体命令：控制电灯关闭class LightOffCommand implements Command &#123; private Light light; public LightOffCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; light.turnOff(); &#125;&#125;// 电灯类class Light &#123; void turnOn() &#123; System.out.println(&quot;Light is on&quot;); &#125; void turnOff() &#123; System.out.println(&quot;Light is off&quot;); &#125;&#125;// 遥控器类class RemoteControl &#123; private Command command; public void setCommand(Command command) &#123; this.command = command; &#125; public void pressButton() &#123; command.execute(); &#125;&#125;// 在这个示例中，我们使用命令模式创建了两种具体的命令：打开电灯和关闭电灯。// 遥控器可以设置不同的命令，然后按下按钮触发相应的操作。// 这样，命令发送者（遥控器）和命令接收者（电灯）之间实现了解耦。public class CommandPatternExample &#123; public static void main(String[] args) &#123; Light livingRoomLight = new Light(); LightOnCommand livingRoomLightOn = new LightOnCommand(livingRoomLight); LightOffCommand livingRoomLightOff = new LightOffCommand(livingRoomLight); RemoteControl remote = new RemoteControl(); remote.setCommand(livingRoomLightOn); remote.pressButton(); // 打开电灯 remote.setCommand(livingRoomLightOff); remote.pressButton(); // 关闭电灯 &#125;&#125; 17. 迭代器模式（Iterator）问题： 在软件开发中，经常需要遍历集合（如列表、数组、树等）中的元素，但不同集合可能有不同的遍历方式，这导致在客户端代码中需要编写不同的遍历逻辑，使代码变得复杂且难以维护。此外，有时候还需要在遍历过程中支持添加、删除等操作，这可能会影响遍历的一致性和正确性。 解决方案： 迭代器模式提供了一种统一的方法来遍历不同类型的集合，而无需暴露集合内部的表示细节。它包括两个主要组件：迭代器和集合。迭代器负责遍历集合并提供统一的访问接口，而集合负责实际存储元素。迭代器和集合之间的解耦使得可以独立地改变它们的实现，而不会影响到客户端代码。 效果： 优点：迭代器模式将遍历操作封装在迭代器中，使客户端代码更加简洁、可读，并且降低了与集合的耦合。它也提供了支持多种遍历方式的灵活性，如正向遍历、逆向遍历等。 权衡：迭代器模式可能会增加一些额外的类和接口，可能会稍微增加复杂性，但从长远来看，可以提高代码的可维护性和可扩展性。 限制：迭代器模式并不适用于所有情况。在一些简单的情况下，直接使用语言内置的遍历机制可能更为方便。 总之，迭代器模式提供了一种解决集合遍历问题的通用方法，使得代码更具结构和可维护性。它在各种编程语言和应用中都有广泛的应用。 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768// 定义一个可迭代的集合接口interface IterableCollection&lt;T&gt; &#123; Iterator&lt;T&gt; createIterator();&#125;// 具体的集合类实现可迭代的集合接口class ConcreteCollection&lt;T&gt; implements IterableCollection&lt;T&gt; &#123; private List&lt;T&gt; items = new ArrayList&lt;&gt;(); public void addItem(T item) &#123; items.add(item); &#125; @Override public Iterator&lt;T&gt; createIterator() &#123; return new ConcreteIterator&lt;&gt;(items); &#125;&#125;// 定义迭代器接口interface Iterator&lt;T&gt; &#123; boolean hasNext(); T next();&#125;// 具体迭代器实现迭代器接口class ConcreteIterator&lt;T&gt; implements Iterator&lt;T&gt; &#123; private List&lt;T&gt; items; private int position = 0; public ConcreteIterator(List&lt;T&gt; items) &#123; this.items = items; &#125; @Override public boolean hasNext() &#123; return position &lt; items.size(); &#125; @Override public T next() &#123; if (hasNext()) &#123; T item = items.get(position); position++; return item; &#125; throw new IndexOutOfBoundsException(&quot;No more elements&quot;); &#125;&#125;// 在这个示例中，我们定义了一个IterableCollection接口来表示可迭代的集合，一个具体的集合类ConcreteCollection实现了这个接口，并提供了一个用于创建迭代器的方法。// 迭代器接口Iterator定义了hasNext和next方法，具体的迭代器类ConcreteIterator实现了这个接口，并通过内部的位置追踪来遍历集合。public class IteratorPatternExample &#123; public static void main(String[] args) &#123; ConcreteCollection&lt;String&gt; collection = new ConcreteCollection&lt;&gt;(); collection.addItem(&quot;Item 1&quot;); collection.addItem(&quot;Item 2&quot;); collection.addItem(&quot;Item 3&quot;); Iterator&lt;String&gt; iterator = collection.createIterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; &#125;&#125; 18. 中介者模式（Mediator）问题： 在一个系统中，对象之间的通信可能会变得复杂，导致对象之间相互依赖，难以管理和维护。当对象之间的通信变得混乱时，就需要一个方法来将通信逻辑集中管理，从而减少耦合度并提高系统的可维护性。 解决方案： 中介者模式引入了一个中介者对象，它负责协调和管理对象之间的通信。对象不再直接与其他对象通信，而是通过中介者来发送和接收消息。这样一来，对象只需要关注自己的职责，而不需要了解其他对象的详细信息。中介者模式的核心思想是将复杂的交互逻辑集中到一个地方，以便更好地管理和调整。 效果： 降低耦合度：对象之间的通信逻辑被集中在中介者中，从而降低了对象之间的直接依赖，减少了耦合度，使系统更加灵活和可维护。 集中管理：所有对象的交互逻辑都集中在中介者中，使得系统的交互逻辑更加清晰可见，便于管理和修改。 复用性：中介者模式将交互逻辑与对象本身的业务逻辑分离，可以更容易地复用这些交互逻辑。 可扩展性：通过增加或修改中介者对象，可以相对容易地扩展系统，而不需要修改对象之间的通信逻辑。 需要注意的是，中介者模式可能会引入一个单一的中心化点，如果设计不当，可能会导致中介者对象本身变得过于复杂。因此，在使用中介者模式时，需要权衡考虑系统的复杂性和灵活性。 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 中介者接口interface ChatMediator &#123; void sendMessage(String message, User user); void addUser(User user);&#125;// 具体中介者类class ConcreteChatMediator implements ChatMediator &#123; private List&lt;User&gt; users = new ArrayList&lt;&gt;(); @Override public void sendMessage(String message, User user) &#123; for (User u : users) &#123; if (u != user) &#123; u.receiveMessage(message); &#125; &#125; &#125; @Override public void addUser(User user) &#123; users.add(user); &#125;&#125;// 用户类class User &#123; private String name; private ChatMediator mediator; public User(String name, ChatMediator mediator) &#123; this.name = name; this.mediator = mediator; &#125; public void sendMessage(String message) &#123; System.out.println(name + &quot; 发送消息: &quot; + message); mediator.sendMessage(message, this); &#125; public void receiveMessage(String message) &#123; System.out.println(name + &quot; 收到消息: &quot; + message); &#125;&#125;// 在这个示例中，ConcreteChatMediator 实现了 ChatMediator 接口，并管理用户列表。// 每个用户对象在构造时都传递了中介者实例，以便用户可以使用中介者发送和接收消息。public class MediatorPatternExample &#123; public static void main(String[] args) &#123; ConcreteChatMediator chatMediator = new ConcreteChatMediator(); User user1 = new User(&quot;Alice&quot;, chatMediator); User user2 = new User(&quot;Bob&quot;, chatMediator); User user3 = new User(&quot;Charlie&quot;, chatMediator); chatMediator.addUser(user1); chatMediator.addUser(user2); chatMediator.addUser(user3); user1.sendMessage(&quot;大家好！&quot;); user2.sendMessage(&quot;你好，Alice！&quot;); &#125;&#125; 19. 备忘录模式（Memento）问题： 在软件设计中，经常会遇到需要记录一个对象的内部状态，并在需要时能够回滚到先前的状态。这可能是为了实现撤销操作、历史记录功能等。 解决方案： 备忘录模式通过引入 “备忘录” 对象，允许在不暴露对象内部结构的情况下，捕获并存储对象的状态。同时，它还提供了一种将对象恢复到之前状态的方式。备忘录模式包括以下角色： Originator（发起人）：这是需要被记录状态的对象。它创建一个备忘录对象，以存储当前状态，也可以从备忘录中恢复状态。 Memento（备忘录）：备忘录对象用于存储 Originator 的状态。通常，备忘录对象具有与原始对象相同的接口，但不会直接暴露其内部状态。 Caretaker（负责人）：负责管理备忘录对象。它可以存储多个备忘录对象，以便在需要时进行状态恢复。 效果： 备忘录模式使得对象的状态管理更加灵活。它允许对象在不暴露其内部结构的情况下进行状态的保存和恢复。这有助于实现撤销和重做功能，以及历史记录和快照功能。然而，使用备忘录模式可能会增加一些内存开销，特别是如果需要存储大量的状态历史。 总之，备忘录模式在需要记录和恢复对象状态的情况下是一个有用的设计模式。它可以帮助保持代码的清晰性和可维护性，同时提供强大的状态管理功能。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// 备忘录类class Memento &#123; private String state; public Memento(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125;&#125;// 原始对象类class Originator &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public Memento createMemento() &#123; return new Memento(state); &#125; public void restoreMemento(Memento memento) &#123; state = memento.getState(); &#125;&#125;// 管理者类class Caretaker &#123; private Memento memento; public Memento getMemento() &#123; return memento; &#125; public void setMemento(Memento memento) &#123; this.memento = memento; &#125;&#125;// 在这个示例中，Originator 类表示原始对象，它具有状态并能够创建和恢复备忘录。// Memento 类表示备忘录对象，保存了特定时刻的状态。Caretaker 类负责保存和获取备忘录对象。// 通过设置初始状态、创建备忘录、修改状态、然后恢复状态，我们可以看到备忘录模式的工作方式。public class MementoPatternExample &#123; public static void main(String[] args) &#123; Originator originator = new Originator(); Caretaker caretaker = new Caretaker(); // 设置初始状态 originator.setState(&quot;State 1&quot;); System.out.println(&quot;Current State: &quot; + originator.getState()); // 创建备忘录并保存状态 caretaker.setMemento(originator.createMemento()); // 修改状态 originator.setState(&quot;State 2&quot;); System.out.println(&quot;Updated State: &quot; + originator.getState()); // 恢复之前的状态 originator.restoreMemento(caretaker.getMemento()); System.out.println(&quot;Restored State: &quot; + originator.getState()); &#125;&#125; 20. 观察者模式（Observer）问题： 在软件设计中，经常会遇到这样的情况：一个对象（主题）的状态发生改变，而其他对象（观察者）需要在状态改变时得到通知并进行相应的更新。但是，如果直接在对象之间建立硬编码的依赖关系，会导致系统的耦合度增加，难以维护和扩展。观察者模式试图解决这个问题，允许主题和观察者之间的松耦合通信。 解决方案： 观察者模式的核心思想是定义一种一对多的依赖关系，使得一个主题（通常称为被观察者）可以同时维护多个观察者，并在其状态改变时自动通知所有观察者。这样，观察者无需关心主题的内部实现细节，而只需要关心主题的状态变化。在实现中，通常会定义一个抽象的主题类和一个抽象的观察者类，具体的主题和观察者类会继承这些抽象类并实现相应的方法。 效果： 观察者模式的应用有以下优点： 松耦合：主题和观察者之间的耦合度降低，使得它们可以独立地进行变化。 可扩展性：可以方便地增加新的观察者，而不会影响到已有的观察者和主题。 自动通知：主题状态改变时会自动通知观察者，减少手动维护通知的工作。 可重用性：主题和观察者可以在不同的场景中重复使用。 然而，观察者模式也有一些限制和权衡： 可能引起性能问题：如果观察者过多或通知机制不合理，可能会导致性能下降。 更新顺序问题：观察者的更新顺序可能会影响到系统的行为，需要特别注意。 过度使用的风险：并不是所有的状态变化都适合使用观察者模式，过度使用可能导致代码复杂化。 总之，观察者模式是一种用于解决对象间状态通知和更新的重要设计模式，它在许多软件系统中都有广泛的应用。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import java.util.ArrayList;import java.util.List;// 主题接口interface Subject &#123; void addObserver(Observer observer); void removeObserver(Observer observer); void notifyObservers();&#125;// 具体主题类class ConcreteSubject implements Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); private int state; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; notifyObservers(); &#125; @Override public void addObserver(Observer observer) &#123; observers.add(observer); &#125; @Override public void removeObserver(Observer observer) &#123; observers.remove(observer); &#125; @Override public void notifyObservers() &#123; for (Observer observer : observers) &#123; observer.update(state); &#125; &#125;&#125;// 观察者接口interface Observer &#123; void update(int state);&#125;// 具体观察者类class ConcreteObserver implements Observer &#123; private String name; public ConcreteObserver(String name) &#123; this.name = name; &#125; @Override public void update(int state) &#123; System.out.println(name + &quot; 收到更新，新状态为: &quot; + state); &#125;&#125;// 在这个示例中，ConcreteSubject 充当主题（被观察者），ConcreteObserver 充当观察者。// 主题维护一个观察者列表，并在状态变化时通知所有观察者。// 当主题的状态发生变化时，所有观察者都会被通知并更新自己的状态。public class ObserverPatternExample &#123; public static void main(String[] args) &#123; ConcreteSubject subject = new ConcreteSubject(); Observer observer1 = new ConcreteObserver(&quot;观察者1&quot;); Observer observer2 = new ConcreteObserver(&quot;观察者2&quot;); subject.addObserver(observer1); subject.addObserver(observer2); subject.setState(10); subject.setState(20); subject.removeObserver(observer1); subject.setState(30); &#125;&#125; 21. 状态模式（State）问题： 当一个对象的行为在不同状态下发生改变，并且对象需要根据其状态执行不同的操作时，就可以考虑使用状态模式。在这种情况下，如果直接在对象内部实现所有状态之间的切换逻辑，会导致代码变得复杂且难以维护。 解决方案： 状态模式的解决方案是将对象的状态抽象成独立的状态类，每个状态类都实现了一组特定状态下的操作。然后，上下文对象（即包含状态的对象）维护一个指向当前状态的引用，通过委托给当前状态的方法来执行操作。这种方式可以将不同状态下的行为逻辑分隔开来，使得状态变化时的代码修改更加容易。 效果： 使用状态模式可以实现以下效果： 清晰的状态切换： 状态模式将每个状态的行为集中在各自的状态类中，使得状态切换的逻辑变得清晰，易于管理和修改。 可维护性： 将状态相关的代码分布在不同的状态类中，使得代码更加模块化和可维护。 扩展性： 添加新的状态只需要创建新的状态类并实现相关操作，不会影响到其他状态类或上下文类的代码。 避免条件语句： 状态模式避免了大量的条件语句，从而提高了代码的可读性和可维护性。 复用性： 状态类之间的逻辑可以被复用，因为它们是独立的实体。 总之，状态模式使得对象在不同状态下能够更加灵活地切换行为，同时保持了代码的可维护性和可扩展性。它在需要处理复杂状态逻辑的情况下特别有用。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899// 状态接口interface ElevatorState &#123; void openDoors(); void closeDoors(); void move(); void stop();&#125;// 具体状态类：开门状态class OpenState implements ElevatorState &#123; @Override public void openDoors() &#123; System.out.println(&quot;Doors are already open.&quot;); &#125; @Override public void closeDoors() &#123; System.out.println(&quot;Closing doors.&quot;); &#125; @Override public void move() &#123; System.out.println(&quot;Cannot move while doors are open.&quot;); &#125; @Override public void stop() &#123; System.out.println(&quot;Stopping while doors are open.&quot;); &#125;&#125;// 具体状态类：关门状态class CloseState implements ElevatorState &#123; @Override public void openDoors() &#123; System.out.println(&quot;Opening doors.&quot;); &#125; @Override public void closeDoors() &#123; System.out.println(&quot;Doors are already closed.&quot;); &#125; @Override public void move() &#123; System.out.println(&quot;Moving.&quot;); &#125; @Override public void stop() &#123; System.out.println(&quot;Stopping.&quot;); &#125;&#125;// 上下文类：电梯class Elevator &#123; private ElevatorState state; public Elevator() &#123; state = new CloseState(); // 初始状态为关门状态 &#125; public void setState(ElevatorState state) &#123; this.state = state; &#125; public void openDoors() &#123; state.openDoors(); &#125; public void closeDoors() &#123; state.closeDoors(); &#125; public void move() &#123; state.move(); &#125; public void stop() &#123; state.stop(); &#125;&#125;// 在这个示例中，我们创建了一个模拟电梯系统，其中有开门状态和关门状态两个具体状态类，以及电梯类作为上下文类。// 通过切换状态，电梯在不同状态下有不同的行为表现。这就是状态模式的基本思想。public class StatePatternExample &#123; public static void main(String[] args) &#123; Elevator elevator = new Elevator(); elevator.openDoors(); // 当前状态：开门 elevator.move(); // 当前状态：开门，无法移动 elevator.closeDoors(); // 当前状态：关门 elevator.move(); // 当前状态：移动中 elevator.stop(); // 当前状态：停止 elevator.openDoors(); // 当前状态：开门 &#125;&#125; 22. 策略模式（Strategy）问题： 在某些情况下，一个软件系统可能需要根据不同的情境或条件使用不同的算法或行为，但是这些算法的选择和使用可能会频繁变化。如果将这些算法都硬编码在主要的类中，会导致代码的臃肿不堪，难以维护和扩展。需要一种方式来灵活地选择和切换不同的算法，同时又不影响到客户端代码。 解决方案： 策略模式提供了一种定义一系列算法的方法，将这些算法封装成独立的策略类，并使它们可以相互替换。在客户端中，创建一个上下文（Context）对象，该对象包含一个对策略类的引用，通过该引用调用相应的策略方法。这样，客户端可以在运行时选择不同的策略，而不需要修改上下文类。 效果： 策略模式的主要优点是实现了算法的解耦，使得算法可以独立于客户端而变化。它提高了代码的可维护性和扩展性，因为新的策略可以很容易地添加到系统中。然而，策略模式也可能导致类的数量增加，因为每个算法都需要一个对应的策略类。在使用策略模式时，需要权衡类的数量与灵活性之间的关系。 总之，策略模式是一种非常有用的设计模式，特别适用于需要根据情境灵活选择不同算法或行为的场景，帮助保持代码的结构清晰且易于维护。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// 首先，我们定义一个接口 MathOperation，表示数学操作的策略// 定义策略接口interface MathOperation &#123; int operate(int a, int b);&#125;// 实现加法策略class Addition implements MathOperation &#123; @Override public int operate(int a, int b) &#123; return a + b; &#125;&#125;// 实现减法策略class Subtraction implements MathOperation &#123; @Override public int operate(int a, int b) &#123; return a - b; &#125;&#125;// 实现乘法策略class Multiplication implements MathOperation &#123; @Override public int operate(int a, int b) &#123; return a * b; &#125;&#125;// 然后，我们创建一个 Calculator 类，它接受一个数学操作策略，并根据用户的选择执行相应的操作class Calculator &#123; private MathOperation operation; public void setOperation(MathOperation operation) &#123; this.operation = operation; &#125; public int performOperation(int a, int b) &#123; if (operation != null) &#123; return operation.operate(a, b); &#125; throw new IllegalStateException(&quot;No operation set&quot;); &#125;&#125;// 在这个示例中，我们通过创建不同的数学操作策略类来实现加法、减法和乘法功能，并通过设置不同的策略来执行不同的操作。这就是策略模式的基本思想。public class StrategyPatternExample &#123; public static void main(String[] args) &#123; Calculator calculator = new Calculator(); calculator.setOperation(new Addition()); int result1 = calculator.performOperation(5, 3); System.out.println(&quot;Addition Result: &quot; + result1); calculator.setOperation(new Subtraction()); int result2 = calculator.performOperation(10, 4); System.out.println(&quot;Subtraction Result: &quot; + result2); calculator.setOperation(new Multiplication()); int result3 = calculator.performOperation(6, 2); System.out.println(&quot;Multiplication Result: &quot; + result3); &#125;&#125; 23. 访问者模式（Visitor）问题： 在面向对象设计中，当一个对象结构中的元素类（例如，不同类型的对象）需要进行多种不同的操作时，常常会导致操作与元素的类相耦合，从而难以扩展新的操作而不影响现有的类。此外，每次添加新的操作都需要修改已存在的元素类。 解决方案： 访问者模式提出了一种解决方案，使得可以在不修改元素类的情况下，将操作从元素类中分离出来。它的核心思想是引入一个称为 “访问者” 的接口或类，该访问者包含了多个访问操作，每个操作对应一个元素类。元素类接受访问者，从而将自身传递给访问者，使得访问者可以对元素执行相应的操作。 效果： 分离关注点：访问者模式将元素类与具体操作分离，使得每个类可以专注于自身的职责，而操作则由访问者来实现。 易于扩展：添加新的操作只需要增加一个新的访问者，不需要修改已存在的元素类，因此对系统的扩展更加容易。 可维护性：由于每个操作被封装在独立的访问者中，使得代码更加清晰、易于维护。 灵活性：可以在不修改元素类的情况下，动态地添加新的操作。 不适用于频繁变化的元素类：如果元素类经常发生变化，会导致频繁修改访问者接口和实现。 总之，访问者模式适用于需要对一组不同类型的对象执行多种不同操作的情况。它在维护、扩展和修改代码时提供了更好的灵活性和可维护性。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687// 首先，我们需要定义图形形状的接口和具体类// 图形形状接口interface Shape &#123; void accept(ShapeVisitor visitor);&#125;// 圆形类class Circle implements Shape &#123; private double radius; public Circle(double radius) &#123; this.radius = radius; &#125; public double getRadius() &#123; return radius; &#125; @Override public void accept(ShapeVisitor visitor) &#123; visitor.visit(this); &#125;&#125;// 矩形类class Rectangle implements Shape &#123; private double width; private double height; public Rectangle(double width, double height) &#123; this.width = width; this.height = height; &#125; public double getWidth() &#123; return width; &#125; public double getHeight() &#123; return height; &#125; @Override public void accept(ShapeVisitor visitor) &#123; visitor.visit(this); &#125;&#125;// 接下来，定义一个访问者接口和具体的访问者实现// 访问者接口interface ShapeVisitor &#123; void visit(Circle circle); void visit(Rectangle rectangle);&#125;// 面积计算访问者class AreaCalculator implements ShapeVisitor &#123; private double area; @Override public void visit(Circle circle) &#123; area += Math.PI * circle.getRadius() * circle.getRadius(); &#125; @Override public void visit(Rectangle rectangle) &#123; area += rectangle.getWidth() * rectangle.getHeight(); &#125; public double getArea() &#123; return area; &#125;&#125;// 在这个示例中，访问者模式允许我们在不修改形状类的情况下，通过实现不同的访问者来执行不同的操作，例如计算面积。// 这样，我们可以轻松地添加新的访问者来执行其他操作，同时保持形状类的不变。public class VisitorPatternExample &#123; public static void main(String[] args) &#123; Circle circle = new Circle(5); Rectangle rectangle = new Rectangle(4, 6); AreaCalculator areaCalculator = new AreaCalculator(); circle.accept(areaCalculator); rectangle.accept(areaCalculator); System.out.println(&quot;Total area: &quot; + areaCalculator.getArea()); &#125;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"finalshell样式配置","path":"/2024/08/01/2024080102/","content":"finalshell 右边 三横-查看-取消侧边和下边显示","tags":["笔记"],"categories":["其他"]},{"title":"MyBatisCodeHelperPro生成代码","path":"/2024/08/01/20240801/","content":"MyBatisCodeHelperPro安装参考 破解版的可能会有一点问题，不用的时候可以在：文件-设置-插件-已安装插件中搜索MyBatisCodeHelperPro生成代码，然后禁用，要用的时候再启用 MyBatisCodeHelperPro生成代码更换电脑后重新激活1.选择 tool -&gt; MybatisCodeHelper -&gt; Activation 2.离线激活（激活码可以随便填） 代码生成","tags":["笔记"],"categories":["Java"]},{"title":"vue,流式输出实现打字机效果","path":"/2024/07/11/20240711/","content":"demo11234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;template&gt; &lt;div&gt; &lt;span id=&quot;response_row&quot; class=&quot;result-streaming&quot;&gt;&#123;&#123; messages &#125;&#125;&lt;/span&gt; &lt;el-button @click=&quot;sss&quot;&gt;发送&lt;/el-button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &#x27;textChat&#x27;, data() &#123; return &#123; messages: &quot;&quot; // 用于存储接收到的消息 &#125;; &#125;, methods: &#123; async sss() &#123; const data = &#123; &quot;input&quot;: &quot;你好，我叫王大锤。&quot;, &quot;task_name&quot;: &quot;0910&quot;, &quot;prompt_id&quot;: &quot;None&quot;, &quot;chat_num&quot;: 3 &#125; const response = await fetch(&#x27;/dev-api/content/chat/chatGPT&#x27;, &#123; method: &quot;POST&quot;, body: JSON.stringify(data), headers: &#123; &quot;Content-Type&quot;: &quot;application/json&quot; &#125; &#125;) //获取UTF8的解码 const encode = new TextDecoder(&quot;utf-8&quot;); //获取body的reader const reader = response.body.getReader(); // 循环读取reponse中的内容 while (true) &#123; const &#123;done, value&#125; = await reader.read(); if (done) &#123; break; &#125; // 解码内容 const text = encode.decode(value); this.messages += text // 当获取错误token时，输出错误信息 // if (text === &quot;&lt;ERR&gt;&quot;) &#123; // output.innerText = &quot;Error&quot;; // break; // &#125; else &#123; // // 获取正常信息时，逐字追加输出 // output.innerText += text; // &#125; &#125; &#125;, &#125;,&#125;;&lt;/script&gt;&lt;style&gt;.result-streaming:after &#123; -webkit-animation: blink 1s steps(5, start) infinite; animation: blink 1s steps(5, start) infinite; content: &quot;▋&quot;; margin-left: 0.25rem; vertical-align: baseline;&#125;&lt;/style&gt; demo2123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213&lt;template&gt; &lt;div style=&quot;margin-top: 10px;&quot;&gt; &lt;el-card class=&quot;box-card&quot; v-loading=&quot;loading&quot;&gt; &lt;div class=&quot;text item&quot;&gt; &lt;div id=&quot;response_row&quot; :class=&quot;streamIsEnd?&#x27;&#x27;:&#x27;result-streaming&#x27;&quot; v-html=&quot;messages&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;div style=&quot;display: flex;justify-content: space-between;text-align: center;margin-top: 20px;margin-bottom: -10px;&quot;&gt; &lt;div style=&quot;display: flex;text-align: center;&quot;&gt; &lt;el-button type=&quot;text&quot; class=&quot;cardBtn&quot; :disabled=&quot;!streamIsEnd&quot; @click=&quot;sendEvent(&#x27;replacementContent&#x27;)&quot;&gt;&lt;i class=&quot;el-icon-success&quot; style=&quot;margin-right: 3px;&quot;&gt;&lt;/i&gt;替换内容 &lt;/el-button&gt; &lt;el-button type=&quot;text&quot; class=&quot;cardBtn&quot; :disabled=&quot;!streamIsEnd&quot; @click=&quot;sendEvent(&#x27;addContent&#x27;)&quot;&gt;&lt;i class=&quot;el-icon-document-add&quot; style=&quot;margin-right: 3px;&quot;&gt;&lt;/i&gt;添加到内容 &lt;/el-button&gt; &lt;el-button type=&quot;text&quot; class=&quot;cardBtn&quot; :disabled=&quot;!streamIsEnd&quot; v-clipboard:copy=&quot;messages&quot; v-clipboard:success=&quot;copyContent&quot; v-clipboard:error=&quot;copyContentError&quot; &gt;&lt;i class=&quot;el-icon-document-copy&quot; style=&quot;margin-right: 3px;&quot;&gt;&lt;/i&gt;复制 &lt;/el-button&gt; &lt;!-- &lt;el-button type=&quot;text&quot; class=&quot;cardBtn&quot; @click=&quot;handleDelete&quot;&gt;&lt;i class=&quot;el-icon-delete-solid&quot;--&gt; &lt;!-- style=&quot;margin-right: 3px;&quot;&gt;&lt;/i&gt;丢弃--&gt; &lt;!-- &lt;/el-button&gt;--&gt; &lt;!-- &lt;el-button type=&quot;text&quot; class=&quot;cardBtn&quot; @click=&quot;getServiceData&quot;&gt;&lt;i class=&quot;el-icon-success&quot;--&gt; &lt;!-- style=&quot;margin-right: 3px;&quot;&gt;&lt;/i&gt;重新生成--&gt; &lt;!-- &lt;/el-button&gt;--&gt; &lt;/div&gt; &lt;div&gt; &lt;el-dropdown @command=&quot;handleCommand&quot; :disabled=&quot;!streamIsEnd&quot;&gt; &lt;span class=&quot;el-dropdown-link cardBtn&quot; v-if=&quot;status&quot; style=&quot;color: blue;&quot;&gt; &#123;&#123;status&#125;&#125;&lt;i class=&quot;el-icon-arrow-down el-icon--right&quot; style=&quot;color: black&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class=&quot;el-dropdown-link cardBtn&quot; v-else&gt; 文案翻译&lt;i class=&quot;el-icon-arrow-down el-icon--right&quot; style=&quot;color: black&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;template #dropdown&gt; &lt;el-dropdown-menu&gt;&lt;!-- &lt;el-dropdown-item :command=&quot;dict.value&quot; v-for=&quot;dict in dict.type.content_language&quot;&gt;--&gt;&lt;!-- &#123;&#123; dict.label &#125;&#125;--&gt;&lt;!-- &lt;/el-dropdown-item&gt;--&gt; &lt;el-dropdown-item v-for=&quot;(dict,index) in dict.type.content_language&quot; :key=&quot;index&quot; :command=&quot;dict.value&quot; &gt;&#123;&#123; dict.label &#125;&#125;&lt;/el-dropdown-item&gt; &lt;/el-dropdown-menu&gt; &lt;/template&gt; &lt;/el-dropdown&gt; &lt;/div&gt; &lt;/div&gt; &lt;/el-card&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123;translateGoogle&#125; from &quot;@/api/system/languageTranslate&quot;;export default &#123; name: &quot;contentCard&quot;, dicts: [&#x27;content_language&#x27;], props: &#123; demand: &#123; type: String, default: [] &#125; &#125;, data() &#123; return &#123; loading: false, streamIsEnd: true, status: undefined, messages: &quot;&quot; &#125;; &#125;, mounted() &#123; this.getServiceData() &#125;, methods: &#123; handleCommand(command) &#123; let obj = this.dict.type.content_language.filter(item =&gt; item.value === command); this.status=obj[0].label // const foundElement = this.dict.type.content_language.find(obj =&gt; obj.value === command); // let result = this.messages.replace(/\\\\/g, &#x27;&#x27;).slice(1, -1); let result = this.messages.replace(/\\\\/g, &#x27;&#x27;); let qs = &#123; prompt: result, to_language: command, text_language: &quot;zh-CN&quot;, &#125; if (this.$isNotEmpty(result)) &#123; this.translateGoogle(qs) &#125; &#125;, translateGoogle(qs) &#123; this.loading = true translateGoogle(qs).then(response =&gt; &#123; this.messages = response.msg &#125;).finally(() =&gt; &#123; this.loading = false &#125;) &#125;, copyContentError() &#123; this.$modal.msgError(&quot;复制出错&quot;); &#125;, copyContent() &#123; this.$modal.msgSuccess(&quot;复制成功&quot;); &#125;, sendEvent(type) &#123; let rd = &#123; type: type, data: this.messages &#125; this.$emit(&#x27;articleManipulation&#x27;, rd) &#125;, handleDelete() &#123; var _this = this this.$modal.confirm(&#x27;是否确认删除该文章？&#x27;).then(function () &#123; _this.messages = &quot;&quot; &#125;); &#125;, async getServiceData() &#123; this.loading = true this.messages = &quot;&quot; let ins = JSON.parse(this.demand) delete ins.language; const data = &#123; &quot;input&quot;: JSON.stringify(ins), // &quot;task_name&quot;: &quot;0910&quot;, // &quot;prompt_id&quot;: &quot;None&quot;, &quot;language&quot;: JSON.parse(this.demand).language, // &quot;chat_num&quot;: 1 &#125; const response = await fetch(&#x27;/dev-api/content/chat/chatGPT&#x27;, &#123; method: &quot;POST&quot;, body: JSON.stringify(data), headers: &#123; &quot;Content-Type&quot;: &quot;application/json&quot; &#125; &#125;) //获取UTF8的解码 const encode = new TextDecoder(&quot;utf-8&quot;); //获取body的reader const reader = response.body.getReader(); this.loading = false this.streamIsEnd = false // 循环读取reponse中的内容 while (true) &#123; const &#123;done, value&#125; = await reader.read(); if (done) &#123; this.streamIsEnd = true break; &#125; // 解码内容 const text = encode.decode(value); this.messages += text.replace(/ /g, &#x27;&lt;br&gt;&#x27;) // 当获取错误token时，输出错误信息 // if (text === &quot;&lt;ERR&gt;&quot;) &#123; // output.innerText = &quot;Error&quot;; // break; // &#125; else &#123; // // 获取正常信息时，逐字追加输出 // output.innerText += text; // &#125; &#125; &#125; &#125;&#125;;&lt;/script&gt;&lt;style&gt;.selected&#123; color:red;&#125;.result-streaming:after &#123; -webkit-animation: blink 1s steps(5, start) infinite; animation: blink 1s steps(5, start) infinite; content: &quot;▋&quot;; margin-left: 0.25rem; vertical-align: baseline;&#125;.cardBtn &#123; font-size: 16px; background-color: #f8f8fa; border-radius: 5px; padding: 2px 8px; color: rgb(128, 128, 128); border: 1px solid #efefef&#125;.text &#123; font-size: 14px;&#125;.item &#123; padding: 10px 0;&#125;.box-card &#123; width: 100%; background-color: #ffffff;&#125;&lt;/style&gt;","tags":["笔记"],"categories":["Vue"]},{"title":"idea关联两个仓库","path":"/2024/06/27/2024062702/","content":"新创建的仓库推送代码后才能刷新出来 如果没有分支，需要新创建分支，在推送 1git push -u origin-company &quot;master&quot; 如果本地分支名称和origin分支名称不一样 1git push origin my-local-branch:my-remote-branch","tags":["笔记"],"categories":["Java"]},{"title":"idea导入项目右侧maven不显示的解决办法","path":"/2024/06/27/2024062703/","content":"原因可能是读取项目出错，未正确加载pom文件造成的。 解决方案一：关闭idea在项目目录中删除.idea文件夹重新打开项目，重新加载。 解决方案二：直接在pom文件中右键选择add as maven project。 解决方案三：如果你之前都是有的，突然之间没有了，可以试试：view -&gt; Tool windows -&gt; Maven 都出来了。","tags":["笔记"],"categories":["Java"]},{"title":"git基本代码","path":"/2024/06/27/2024062701/","content":"git clonegit add .git commit -m “xxx”git push origin master git clone -b dev –single-branch 仓库地址 vscode看不到新建的远程分支在项目文件打开git运行命令：git remote update origin –prune git remote update 远程仓库名字–prune","tags":["笔记"],"categories":["git"]},{"title":"Lambda expression are not supported at language level '5'","path":"/2024/06/19/2024062705/","content":"错误信息12Lambda expression are not supported at language level &#x27;5&#x27;Error:(28, 39) java: -source 1.5 中不支持 lambda 表达式 解决方法在IDEA中编译运行程序，除了可以指定编译的JDK版本外，还可以指定编译的Language Level。如果指定的Language Level选择不正确，即使使用的是java正确对应版本，在编译程序的时候还是会可能发生程序编译错误。 上面的错误是lambda表达式语言特性在Language Level 5下是不支持。这需要我们将Language Level调整到8. 具体操作如下: 点击File|Project Structure..或者使用快捷键Ctrl+Alt+Shift+S调整项目结构设置。 将Sources中Language Level 由级别5调整到级别8 如果Language Level没有级别8的支持Lambda表达式的选项，请设置工程编译SDK为1.8+，当然你前提是需要安装JDK1.8哦，并已经设置好环境变量等。 注意，如果项目有多模块，那么每个模块都需要设置","tags":["报错"],"categories":["Java"]},{"title":"Java 8 stream","path":"/2024/06/19/2024061902/","content":"一、概述Stream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。也可以使用 Stream API 来并行执行操作。简而言之，Stream API 提供了一种高效且易于使用的处理数据的方式。 特点： 1 . 不是数据结构，不会保存数据。 不会修改原来的数据源，它会将操作后的数据保存到另外一个对象中。（保留意见：毕竟peek方法可以修改流中元素） 惰性求值，流在中间处理过程中，只是对操作进行了记录，并不会立即执行，需要等到执行终止操作的时候才会进行实际的计算。 二、分类 无状态：指元素的处理不受之前元素的影响； 有状态：指该操作只有拿到所有元素之后才能继续下去。 非短路操作：指必须处理所有元素才能得到最终结果； 短路操作：指遇到某些符合条件的元素就可以得到最终结果，如 A || B，只要A为true，则无需判断B的结果。 三、具体用法1. 流的常用创建方法1.1 使用Collection下的 stream() 和 parallelStream() 方法 123List list = new ArrayList&lt;&gt;();Stream stream = list.stream(); //获取一个顺序流Stream parallelStream = list.parallelStream(); //获取一个并行流 1.2 使用Arrays 中的 stream() 方法，将数组转成流 12Integer[] nums = new Integer[10];Stream stream = Arrays.stream(nums); 1.3 使用Stream中的静态方法：of()、iterate()、generate() 1234567Stream stream = Stream.of(1,2,3,4,5,6);Stream stream2 = Stream.iterate(0, (x) -&gt; x + 2).limit(6);stream2.forEach(System.out::println); // 0 2 4 6 8 10Stream stream3 = Stream.generate(Math::random).limit(2);stream3.forEach(System.out::println); 1.4 使用 BufferedReader.lines() 方法，将每行内容转成流 123BufferedReader reader = new BufferedReader(new FileReader(&quot;F:\\\\test_stream.txt&quot;));Stream lineStream = reader.lines();lineStream.forEach(System.out::println); 1.5 使用 Pattern.splitAsStream() 方法，将字符串分隔成流 123Pattern pattern = Pattern.compile(&quot;,&quot;);Stream stringStream = pattern.splitAsStream(&quot;a,b,c,d&quot;);stringStream.forEach(System.out::println); 2. 流的中间操作2.1 筛选与切片filter：过滤流中的某些元素；limit(n)：获取n个元素；skip(n)：跳过n元素，配合limit(n)可实现分页；distinct：通过流中元素的 hashCode() 和 equals() 去除重复元素； 1234567Stream stream = Stream.of(6, 4, 6, 7, 3, 9, 8, 10, 12, 14, 14);Stream newStream = stream.filter(s -&gt; s &gt; 5) //6 6 7 9 8 10 12 14 14 .distinct() //6 7 9 8 10 12 14 .skip(2) //9 8 10 12 14 .limit(2); //9 8newStream.forEach(System.out::println); 2.2 映射map：接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。flatMap：接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流。 12345678910111213List list = Arrays.asList(&quot;a,b,c&quot;, &quot;1,2,3&quot;);//将每个元素转成一个新的且不带逗号的元素Stream s1 = list.stream().map(s -&gt; s.replaceAll(&quot;,&quot;, &quot;&quot;));s1.forEach(System.out::println); // abc 123Stream s3 = list.stream().flatMap(s -&gt; &#123; //将每个元素转换成一个stream String[] split = s.split(&quot;,&quot;); Stream s2 = Arrays.stream(split); return s2;&#125;);s3.forEach(System.out::println); // a b c 1 2 3 2.3 排序sorted()：自然排序，流中元素需实现Comparable接口sorted(Comparator com)：定制排序，自定义Comparator排序器 1234567891011121314151617181920List list = Arrays.asList(&quot;aa&quot;, &quot;ff&quot;, &quot;dd&quot;);//String 类自身已实现Compareable接口list.stream().sorted().forEach(System.out::println);// aa dd ffStudent s1 = new Student(&quot;aa&quot;, 10);Student s2 = new Student(&quot;bb&quot;, 20);Student s3 = new Student(&quot;aa&quot;, 30);Student s4 = new Student(&quot;dd&quot;, 40);List studentList = Arrays.asList(s1, s2, s3, s4);//自定义排序：先按姓名升序，姓名相同则按年龄升序studentList.stream().sorted( (o1, o2) -&gt; &#123; if (o1.getName().equals(o2.getName())) &#123; return o1.getAge() - o2.getAge(); &#125; else &#123; return o1.getName().compareTo(o2.getName()); &#125; &#125;).forEach(System.out::println); 2.4 消费peek：如同于map，能得到流中的每一个元素。但map接收的是一个Function表达式，有返回值；而peek接收的是Consumer表达式，没有返回值。 1234567891011Student s1 = new Student(&quot;aa&quot;, 10);Student s2 = new Student(&quot;bb&quot;, 20);List studentList = Arrays.asList(s1, s2);studentList.stream() .peek(o -&gt; o.setAge(100)) .forEach(System.out::println);//结果：Student&#123;name=&#x27;aa&#x27;, age=100&#125;Student&#123;name=&#x27;bb&#x27;, age=100&#125; 3. 流的终止操作3.1 匹配、聚合操作allMatch：接收一个 Predicate 函数，当流中每个元素都符合该断言时才返回true，否则返回falsenoneMatch：接收一个 Predicate 函数，当流中每个元素都不符合该断言时才返回true，否则返回falseanyMatch：接收一个 Predicate 函数，只要流中有一个元素满足该断言则返回true，否则返回falsefindFirst：返回流中第一个元素findAny：返回流中的任意元素count：返回流中元素的总个数max：返回流中元素最大值min：返回流中元素最小值 123456789101112List list = Arrays.asList(1, 2, 3, 4, 5);boolean allMatch = list.stream().allMatch(e -&gt; e &gt; 10); //falseboolean noneMatch = list.stream().noneMatch(e -&gt; e &gt; 10); //trueboolean anyMatch = list.stream().anyMatch(e -&gt; e &gt; 4); //trueInteger findFirst = list.stream().findFirst().get(); //1Integer findAny = list.stream().findAny().get(); //1long count = list.stream().count(); //5Integer max = list.stream().max(Integer::compareTo).get(); //5Integer min = list.stream().min(Integer::compareTo).get(); //1 3.2 规约操作Optional 123456789101112131415161718192021222324252627282930//经过测试，当元素个数小于24时，并行时线程数等于元素个数，当大于等于24时，并行时线程数为16List list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24);Integer v = list.stream().reduce((x1, x2) -&gt; x1 + x2).get();System.out.println(v); // 300Integer v1 = list.stream().reduce(10, (x1, x2) -&gt; x1 + x2);System.out.println(v1); //310Integer v2 = list.stream().reduce(0, (x1, x2) -&gt; &#123; System.out.println(&quot;stream accumulator: x1:&quot; + x1 + &quot; x2:&quot; + x2); return x1 - x2; &#125;, (x1, x2) -&gt; &#123; System.out.println(&quot;stream combiner: x1:&quot; + x1 + &quot; x2:&quot; + x2); return x1 * x2; &#125;);System.out.println(v2); // -300Integer v3 = list.parallelStream().reduce(0, (x1, x2) -&gt; &#123; System.out.println(&quot;parallelStream accumulator: x1:&quot; + x1 + &quot; x2:&quot; + x2); return x1 - x2; &#125;, (x1, x2) -&gt; &#123; System.out.println(&quot;parallelStream combiner: x1:&quot; + x1 + &quot; x2:&quot; + x2); return x1 * x2; &#125;);System.out.println(v3); //197474048 3.3 收集操作collect：接收一个Collector实例，将流中元素收集成另外一个数据结构。Collector 1234567891011121314151617181920212223242526272829303132333435363738394041Student s1 = new Student(&quot;aa&quot;, 10,1);Student s2 = new Student(&quot;bb&quot;, 20,2);Student s3 = new Student(&quot;cc&quot;, 10,3);List list = Arrays.asList(s1, s2, s3);//装成listList ageList = list.stream().map(Student::getAge).collect(Collectors.toList()); // [10, 20, 10]//转成setSet ageSet = list.stream().map(Student::getAge).collect(Collectors.toSet()); // [20, 10]//转成map,注:key不能相同，否则报错Map studentMap = list.stream().collect(Collectors.toMap(Student::getName, Student::getAge)); // &#123;cc=10, bb=20, aa=10&#125;//字符串分隔符连接String joinName = list.stream().map(Student::getName).collect(Collectors.joining(&quot;,&quot;, &quot;(&quot;, &quot;)&quot;)); // (aa,bb,cc)//聚合操作//1.学生总数Long count = list.stream().collect(Collectors.counting()); // 3//2.最大年龄 (最小的minBy同理)Integer maxAge = list.stream().map(Student::getAge).collect(Collectors.maxBy(Integer::compare)).get(); // 20//3.所有人的年龄Integer sumAge = list.stream().collect(Collectors.summingInt(Student::getAge)); // 40//4.平均年龄Double averageAge = list.stream().collect(Collectors.averagingDouble(Student::getAge)); // 13.333333333333334// 带上以上所有方法DoubleSummaryStatistics statistics = list.stream().collect(Collectors.summarizingDouble(Student::getAge));System.out.println(&quot;count:&quot; + statistics.getCount() + &quot;,max:&quot; + statistics.getMax() + &quot;,sum:&quot; + statistics.getSum() + &quot;,average:&quot; + statistics.getAverage());//分组Map&gt; ageMap = list.stream().collect(Collectors.groupingBy(Student::getAge));//多重分组,先根据类型分再根据年龄分Map&gt;&gt; typeAgeMap = list.stream().collect(Collectors.groupingBy(Student::getType, Collectors.groupingBy(Student::getAge)));//分区//分成两部分，一部分大于10岁，一部分小于等于10岁Map&gt; partMap = list.stream().collect(Collectors.partitioningBy(v -&gt; v.getAge() &gt; 10));//规约Integer allAge = list.stream().map(Student::getAge).collect(Collectors.reducing(Integer::sum)).get(); //40 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//toList 源码public static Collector&gt; toList() &#123; return new CollectorImpl&lt;&gt;((Supplier&gt;) ArrayList::new, List::add, (left, right) -&gt; &#123; left.addAll(right); return left; &#125;, CH_ID);&#125;//为了更好地理解，我们转化一下源码中的lambda表达式public Collector&gt; toList() &#123; Supplier&gt; supplier = () -&gt; new ArrayList(); BiConsumer, T&gt; accumulator = (list, t) -&gt; list.add(t); BinaryOperator&gt; combiner = (list1, list2) -&gt; &#123; list1.addAll(list2); return list1; &#125;; Function, List&gt; finisher = (list) -&gt; list; Set characteristics = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.IDENTITY_FINISH)); return new Collector, List&gt;() &#123; @Override public Supplier supplier() &#123; return supplier; &#125; @Override public BiConsumer accumulator() &#123; return accumulator; &#125; @Override public BinaryOperator combiner() &#123; return combiner; &#125; @Override public Function finisher() &#123; return finisher; &#125; @Override public Set characteristics() &#123; return characteristics; &#125; &#125;;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"MybatisPlus常用操作","path":"/2024/06/18/2024061802/","content":"其他12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667if (ObjectUtil.isNotEmpty(condition.getState())) &#123; if (condition.getState().equals(UserListByCondition.STATE_DISABLE)) &#123; queryWrapperSysUser.eq(SysUser::getStatus, CommonConstant.DISABLE); &#125; else if (condition.getState().equals(UserListByCondition.STATE_DIMISSION)) &#123; queryWrapperSysUser.eq(SysUser::getDimission, CommonConstant.DIMISSION); &#125; &#125; else &#123; queryWrapperSysUser.isNull(SysUser::getDimission).or().ne(SysUser::getDimission, CommonConstant.DIMISSION); &#125; if (StringUtils.isNotBlank(condition.getValue())) queryWrapperSysUser.like(SysUser::getUserName, condition.getValue()) .or() .like(SysUser::getEmail, condition.getValue()) .or() .like(SysUser::getPhoneNumber, condition.getValue()); if (ObjectUtil.isNotEmpty(condition.getDeptId())) &#123; queryWrapperSysUser.eq(SysUser::getDeptId, condition.getDeptId()); &#125;//生成的sql-&gt; SELECT * FROM sys_user WHERE (dimission IS NULL OR dimission &lt;&gt; 1 AND dept_id = 282) if (ObjectUtil.isNotEmpty(condition.getState())) &#123; if (condition.getState().equals(UserListByCondition.STATE_DISABLE)) &#123; queryWrapperSysUser.eq(SysUser::getStatus, CommonConstant.DISABLE); &#125; else if (condition.getState().equals(UserListByCondition.STATE_DIMISSION)) &#123; queryWrapperSysUser.eq(SysUser::getDimission, CommonConstant.DIMISSION); &#125; &#125; else &#123; queryWrapperSysUser.nested(q -&gt; q.isNull(SysUser::getDimission).or().ne(SysUser::getDimission, CommonConstant.DIMISSION)); &#125; if (StringUtils.isNotBlank(condition.getValue())) queryWrapperSysUser.like(SysUser::getUserName, condition.getValue()) .or() .like(SysUser::getEmail, condition.getValue()) .or() .like(SysUser::getPhoneNumber, condition.getValue()); if (ObjectUtil.isNotEmpty(condition.getDeptId())) &#123; queryWrapperSysUser.eq(SysUser::getDeptId, condition.getDeptId()); &#125;//生成的sql-&gt;select * FROM sys_user WHERE ((dimission IS NULL OR dimission &lt;&gt; ?) AND dept_id = ?)//使用 nested() 方法将 (dimission IS NULL OR dimission &lt;&gt; 1) 这部分条件括起来,形成一个独立的查询块 if (ObjectUtil.isNotEmpty(condition.getState())) &#123; if (condition.getState().equals(UserListByCondition.STATE_DISABLE)) &#123; queryWrapperSysUser.eq(SysUser::getStatus, CommonConstant.DISABLE); &#125; else if (condition.getState().equals(UserListByCondition.STATE_DIMISSION)) &#123; queryWrapperSysUser.eq(SysUser::getDimission, CommonConstant.DIMISSION); &#125; &#125; else &#123; queryWrapperSysUser.nested(q -&gt; q.isNull(SysUser::getDimission).or().ne(SysUser::getDimission, CommonConstant.DIMISSION)); &#125; if (StringUtils.isNotBlank(condition.getValue())) queryWrapperSysUser.nested(q -&gt; q.like(SysUser::getUserName, condition.getValue()) .or() .like(SysUser::getEmail, condition.getValue()) .or() .like(SysUser::getPhoneNumber, condition.getValue())); if (ObjectUtil.isNotEmpty(condition.getDeptId())) &#123; queryWrapperSysUser.eq(SysUser::getDeptId, condition.getDeptId()); &#125;//生成的sql-&gt;select * FROM sys_user WHERE ((dimission IS NULL OR dimission &lt;&gt; ?) AND (user_name LIKE ? OR email LIKE ? OR phone_number LIKE ?) AND dept_id = ?) 直接执行sql1.apply2. 12345678910111213141516171819202122PageHelper.startPage(rankingUserBO.getPageNo(), rankingUserBO.getPageSize()); QueryWrapper&lt;UserInfo&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.select(&quot;invite_user_id, COUNT(*) as invite_count&quot;) .groupBy(&quot;invite_user_id&quot;) .orderByDesc(&quot;invite_count&quot;); if (ObjectUtil.isNotNull(rankingUserBO.getStart())) &#123; queryWrapper.ge(&quot;create_time&quot;, rankingUserBO.getStart().toInstant()); &#125; if (ObjectUtil.isNotNull(rankingUserBO.getEnd())) &#123; queryWrapper.le(&quot;create_time&quot;, rankingUserBO.getEnd().toInstant()); &#125; List&lt;Map&lt;String, Object&gt;&gt; result = userInfoMapper.selectMaps(queryWrapper); List&lt;InviteCountBO&gt; boList = result.stream() .map(map -&gt; &#123; InviteCountBO bo = new InviteCountBO(); bo.setInviteUserId((String) map.get(&quot;invite_user_id&quot;)); bo.setInviteCount((Long) map.get(&quot;invite_count&quot;)); return bo; &#125;) .collect(Collectors.toList()); 组合条件12345678910LambdaQueryWrapper&lt;SysUser&gt; queryWrapperSysUser = new LambdaQueryWrapper&lt;&gt;();queryWrapperSysUser.isNull(SysUser::getDimission).or().ne(SysUser::getDimission, CommonConstant.DIMISSION);if (StringUtils.isNotBlank(condition.getValue())) queryWrapperSysUser.like(SysUser::getUserName, condition.getValue()) .or() .like(SysUser::getEmail, condition.getValue()) .or() .like(SysUser::getPhoneNumber, condition.getValue()); 排序1queryWrapperSysUser.orderByAsc(SysUser::getUserName); 循环12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//单体@Override public List&lt;SysUser&gt; selectAllNormalUserByDeptAndChildId(Long deptId) &#123; LambdaQueryWrapper&lt;SysDept&gt; queryWrapperSysDept = new LambdaQueryWrapper&lt;&gt;(); queryWrapperSysDept.eq(SysDept::getDelFlag, CommonConstant.NOT_DELETED); queryWrapperSysDept.like(SysDept::getAncestors, deptId); List&lt;SysDept&gt; dList = sysDeptPService.list(queryWrapperSysDept); List&lt;Long&gt; ds = new ArrayList&lt;&gt;(); if (CollectionUtil.isNotEmpty(dList)) ds = dList.stream().map(SysDept::getDeptId).collect(Collectors.toList()); ds.add(deptId); LambdaQueryWrapper&lt;SysUser&gt; queryWrapperSysUser = new LambdaQueryWrapper&lt;&gt;(); queryWrapperSysUser.eq(SysUser::getDelFlag, CommonConstant.NOT_DELETED); queryWrapperSysUser.eq(SysUser::getStatus, CommonConstant.NOT_DISABLE); queryWrapperSysUser.nested(q -&gt; q.isNull(SysUser::getDimission).or().ne(SysUser::getDimission, CommonConstant.DIMISSION)); queryWrapperSysUser.in(SysUser::getDeptId, ds); return list(queryWrapperSysUser); &#125;//循环 @Override public List&lt;SysUser&gt; selectAllNormalUserByDeptAndChildId(List&lt;Long&gt; deptIds) &#123; LambdaQueryWrapper&lt;SysDept&gt; queryWrapperSysDept = new LambdaQueryWrapper&lt;&gt;(); queryWrapperSysDept.eq(SysDept::getDelFlag, CommonConstant.NOT_DELETED); // 使用nested方法添加条件，避免影响其他查询 queryWrapperSysDept.nested(i -&gt; &#123; // 这里可以添加其他条件，例如：// i.eq(SysDept::getStatus, CommonConstant.NOT_DISABLE); // 假设我们只关心状态为0的部门 // 循环添加deptId条件 deptIds.forEach(deptId -&gt; i.or().like(SysDept::getAncestors, deptId.toString()));//这段代码创建了一个条件分组，对于 deptIds 列表中的每个 deptId，都添加了一个 OR 条件。这意味着，如果任何一个 deptId 的条件满足，那么整个分组条件就满足//不使用 OR,如果 deptIds 列表中有多个值，它们将被添加为 AND 条件。这意味着，只有当所有这些值都满足时，整个分组条件才满足 &#125;); // 从数组创建流并构建查询条件,没有其他条件// Stream.of(deptIds).forEach(deptId -&gt; &#123;// queryWrapperSysDept.or(wrapper -&gt; wrapper.eq(SysDept::getAncestors, deptId));// &#125;); List&lt;SysDept&gt; dList = sysDeptPService.list(queryWrapperSysDept); List&lt;Long&gt; ds = new ArrayList&lt;&gt;(); if (CollectionUtil.isNotEmpty(dList)) ds = dList.stream().map(SysDept::getDeptId).collect(Collectors.toList()); ds.addAll(deptIds); LambdaQueryWrapper&lt;SysUser&gt; queryWrapperSysUser = new LambdaQueryWrapper&lt;&gt;(); queryWrapperSysUser.eq(SysUser::getDelFlag, CommonConstant.NOT_DELETED); queryWrapperSysUser.eq(SysUser::getStatus, CommonConstant.NOT_DISABLE); queryWrapperSysUser.nested(q -&gt; q.isNull(SysUser::getDimission).or().ne(SysUser::getDimission, CommonConstant.DIMISSION)); queryWrapperSysUser.in(SysUser::getDeptId, ds); return list(queryWrapperSysUser); &#125; like和likeRightlike 方法用于模糊匹配字段中包含指定字符串的情况。例如，如果使用 queryWrapperSysDept.like(SysDept::getAncestors, “123”)，它将生成 SQL 条件，查找 ancestors 字段中包含子字符串 “123” 的记录。 likeRight 方法用于模糊匹配字段值以指定字符串结尾的情况。例如，如果使用 queryWrapperSysDept.likeRight(SysDept::getAncestors, “123”)，它将生成 SQL 条件，查找 ancestors 字段的值以 “123” 结尾的记录。 设置空值1234567public Boolean cancelPrincipal(Long deptId) &#123; LambdaUpdateWrapper&lt;SysDept&gt; updateWrapperSysDept = new LambdaUpdateWrapper&lt;&gt;(); updateWrapperSysDept.eq(SysDept::getDeptId, deptId); updateWrapperSysDept.set(SysDept::getLeaderUserId, null); updateWrapperSysDept.set(SysDept::getLeader, &quot;&quot;); return update(updateWrapperSysDept); &#125; find_in_set1234567public Boolean checkDeptChild(Long deptId) &#123; LambdaQueryWrapper&lt;SysDept&gt; queryWrapperSysDept = new LambdaQueryWrapper&lt;&gt;(); queryWrapperSysDept.eq(SysDept::getStatus, CommonConstant.NOT_DISABLE); queryWrapperSysDept.eq(SysDept::getDelFlag, CommonConstant.NOT_DELETED); queryWrapperSysDept.apply(&quot;find_in_set(&#123;0&#125;, ancestors)&quot;, deptId); return count(queryWrapperSysDept) &gt; 0L; &#125; last123456if (Strings.isNotBlank(queryDTO.getSortField())) &#123; if (ObjectUtil.isEmpty(queryDTO.getAsc())) queryDTO.setAsc(false); queryWrapper.last(&quot;order by &quot; + StrUtil.toUnderlineCase(queryDTO.getSortField()) + &quot; &quot; + (queryDTO.getAsc() ? &quot;asc&quot; : &quot;desc&quot;) + &quot;,id DESC&quot;); &#125; else queryWrapper.orderByAsc(ProjectRefactorBug::getState).orderByDesc(ProjectRefactorBug::getId); //排序 激活——已解决——已关闭 + ID从大到小 入库的时候忽略某个字段12@TableField(exist = false)private Long[] menuIds;","tags":["笔记"],"categories":["Java"]},{"title":"MybatisPlus条件语句","path":"/2024/06/18/2024061901/","content":"说明MybatisPlus通过Wrapper（条件构造器）或者来让用户自由的构建查询条件，简单便捷，没有额外的负担，能够有效提高开发效率如果第一个参数为：boolean condition表示该条件是否加入最后生成的sql中以下出现的泛型Param均为Wrapper的子类实例(均具有AbstractWrapper的所有方法)方法参数中出现的R为泛型，在普通wrapper中是String方法参数中的R column均表示数据库字段，当R为String时则为数据库字段名称(字段名是数据库关键字的自己用转义符包裹!)，而不是实体类的属性名称 AbstractWrapperQueryWrapper和UpdateWrapper的父类，用于生成sql的where条件 allEq全部eq(或个别isNull) 123allEq(Map&lt;R, V&gt; params)allEq(Map&lt;R, V&gt; params, boolean null2IsNull)allEq(boolean condition, Map&lt;R, V&gt; params, boolean null2IsNull) 例1: allEq({id:1,name:“张三”,age:null})—&gt;id = 1 and name = ‘张三’ and age is null例2: allEq({id:1,name:“张三”,age:null}, false)—&gt;id = 1 and name = ‘张三’ 123allEq(BiPredicate&lt;R, V&gt; filter, Map&lt;R, V&gt; params)allEq(BiPredicate&lt;R, V&gt; filter, Map&lt;R, V&gt; params, boolean null2IsNull)allEq(boolean condition, BiPredicate&lt;R, V&gt; filter, Map&lt;R, V&gt; params, boolean null2IsNull) 例1: allEq((k,v) -&gt; k.indexOf(“a”) &gt; 0, {id:1,name:“张三”,age:null})—&gt;name = ‘张三’ and age is null例2: allEq((k,v) -&gt; k.indexOf(“a”) &gt; 0, {id:1,name:“张三”,age:null}, false)—&gt;name = ‘张三’ 个别参数说明: params : key为数据库字段名,value为字段值null2IsNull : 为true则在map的value为null时调用 isNull 方法,为false时则忽略value为null的filter : 过滤函数,是否允许字段传入比对条件中 eq等于 = 12eq(R column, Object val)eq(boolean condition, R column, Object val) 例: eq(“name”, “张三”)—&gt;name = ‘张三’ ne不等于 &lt;&gt; 12ne(R column, Object val)ne(boolean condition, R column, Object val) 例: ne(“name”, “张三”)—&gt;name &lt;&gt; ‘张三’ gt大于 &gt; 12gt(R column, Object val)gt(boolean condition, R column, Object val) 例: gt(“age”, 18)—&gt;age &gt; 18 ge大于等于 &gt;= 123ge(R column, Object val)ge(boolean condition, R column, Object val) 例: ge(“age”, 18)—&gt;age &gt;= 18 lt小于 &lt; 123lt(R column, Object val)lt(boolean condition, R column, Object val) 例: lt(“age”, 18)—&gt;age &lt; 18 le小于等于 &lt;= 123le(R column, Object val)le(boolean condition, R column, Object val) 例: le(“age”, 18)—&gt;age &lt;= 18 betweenBETWEEN 值1 AND 值2 123between(R column, Object val1, Object val2)between(boolean condition, R column, Object val1, Object val2) 例: between(“age”, 18, 30)—&gt;age between 18 and 30 notBetweenNOT BETWEEN 值1 AND 值2 123notBetween(R column, Object val1, Object val2)notBetween(boolean condition, R column, Object val1, Object val2) 例: notBetween(“age”, 18, 30)—&gt;age not between 18 and 30 likeLIKE ‘%值%’ 12like(R column, Object val)like(boolean condition, R column, Object val) 例: like(“name”, “王”)—&gt;name like ‘%王%’ notLikeNOT LIKE ‘%值%’ 12notLike(R column, Object val)notLike(boolean condition, R column, Object val) 例: notLike(“name”, “王”)—&gt;name not like ‘%王%’ likeLeftLIKE ‘%值’ 12likeLeft(R column, Object val)likeLeft(boolean condition, R column, Object val) 例: likeLeft(“name”, “王”)—&gt;name like ‘%王’ likeRightLIKE ‘值%’ 12likeRight(R column, Object val)likeRight(boolean condition, R column, Object val) 例: likeRight(“name”, “王”)—&gt;name like ‘王%’ isNull字段 IS NULL 12isNull(R column)isNull(boolean condition, R column) 例: isNull(“name”)—&gt;name is null isNotNull字段 IS NOT NULL 12isNotNull(R column)isNotNull(boolean condition, R column) 例: isNotNull(“name”)—&gt;name is not null in字段 IN (value.get(0), value.get(1), …) 12in(R column, Collection&lt;?&gt; value)in(bo```olean condition, R column, Collection&lt;?&gt; value) 例: in(“age”,{1,2,3})—&gt;age in (1,2,3) 字段 IN (v0, v1, …) 12in(R column, Object... values)in(boolean condition, R column, Object... values) 例: in(“age”, 1, 2, 3)—&gt;age in (1,2,3) notIn字段 IN (value.get(0), value.get(1), …) 12notIn(R column, Collection&lt;?&gt; value)notIn(boolean condition, R column, Collection&lt;?&gt; value) 例: notIn(“age”,{1,2,3})—&gt;age not in (1,2,3) 字段 NOT IN (v0, v1, …) 12notIn(R column, Object... values)notIn(boolean condition, R column, Object... values) 例: notIn(“age”, 1, 2, 3)—&gt;age not in (1,2,3) inSql字段 IN ( sql语句 ) 12inSql(R column, String inValue)inSql(boolean condition, R column, String inValue) 例: inSql(“age”, “1,2,3,4,5,6”)—&gt;age in (1,2,3,4,5,6)例: inSql(“id”, “select id from table where id &lt; 3”)—&gt;id in (select id from table where id &lt; 3) notInSql字段 NOT IN ( sql语句 ) 12notInSql(R column, String inValue)notInSql(boolean condition, R column, String inValue) 例: notInSql(“age”, “1,2,3,4,5,6”)—&gt;age not in (1,2,3,4,5,6)例: notInSql(“id”, “select id from table where id &lt; 3”)—&gt;age not in (select id from table where id &lt; 3) groupBy分组：GROUP BY 字段, … 12groupBy(R... columns)groupBy(boolean condition, R... columns) 例: groupBy(“id”, “name”)—&gt;group by id,name orderByAsc排序：ORDER BY 字段, … ASC 12orderByAsc(R... columns)orderByAsc(boolean condition, R... columns) 例: orderByAsc(“id”, “name”)—&gt;order by id ASC,name ASC orderByDesc排序：ORDER BY 字段, … DESC 12orderByDesc(R... columns)orderByDesc(boolean condition, R... columns) 例: orderByDesc(“id”, “name”)—&gt;order by id DESC,name DESC orderBy排序：ORDER BY 字段, … 1orderBy(boolean condition, boolean isAsc, R... columns) 例: orderBy(true, true, “id”, “name”)—&gt;order by id ASC,name ASC havingHAVING ( sql语句 ) 12having(String sqlHaving, Object... params)having(boolean condition, String sqlHaving, Object... params) 例: having(“sum(age) &gt; 10”)—&gt;having sum(age) &gt; 10例: having(“sum(age) &gt; {0}”, 11)—&gt;having sum(age) &gt; 11 or拼接 OR 12or()or(boolean condition) 例: eq(“id”,1).or().eq(“name”,“老王”)—&gt;id = 1 or name = ‘老王’ 注意事项:主动调用or表示紧接着下一个方法不是用and连接!(不调用or则默认为使用and连接) OR 嵌套 12or(Function&lt;Param, Param&gt; func)or(boolean condition, Function&lt;Param, Param&gt; func) 例: or(i -&gt; i.eq(“name”, “李白”).ne(“status”, “活着”))—&gt;or (name = ‘李白’ and status &lt;&gt; ‘活着’) andAND 嵌套 12and(Function&lt;Param, Param&gt; func)and(boolean condition, Function&lt;Param, Param&gt; func) 例: and(i -&gt; i.eq(“name”, “李白”).ne(“status”, “活着”))—&gt;and (name = ‘李白’ and status &lt;&gt; ‘活着’) nested正常嵌套 不带 AND 或者 OR 12nested(Function&lt;Param, Param&gt; func)nested(boolean condition, Function&lt;Param, Param&gt; func) 例: nested(i -&gt; i.eq(“name”, “李白”).ne(“status”, “活着”))—&gt;(name = ‘李白’ and status &lt;&gt; ‘活着’) apply拼接 sql 12apply(String applySql, Object... params)apply(boolean condition, String applySql, Object... params) 例: apply(“id = 1”)—&gt;id = 1例: apply(“date_format(dateColumn,’%Y-%m-%d’) = ‘2008-08-08’”)—&gt;date_format(dateColumn,’%Y-%m-%d’) = ‘2008-08-08’”)例: apply(“date_format(dateColumn,’%Y-%m-%d’) = {0}”, “2008-08-08”)—&gt;date_format(dateColumn,’%Y-%m-%d’) = ‘2008-08-08’”) 注意事项:该方法可用于数据库函数动态入参的params对应前面applySql内部的{index}部分.这样是不会有sql注入风险的,反之会有! last无视优化规则直接拼接到sql的最后 12last(String lastSql)last(boolean condition, String lastSql) 例: last(“limit 1”) 注意事项:只能调用一次,多次调用以最后一次为准 有sql注入的风险,请谨慎使用 exists拼接 EXISTS ( sql语句 ) 12exists(String existsSql)exists(boolean condition, String existsSql) 例: exists(“select id from table where age = 1”)—&gt;exists (select id from table where age = 1) notExists拼接 NOT EXISTS ( sql语句 ) 12notExists(String notExistsSql)notExists(boolean condition, String notExistsSql) 例: notExists(“select id from table where age = 1”)—&gt;not exists (select id from table where age = 1) QueryWrapper继承自AbstractWrapper，自身的内部属性entity也用于生成where条件 select设置查询字段 123select(String... sqlSelect)select(Predicate&lt;TableFieldInfo&gt; predicate)select(Class&lt;T&gt; entityClass, Predicate&lt;TableFieldInfo&gt; predicate) 例: select(“id”, “name”, “age”)例: select(i -&gt; i.getProperty().startsWith(“test”)) UpdateWrapper继承自AbstractWrapper，自身的内部属性entity也用于生成where条件 setSQL SET 字段 12set(String column, Object val)set(boolean condition, String column, Object val) 例: set(“name”, “老李头”)例: set(“name”, “”)—&gt;数据库字段值变为空字符串例: set(“name”, null)—&gt;数据库字段值变为null setSql设置 SET 部分 SQL 1setSql(String sql) 例: set(“name = ‘老李头’) 使用Wrapper自定义SQL注解方式在Mapper接口中自定义方法，参数为Wrapper类型，并添加注解 12@Select(&quot;select * from mysql_data $&#123;ew.customSqlSegment&#125;&quot;)List&lt;MysqlData&gt; getAll(@Param(Constants.WRAPPER) Wrapper wrapper); XML形式在Mapper.xml映射文件中，添加sql语句 123&lt;select id=&quot;getAll&quot; resultType=&quot;MysqlData&quot;&gt; SELECT * FROM mysql_data $&#123;ew.customSqlSegment&#125;&lt;/select&gt; 构造器应用比较运算123456QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.gt(&quot;age&quot;, 20);List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person WHERE age &gt; ? between123456QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.between(&quot;age&quot;, 21, 28);List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person WHERE age BETWEEN ? AND ? like1234567QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.like(&quot;last_name&quot;, &quot;张&quot;);List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person WHERE last_name LIKE ?Parameters: %张%(String) in1234567QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.in(&quot;id&quot;, 1,2,3);List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person WHERE last_name LIKE ?Parameters: %张%(String) 分组1234567891011//接口中添加自定义方法@Select(&quot;select gender,count(gender) num from tmp_person $&#123;ew.customSqlSegment&#125;&quot;)List&lt;Map&lt;String, Object&gt;&gt; selectGroupByGender(@Param(Constants.WRAPPER) Wrapper queryWrapper);//测试QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.groupBy(&quot;gender&quot;);List&lt;Map&lt;String, Object&gt;&gt; list = personMapper.selectGroupByGender(queryWrapper);//生成的sql语句select gender,count(gender) num from tmp_person GROUP BY gender 排序123456QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.orderBy(true, true , &quot;age&quot;,&quot;id&quot;);List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person ORDER BY age ASC , id ASC or主动调用or表示紧接着调用下一个方法是用or连接 123456QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.lt(&quot;age&quot;, 20).or().like(&quot;last_name&quot;, &quot;j&quot;);List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person WHERE age &lt; ? OR last_name LIKE ? 利用lambda表达式实现or的嵌套 123456QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.ge(&quot;age&quot;, 20).or(i-&gt;i.eq(&quot;gender&quot;,1).ne(&quot;last_name&quot;, &quot;tom&quot;));List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person WHERE age &gt;= ? OR ( gender = ? AND last_name &lt;&gt; ? ) and默认为使用and连接，表示紧接着调用下一个方法是用and连接 123456QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.gt(&quot;age&quot;, 20).eq(&quot;gender&quot;, 1);List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person WHERE age &gt; ? AND gender = ? 利用lambda表达式实现and的嵌套123456QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.ge(&quot;age&quot;, 20).and(i-&gt;i.eq(&quot;gender&quot;,1).or().ne(&quot;last_name&quot;, &quot;tom&quot;));List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person WHERE age &gt;= ? AND ( gender = ? OR last_name &lt;&gt; ? ) select设置查询字段123456QueryWrapper&lt;Person&gt; queryWrapper = new QueryWrapper&lt;&gt;();queryWrapper.select(&quot;id&quot;,&quot;last_name&quot;,&quot;age&quot;);List&lt;Person&gt; list = personMapper.selectList(queryWrapper);//生成的sql语句SELECT id,last_name,age FROM tmp_person LambdaQueryWrapper1234567//获取支持lambda表达式的条件构造器LambdaQueryWrapper&lt;Person&gt; lambdaQueryWrapper = new QueryWrapper&lt;Person&gt;().lambda();lambdaQueryWrapper.eq(Person::getLastName, &quot;tom&quot;);List&lt;Person&gt; list = personMapper.selectList(lambdaQueryWrapper);//生成的sql语句SELECT id,last_name,age,gender,email FROM tmp_person WHERE last_name = ?","tags":["笔记"],"categories":["Java"]},{"title":"Java-list,map常用操作","path":"/2024/06/18/20240617hh/","content":"简单升序和降序1234List&lt;Long&gt; refactorReports = List.of(5L, 3L, 9L, 1L, 4L); // 升序排序 Collections.sort(refactorReports, Comparator.naturalOrder()); 1234List&lt;Long&gt; refactorReports = List.of(5L, 3L, 9L, 1L, 4L);// 降序排序Collections.sort(refactorReports, Comparator.reverseOrder()); List分页12voList=voList.stream().skip((long) queryDTO.getPageSize() * (queryDTO.getPageNum() - 1)).limit(queryDTO.getPageSize()).collect(Collectors.toList()); 返回其他类型的集合123456789public static List&lt;ReportTemplateVO&gt; toReportTemplateVO(List&lt;RefactorReportTemplate&gt; templates, RefactorReportContentTemplateService contentTemplateService, Boolean isCopy) &#123; Map&lt;Long, List&lt;RefactorReportContentTemplate&gt;&gt; contentTemplateMap = contentTemplateService.list().stream().collect(Collectors.groupingBy(RefactorReportContentTemplate::getTemplateBaseId)); return templates.stream() .map(template -&gt; &#123; // 根据模板ID获取对应的内容模板列表，如果不存在则返回空列表 List&lt;RefactorReportContentTemplate&gt; ct = contentTemplateMap.getOrDefault(template.getTemplateBaseId(), Collections.emptyList()); return toReportTemplateVO(template, ct, isCopy); &#125;).collect(Collectors.toList()); &#125; List用属性名称变量排序12345678910111213141516171819if (queryDTO.getAsc()) &#123;voList.sort(Comparator.comparing(projectRefactorBugVo -&gt; &#123;try &#123;Field field = projectRefactorBugVo.getClass().getSuperclass().getDeclaredField(queryDTO.getSortField());field.setAccessible(true);return (Comparable) field.get(projectRefactorBugVo);&#125;catch (Exception e) &#123;throw new RuntimeException(e);&#125;&#125;, Comparator.naturalOrder()));&#125;else &#123;voList.sort(Comparator.comparing(projectRefactorBugVo -&gt; &#123;try &#123;Field field = projectRefactorBugVo.getClass().getSuperclass().getDeclaredField(queryDTO.getSortField());field.setAccessible(true);return (Comparable) field.get(projectRefactorBugVo);&#125;catch (Exception e) &#123;throw new RuntimeException(e);&#125;&#125;, Comparator.reverseOrder()));&#125; 流，双层map1234Map&lt;String, Map&lt;String, SysDictDataPlus&gt;&gt; dict = sysDictDataPlusService.list(queryWrapperSysDictDataPlus).stream().collect(Collectors.groupingBy(SysDictDataPlus::getDictType, // 外层Map的键Collectors.toMap(SysDictDataPlus::getDictValue, e -&gt; e) // 内层Map的键和值)); 流map1234Map&lt;Long, List&lt;RefactorReportInstance&gt;&gt; ins = instanceService.selectInstanceByInsIds(temIdList) .stream().collect(Collectors.groupingBy(RefactorReportInstance::getTemplateBaseId));Map&lt;Long, SysUser&gt; usMap = userService.list().stream().collect(Collectors.toMap(SysUser::getUserId, t -&gt; t)); 流单map，单值过滤1234567891011 Map&lt;Long, RefactorReportInstance&gt; collect = instanceService.selectInstanceByInsIds(temIdList).stream().collect(Collectors.toMap( RefactorReportInstance::getTemplateBaseId, // 作为key e -&gt; e, // 作为value (exiValue, newValue) -&gt; &#123; // 当value冲突时 // 比较两个对象的sort字段，返回具有最大sort值的对象 return exiValue.getTemplateInstanceId() &gt;= newValue.getTemplateInstanceId() ? exiValue : newValue; &#125; ));Map&lt;Long, RefactorReportInstance&gt; temIns = instanceService.selectInstanceByInsIds(temIdList).stream().collect(Collectors.toMap( RefactorReportInstance::getTemplateBaseId,e -&gt; e,(exiValue, newValue) -&gt; exiValue.getTemplateInstanceId() &gt;= newValue.getTemplateInstanceId() ? exiValue : newValue)); 流，list分组1Map&lt;Long, List&lt;SysDept&gt;&gt; deptMapBytParentId = list.stream().collect(Collectors.groupingBy(SysDept::getParentId)); 流，是否包含1boolean b = refactorReports.stream().anyMatch(person -&gt; person.getTemplateInstanceId().equals(ins.getTemplateInstanceId())); 流，遍历修改list1234567891011List&lt;RefactorReportContentTemplate&gt; up = delRefactorReportContentTemplate.stream().peek(e -&gt; &#123; e.setDelFlag(CommonConstant.DELETED_BYTE); e.setUpdateTime(DateTimeUtil.getCurrentBeijingTime()); e.setUpdateBy(user.getUserName()); &#125;).collect(Collectors.toList()); delRefactorReportContentTemplate = delRefactorReportContentTemplate.stream().peek(e -&gt; &#123; e.setDelFlag(CommonConstant.DELETED_BYTE); e.setUpdateTime(DateTimeUtil.getCurrentBeijingTime()); e.setUpdateBy(user.getUserName()); &#125;).collect(Collectors.toList()); 简单差集123List&lt;Long&gt; diff = reportCountUserIdList.stream() .filter(e -&gt; !subUserIdList.contains(e)) .collect(Collectors.toList()); 简单交集1234567List&lt;Long&gt; list1 = List.of(1L, 2L, 3L);List&lt;Long&gt; list2 = List.of(2L, 3L, 4L);List&lt;Long&gt; intersection = list1.stream() .filter(list2::contains) .distinct() .collect(Collectors.toList()); 简单并集12A.addAll(B);List&lt;String&gt; AuB = A.stream().distinct().collect(Collectors.toList()); 对象交集差集现在有两个类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class ClassA &#123; String id; String realName; public ClassA(String id, String realName) &#123; this.id = id; this.realName = realName; &#125; @Override public String toString() &#123; return &quot;ClassA&#123;&quot; + &quot;id=&#x27;&quot; + id + &#x27;\\&#x27;&#x27; + &quot;, realName=&#x27;&quot; + realName + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125; public String getId() &#123; return id; &#125; public String getRealName() &#123; return realName; &#125;&#125;class ClassB &#123; String id; String nickName; public ClassB(String id, String nickName) &#123; this.id = id; this.nickName = nickName; &#125; @Override public String toString() &#123; return &quot;ClassB&#123;&quot; + &quot;id=&#x27;&quot; + id + &#x27;\\&#x27;&#x27; + &quot;, nickName=&#x27;&quot; + nickName + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125; public String getId() &#123; return id; &#125; public String getNickName() &#123; return nickName; &#125;&#125; 现在有两个集合，分别是ClassA对象的集合、ClassB对象的集合 1234567891011List&lt;ClassA&gt; aList = new ArrayList&lt;&gt;(Arrays.asList( new ClassA(&quot;1&quot;, &quot;张三&quot;), new ClassA(&quot;2&quot;, &quot;李四&quot;), new ClassA(&quot;3&quot;, &quot;王五&quot;)));List&lt;ClassB&gt; bList = new ArrayList&lt;&gt;(Arrays.asList( new ClassB(&quot;2&quot;, &quot;李某&quot;), new ClassB(&quot;3&quot;, &quot;王某&quot;), new ClassB(&quot;4&quot;, &quot;赵某&quot;))); 基本思想就是想遍历第一个集合，取出第一个集合中的每个元素的某个属性，并使用这个属性遍历第二个集合，看这个属性是否在第二个集合中存在。相当于是有两层循环。Java 8中引入了Stream和Lambda表达式，使用它们无需自己编写for循环，只需一行代码就能实现上述功能。 代码实现 1234567891011121314//aList与bList的交集List&lt;ClassA&gt; intersectA = aList .stream() //获取第一个集合的Stream1 .filter( //取出Stream1中符合条件的元素组成新的Stream2，lambda表达式1返回值为true时为符合条件 a -&gt; //lambda表达式1，a为lambda表达式1的参数，是Stream1中的每个元素 bList.stream() //获取第二个集合的Stream3 .map(ClassB::getId) //将第二个集合每个元素的id属性取出来，映射成新的一个Stream4 .anyMatch( //返回值（boolean）：Stream4中是否至少有一个元素使lambda表达式2返回值为true id -&gt; //lambda表达式2，id为lambda表达式2的参数，是Stream4中的每个元素 Objects.equals(a.getId(), id) //判断id的值是否相等 ) ) .collect(Collectors.toList()); //将Stream2转换为ListSystem.out.println(intersectA); 123456789101112131415161718//实际交集示例List&lt;RefactorReportContentTemplate&gt; upDateRefactorReportContentTemplate = oldContentTemplates.stream() .filter(a -&gt; newContentTemplates.stream().map(RefactorReportContentTemplate::getId) .anyMatch(id -&gt; Objects.equals(a.getId(), id))).collect(Collectors.toList());//多条件扩展List&lt;RefactorReportContentTemplate&gt; upDateRefactorReportContentTemplate = oldContentTemplates.stream() .filter(oldTemplate -&gt; newContentTemplates.stream() .filter(e -&gt; ObjectUtil.isNotEmpty(e.getId())) .anyMatch(newTemplate -&gt; Objects.equals(oldTemplate.getId(), newTemplate.getId()) &amp;&amp; ( !oldTemplate.getName().equals(newTemplate.getName()) || !oldTemplate.getStatus().equals(newTemplate.getStatus()) || !oldTemplate.getContentType().equals(newTemplate.getContentType()) || !oldTemplate.getPlaceholder().equals(newTemplate.getPlaceholder()) || !oldTemplate.getCannotEdit().equals(newTemplate.getCannotEdit()) ))).collect(Collectors.toList()); 123//bList与aList的差集List&lt;ClassB&gt; differenceB = bList.stream().filter(b -&gt; aList.stream().map(ClassA::getId).noneMatch(id -&gt; Objects.equals(b.getId(), id))).collect(Collectors.toList());System.out.println(differenceB); 简单去重1234 List&lt;Long&gt; makeDepts = new ArrayList&lt;&gt;();// 假设makeDepts被填充了一些可能包含重复的元素// 使用Stream API去重makeDepts = makeDepts.stream().distinct().collect(Collectors.toList()); 流类型转换，map123list(queryWrapperBing).stream().collect(Collectors.groupingBy(sysDataBindPlus -&gt; Long.valueOf(sysDataBindPlus.getMainId()),Collectors.toList())); 1Map&lt;Long, List&lt;RefactorReport&gt;&gt; collect = reportList.stream().collect(Collectors.groupingBy(RefactorReport::getTemplateInstanceId, Collectors.toList())); 12Map&lt;Long, User&gt; userMap = userList.stream().collect(Collectors.toMap(User::getId, t -&gt; t)); 转数组12long[] pos = sysUserPosts1.stream().mapToLong(SysUserPost::getPostId).toArray();Long[] pos = sysUserPosts1.stream().map(SysUserPost::getPostId).toArray(Long[]::new); 数组转list1List&lt;Long&gt; longList = Arrays.asList(longArray); List，倒序1Collections.sort(voList, (s1, s2) -&gt; s2.getState().compareTo(s1.getState())); List，升序1Collections.sort(voList, Comparator.comparing(ProjectRefactorBugVo::getState)); 12345if (Strings.isNotBlank(queryDTO.getSortField())) &#123;if (ObjectUtil.isEmpty(queryDTO.getAsc()))queryDTO.setAsc(false);queryWrapper.last(&quot;order by &quot; + StrUtil.toUnderlineCase(queryDTO.getSortField()) + &quot; &quot; + ((queryDTO.getAsc()) ? &quot;asc&quot; : &quot;desc&quot;));&#125; List 转字符串1String join = String.join(&quot;, &quot;, list); 去除另外1个list中有的元素1234newRole = newRole.stream().filter(newRoleItem -&gt; oldRole.stream().noneMatch(oldRoleItem -&gt; oldRoleItem.getRoleId().equals(newRoleItem.getRoleId()))).collect(Collectors.toList()); 本地懒得启动，就用远程调试。如果要一定要本地调试，就用 ktctl 引导 集群镜像一份流量 到 本地JVM","tags":["笔记"],"categories":["Java"]},{"title":"全局错误码国际化。枚举中注入bean","path":"/2023/09/25/20230925e/","content":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import com.google.common.base.Strings;import lombok.extern.slf4j.Slf4j;import org.springframework.context.MessageSource;import org.springframework.context.i18n.LocaleContextHolder;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;import javax.annotation.Resource;@Slf4jpublic enum ResultCode &#123; /** * */ SUCCESS(20000, &quot;成功&quot;), ERROR(20001, &quot;服务器内部错误&quot;), EMPTY_PARAM(20003, &quot;非空参数需要传递&quot;), BAD_PARAM(20004, &quot;参数错误&quot;), USER_REGISTER_PARAMS_REPEAT(10001, &quot;用户注册信息重复&quot;), USER_NOT_LOGIN(10002, &quot;用户未登录&quot;), USER_NOT_EXIST(10003, &quot;用户手机号未注册&quot;), USER_LOCKED(10004, &quot;账号已被锁定，联系管理员&quot;), USER_CHAT_LIMITED(30001, &quot;用户当日聊天功能已达到上限！&quot;), USER_FILE_UPLOAD_LIMITED(30002, &quot;用户当日文件上传功能已达到上限！&quot;), ADMIN_OPERATE_FORBIDDEN(40001, &quot;禁止操作管理员权限的功能！&quot;), ADMIN_APIKEY_NULL(40002, &quot;系统API-Key使用繁忙！请稍后再试~&quot;), UPLOAD_FILE_ERROR(50001, &quot;文件处理失败，请检查文件页数！&quot;), ; public final int code; public final String msg; public String getMsg() &#123; String message = &quot;&quot;; try &#123; message = ReportTypeServiceInjector.messageSource.getMessage(code + &quot;&quot;, null, LocaleContextHolder.getLocale()); &#125; catch (Exception e) &#123; log.error(&quot;&#123;&#125;的国际化错误信息未添加或出错.&quot;, code); &#125; if (!Strings.isNullOrEmpty(message)) return message; return msg; &#125; ResultCode(int code, String msg) &#123; this.code = code; this.msg = msg; &#125; @Component public static class ReportTypeServiceInjector &#123; @Resource private MessageSource messagSource; private static MessageSource messageSource; @PostConstruct private void postConstruct() &#123; ReportTypeServiceInjector.messageSource = messagSource; &#125; &#125;&#125; application.properties中，配置了2个国际化语言包spring.messages.basename= i18n.messages,i18n.errors 其他地方调用 1throw new BaseException(ResultCode.ADMIN_APIKEY_NULL.getMsg());","tags":["笔记"],"categories":["Java"]},{"title":"cenos8安装java1.8","path":"/2023/09/22/20230922java8/","content":"1.安装方法： CentOS8上使用 yum 直接安装，环境变量会自动配置完成 。 查询可安装jdk列表： 执行命令： 1java -version 如果出现以下字样，则表示已安装： 1openjdk version &quot;1.8.0_222&quot; 查询可安装jdk列表 1yum list java-1.8* 安装jdk1.8 1yum -y install java-1.8.0-openjdk*x86_64 查看是否安装成功 12java -versionjavac -version","tags":["笔记"],"categories":["Java"]},{"title":"SpringBoot拦截器中获取token中的用户信息并通过注解可以在任何一个Controller上获取到用户基本信息","path":"/2023/09/22/20230922/","content":"前端调用后端Controller方法时，进入Controller方法后，经常需要获取当前登录用户的信息，便于一些后续的用户操作(比如保存时需要自动填入当前登录用户的用户名)。 通常的做法是，前端将token信息放入请求头中，后端拿到请求头中的token后，再将token解析成用户信息。 解决方案token解析工具类方法 校验token有效性：boolean isValid = tokenUtils.isValid(token); 解析token为User：User user = tokenUtils.getUserInfoByToken(token); 直接在需要使用用户信息的地方调用token解析方法获取User对象。 WebMvcConfigurer + HandlerInterceptor + HandlerMethodArgumentResolver Spring内部的一种配置方法，通过用java代码代替xml配置Bean，可以通过实现WebMvcConfigurer接口自定义一些MVC相关的Handler，Interceptor等。 1234567891011121314151617181920212223242526272829@Configurationpublic class SecurityAutoConfiguration implements WebMvcConfigurer&#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; // addInterceptor：添加一个实现HandlerInterceptor了接口的拦截器实例 // addPathPatterns：用于设置拦截器的过滤路径规则 registry.addInterceptor(getAuthInterceptor()).addPathPatterns(&quot;/**&quot;); &#125; @Bean public AuthInterceptor getAuthInterceptor() &#123; // 声明AuthInterceptor拦截器Bean，需实现HandlerInterceptor接口 return new AuthInterceptor(); &#125; @Bean public CurrentUserMethodArgumentResolver currentUserMethodArgumentResolver() &#123; // 声明自定义方法参数解析器 return new CurrentUserMethodArgumentResolver(); &#125; @Override public void addArgumentResolvers(List argumentResolvers) &#123; // 添加CurrentUserMethodArgumentResolver参数解析器 argumentResolvers.add(currentUserMethodArgumentResolver()); &#125;&#125; 自定义HandlerInterceptor进行权限校验，token解析 123456789101112131415161718192021222324public class AuthInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String tokenId = request.getHeader(CommonDefs.AUTHORIZATION); if (!StringUtils.hasLength(tokenId)) &#123; return false; &#125; // 校验token是否有效 boolean isValid = tokenUtils.isValid(token); if (!isValid) &#123; return false; &#125; // 转换token为User实例 User user = tokenUtils.getUserInfoByToken(token); if (user == null) &#123; return false; &#125; // 将用户信息user保存到request属性中 request.setAttribute(&quot;current_user&quot;, user); return true; &#125;&#125; 自定义@CurrentUser注解，并加入到controller接口中 123456@Target(&#123;ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface CurrentUser &#123; String value() default &quot;current_user&quot;;&#125; 123456@GetMapping(&quot;/getUserInfo&quot;)@ApiOperation(value = &quot;查询用户信息&quot;)public Result getUserInfo(@ApiIgnore @CurrentUser User user) &#123; // 通过@CurrentUser修饰，user即为当前登录用户信息 return Result.ok(user);&#125; 自定义HandlerMethodArgumentResolver，将request中的User传给@CurrentUser 1234567891011121314151617181920212223// Controller参数解析器public class CurrentUserMethodArgumentResolver implements HandlerMethodArgumentResolver &#123; public CurrentUserMethodArgumentResolver() &#123; &#125; @Override // 判断Controller层中的参数，是否满足条件，满足条件则执行resolveArgument方法，不满足则跳过 public boolean supportsParameter(MethodParameter parameter) &#123; // 如果controller中的参数有CurrentUser注解修饰，则执行resolveArgument方法 return parameter.hasParameterAnnotation(CurrentUser.class); &#125; @Override // Controller中的参数满足supportsParameter()条件时执行 // 将返回值赋值给Controller层中的这个参数 public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; // 获取CurrentUser注解 CurrentUser currentUserAnnotation = (CurrentUser)parameter.getParameterAnnotation(CurrentUser.class); // 将request请求中的&quot;current_user&quot;属性赋值给当前参数 // &quot;current_user&quot;保存的是当前登录用户的信息 return webRequest.getAttribute(currentUserAnnotation.value(), 0); &#125;&#125; 如果没生效，排查一下 implements WebMvcConfigurer 的配置类 是否将解析器注入到了SpirngMVC 如果没有 可参考 1234567891011121314151617181920import com.chentawen.springbootall.config.annotation.UserIdResolver;import org.springframework.context.annotation.Configuration;import org.springframework.web.method.support.HandlerMethodArgumentResolver;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;import java.util.List;/** * @author admin */@Configurationpublic class IntercaptorConfig implements WebMvcConfigurer &#123; @Override public void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; resolvers) &#123; resolvers.add(new UserIdResolver()); &#125; &#125;","tags":["笔记"],"categories":["Java"]},{"title":"cenos8安装redis7.0.11","path":"/2023/09/21/20230921cenos8-redis/","content":"1.下载：1:https://redis.io/download/2:https://download.redis.io/releases/?_gl=1*10x9wj*_ga*MTQ5MDEyMDY4Mi4xNjk1MTE3MjI2*_ga_8BKGRQKRPV*MTY5NTI2NDM2MS4yLjAuMTY5NTI2NDM2NC41Ny4wLjA. 下载好后把安装包上传至服务器 2.安装：###解压redis： 12[root@node202 ~]# cd /usr/local/soft/[root@node202 soft]# tar -zxvf redis-7.0.11.tar.gz ###安装： 1234[root@node202 soft]# cd redis-7.0.11/#安装必要类库[root@node202 redis-7.0.11]# yum -y install gcc automake autoconf libtool make[root@node202 redis-7.0.11]# make &amp; make install ###启动 12[root@node202 redis-7.0.11]# cd src[root@node202 src]# ./redis-server /usr/local/soft/redis-7.0.11/redis.conf 日志： 1234567891011121314151617181920212223242526278789:C 11 May 2023 01:53:49.076 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo8789:C 11 May 2023 01:53:49.076 # Redis version=7.0.11, bits=64, commit=00000000, modified=0, pid=8789, just started8789:C 11 May 2023 01:53:49.076 # Configuration loaded8789:M 11 May 2023 01:53:49.077 * Increased maximum number of open files to 10032 (it was originally set to 1024).8789:M 11 May 2023 01:53:49.077 * monotonic clock: POSIX clock_gettime _._ _.-``__ &#x27;&#x27;-._ _.-`` `. `_. &#x27;&#x27;-._ Redis 7.0.11 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ &#x27;&#x27;-._ ( &#x27; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;| Port: 6379 | `-._ `._ / _.-&#x27; | PID: 8789 `-._ `-._ `-./ _.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | https://redis.io `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; `-._ `-.__.-&#x27; _.-&#x27; `-._ _.-&#x27; `-.__.-&#x27; 8789:M 11 May 2023 01:53:49.078 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.8789:M 11 May 2023 01:53:49.078 # Server initialized8789:M 11 May 2023 01:53:49.078 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add &#x27;vm.overcommit_memory = 1&#x27; to /etc/sysctl.conf and then reboot or run the command &#x27;sysctl vm.overcommit_memory=1&#x27; for this to take effect.8789:M 11 May 2023 01:53:49.078 * Ready to accept connections ###使用 123456[root@node202 src]# ./redis-cli 127.0.0.1:6379&gt; set foo barOK127.0.0.1:6379&gt; get foo&quot;bar&quot;127.0.0.1:6379&gt; ##配置 创建一个用于存储 Redis 配置文件目录（/etc/redis）和数据目录（/var/redis）： 12mkdir -p /etc/redismkdir -p /var/redis 复制配置文件： 1cp /usr/local/soft/redis-7.0.11/redis.conf /etc/redis/ 复制编辑启动脚本： 1cp /usr/local/soft/redis-7.0.11/utils/redis_init_script /etc/init.d/redis 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556vim /etc/init.d/redis#!/bin/sh# # Simple Redis init.d script conceived to work on Linux systems# as it does use of the /proc filesystem.### BEGIN INIT INFO# Provides: redis_6379# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Redis data structure server# Description: Redis data structure server. See https://redis.io### END INIT INFOREDISPORT=6379EXEC=/usr/local/bin/redis-serverCLIEXEC=/usr/local/bin/redis-cliPIDFILE=/var/run/redis_$&#123;REDISPORT&#125;.pidCONF=&quot;/etc/redis/redis.conf&quot;case &quot;$1&quot; instart) if [ -f $PIDFILE ] then echo &quot;$PIDFILE exists, process is already running or crashed&quot; else echo &quot;Starting Redis server...&quot; $EXEC $CONF fi ;;stop) if [ ! -f $PIDFILE ] then echo &quot;$PIDFILE does not exist, process is not running&quot; else PID=$(cat $PIDFILE) echo &quot;Stopping ...&quot; $CLIEXEC -p $REDISPORT shutdown while [ -x /proc/$&#123;PID&#125; ] do echo &quot;Waiting for Redis to shutdown ...&quot; sleep 1 done echo &quot;Redis stopped&quot; fi ;;restart) &quot;$0&quot; stop sleep 3 &quot;$0&quot; start ;;*) echo &quot;Please use start or stop or restart as first argument&quot; ;;esac 设置开机自启动： 123456chmod +x /etc/init.d/redis #给脚本设置权限chkconfig --add redis #添加redis服务chkconfig redis on #设置redis服务开机启动 完结。 解决服务器Redis无法连接问题 找到你的redis配置文件，进行以下步骤修改。（本人的在/etc/redis.conf，如果找不到，直接创建一个，然后度娘一个默认的redis配置文件粘贴上去即可，启动时使用命令redis-cli +文件路径，下文会讲） 修改bind，默认为bind 127.0.0.1，将其注释(前面加个#)，如果没有找到bind 127.0.0.1或已经注释，跳过此步，注意搜索一下127.0.0.1，可能不止1个地方有 1234567# By default Redis listens for connections from all the network interfaces# available on the server. It is possible to listen to just one or multiple# interfaces using the &quot;bind&quot; configuration directive, followed by one or# more IP addresses.## Examples:# bind 127.0.0.1 关闭保护模式，默认为protected-mode yes,将yes修改为no，如果没有找到protected-mode yes，可以随意另起一行添加protected-mode no；或已经修改为protected-mode no，跳过此步。 123456789101112131415# When protected mode is on and if:## 1) The server is not binding explicitly to a set of addresses using the# &quot;bind&quot; directive.# 2) No password is configured.## The server only accepts connections from clients connecting from the# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain# sockets.## By default protected mode is enabled. You should disable it only if# you are sure you want clients from other hosts to connect to Redis# even if no authentication is configured, nor a specific set of interfaces# are explicitly listed using the &quot;bind&quot; directive.protected-mode no 如果有需求，设置密码（没有需求则跳过），添加一行requirepass 123456，作用是设置连接密码为123456，如有需求可以修改密码 123456789101112131415################################## SECURITY #################################### Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other# commands. This might be useful in environments in which you do not trust# others with access to the host running redis-server.## This should stay commented out for backward compatibility and because most# people do not need auth (e.g. they run their own servers).## Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.## requirepass foobaredrequirepass 123456 重启你的redis，在安装redis的位置使用命令redis-cli shutdown，然后再使用命令./redis-server /etc/redis.conf启动redis，请注意，如果你修改的配置文件在其他地方：例如/opt/redis/redis.conf，请你使用./redis-server /opt/redis/redis.conf启动redis。如果启动后无法进行其他操作，请使用Ctrl+C结束该进程后，找到刚刚修改的配置文件，找到并修改为或者添加daemonize=yes（稍微提一嘴，windows版本不支持），然后再启动redis。 1daemonize=yes 最后关闭你的防火墙，或者将redis加入白名单，这里只做关闭处理，这一步操作因linux版本而异 12systemctl status firewalld.service #查看防火墙状态systemctl stop firewalld.service #关闭防火墙","tags":["笔记"],"categories":["其他"]},{"title":"cenos8安装mysql5.7","path":"/2023/09/19/20230919/","content":"安装Mysql5.7详细教程，注意细节～1.获取安装包1wget http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm 如果提示wget不能识别或者不存在 1yum install -y wget 如果安装wget报错：repo ‘appstream’: Cannot prepare internal mirrorlist: No URLs in mirrorlist这是因为在CentOS8.0中默认不再支持ntp软件包，时间同步将由chrony来实现，像我这种习惯了ntp同步时间的，一时难以去适应chrony如果仍然需要运行CentOS 8，你可以在/etc/yum.repos.d中更新一下源。使用vault.centos.org代替mirror.centos.org。 12sudo sed -i -e &quot;s|mirrorlist=|#mirrorlist=|g&quot; /etc/yum.repos.d/CentOS-*sudo sed -i -e &quot;s|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g&quot; /etc/yum.repos.d/CentOS-* 如果出现报错：cenos8 Failed to set locale, defaulting to C.UTF-8 这里会有两种原因 系统没有安装对应的语言包没有配置正确的语言环境一般情况下都是第二种情况居多首先使用 locale -a 查看已安装的语言包 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@hecs-131104 data]# locale -alocale: Cannot set LC_CTYPE to default locale: No such file or directorylocale: Cannot set LC_MESSAGES to default locale: No such file or directorylocale: Cannot set LC_COLLATE to default locale: No such file or directoryCC.utf8POSIXen_AGen_AUen_AU.utf8en_BWen_BW.utf8en_CAen_CA.utf8en_DKen_DK.utf8en_GBen_GB.iso885915en_GB.utf8en_HKen_HK.utf8en_IEen_IE.utf8en_IE@euroen_ILen_INen_NGen_NZen_NZ.utf8en_PHen_PH.utf8en_SC.utf8en_SGen_SG.utf8en_USen_US.iso885915en_US.utf8en_ZAen_ZA.utf8en_ZMen_ZWen_ZW.utf8 这里有en_US.utf8，所以是第二种情况。执行以下命令即可 123echo &quot;export LC_ALL=en_US.UTF-8&quot; &gt;&gt; /etc/profileecho &quot;export LC_CTYPE=en_US.UTF-8&quot; &gt;&gt; /etc/profilesource /etc/profile 2.开始安装1yum localinstall mysql57-community-release-el7-11.noarch.rpm 看到下面这个场景：👇 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 3.安装mysql-community-server1yum install mysql-community-server 如果出现下图的错误，请执行检查： ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 检查mysql源是否安装成功： 1yum repolist enabled | grep &quot;mysql.*.community.*&quot; ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 如果有类似上图这些信息则表示成功的，如果没有，请重新执行第二步。再依次执行下面两条语句： 12yum module disable mysqlyum -y install mysql-community-server ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 这里有问题的可以执行下下面这个语句： (没问题的可以不执行) 123rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022yum clean packagesyum -y install mysql-community-server 如果安装过程出现mariadb冲突，可参考下面这篇文章解决：https://blog.csdn.net/dietime1943/article/details/127636430 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 报错：Error: Transaction test error: file /etc/my.cnf from install of mysql-community-server问题描述在安装MySQL过程中出现错误 file /etc/my.cnf from install of mysql-community-server-xxx conflicts with file from package mariadb-connector-c-config-xxx.noarch提示。 具体错误信息如下： 123456789Total 588 kB/s | 1.4 MB 00:02Running transaction checkTransaction check succeeded.Running transaction testThe downloaded packages were saved in cache until the next successful transaction.You can remove cached packages by executing &#x27;yum clean packages&#x27;.Error: Transaction test error: file /etc/my.cnf from install of mysql-community-server-8.0.15-1.el7.x86_64 conflicts with file from package mariadb-connector-c-config-3.1.11-2.el8_3.noarch 原因分析从错误信息中看，是冲突了，因为错误信息中有写 conflicts with file from package，但是这是一个全新的Linux8，正常没有安装过MySQL也没有安装过Mariadb，所以猜测是该Linux机器内嵌集成了该Mariadb包，造成冲突。 解决办法查看本机被内嵌的Mariadb 1rpm -qa | grep mariadb 可以看到执行查找的时候，在系统中有内嵌两个mariadb包 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 使用rpm -e –nodeps package将内嵌集成的Mariadb卸载掉 12rpm -e --nodeps mariadb-connector-c-config-3.1.11-2.el8_3.noarchrpm -e --nodeps mariadb-connector-c-3.1.11-2.el8_3.x86_64 执行卸载如图所示： ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 卸载掉冲突的mariadb后，再次尝试安装mysql成功 其他解决办法(推荐用上面的)该办法来源于评论区网友的解答： 直接sudo yum remove mariadb-common-3:10.3.9-9.p02.ky10.x86_64也是ok的，即运行命令： 1sudo yum remove mariadb-common-3:10.3.9-9.p02.ky10.x86_64 ; 4.启动MySQL1systemctl start mysqld.service 5.查看状态1234systemctl status mysql.service# 如果出现如下报错，请换成 service mysqld status 这条命令Unit mysql.service could not be found. 看到类似下图表示成功： ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 6.设置开机启动12systemctl enable mysqldsystemctl daemon-reload 7.查看开机启动状态1systemctl list-unit-files | grep mysqld 如下图，表示设置成功： ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 8.获取初始密码1grep &#x27;temporary password&#x27; /var/log/mysqld.log 马赛克隐藏的地方就是你的初始密码： ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 9.登录mysql修改密码，并开启远程访问1mysql -u root -p 输入密码后再输入 1set password for &#x27;root&#x27;@&#x27;localhost&#x27;=你的新密码 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 设置新密码与远程访问：（默认密码需要强密码，大小写+数字+字符） 12345678910# 如果想要密码规则简单一点，可以修改两个全局参数（可以不用设置）set global validate_password_policy=0;set global validate_password_length=1;# 设置新密码（需要大写、小写、数字、符号）set password for &#x27;root&#x27;@&#x27;localhost&#x27;=&#x27;你的新密码&#x27;;# 设置远程访问GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;你的新密码&#x27; WITH GRANT OPTION;# 刷新使配置生效flush privileges;# 注意最后的;不能去掉 退出mysql命令行 123quit或者exit或者在MySQL命令行界面中，按下Ctrl + D键即可退出。这将关闭MySQL命令行界面并返回到操作系统的终端窗口 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 到此，大功告成，记得去把 3306 端口的防火墙放开!","tags":["笔记"],"categories":["mysql"]},{"title":"【SpringCloud】微服务笔记2","path":"/2023/07/20/2023072003jsc/","content":"技术版本cloudHoxton.SR1boot2.2.2.RELEASEcloud alibaba2.1.0.RELEASEjavajava8Maven3.5及以上Mysql5.7及以上 1. 新建Maven父工程 cloud2020maven架构选择org.apache.maven.archetypes:maven-archetype-sitepom.xml代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; &lt;packaging&gt;pompackaging&gt; &lt;name&gt;Mavenname&gt; &lt;url&gt;http://maven.apache.org/url&gt; &lt;inceptionYear&gt;2001inceptionYear&gt; &lt;distributionManagement&gt; &lt;site&gt; &lt;id&gt;websiteid&gt; &lt;url&gt;scp://webhost.company.com/www/websiteurl&gt; site&gt; distributionManagement&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8maven.compiler.target&gt; &lt;junit.version&gt;4.12junit.version&gt; &lt;log4j.version&gt;1.2.17log4j.version&gt; &lt;lombok.version&gt;1.16.18lombok.version&gt; &lt;mysql.version&gt;5.1.47mysql.version&gt; &lt;druid.version&gt;1.1.16druid.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0mybatis.spring.boot.version&gt; properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-dependenciesartifactId&gt; &lt;version&gt;2.2.2.RELEASEversion&gt; &lt;type&gt;pomtype&gt; &lt;scope&gt;importscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-dependenciesartifactId&gt; &lt;version&gt;Hoxton.SR1version&gt; &lt;type&gt;pomtype&gt; &lt;scope&gt;importscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependenciesartifactId&gt; &lt;version&gt;2.1.0.RELEASEversion&gt; &lt;type&gt;pomtype&gt; &lt;scope&gt;importscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysqlgroupId&gt; &lt;artifactId&gt;mysql-connector-javaartifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibabagroupId&gt; &lt;artifactId&gt;druidartifactId&gt; &lt;version&gt;$&#123;druid.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; &lt;version&gt;$&#123;mybatis.spring.boot.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junitgroupId&gt; &lt;artifactId&gt;junitartifactId&gt; &lt;version&gt;$&#123;junit.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;version&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; dependencies&gt; dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-maven-pluginartifactId&gt; &lt;configuration&gt; &lt;fork&gt;truefork&gt; &lt;addResources&gt;trueaddResources&gt; configuration&gt; plugin&gt; plugins&gt; build&gt;project&gt; 2. 建立支付module: cloud-provider-payment8001项目结构： ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 2.1 pom.xml如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; parent&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;artifactId&gt;cloud-provider-payment8001artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibabagroupId&gt; &lt;artifactId&gt;druid-spring-boot-starterartifactId&gt; &lt;version&gt;1.1.10version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysqlgroupId&gt; &lt;artifactId&gt;mysql-connector-javaartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbcartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; dependencies&gt;project&gt; 2.2 application.yml12345678910111213141516server: port: 8001spring: application: name: cloud-provider-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/db2019?useUnicode=true&amp;characterEncoding-utr-8&amp;useSSL=false username: root password: rootmybatis: mapper-locations: classpath:mapper/*.xml type-aliases-package: com.atguigu.springcloud.entities 2.3 主启动类 PaymentMain8001123456789101112package com.atguigu.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class,args); &#125;&#125; 2.4 数据库建库： 12345CREATE TABLE `payment`(\t`id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;ID&#x27;,\t`serial` varchar(200) DEFAULT &#x27;&#x27;,\tPRIMARY KEY (`id`)) ENGING=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 2.5 业务类1234567891011121314package com.atguigu.springcloud.entities;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Payment &#123; private Long id; private String serial;&#125; 123456789101112131415161718package com.atguigu.springcloud.entities;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class CommonResult&lt;T&gt; &#123; private Integer code; private String message; private T data; public CommonResult(Integer code,String message)&#123; this(code,message,null); &#125;&#125; 123456789101112package com.atguigu.springcloud.dao;import com.atguigu.springcloud.entities.Payment;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param;@Mapperpublic interface PaymentDao &#123; int create(Payment payment); Payment getPaymentById(@Param(&quot;id&quot;) Long id);&#125; 1234567891011121314151617DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.atguigu.springcloud.dao.PaymentDao&quot;&gt; &lt;insert id=&quot;create&quot; parameterType=&quot;Payment&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; insert into payment(serial) values(#&#123;serial&#125;) insert&gt; &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.atguigu.springcloud.entities.Payment&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot; jdbcType=&quot;BIGINT&quot;/&gt; &lt;result column=&quot;serial&quot; property=&quot;serial&quot; jdbcType=&quot;VARCHAR&quot;/&gt; resultMap&gt; &lt;select id=&quot;getPaymentById&quot; parameterType=&quot;Long&quot; resultMap=&quot;BaseResultMap&quot;&gt; select * from payment where id=#&#123;id&#125;; select&gt;mapper&gt; 123456789package com.atguigu.springcloud.service;import com.atguigu.springcloud.entities.Payment;import org.apache.ibatis.annotations.Param;public interface PaymentService &#123; public int create(Payment payment); public Payment getPaymentById(@Param(&quot;id&quot;) Long id);&#125; 123456789101112131415161718package com.atguigu.springcloud.service;import com.atguigu.springcloud.dao.PaymentDao;import com.atguigu.springcloud.entities.Payment;import org.springframework.stereotype.Service;import javax.annotation.Resource;@Servicepublic class PaymentServiceImpl implements PaymentService&#123; @Resource private PaymentDao paymentDao; public int create(Payment payment)&#123; return paymentDao.create(payment); &#125; public Payment getPaymentById(Long id)&#123; return paymentDao.getPaymentById(id); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839package com.atguigu.springcloud.controller;import com.atguigu.springcloud.entities.CommonResult;import com.atguigu.springcloud.entities.Payment;import com.atguigu.springcloud.service.PaymentService;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;@RestController@Slf4jpublic class PaymentController &#123; @Resource private PaymentService paymentService; @PostMapping(value = &quot;/payment/create&quot;) public CommonResult create(Payment payment)&#123; int result = paymentService.create(payment); log.info(&quot;*****插入结果：&quot;+result); if(result &gt; 0)&#123; return new CommonResult(200,&quot;插入数据成功&quot;,result); &#125;else&#123; return new CommonResult(444,&quot;插入数据失败&quot;,null); &#125; &#125; @GetMapping(value = &quot;/payment/get/&#123;id&#125;&quot;) public CommonResult getPaymentById(@PathVariable(&quot;id&quot;) Long id)&#123; Payment payment = paymentService.getPaymentById(id); log.info(&quot;*****插入结果：&quot;+payment); if(payment != null)&#123; return new CommonResult(200,&quot;查询成功&quot;,payment); &#125;else&#123; return new CommonResult(444,&quot;没有对应记录,查询ID：&quot;+id,null); &#125; &#125;&#125; 2.6测试Chrom浏览器可能不支持Post请求，可以使用PostMan工具测试 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 总结： 1. 建module 2. 改pom 3. 写yml 4. 主启动 5. 业务类 ; 3. 建立消费者订单module:,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 3.1 pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; parent&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;artifactId&gt;cloud-consumer-order80artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; dependencies&gt;project&gt; 3.2 application.yml12server: port: 80 3.3 主启动123456789package com.atguigu.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class OrderMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderMain80.class,args); &#125;&#125; 3.4业务类订单也需要Payment、CommonResult实体类，但是不需要操作数据库，没有Service、Dao，只需添加Controller即可。 12345678910111213package com.atguigu.springcloud.entities;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Payment &#123; private Long id; private String serial;&#125; 12345678910111213141516171819package com.atguigu.springcloud.entities;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class CommonResult&lt;T&gt; &#123; private Integer code; private String message; private T data; public CommonResult(Integer code,String message)&#123; this(code,message,null); &#125;&#125; 首说RestTemplate： RestTemplate提供了多种便捷访问远程Http服务的方法，是一种简单便捷的访问restful服务模板类，是Spring提供的用于访问Rest服务的客户端模板工具集，实现80到8001的远程调用。官网地址：https://docs.spring.io/spring-framework/docs/5.2.2.RELEASE/javadoc-api/org/springframework/web/client/RestTemplate.html使用：使用restTemplate访问restful接口非常的简单粗暴，（url、requestMap、ResponseBean.class）这三个参数分别代表REST请求地址、请求参数、HTTP响应转换被转换成的对象类型。 将RestTemplate对象注册到容器中 123456789101112package com.atguigu.springcloud.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class ApplicationContextConfig &#123; @Bean public RestTemplate getRestTemplate()&#123; return new RestTemplate(); &#125;&#125; 123456789101112131415161718192021222324252627package com.atguigu.springcloud.controller;import com.atguigu.springcloud.entities.CommonResult;import com.atguigu.springcloud.entities.Payment;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import javax.annotation.Resource;@RestController@Slf4jpublic class OrderController &#123; private static final String PAYMENT_URL=&quot;http://localhost:8001&quot;; @Resource private RestTemplate restTemplate;\t@GetMapping(&quot;/consumer/payment/create&quot;) public CommonResult&lt;Payment&gt; create(Payment payment)&#123; return restTemplate.postForObject(PAYMENT_URL+&quot;/payment/create&quot;,payment,CommonResult.class); &#125; @GetMapping(&quot;/consumer/payment/get/&#123;id&#125;&quot;) public CommonResult&lt;Payment&gt; getPayment(@PathVariable(&quot;id&quot;) Long id)&#123; return restTemplate.getForObject(PAYMENT_URL+&quot;/payment/get/&quot;+id,CommonResult.class); &#125;&#125; 3.5启动80、8001服务，测试80服务调用8001服务，实现效果如下： 查询：,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 添加：) 浏览器并没有返回错误，但是我们来看数据库：) 可以看到数据库只插入主键，并没有插入内容，要在8001的PaymentController加@RequestBody注解。,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 然后就可以插入了,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 4. 工程重构项目中存在相同的代码（entities包下的Payment.class和CommonResult.class）,造成代码冗余，可以进行重构。通过Maven聚合父工程，把相同重复的代码移到公开公用的工程里面，还可以放第三方接口、工具类，统一调配使用。 4.1 建立公共module,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 4.2 pom.xml1234567891011121314151617181920212223242526272829303132&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; parent&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutoolgroupId&gt; &lt;artifactId&gt;hutool-allartifactId&gt; &lt;version&gt;5.1.0version&gt; dependency&gt; dependencies&gt;project&gt; 4.3 将entities包复制到cloud-api-commons,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 4.4 使用Maven打包发布上传到公用本地库里打开Maven窗口，执行clean测试一下，无误后出现BUILD SUCCESS，然后执行install ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 4.5 删除重复entities，引入maven install的jar包坐标即可使用。123456&lt;dependency&gt;\t&lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt;dependency&gt; 5.EurekaServer服务端安装5.1建module cloud-eureka-server7001,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 5.2 pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; parent&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;artifactId&gt;cloud-eureka-server7001artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-serverartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junitgroupId&gt; &lt;artifactId&gt;junitartifactId&gt; dependency&gt; dependencies&gt;project&gt; 5.3 application.yml123456789101112131415server: port: 7001eureka: instance: hostname: localhost client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 5.4 主启动类123456789101112package com.atguigu.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaMain7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaMain7001.class,args); &#125;&#125; 这是个服务注册中心，主要干的活就是服务注册，不需要写业务类。但是注意：Eureka有两个组件，一定要标清楚哪个是Server，哪个是Client。@EnableEurekaServer代表服务注册中心 5.5测试,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 出现上面图标，表示Eureka 服务端安装成功。No instances available表示当前没有服务注册进来 ; 6. 单机Eureka构建：支付微服务8001入驻进eurekaServer6.1将 Eureka-client 依赖引入，便于使用注解@EnableEurekaClient标注这是个Eureka Client端12345&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt;dependency&gt; 6.2 在application.yml添加Eureka相关配置12345678eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka 6.3 主启动类添加注解@EnableEurekaClient,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 6.4 测试注意： 要先启动EurekaServer ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 这样就注册进来了，入住进Eureka服务器的名称就是8001yml中配置的spring.application.name。红色警告是Eureka的自我保护机制，后面会详细说。 7. 单机Eureka构建：订单微服务入驻进eurekaServer7.1 在pom添加 Eureka-client依赖12345&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt;dependency&gt; 7.2 在application.yml添加相关配置1234567891011spring: application: name: cloud-order-servereureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka 7.3 主启动类添加注解@EnableEurekaClient,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 7.4 测试PS： 先启动EurekaServer，7001服务，再启动服务提供者provider，8001服务 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) cloud-order-server服务以入住，查询功能也可以正常执行 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 8. EurekaServer集群环境构建8.1 创建module cloud-eureka-server7002,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 8.2 pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; parent&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;artifactId&gt;cloud-eureka-server7002artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-serverartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junitgroupId&gt; &lt;artifactId&gt;junitartifactId&gt; dependency&gt; dependencies&gt;project&gt; 8.3 写yml之前修改映射文件找到 C:\\Windows\\System32\\drivers\\etc路径下的hosts文件 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 修改映射配置添加进hosts文件 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 8.4 修改7001和7002的application.yml,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 8.5 主启动类123456789101112package com.atguigu.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableEurekaServerpublic class EurekaMain7002 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaMain7002.class,args); &#125;&#125; 8.6测试启动7001、7002 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 使用域名映射： ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 同时看到Eureka图标，且7001指着7002，7002指着7001，说明Eureka集群搭建成功。 ; 9. 将两个微服务发布到Eureka集群配置中只需修改application.yml ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 测试PS： 先启动EurekaServer，7001/7002服务；再启动服务提供者provider，8001；再启动消费者，80 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 现在，就已经把支付服务8001、订单服务80注册进Eureka集群环境，调用也OK。 ; 10. 支付提供者8001集群环境搭建10.1 创建module cloud-provider-payment8002,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 10.2 pom.xml 同8001的 pom.xml 一样10.3 写application.yml，注意改端口,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 10.4 主启动类和业务类直接从8001拷贝,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 10.5 修改8001和8002的controller，默认的负载均衡方式是轮询，看执行查询具体调用那台provider,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ; 10.6 测试PS： 启动顺序：7001、7002、8001、8002、80 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 8001和8002也都访问正常，那如果我们用80访问呢？发现怎么刷新都是8001，这是因为我们的源程序地址是写死的： ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 单机版写死是没有问题的，但是现在有8001、8002了，所有不应该再关注具体的IP和端口，而是只认服务名称。代码修改为一下在试。 12345678910111213141516171819@RestController@Slf4jpublic class OrderController &#123; private static final String PAYMENT_URL = &quot;http://CLOUD-PROVIDER-SERVICE&quot;; @Resource private RestTemplate restTemplate; @GetMapping(&quot;/consumer/payment/create&quot;) public CommonResult&lt;Payment&gt; create(Payment payment)&#123; return restTemplate.postForObject(PAYMENT_URL+&quot;/payment/create&quot;,payment,CommonResult.class); &#125; @GetMapping(&quot;/consumer/payment/get/&#123;id&#125;&quot;) public CommonResult&lt;Payment&gt; getPayment(@PathVariable(&quot;id&quot;) Long id)&#123; return restTemplate.getForObject(PAYMENT_URL+&quot;/payment/get/&quot;+id,CommonResult.class); &#125;&#125; ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 发现报错了，现在对外暴露的不再是地址和端口，只认微服务名称了，可是微服务并不知道下面有几个，找不到这个主机名称，需要使用@LoadBalanced注解开启RestTemplate负载均衡功能。提前说一下：这个就是后面要介绍的Ribbon负载均衡功能。 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 然后测试，多次刷新，就会发现8001、8002端口交替出现。 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 这样Ribbon和Eureka整合后Consumer可以直接调用服务而不用再关心地址和端口号，且该服务还有负载均衡功能了。O(∩_∩)O ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 这个架构是初级篇里面的重点，务必要学会，难的是后面的Alibaba的Nacos，也有服务注册和配置中心，Alibaba Nacos集群就比这个复杂了 ,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMjExNjQy,size_16,color_FFFFFF,t_70) 初级篇完结，后续请在博客分类中查找。","tags":["笔记"],"categories":["Java"]},{"title":"快速转载文章为md文件","path":"/2023/07/20/230720note/","content":"我比较懒，有时候网上看到一些不错的笔记都是收藏到浏览器里，一段时间后这些文章要么消失，要么被删了，所以为了保险起见还是搬运到自己博客里比较保险。 但是csdn等一些平台，别人的博客是不能直接下载的，咋办呢？ 简悦在浏览器中下载插件简悦 安装好插件后，回到目标页面，刷新一下页面，然后点击红色的插件图标 进入插件预览页后点击动作，选择自己需要的格式 Clean-markhttps://github.com/croqaz/clean-markhttps://github.com/croqaz/clean-mark 安装：1npm install clean-mark --global 使用：1clean-mark &quot;http://some-website.com/fancy-article&quot; 执行后如果找不到下载的文件，Windows电脑可以参考以下路径:C:\\Users\\Administrator 更多：https://github.com/croqaz/clean-mark#why-https://github.com/croqaz/clean-mark#why- 油猴插件https://greasyfork.org/zh-CN/scripts/370299-%E5%A4%8D%E5%88%B6%E4%B8%BAmarkdown%E6%A0%BC%E5%BC%8F/codehttps://greasyfork.org/zh-CN/scripts/370299-%E5%A4%8D%E5%88%B6%E4%B8%BAmarkdown%E6%A0%BC%E5%BC%8F/code 图片处理文章down下来后基本没有太多要动的东西，直接发布就可以。 如果想把图片也扒下来，手动的话肯定太慢了，我网上找了一波，没有看到好的解决方案。行吧，自己动手丰衣足食，开始打算用c#写脚本，但是公司电脑没安装环境，就用js搞了一个。 没办法，虽然用c#写成软件的话不存在跨域和跨浏览器的问题，而且用h5的话使用体验要差很多，但架不住h5方便啊，打开地址直接就可以操作。 https://su3.cn/tools/mdimgstool/mdimgstool.htmlhttps://su3.cn/tools/mdimgstool/mdimgstool.html 执行顺序:打开页面后鼠标右键-》下载网页-》打开刚刚下载的网页-》选择文件-》解析-》下载图片 必须把网页下载到本地，否则会出现跨域问题导致下载的图片不正常","tags":["随笔"],"categories":["其他"]},{"title":"【SpringCloud】微服务笔记","path":"/2023/07/20/23072022jsc/","content":"集中什么是微服务架构： SpringCloud 是微服务一站式服务解决方案，微服务全家桶。它是微服务开发的主流技术栈。它采用了名称，而非数字版本号。 SpringCloud 和 springCloud Alibaba 目前是最主流的微服务框架组合。 版本选择： 选用 springboot 和 springCloud 版本有约束，不按照它的约束会有冲突。 ; 版本问题本次学习的各种软件的版本： boot使用的是数字作为版本。官网强烈建议升级到2.0以上 cloud使用的是字母作为版本，伦敦地铁站站名 Cloud Release TrainBoot VersionHoxton 2.2.x, 2.3.x (Starting with SR5)Greenwich 2.1.xFinchley 2.0.xEdgware 1.5.xDalston 1.5.x 查看版本对应关系：https://start.spring.io/actuator/info 1234567891011121314151617181920&quot;spring-cloud&quot;: &#123; &quot;Finchley.M2&quot;: &quot;Spring Boot &gt;=2.0.0.M3 and , &quot;Finchley.M3&quot;: &quot;Spring Boot &gt;=2.0.0.M5 and , &quot;Finchley.M4&quot;: &quot;Spring Boot &gt;=2.0.0.M6 and , &quot;Finchley.M5&quot;: &quot;Spring Boot &gt;=2.0.0.M7 and , &quot;Finchley.M6&quot;: &quot;Spring Boot &gt;=2.0.0.RC1 and , &quot;Finchley.M7&quot;: &quot;Spring Boot &gt;=2.0.0.RC2 and , &quot;Finchley.M9&quot;: &quot;Spring Boot &gt;=2.0.0.RELEASE and , &quot;Finchley.RC1&quot;: &quot;Spring Boot &gt;=2.0.1.RELEASE and , &quot;Finchley.RC2&quot;: &quot;Spring Boot &gt;=2.0.2.RELEASE and , &quot;Finchley.SR4&quot;: &quot;Spring Boot &gt;=2.0.3.RELEASE and , &quot;Finchley.BUILD-SNAPSHOT&quot;: &quot;Spring Boot &gt;=2.0.999.BUILD-SNAPSHOT and , &quot;Greenwich.M1&quot;: &quot;Spring Boot &gt;=2.1.0.M3 and , &quot;Greenwich.SR6&quot;: &quot;Spring Boot &gt;=2.1.0.RELEASE and , &quot;Greenwich.BUILD-SNAPSHOT&quot;: &quot;Spring Boot &gt;=2.1.18.BUILD-SNAPSHOT and , &quot;Hoxton.SR8&quot;: &quot;Spring Boot &gt;=2.2.0.M4 and , &quot;Hoxton.BUILD-SNAPSHOT&quot;: &quot;Spring Boot &gt;=2.3.5.BUILD-SNAPSHOT and , &quot;2020.0.0-M3&quot;: &quot;Spring Boot &gt;=2.4.0.M1 and , &quot;2020.0.0-SNAPSHOT&quot;: &quot;Spring Boot &gt;=2.4.0.M2&quot;&#125;, 尚硅谷阳哥教程版本： cloudHoxton.SR1boot2.2.2.RELEASEcloud alibaba2.1.0.RELEASEjavajava8maven3.5及以上mysql5.7及以上 cloud版本决定了boot版本 微服务停更说明1,Eureka停用,可以使用zk作为服务注册中心 2,服务调用,Ribbon准备停更,代替为LoadBalance 3,Feign改为OpenFeign 4,Hystrix停更,改为resilence4j ​ 或者阿里巴巴的sentienl 5.Zuul改为gateway 6,服务配置Config改为 Nacos 7,服务总线Bus改为Nacos ; Cloud简介参考资料，尽量去官网 https://cloud.spring.io/spring-cloud-static/Hoxton.SR1/reference/htmlsingle/ 工程建造写一个下图的Hello World 构建父工程，后面的项目模块都在此工程中： 设置编码：Settings -&gt; File Encodings 注解激活： Java版本确定： ; 父工程pom配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; &lt;packaging&gt;pompackaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8maven.compiler.target&gt; &lt;junit.version&gt;4.12junit.version&gt; &lt;log4j.version&gt;1.2.17log4j.version&gt; &lt;lombok.version&gt;1.16.18lombok.version&gt; &lt;mysql.version&gt;5.1.47mysql.version&gt; &lt;druid.version&gt;1.1.16druid.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0mybatis.spring.boot.version&gt; properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.pluginsgroupId&gt; &lt;artifactId&gt;maven-project-info-reports-pluginartifactId&gt; &lt;version&gt;3.0.0version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-dependenciesartifactId&gt; &lt;version&gt;2.2.2.RELEASEversion&gt; &lt;type&gt;pomtype&gt; &lt;scope&gt;importscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-dependenciesartifactId&gt; &lt;version&gt;Hoxton.SR1version&gt; &lt;type&gt;pomtype&gt; &lt;scope&gt;importscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependenciesartifactId&gt; &lt;version&gt;2.1.0.RELEASEversion&gt; &lt;type&gt;pomtype&gt; &lt;scope&gt;importscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysqlgroupId&gt; &lt;artifactId&gt;mysql-connector-javaartifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;version&gt; &lt;scope&gt;runtimescope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibabagroupId&gt; &lt;artifactId&gt;druidartifactId&gt; &lt;version&gt;$&#123;druid.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; &lt;version&gt;$&#123;mybatis.spring.boot.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junitgroupId&gt; &lt;artifactId&gt;junitartifactId&gt; &lt;version&gt;$&#123;junit.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4jgroupId&gt; &lt;artifactId&gt;log4jartifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;version&gt; dependency&gt; dependencies&gt; dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-maven-pluginartifactId&gt; &lt;configuration&gt; &lt;fork&gt;truefork&gt; &lt;addResources&gt;trueaddResources&gt; configuration&gt; plugin&gt; plugins&gt; build&gt;project&gt; 上面配置的解释： 首先要加 &lt;packaging&gt;pom&lt;/packaging&gt; 这个。为了让项目顺利的运行，我们必须使用统一的版本号；1、dependencyManagement(1)在我们项目中，我们会发现在父模块的pom文件中常常会出现dependencyManagement元素，这是因为我们可以通过其来管理子模块的版本号，也就是说我们在父模块中 声明号依赖的版本，但是并不实现引入；2、dependencies(1)上面说到dependencyManagement只是声明一个依赖，而不实现引入，故我们在子模块中也需要对依赖进行声明，倘若不声明子模块自己的依赖，是不会从父模块中继承的；只有子模块中也声明了依赖。并且没有写对应的版本号它才会从父类中继承；并且version和scope都是取自父类；此外要是子模块中自己定义了自己的版本号，是不会继承自父类的。3、总结dependencyManagement只是用来管理依赖，规定未添加版本号的子模块依赖继承自它，dependencies是用来声明子模块自己的依赖，可以在其中来写自己需要的版本号聚合版本依赖，dependencyManagement只声明依赖，并不实现引入，所以子项目还需要写要引入的依赖。 可以统一版本 父工程创建完成执行mvn:install将父工程发布到仓库方便子工程继承 第一个微服务架构创建一个module后(只能改a)，在父工程的pom里多了个 &lt;modules&gt;&lt;/modules&gt;， 在模块的pom里没有gv，只有a。 模块里的 &lt;dependencies&gt;&lt;/dependencies&gt;里的依赖只有ga，没有v 提供者cloud-provider-payment8001 子工程的pom文件： 这里面的 lombok 这个包，引入以后，实体类不用再写set 和 get可以如下写实体类： 123456789101112import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.io.Serializable;@Data@AllArgsConstructor@NoArgsConstructorpublic class Payment implements Serializable &#123; private Integer id; private String serial;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; parent&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;artifactId&gt;cloud-provider-payment8001artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.springcloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibabagroupId&gt; &lt;artifactId&gt;druid-spring-boot-starterartifactId&gt; &lt;version&gt;1.1.10version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysqlgroupId&gt; &lt;artifactId&gt;mysql-connector-javaartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbcartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; dependencies&gt;project&gt; cloud-provider-payment8001 子工程的yml文件： 123456789101112131415server: port: 8001spring: application: name: cloud-provider-payment8001 datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/cloud2020?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456mybatis: mapper-locations: classpath:mapper/*.xml type-aliases-package: com.dkf.springcloud.entities cloud-provider-payment8001 子工程的主启动类： 12345678910package com.dkf.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class PaymentMain8001 &#123; public static void main(String[] args)&#123; SpringApplication.run(PaymentMain8001.class, args); &#125;&#125; 下面的常规操作： ①建表SQL 12345678create table `payment`( `id` bigint(20) not null auto_increment comment &#x27;ID&#x27;, `serial` varchar(200) default &#x27;&#x27;, PRIMARY KEY (`id`))ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8select * from payment; entities12345678910111213import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.io.Serializable;@Data@AllArgsConstructor@NoArgsConstructorpublic class Payment implements Serializable &#123; private long id; private String serial;&#125; 12345678910111213141516import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class CommonResult&lt;T&gt; &#123; private Integer code; private String message; private T data; public CommonResult(Integer code, String message)&#123; this(code, message, null); &#125;&#125; dao1234567@Mapperpublic interface PaymentDao &#123; int create(Payment payment); Payment getPaymentById(@Param(&quot;id&quot;) Long id);&#125; resource下创建mapper文件夹，新建PaymentMapper.xml。在yml里有所有entity别名类所在包，所有payment不用写全类名 12345678910111213141516DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;&lt;mapper namespace=&quot;com.xzq.springcloud.dao.PaymentDao&quot;&gt; &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.xzq.springcloud.entities.Payment&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot; jdbcType=&quot;BIGINT&quot;/&gt; &lt;id column=&quot;serial&quot; property=&quot;serial&quot; jdbcType=&quot;VARCHAR&quot;/&gt; resultMap&gt; &lt;insert id=&quot;create&quot; parameterType=&quot;Payment&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; insert into payment(serial) values (#&#123;serial&#125;) insert&gt; &lt;select id=&quot;getPaymentById&quot; parameterType=&quot;Long&quot; resultMap=&quot;BaseResultMap&quot;&gt; select * from payment where id = #&#123;id&#125; select&gt;mapper&gt; @Param注解：https://blog.csdn.net/qq_39505065/article/details/90550705 service12345public interface PaymentService &#123; int create(Payment payment); Payment getPaymentById(@Param(&quot;id&quot;) Long id);&#125; 12345678910111213141516@Servicepublic class PaymentServiceImpl implements PaymentService &#123; @Autowired private PaymentDao paymentDao; @Override public int create(Payment payment) &#123; return paymentDao.create(payment); &#125; @Override public Payment getPaymentById(Long id) &#123; return paymentDao.getPaymentById(id); &#125;&#125; controller12345678910111213141516171819202122232425262728@RestController@Slf4jpublic class PaymentController &#123; @Resource private PaymentService paymentService; @PostMapping(value = &quot;/payment/create&quot;) public CommonResult create(@RequestBody Payment payment)&#123; int result = paymentService.create(payment); log.info(&quot;****插入结果：&quot; + result); if(result &gt; 0)&#123; return new CommonResult(200, &quot;插入数据库成功&quot;, result); &#125; return new CommonResult(444, &quot;插入数据库失败&quot;, null); &#125; @GetMapping(value = &quot;/payment/&#123;id&#125;&quot;) public CommonResult getPaymentById(@PathVariable(&quot;id&quot;)Long id)&#123; Payment result = paymentService.getPaymentById(id); log.info(&quot;****查询结果：&quot; + result); if(result != null)&#123; return new CommonResult(200, &quot;查询成功&quot;, result); &#125; return new CommonResult(444, &quot;没有对应id的记录&quot;, null); &#125;&#125; 对应POST方式的请求，要学会用 POSTMAN工具 微服务多了之后就使用run dashboard 不但编译有个别地方会报错，启动也会报错，但是测试两个接口都是没问题的，推测启动报错是因为引入了下面才会引入的jar包，目前不影响。 热部署配置devtools代码改动后希望自动生效 具体模块里添加Jar包到工程中，上面的pom文件已经添加上了 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt;dependency&gt; 添加plugin到父工程的pom文件中：上面也已经添加好了 123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-maven-pluginartifactId&gt; &lt;configuration&gt; &lt;fork&gt;truefork&gt; &lt;addResources&gt;trueaddResources&gt; configuration&gt; plugin&gt; plugins&gt;build&gt; shift + ctrl + alt + / 四个按键一块按，选择Reg项： 重启IDEA 热部署只允许在开发阶段使用 消费者新建模块cloud-consumer-order80 消费者现在只模拟调用提供者的Controller方法，没有持久层配置，只有Controller和实体类当然也要配置主启动类和启动端口 pom文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; parent&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;artifactId&gt;cloud-customer-order80artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; dependencies&gt;project&gt; 把CommonResult 和 Payment 两个 实体类也创建出来 config/ApplicationContextCOnfig.java controller/OrderController.java entities/CommonResult.java entities/Payment.java OrderMain80.java application.yml 12server:\tport:80 OrderMain80.java 123456@SpringbootApplicationpublic class OrderMain80&#123; public static void main(String[] args)&#123; SpringApplication.run(OrderMain80.class,args); &#125;&#125; entites包中的类也拷贝到本项目中 entities/CommonResult.java entities/Payment.java 配置RestTemplateApplicationContextConfig 内容： 123456789101112131415package com.dkf.springcloud.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class ApplicationContextConfig &#123; @Bean public RestTemplate getRestTemplate()&#123; return new RestTemplate(); &#125;&#125; Controller1234567891011121314151617181920212223@RestController@Slf4jpublic class OrderController &#123; public static final String PAYMENY_URL = &quot;http://localhost:8001&quot;; @Resource private RestTemplate restTemplate; @PostMapping(&quot;customer/payment/create&quot;) public CommonResult&lt;Payment&gt; create (Payment payment)&#123; return restTemplate.postForObject(PAYMENY_URL + &quot;/payment/create&quot;, payment, CommonResult.class); &#125; @GetMapping(&quot;customer/payment/&#123;id&#125;&quot;) public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(&quot;id&quot;)Long id)&#123; return restTemplate.getForObject(PAYMENY_URL + &quot;/payment/&quot; + id, CommonResult.class); &#125;&#125; 如果 runDashboard 控制台没有出来，右上角搜索 即可 运用spring cloud框架基于spring boot构建微服务，一般需要启动多个应用程序，在idea开发工具中，多个同时启动的应用 需要在RunDashboard运行仪表盘中可以更好的管理，但有时候idea中的RunDashboard窗口没有显示出来，也找不到直接的开启按钮 idea中打开Run Dashboard的方法如下 view &gt; Tool Windows &gt; Run Dashboard 如果上述列表找不到Run Dashboard,则可以在工程目录下找到.idea文件夹下的workspace.xml，在其中相应位置加入以下代码（替换）即可： 1234567891011121314151617&lt;component name=&quot;RunDashboard&quot;&gt; &lt;option name=&quot;configurationTypes&quot;&gt; &lt;set&gt; &lt;option value=&quot;SpringBootApplicationConfigurationType&quot;/&gt; set&gt; option&gt; &lt;option name=&quot;ruleStates&quot;&gt; &lt;list&gt; &lt;RuleState&gt; &lt;option name=&quot;name&quot; value=&quot;ConfigurationTypeDashboardGroupingRule&quot;/&gt; RuleState&gt; &lt;RuleState&gt; &lt;option name=&quot;name&quot; value=&quot;StatusDashboardGroupingRule&quot;/&gt; RuleState&gt; list&gt; option&gt;component&gt; 工程重构 上面 两个子项目，有多次重复的 导入 jar，和重复的 Entity 实体类。可以把 多余的部分，加入到一个独立的模块中，将这个模块打包，并提供给需要使用的 module 新建一个 cloud-api-commons 子模块 将 entities 包里面的实体类放到这个子模块中，也将 pom 文件中，重复导入的 jar包放到这个新建的 模块的 pom 文件中。如下： 12345678910111213141516171819202122232425262728293031323334&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020artifactId&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;version&gt;1.0-SNAPSHOTversion&gt; parent&gt; &lt;modelVersion&gt;4.0.0modelVersion&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutoolgroupId&gt; &lt;artifactId&gt;hutool-allartifactId&gt; &lt;version&gt;5.1.0version&gt; dependency&gt; dependencies&gt;project&gt; mvn跳过test，mvc clean，mvn install 将此项目打包 install 到 maven仓库。 将 提供者 和 消费者 两个项目中的 entities 包删除，并删除掉加入到 cloud-api-commons 模块的 依赖配置。 将 打包到 maven 仓库的 cloud-api-commons 模块，引入到 提供者 和 消费者的 pom 文件中，如下所示 12345&lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt;dependency&gt; 服务注册中心 如果是上面只有两个微服务，通过 RestTemplate ，是可以相互调用的，但是当微服务项目的数量增大，就需要服务注册中心。目前没有学习服务调用相关技术，使用 SpringCloud 自带的 RestTemplate 来实现RPC ; Eureka什么是服务治理： SpringCloud封装了Netflix公司开发的Eureka模块来实现服务治理 在传统的rpc远程调用框架中，管理每个服务与服务之间依赖关系比较复杂，管理比较复杂，所以需要使用服务治理，管理服务于服务之间依赖关系，可以实现服务调用、负载均衡、容错等，实现服务发现与注册。 什么是服务注册与发现： Eureka采用了CS的设计结构，Eureka Server服务注册功能的服务器，它是服务注册中心。而系统中的其他微服务，使用Eureka的客户端连接到Eureka Server并维持心跳连接。这样系统的维护人员就可以通过Eureka Server来监控系统中各个微服务是否正常运行。这点和zookeeper很相似 在服务注册与发现中，有一个注册中心。当服务器启动时候，会把当前自己服务器的信息 比如服务地址 通讯地址等以别名方式注册到注册中心上。另一方（消费者服务提供者），以该别名的方式去注册中心上获取到实际的服务通讯地址，然后再实现本地RPC调用。RPC远程调用框架核心设计思想：在于注册中心，因为便用注册中心管理每个服务与服务之间的一个依赖关系（服务治理概念)。在任何rpc远程框架中，都会有一个注册中心（存放服务地址相关信息（接口地址）） Eureka 官方停更不停用，以后可能用的越来越少。Eureka 是 Netflix 开发的，一个基于 REST 服务的，服务注册与发现的组件，以实现中间层服务器的负载平衡和故障转移。Eureka 分为 Eureka Server 和 Eureka Client及服务端和客户端。 Eureka Server为注册中心，是服务端，而服务提供者和消费者即为客户端，消费者也可以是服务者，服务者也可以是消费者。同时Eureka Server在启动时默认会注册自己，成为一个服务，所以Eureka Server也是一个客户端，这是搭建Eureka集群的基础。 Eureka Client：一个Java客户端，用于简化与 Eureka Server 的交互（通常就是微服务中的客户端和服务端）。通过注册中心进行访问。是一个Java客户端，用于简化Eureka Server的交互，客户端同时也具备一个内置的、使用轮询（roundrobin）负载算氵去的负载均衡器在应用启动后，将会向Eureka Server发送心跳（默认周期为30秒）。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，Eureka Server将会从服务注册表中把这个服务节点移除（默认90秒） Eureka Server：提供服务注册服务，各个微服务节，通过配置启动后，会在Eureka Serverc中进行注册，这样Eureka Server中的服务注册表中将会存储所有可用服务节点信息，服务节点的信息可以在界面中直观看到。 服务在Eureka上注册，然后每隔30秒发送心跳来更新它们的租约。如果客户端不能多次续订租约，那么它将在大约90秒内从服务器注册表中剔除。注册信息和更新被复制到集群中的所有eureka节点。来自任何区域的客户端都可以查找注册表信息（每30秒发生一次）来定位它们的服务（可能在任何区域）并进行远程调用服务 提供者向注册中心注册服务，并 每隔30秒发送一次心跳，就如同人还活着存在的信号一样，如果Eureka在90秒后还未收到服务提供者发来的心跳时，那么它就会认定该服务已经死亡就会注销这个服务。这里注销并不是立即注销，而是会在60秒以后对在这个之间段内”死亡”的服务集中注销，如果立即注销，势必会对Eureka造成极大的负担。这些时间参数都可以人为配置。Eureka还有自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，所以不会再接收心跳，也不会删除服务。客户端消费者会向注册中心拉取服务列表，因为一个服务器的承载量是有限的，所以同一个服务会部署在多个服务器上，每个服务器上的服务都会去注册中心注册服务，他们会有相同的服务名称但有不同的实例id，所以 拉取的是服务列表。我们最终通过负载均衡来获取一个服务，这样可以均衡各个服务器上的服务。 ; 单机版Eureka构建：消费者端口80，提供者端口8001。 Eureka端口7001 1) Server模块pom 版本说明： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-serverartifactId&gt;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-eurekaartifactId&gt;dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637\t&lt;artifactId&gt;cloud-eureka-server7001artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-serverartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt;dependencies&gt; application.yml 123456789101112131415server:\tport: 7001eureka:\tinstance: hostname: localhost\tclient: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ @EnableEurekaServer最后写主启动类，如果启动报错，说没有配置 DataSource ，就在 主启动类的注解加上 这样的配置： 12345678@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@EnableEurekaServerpublic class EurekaServerMain7001 &#123; public static void main(String[] args)&#123; SpringApplication.run(EurekaServerMain7001.class, args); &#125;&#125; 启动测试，访问 7001 端口 2) 提供者 这里的提供者，还是使用 上面的 cloud-provider-payment8001 模块，做如下修改： 在 pom 文件的基础上引入 eureka 的client包，pom 的全部依赖如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;artifactId&gt;cloud-provider-payment8001artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibabagroupId&gt; &lt;artifactId&gt;druid-spring-boot-starterartifactId&gt; &lt;version&gt;1.1.10version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysqlgroupId&gt; &lt;artifactId&gt;mysql-connector-javaartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbcartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt;dependencies&gt; @EnableEurekaClient 主启动类 加上注解 ： @EnableEurekaClient yml 文件添加关于 Eureka 的配置： 12345678910111213spring: application: name: cloud-payment-serviceeureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka/ 3) 消费者 这里的消费者 也是上面 的 cloud-customer-order80 模块 修改 pom 文件，加入Eureka 的有关依赖， 全部 pom 依赖如下： 12345678910111213141516171819202122232425262728293031323334353637&lt;artifactId&gt;cloud-customer-order80artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt;dependencies&gt; @EnableEurekaClient 主启动类 加上注解 ： @EnableEurekaClient yml 文件必须添加的内容： 123456789eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka/spring: application: name: cloud-order-service Eureka 集群700X 1先启动eureka注册中心 2启动服务提供者payment支付服务 3支付服务启动后会把自身信息化 服务以别名方式注册进eureka 4消费者order服务在要调用接囗时， 使用服务别名去注册中心取实际的RPC远程调用地址 5 消费者获得调用地址后，底层实际是利用 HttpClient 技术实现远程调用 6 *消费者获得服务地址后会存 jvm内存 中，默认每间隔30s更新一次服务调用地址 Eureka Server在设计的时候就考虑了高可用设计，在Eureka服务治理设计中， 所有节点既是服务的提供方，也是服务的消费方，服务注册中心也不例外。 Eureka Server的高可用实际上就是将自己做为服务向其他服务注册中心注册自己，这样就可以形成一组互相注册的服务注册中心，以实现服务清单的互相同步，达到高可用的效果。 Eureka Server的同步遵循着一个非常简单的原则：只要有一条边将节点连接，就可以进行信息传播与同步。可以采用两两注册的方式实现集群中节点完全对等的效果，实现最高可用性集群，任何一台注册中心故障都不会影响服务的注册与发现。 问题：微服务RPC远程服务调用最核心的是什么： 高可用，试想你的注册中心只有一个。onlyone,它出故障了那就呵呵了，会导致整个为服务环境不可用，所以要搭建Eureka注册中心集群，实现负载均衡+故障容错 Eureka 集群的原理：相互注册，互相守望。每台Eureka服务器都有集群里其他Eureka服务器地址的信息 开始构建Eureka集群： 现在创建 cloud-eureka-server7002 ，也就是第二个 Eureka 服务注册中心，pom 文件和 主启动类，与第一个Server一致。 模拟多个 为了不用输出C:\\Windows\\System32\\drivers\\etc\\hosts 添加如下：127.0.0.1 eureka7001.com127.0.0.1 eureka7002.com 现在修改这两个 Server 的 yml 配置： 7001 端口的Server yml文件： 12345678910111213server: port: 7001eureka: instance: hostname: eureka7001.com client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/ 7002 端口的Server yml文件： 12345678910111213server: port: 7002eureka: instance: hostname: eureka7002.com client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://eureka7001.com:7001/eureka/ eureka.instance.hostname 才是启动以后 本 Server 的注册地址，而 service-url 是 map 类型，只要保证 key:value 格式就行，它代表 本Server 指向了那些 其它Server 。利用这个，就可以实现Eureka Server 相互之间的注册，从而实现集群的搭建。 提供者集群800X上面配置了多个Eureka作为集群，接下来要配置的是提供者集群，让提供者高可用 为提供者 cloud-provider-payment8001 模块创建集群，新建模块名为 cloud-provider-payment8002 即两个提供者8001和8002 其余配置都一致，需要配置集群的配置如下： 配置区别要点： 集群中多个提供者的 spring:application:name:要一致 启动类添加 @EnableDiscoveryClient或者 @EnableEurekaClient1， @EnableDiscoveryClient注解是基于 spring-cloud-commons依赖，并且在classpath中实现；2， @EnableEurekaClient注解是基于 spring-cloud-netflix依赖，只能为eureka作用；如果你的classpath中添加了eureka，则它们的作用是一样的。 消费者（一般需要连接其他微服务的服务或者gateway/zuul） 123456789101112131415161718192021222324server: port: 8001spring: application: name: cloud-provider-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/cloud2020?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456mybatis: mapper-locations: classpath:mapper/*.xml type-aliases-package: com.dkf.springcloud.entitieseureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 注意在 Controller 返回不同的消息，从而区分者两个提供者的工作状态。（只是为了学习测试才这么做，生产环境直接复制即可） 在提供者的controller中 12@Value(&quot;$&#123;server.port&#125;&quot;)private String serverPort; 消费者80此时消费者一旦消费完之后，他以后访问的还是那台提供者。明显不对，原因在于消费者并没有去Rureka里找服务，而是自己找的 就是消费者如何访问 由这两个提供者组成的集群？ Eureka Server 上的提供者的服务名称如下： 12345678910111213141516171819@RestController@Slf4jpublic class OrderController &#123; public static final String PAYMENY_URL = &quot;http://CLOUD-PROVIDER-SERVICE&quot;; @Resource private RestTemplate restTemplate; @PostMapping(&quot;customer/payment/create&quot;) public CommonResult&lt;Payment&gt; create (Payment payment)&#123; return restTemplate.postForObject(PAYMENY_URL + &quot;/payment/create&quot;, payment, CommonResult.class); &#125; @GetMapping(&quot;customer/payment/&#123;id&#125;&quot;) public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(&quot;id&quot;)Long id)&#123; return restTemplate.getForObject(PAYMENY_URL + &quot;/payment/&quot; + id, CommonResult.class); &#125;&#125; 123456789101112131415161718192021server: port: 80spring: application: name: cloud-order-service zipkin: base-url: http://localhost:9411 sleuth: sampler: probability: 1eureka: client: register-with-eureka: false fetchRegistry: true service-url: defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka @LoadBalanced还有，消费者里面对RestTemplate配置的config文件，需要更改成如下：（就是加一个注解 @LoadBalanced） 123456789@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced public RestTemplate getRestTemplate()&#123; return new RestTemplate(); &#125;&#125; 这时候，消费者消费的提供者多次访问就会变化了（这就是Ribbon的负载平衡功能） actuator让Eureka显示ip为了在微服务Eureka控制台能看到我们的某个具体服务是在哪台服务器上部署的，我们需要配置一些内容。 修改 提供者在Eureka 注册中心显示的 主机名：即修改 eureka:instance:instance-id:和 eureka:instance:prefer-ip-address: 12345678910111213server: port: 8001eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ instance: instance-id: payment8001 prefer-ip-address: true 服务发现Discovery @EnableDiscoveryClient对于注册进eureka里面的微服务，可以通过服务发现来获得该服务的信息。（即我们前面可视化页面的信息） 在主启动类上添加注解： @EnableDiscoveryClient 在 Controller 里面打印信息： 123456789101112131415161718@Resourceprivate DiscoveryClient discoveryClient;@GetMapping(&quot;/customer/discovery&quot;)public Object discovery()&#123; List&lt;String&gt; services = discoveryClient.getServices(); for(String service: services)&#123; log.info(&quot;*****service: &quot; + service); &#125; List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(&quot;CLOUD-ORDER-SERVICE&quot;); for(ServiceInstance serviceInstance:instances)&#123; log.info(serviceInstance.getServiceId() + &quot;\\t&quot; + serviceInstance.getHost() + &quot;\\t&quot; + serviceInstance.getPort() + &quot;\\t&quot; + serviceInstance.getUri()); &#125; return this.discoveryClient;&#125; Eureka 自我保护机制某时刻某一个微服务不可用了，Eureka不会立即清理，依旧会对该微服务的信息进行保存。属于CAP里的AP（高可用）分支 保护模式主要用于一组客户和Eureka Server之间存在网络分区场景下保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中固定信息，也就是不会注销任何微服务。 如果在Eureka Server的首页看到以下这段提示，则说明Eureka讲入了保护模式： EMERGENCY!EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE 为什么会产生Eureka自我保护机制？ 为了防止Eureka Client可以正常运行但是与Eureka Server网络不通情况下，Eureka Server不会立刻将Eureka Client服务剔除 什么是自我保护模式？ 默认情况下，如果Eureka Server在一定时间内没有接收到某个微服务实例的心跳，Eureka Server将会注销该实例（默认90秒）。但是当网络分区故障发生时、卡顿、拥挤）时，微服务与Eureka Server之间无法正常通信，以上行为可能变得非常危险了—因为微服务本身其实是健康的，此时本不应该注销这个微服务。Eureka通过”自我保护模式”来解决这个问题—当Eureka Server节点在短时间内丢失过多客户端时（可能发生了网络分区故障），那么这个节点就会进入自我保护模式。 自我保护机制：默认情况下Eureka CIient定时向Eureka Server端发送心跳包。 如果Eureka在server端在一定时间内（默认90秒）没有收到Eureka Client发送心跳包，便会直接从服务注册列表中剔除该服务，但是在短时间（90秒内）内丢失了大量的服务实例心跳，这时Eureka Server会开启自我保护机制，不会剔除该服务（该现象可能出现如果网络不通但是Eureka Client出现宕机，此时如果别的注册中心如果一定时间内没有收到心跳会将剔除该服务这样就出现了严重失误，因为客户端还能正常发送心跳，只是网络延迟问题，而保护机制是为了解决此问题而产生的 在自我保护模式中，Eureka Server会保护服务注册表中的信息，不再注册任何服务实例。 它的设计哲学就是宁可保留错误的服务注册信息，也不盲目注销任何可能健康的服务实例。一句话讲解：好死不如赖活着 综上，自我保护模式是一种应对网络异常的安全保护措施。它的架构哲学是宁可同时保留所有微服务（健康的微服务和不健康的微服务都会保留）也不盲目注销任何健康的微服务。使用自我保护模式，可以让Eureka集群更加的健壮、稳定。 禁止自我保护:（如果想） 在 Eureka Server 的模块中的 yml 文件进行配置： 12345678910111213141516server:port: 7001eureka:instance: hostname: eureka7001.comclient: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/server:\tenable-self-preservation: false\teviction-interval-timer-in-ms: 2000 修改 Eureka Client 模块的 心跳间隔时间： 1234567891011121314151617server: port: 8001eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ instance: instance-id: payment8001 prefer-ip-address: true least-renewal-interval-in-seconds: 1 least-expiration-duration-in-seconds: 2 eureka配置项解读：在注册服务之后，服务提供者会维护一个心跳用来持续高速Eureka Server，”我还在持续提供服务”，否则Eureka Server的剔除任务会将该服务实例从服务列表中排除出去。我们称之为服务续约。面是服务续约的两个重要属性： （1）eureka.instance.lease-expiration-duration-in-secondsleaseExpirationDurationInSeconds，表示eureka server至上一次收到client的心跳之后，等待下一次心跳的超时时间，在这个时间内若没收到下一次心跳，则将移除该instance。默认为90秒如果该值太大，则很可能将流量转发过去的时候，该instance已经不存活了。如果该值设置太小了，则instance则很可能因为临时的网络抖动而被摘除掉。该值至少应该大于leaseRenewalIntervalInSeconds （2）eureka.instance.lease-renewal-interval-in-secondsleaseRenewalIntervalInSeconds，表示eureka client发送心跳给server端的频率。如果在leaseExpirationDurationInSeconds后，server端没有收到client的心跳，则将摘除该instance。除此之外，如果该instance实现了HealthCheckCallback，并决定让自己unavailable的话，则该instance也不会接收到流量。默认30秒 eureka.client.registry-fetch-interval-seconds* :表示eureka client间隔多久去拉取服务注册信息，默认为30秒，对于api-gateway，如果要迅速获取服务注册状态，可以缩小该值，比如5秒 eureka.server.enable-self-preservation*是否开启自我保护模式，默认为true。默认情况下，如果Eureka Server在一定时间内没有接收到某个微服务实例的心跳，Eureka Server将会注销该实例（默认90秒）。但是当网络分区故障发生时，微服务与Eureka Server之间无法正常通信，以上行为可能变得非常危险了——因为微服务本身其实是健康的，此时本不应该注销这个微服务。Eureka通过”自我保护模式”来解决这个问题——当Eureka Server节点在短时间内丢失过多客户端时（可能发生了网络分区故障），那么这个节点就会进入自我保护模式。一旦进入该模式，Eureka Server就会保护服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。当网络故障恢复后，该Eureka Server节点会自动退出自我保护模式。综上，自我保护模式是一种应对网络异常的安全保护措施。它的架构哲学是宁可同时保留所有微服务（健康的微服务和不健康的微服务都会保留），也不盲目注销任何健康的微服务。使用自我保护模式，可以让Eureka集群更加的健壮、稳定。 eureka.server.eviction-interval-timer-in-ms*eureka server清理无效节点的时间间隔，默认60000毫秒，即60秒 Eureka停更说明： 2.0后停更了。 ZookeeperspringCloud 整合 zookeeper zookeeper是一个分布式协调工具，可以实现注册中心功能 关闭Linux服务器防火墙后动zookeeper服务器 zookeeper服务器取代Eureka服务器，zk作为服务注册中心 提供者新建模块cloud-provider-payment8004 pom文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;artifactId&gt;cloud-provider-payment8004artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discoveryartifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeepergroupId&gt; &lt;artifactId&gt;zookeeperartifactId&gt; exclusion&gt; exclusions&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeepergroupId&gt; &lt;artifactId&gt;zookeeperartifactId&gt; &lt;version&gt;3.4.9version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4jgroupId&gt; &lt;artifactId&gt;slf4j-log4j12artifactId&gt; exclusion&gt; exclusions&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibabagroupId&gt; &lt;artifactId&gt;druid-spring-boot-starterartifactId&gt; &lt;version&gt;1.1.10version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysqlgroupId&gt; &lt;artifactId&gt;mysql-connector-javaartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbcartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt;dependencies&gt; yaml 123456789server: port: 8004spring: application: name: cloud-provider-service cloud: zookeeper: connect-string: 192.168.40.100:2181 主启动类： 1234567891011import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@SpringBootApplication@EnableDiscoveryClientpublic class PaymentMain8004 &#123; public static void main(String[] args)&#123; SpringApplication.run(PaymentMain8004.class, args); &#125;&#125; Controller 打印信息： 123456789101112131415@RestController@Slf4jpublic class PaymentController &#123; @Resource private PaymentService paymentService; @Value(&quot;$&#123;server.port&#125;&quot;) private String serverPort; @RequestMapping(&quot;/payment/zk&quot;) public String paymentzk()&#123; return &quot;springcloud with zookeeper :&quot; + serverPort + &quot;\\t&quot; + UUID.randomUUID().toString(); &#125;&#125; 如果 zookeeper 的版本和导入的jar包版本不一致，启动就会报错，由zk-discovery和zk之间的jar包冲突的问题。 解决这种冲突，需要在 pom 文件中，排除掉引起冲突的jar包，添加和服务器zookeeper版本一致的 jar 包， 但是新导入的 zookeeper jar包 又有 slf4j 冲突问题，于是再次排除引起冲突的jar包 12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discoveryartifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeepergroupId&gt; &lt;artifactId&gt;zookeeperartifactId&gt; exclusion&gt; exclusions&gt;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeepergroupId&gt; &lt;artifactId&gt;zookeeperartifactId&gt; &lt;version&gt;3.4.9version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4jgroupId&gt; &lt;artifactId&gt;slf4j-log4j12artifactId&gt; exclusion&gt; exclusions&gt;dependency&gt; 启动测试： 123456# 在zk客户端ls /services # 输入[cloud-provider-service] #输出# 继续向下查看ls /services/cloud-provider-service# 继续向下，然后get，返回了个json 我们在zk上注册的node是临时节点,当我们的服务一定时间内没有发送心跳，那么zk就会将这个服务的znode删除了。没有自我保护机制。重新建立连接后znode-id号也会变 消费者 创建测试zookeeper作为服务注册中心的 消费者 模块 cloud-customerzk-order80主启动类、pom文件、yml文件和提供者的类似 config类，注入 RestTemplate 1234567891011121314151617@SpringBootConfigurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced public RestTemplate getTemplate()&#123; return new RestTemplate(); &#125;&#125;@SpringBootApplication@EnableDiscoveryClientpublic class OrderZKMain80&#123; public static void main(String[] args) &#123; SpringApplication.run(OrderZKMain80.class, args); &#125;&#125; controller层也是和之前类似： 123456789101112131415@RestController@Slf4jpublic class CustomerZkController &#123; public static final String INVOKE_URL=&quot;http://cloud-provider-service&quot;; @Resource private RestTemplate restTemplate; @RequestMapping(&quot;/customer/payment/zk&quot;) public String paymentInfo()&#123; String result = restTemplate.getForObject(INVOKE_URL + &quot;/payment/zk&quot;,String.class); return result; &#125;&#125; 然后就在zk里查到consumer信息了。 关于 zookeeper 的集群搭建，目前使用较少，而且在 yml 文件中的配置也是类似，以列表形式写入 zookeeper 的多个地址即可，而且zookeeper 集群，在 hadoop的笔记中也有记录。总而言之，只要配合zookeeper集群，以及yml文件的配置就能完成集群搭建 后面会用ribbon代替RestTemplate Consul consul也是服务注册中心的一个实现，是由go语言写的。官网地址： https://www.consul.io/intro 中文地址： https://www.springcloud.cc/spring-cloud-consul.htmlConsul是一套开源的分布式服务发现和配置管理系统。提供了微服务系统中的服务治理，配置中心，控制总线等功能。这些功能中的每一个都可以根据需要单独使用，也可以一起使用以构建全方位的服务网络。 服务发现：提供HTTP和DNS两种发现方式 健康监测：支持多种方式，HTTP、TCP、Docker、Shell脚本定制化 KV存储：Key、Value的存储方式 多数据中心：Consul支持多数据中心 可视化Web界面 安装并运行 下载地址：https://www.consul.io/downloads.html打开下载的压缩包，只有一个exe文件，实际上是不用安装的，在exe文件所在目录打开dos窗口使用即可。使用开发模式启动：consul agent -dev访问8500端口，即可访问首页 提供者 新建提供者模块：cloud-providerconsul-service8006 pom 文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;artifactId&gt;cloud-providerconsul-service8006artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discoveryartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; yml 文件： 1234567891011server: port: 8006spring: application: name: consul-provider-service cloud: consul: host: localhost port: 8500 discovery: service-name: $&#123;spring.application.name&#125; 主启动类： 1234567@SpringBootApplication@EnableDiscoveryClientpublic class ConsulProviderMain8006 &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsulProviderMain8006.class,args); &#125;&#125; controller也是简单的写一下就行。 消费者 新建 一个 在82端口的 消费者模块。pom和yml和提供者的类似，主启动类不用说，记得注入RestTemplate 1234567891011121314151617@SpringBootApplication@EnableDiscoveryClientpublic class OrderConsulMain80&#123; public static void main(String[] args) &#123; SpringApplication.run(OrderConsulMain80.class, args); &#125;&#125;@Configurationpublic class ApplicationContextConfig&#123; @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; controller层： 1234567891011121314@RestControllerpublic class CustomerConsulController &#123; public static final String INVOKE_URL=&quot;http://consul-provider-service&quot;; @Resource private RestTemplate restTemplate; @RequestMapping(&quot;/customer/payment/consul&quot;) public String paymentInfo()&#123; String result = restTemplate.getForObject(INVOKE_URL + &quot;/payment/consul&quot;,String.class); return result; &#125;&#125; 总结组件名语言CAP服务健康检查对外暴露接口SpringCloud集合EurekajavaAP可配支持HTTP已集成ConsulGoCP支持HTTP/DNS已集成ZookeeperjavaCP支持客户端已集成 CAP： C：Consitency 强一致性 A：Available 可用性 P：Partition tolerance 分区容错性 CAP理论关注粒度是数据，而不是整体系统设计的 上面讲了服务注册中心，下面讲服务调用 ; 服务调用RestTemplate不是给我们提供远程调用了吗，那还要学其他的做什么。答案是负载均衡，在发送请求时通过负载均衡算法从提供者列表中选择一个。 都是使用在 client端，即有 “消费者” 需求的模块中。 Ribbon我们这里提前启动好之前在搭建的 eureka Server 集群（5个模块） 简介SpringCloud Ribbon是基于NetfIixRibbon实现的一套 客户端负载均衡的工具。 简单的说，Ribbon是Neix发布的开源项目，主要功能是提供 客户端的软件负载均衡算法和服务调用。Ribbon客户端组件提供一系列完善的配置项如 连接超时，重试等。简单的说，就是在配置文件中列出LoadBalancer（简称LB)后面所有的机器，Ribbon会自动的帮助你基于某种规则（如简单轮询，随机连接等）去连接这些机器。我们很容易使用Ribbon实现自定义的负载均衡算法。 LB负载均衡(LoadBalance)是什么？ 简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA（高可用）。 常见的负载均衡有软件Nginx，LVS，硬件F5等。 Ribbon本地负载均衡客户端 VS Nginx服务端负载均衡区别： Nginx是 服务器负载均衡（集中式LB），客户端所有请求都会交给nginx，然后由nginx实现转发请求。即负载均衡是由服务端实现的。 Ribbon是 本地负载均衡（进程内LB），在调用微服务接口时候，会 在注册中心上获取注册信息服务列表之后缓存到JVM本地，从而在本地实现RPC远程服务调用技术。 集中式LB：即在服务的消费方和提供方之间使用独立的LB设施（可以是硬件，如F5，也可以是软件，如nginx),由该设施负责把访问请求通过某种策略转发至服务的提供方； 进程内LB：将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器！Ribbon就属于进程内LB,它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址。 Ribbon在工作时分成两步： 第一步先选择Eureka Server，它优先选择在同一个区域内负载较少的server 第二步再根据用户指定的策略，在从server取到的服务注册列表中选择一个地址。 其中Ribbon提供了多种策略：比如轮询、随相和根据响应时间加权。 上面在eureka时，确实实现了负载均衡机制，那是因为 eureka-client包里面自带着ribbon： 一句话， Ribbon 就是 负载均衡 + RestTemplate 调用。实际上不止eureka的jar包有，zookeeper的jar包，还有consul的jar包都包含了他，就是上面使用的服务调用。 如果自己添加，在 模块的 pom 文件中引入： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbonartifactId&gt;dependency&gt; RestTemplate对于RestTemplate 的一些说明： 有两种请求方式：post和get ,还有两种返回类型：object 和 Entity getForObject()/getForEntity() Object：返回对象响应体中数据转化成的对象，基本上可以理解成json Entity：返回对象是ResponseEntity对象，包含了响应中的一些重要信息，比如响应头、响应状态码、响应体等 返回的 entity.getBody()即得到了Object postForObject()/postForEntity() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.atguigu.springcloud.controller;@RestController@Slf4jpublic class OrderController&#123; public static final String PAYMENT_URL = &quot;http://CLOUD-PAYMENT-SERVICE&quot;; @Resource private RestTemplate restTemplate; @Resource private LoadBalancer loadBalancer; @Resource private DiscoveryClient discoveryClient; @GetMapping(&quot;/consumer/payment/create&quot;) public CommonResult&lt;Payment&gt; create(Payment payment)&#123; return restTemplate.postForObject(PAYMENT_URL +&quot;/payment/create&quot;,payment,CommonResult.class); &#125; @GetMapping(&quot;/consumer/payment/get/&#123;id&#125;&quot;) public CommonResult&lt;Payment&gt; getPayment(@PathVariable(&quot;id&quot;) Long id)&#123; return restTemplate.getForObject(PAYMENT_URL+&quot;/payment/get/&quot;+id,CommonResult.class); &#125; @GetMapping(&quot;/consumer/payment/getForEntity/&#123;id&#125;&quot;) public CommonResult&lt;Payment&gt; getPayment2(@PathVariable(&quot;id&quot;) Long id)&#123; ResponseEntity&lt;CommonResult&gt; entity = restTemplate.getForEntity(PAYMENT_URL+&quot;/payment/get/&quot;+id,CommonResult.class); if(entity.getStatusCode().is2xxSuccessful())&#123; return entity.getBody(); &#125;else&#123; return new CommonResult&lt;&gt;(444,&quot;操作失败&quot;); &#125; &#125; @GetMapping(value = &quot;/consumer/payment/lb&quot;) public String getPaymentLB()&#123; List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(&quot;CLOUD-PAYMENT-SERVICE&quot;); if(instances == null || instances.size() 0)&#123; return null; &#125; ServiceInstance serviceInstance = loadBalancer.instances(instances); URI uri = serviceInstance.getUri(); return restTemplate.getForObject(uri+&quot;/payment/lb&quot;,String.class); &#125; @GetMapping(&quot;/consumer/payment/zipkin&quot;) public String paymentZipkin()&#123; String result = restTemplate.getForObject(&quot;http://localhost:8001&quot;+&quot;/payment/zipkin/&quot;, String.class); return result; &#125;&#125; 负载均衡IRule：根据特定算法从服务列表中选择一个要访问的服务 Ribbon 负载均衡规则类型： com.netflix.loadbalancer.RoundRobinRule：轮询 com.netflix.loadbalancer.RandomRule：随机 com.netfIix.IoadbaIancer.RetryRuIe：先按照RoundRobinRule的策略获取服务，如果获取服务失败则在指定时间内会进行重试，获取可用的服务 WeightedResponseTimeRule：对RoundRobinRule的扩展，响应速度越快的实例选择权重越大，越容易被选择 BestAvailableRule：会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务 AvailabilityFilteringRule：先过滤掉故障实例，再选择并发较小的实例 ZoneAvoidanceRule：默认规则，复合判断server所在区域的性能和server的可用性选择服务器 配置负载均衡规则： 官方文档明确给出了警告： 这个自定义配置类不能放在@ComponentScan 所扫描的当前包下以及子包下，否则我们自定义的这个配置类就会被所有的Ribbon客户端所共享，达不到特殊化定制的目的了。 注意上面说的，而Springboot主启动类上的 @SpringBootApplication 注解，相当于加了@ComponentScan注解，会自动扫描当前包及子包，所以注意不要放在SpringBoot主启动类的包内。 创建包： java com.hh myrule MySelfRule.java springcloud 主启动类 在这个包下新建 MySelfRule类： 123456789101112package com.dkf.myrule;import com.netflix.loadbalancer.IRule;import com.netflix.loadbalancer.RandomRule;@Configurationpublic class MySelfRule &#123; @Bean public IRule myrule()&#123; return new RandomRule(); &#125;&#125; 然后在主启动类上添加如下注解 @RibbonClient： 1234567891011121314package com.dkf.springcloud;import com.dkf.myrule.MySelfRule;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@RibbonClient(name=&quot;CLOUD-PROVIDER-SERVICE&quot;, configuration = MySelfRule.class)public class OrderMain80 &#123; public static void main(String[] args)&#123; SpringApplication.run(OrderMain80.class, args); &#125;&#125; 轮询算法原理负载均衡轮询算法 ： rest接口第几次请求次数 % 服务器集群总数量 = 实际调用服务器位置下标 每次服务器重启后，rest接口计数从1开始。 ribbon源码： 1234567891011121314151617181920212223242526272829303132333435363738394041private AtomicInteger nextServerCyclicCounter;public Server choose(ILoadBalancer lb, Object key) &#123; Server server = null; int count = 0; while (server == null &amp;&amp; count++ &lt; 10) &#123; List&lt;Server&gt; reachableServers = lb.getReachableServers(); List&lt;Server&gt; allServers = lb.getAllServers(); int upCount = reachableServers.size(); int serverCount = allServers.size(); int nextServerIndex = incrementAndGetModulo(serverCount); server = allServers.get(nextServerIndex); if (server == null) &#123; Thread.yield(); continue; &#125; if (server.isAlive() &amp;&amp; (server.isReadyToServe())) &#123; return (server); &#125; server = null; &#125; if (count &gt;= 10) &#123; log.warn(&quot;No available alive servers after 10 tries from load balancer: &quot; + lb); &#125; return server;&#125;private int incrementAndGetModulo(int modulo) &#123; for (;;) &#123; int current = nextServerCyclicCounter.get(); int next = (current + 1) % modulo; if (nextServerCyclicCounter.compareAndSet(current, next)) return next; &#125;&#125; 手写负载算法：cas+自旋 首先8001、8002服务controller层加上 1234@GetMapping(&quot;/payment/lb&quot;)public String getPaymentLB() &#123; return SERVER_PORT;&#125; LoadBalancer接口： 123456import org.springframework.cloud.client.ServiceInstance;import java.util.List;public interface LoadBalancer &#123; ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances);&#125; 实现 1234567891011121314151617181920212223242526import org.springframework.cloud.client.ServiceInstance;import java.sql.SQLOutput;@Componentpublic class MyLB implements LoadBalancer &#123; private AtomicInteger atomicInteger = new AtomicInteger(0); private final int getAndIncrement() &#123; int current; int next; do &#123; current = this.atomicInteger.get(); next = current &gt;= Integer.MAX_VALUE ? 0 : current + 1; &#125; while (!atomicInteger.compareAndSet(current, next)); System.out.println(&quot;第几次访问,次数next:&quot; + next); return next; &#125; @Override public ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances) &#123; int index = getAndIncrement() % serviceInstances.size(); return serviceInstances.get(index); &#125;&#125; controller类中添加： 123456789101112@GetMapping(&quot;/consumer/payment/lb&quot;)public String getPaymentLB() &#123; List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(&quot;CLOUD-PAYMENT-SERVICE&quot;); if (instances == null || instances.size() 0) &#123; return null; &#125; ServiceInstance serviceInstance = loadBalancer.instances(instances); URI uri = serviceInstance.getUri(); return restTemplate.getForObject(uri + &quot;/payment/lb&quot;, String.class);&#125; OpenFeign概述 这里和之前学的dubbo很像，例如消费者的controller 可以调用提供者的 service层方法，但是不一样，它貌似只能调用提供者的 controller，即写一个提供者项目的controller的接口，消费者来调用这个接口方法，就还是相当于是调用提供者的 controller ，和RestTemplate 没有本质区别 Feign能干什么： Feign旨在使编写JavaHttp客户端变得更容易。 前面在使用Ribbon+RestTemplate时，利用RestTemplate对http请求的封装处理，形成了一套模版化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接囗会被多处调用，所以通常都会针对每个微服务自行封装些客户端类来包装这些依赖服务的调用。所以，Feign在此基础上做了进一步封装，由他来帮助我们定义和实现依赖服务接口的定义。在Feign的实现下，我们 只需创建一个接口并使用注解的方式来配置它（以前是Dao接口上面标注Mapper注解，现在是一个微服务接口上面标注一个Feign注解即可，即可完成对服务提供方的接口绑定，简化了使用Springcloud Ribbon时，自动封装服务调用客户端的开发量。 Feign集成了Ribbon 利用Ribbon维护了Payment的服务列表信息，并目通过轮询实现了客户端的负载均衡。而与Ribbon不同的是，通过feign只需要定义服务绑定接口目以声明式的方法，优雅而简单的实现了服务调用 FeignOpenFeignFeign是SpringCloud组件中的一个轻量级RESTful的HTTP服务客户端。Feign内置了Ribbon，用来做客户端负载均衡，去调用服务注册中心的服务。Feign的使用方式是：使用Feign的注解定义接口，调用这个接口，就可以调用服务注册中心的服务OpenFeign是SpringCloud在Feign的基础上支持了SpringMVC的注解，如@RequestMapping等等。OpenFeign的 @FeignClient 可以解析SpringMVC的下的接囗，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务。 org.springframework.cloud spring-cloud-starter-feign org.springframework.cloud spring-cloud-starter-openfeign 消费端新建cloud-consumer-feign-order80模块 feign用在消费端，feign自带负载均衡配置，所以不用手动配置 pom ： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeignartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; dependencies&gt; yaml 12345678server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ @EnableFeignClients主启动类： 1234567@SpringBootApplication@EnableFeignClientspublic class CustomerFeignMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(CustomerFeignMain80.class, args); &#125;&#125; @FeignClient新建一个service 这个service还是 customer 模块的接口，和提供者没有任何关系，不需要包类名一致。它使用起来就相当于是普通的service。推测大致原理，对于这个service 接口，读取它某个方法的注解（GET或者POST注解不写报错），知道了请求方式和请求地址，而抽象方法，只是对于我们来讲，调用该方法时，可以进行传参等。 123456789101112@Component@FeignClient(value = &quot;CLOUD-PROVIDER-SERVICE&quot;)public interface PaymentFeignService&#123; @GetMapping(value = &quot;/payment/get/&#123;id&#125;&quot;) public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(&quot;id&quot;) Long id); @GetMapping(value = &quot;/payment/feign/timeout&quot;) public String paymentFeignTimeout();&#125; Controller层： 123456789101112@RestControllerpublic class CustomerFeignController &#123; @Resource private PaymentFeignService paymentFeignService; @GetMapping(&quot;/customer/feign/payment/&#123;id&#125;&quot;) public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(&quot;id&quot;) Long id)&#123; return paymentFeignService.getPaymentById(id); &#125;&#125; 超时控制超时设置，故意设置超时演示出错情况： 服务提供方8001故意写暂停程序 服务消费方80添加超时方法PaymentFeignService 服务消费方80添加超时方法OrderFeignControIIer 测试：http://localhost/consumer/payment/feign/timeout错误页面 Openfeign默认超时等待为一秒，在消费者里面配置超时时间 1234567@GetMapping(value = &quot;/payment/feign/timeout&quot;)public String paymentFeignTimeout()&#123; try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return serverPort;&#125; 123456@GetMapping(value = &quot;/consumer/payment/feign/timeout&quot;)public String paymentFeignTimeout()&#123; return paymentFeignService.paymentFeignTimeout();&#125; 1234567891011eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ribbon: ReadTimeout: 5000 ConnectTimeout: 5000 开启日志打印Feign共了日志打印功能，我们可以诵过配置来调整日志级别，从而了解Feign中Tttp请求的细节。 说白了就是对Feign接口的调用情况进行监控和输出。 日志级别： NONE.默认的，不显示任何日志； BASIC，仅记录请求方法、URL、响应状态码及执行时间； HEADERS：除了BASIC中定义的信息之外，还有请求和响应的头信息 FULL:除了HEADERS中定义的信息之外，还有请求和响应的正文及元数据。 首先写一个config配置类： 1234567891011package com.atguigu.springcloud.config;import feign.Logger;@Configurationpublic class FeignConfig&#123; @Bean Logger.Level feignLoggerLevel()&#123; return Logger.Level.FULL; &#125;&#125; 然后在yml文件中开启日志打印配置： 12345678910111213141516171819server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ribbon: ReadTimeout: 5000 ConnectTimeout: 5000logging: level: com.atguigu.springcloud.service.PaymentFeignService: debug 中级部分 主要是服务降级、服务熔断、服务限流的开发思想和框架实现 ; Hystrix 断路器 官方地址：https://github.com/Netflix/Hystrix/wiki/How-To-Use“断路器”本身是一种开关装置，当某个服务单元发生故障之后，涌过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的备选响应(FallBack)，而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 概述服务雪崩：多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，这就是所谓的” 扇出“ 12A--&gt;B,CBC--&gt;D 如果扇出的链路上某个微服务的调用响应时间过长或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，即所谓的” 雪崩效应“。 对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几秒钟内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障。这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。 Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。 Hystrix停止更新，进入维护阶段：https://github.com/Netflix/Hystrixhttps://github.com/Netflix/Hystrix/wiki/How-To-Use 服务降级：fallback 服务器忙碌或者网络拥堵时，不让客户端等待并立刻返回一个友好提示，fallback。 对方系统不可用了，你需要给我一个 兜底的方法，不要耗死。 向调用方返回一个符合预期的、可处理的 备选响应(FallBack)，而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 降低发生的情况： 程序运行异常 超时 服务熔断触发服务降级 线程池/信号量打满也会导致服务降级 服务熔断：break 类比保险丝达到最大服务访问后， 直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示 就是保险丝：服务的降级-&gt;进熔断-&gt;恢复调用链路 服务限流：flowlimit 秒杀高并发等操作，严禁一窝蜂的过来拥挤，大家排队，一秒钟几个，有序进行 可见，上面的技术不论是消费者还是提供者，根据真实环境都是可以加入配置的。 断路案例 首先构建一个eureka作为服务中心的单机版微服务架构 ，这里使用之前eureka Server 7001模块，作为服务中心 新建 提供者 cloud-provider-hystrix-payment8001 模块： pom 文件： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrixartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; 下面主启动类、service、和controller代码都很简单普通。 主启动类： 1234567@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@EnableEurekaClientpublic class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class,args); &#125;&#125; service层： 123456789101112131415161718@Servicepublic class PaymentService &#123; public String paymentinfo_Ok(Integer id)&#123; return &quot;线程池：&quot; + Thread.currentThread().getName() + &quot;--paymentInfo_OK，id:&quot; + id; &#125; public String paymentinfo_Timeout(Integer id)&#123; int interTime = 3; try&#123; TimeUnit.SECONDS.sleep(interTime); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return &quot;线程池：&quot; + Thread.currentThread().getName() + &quot;--paymentInfo_Timeout，id:&quot; + id + &quot;耗时&quot; + interTime + &quot;秒钟--&quot;; &#125;&#125; controller层： 12345678910111213141516171819202122@RestController@Slf4jpublic class PaymentController &#123; @Resource private PaymentService paymentService; @Value(&quot;$&#123;server.port&#125;&quot;) private String serverPort; @GetMapping(&quot;/payment/hystrix/&#123;id&#125;&quot;) public String paymentInfo_OK(@PathVariable(&quot;id&quot;)Integer id)&#123; log.info(&quot;paymentInfo_OKKKKOKKK&quot;); return paymentService.paymentinfo_Ok(id); &#125; @GetMapping(&quot;/payment/hystrix/timeout/&#123;id&#125;&quot;) public String paymentInfo_Timeout(@PathVariable(&quot;id&quot;)Integer id)&#123; log.info(&quot;paymentInfo_timeout&quot;); return paymentService.paymentinfo_Timeout(id); &#125;&#125; 模拟高并发JMeter这里使用一个新东西 JMeter 压力测试器，模拟多个请求 下载压缩包，解压，双击 /bin/ 下的 jmeter.bat 即可启动 ctrl + S 保存后，输入请求地址开始压测。 从测试可以看出，当模拟的超长请求被高并发以后，访问普通的小请求速率也会被拉低。 tomcat的默认工作线程数被打满了，没有多余的线程来分解压力和处理。 上面还是服务8001自己测试，加入此时外部的消费者80页来访问，那消费者只能干等，最终导致消费端80不满意，服务端8001直接被拖死。 测试可见，当启动高并发测试时，消费者访问也会变得很慢，甚至出现超时报错。 演示问题：8001端口自身已经被打满了，80还要访问8001，80也响应慢了。 超时导致服务器变慢（转圈）：超时不再等待 出错（宕机或程序运行出错）：出错要有兜底 解决思路： 对方服务（8001） 超时了，调用者（80）不能一直卡死等待，必须有服务降级 对方服务（8001) down机了，调用者（80）不能一直卡死等待，必须有服务降级 对方服务（8001) OK，调用者（80）自己出故障或有自我要求（自己的等待时间小于服务提供者），自己处理降级 ; 服务降级案例新建消费者 cloud-customer-feign-hystrix-order80 模块：以feign为服务调用，eureka为服务中心的模块， 12345678910111213141516&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeignartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrixartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; 123456789101112server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/feign: hystrix: enabled: true 主启动类 12345678@SpringBootApplication@EnableFeignClients@EnableHystrixpublic class OrderHystrixMain80&#123; public static void main(String[] args) &#123; SpringApplication.run(OrderHystrixMain80.class,args); &#125;&#125; 一般服务降级放在客户端，即 消费者端 ，但是提供者端一样能使用。首先提供者，即8001 先从自身找问题，设置自身调用超时的峰值，峰值内正常运行，超出峰值需要有兜底的方法处理，作服务降级fallback 服务端降级 @HystrixCommand首先 对 8001的service进行配置（对容易超时的方法进行配置) : 降级配置： @HystrixCommand，可以在里面指定超时/出错的回调方法，作为兜底方法 提供方 service方法：演示超时 12345678910111213@HystrixCommand(fallbackMethod = &quot;paymentInfo_TimeOutHandler&quot;, commandProperties = &#123; @HystrixProperty(name=&quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value=&quot;3000&quot;)&#125;)public String paymentInfo_TimeOut(Integer id)&#123; try &#123; TimeUnit.MILLISECONDS.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return &quot;线程池: &quot;+Thread.currentThread().getName()+&quot; id: &quot;+id+&quot;\\t&quot;+&quot;O(∩_∩)O哈哈~&quot;+&quot; 耗时(秒): &quot;;&#125;public String paymentInfo_TimeOutHandler(Integer id)&#123; return &quot;线程池: &quot;+Thread.currentThread().getName()+&quot; 8001系统繁忙或者运行报错，请稍后再试,id: &quot;+id+&quot;\\t&quot;+&quot;o(╥﹏╥)o&quot;;&#125; 提供方 主启动类： 1234567@SpringBootApplication@EnableEurekaClient@EnableCircuitBreakerpublic class PaymentHystrixMain8001&#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentHystrixMain8001.class, args); &#125; 上面演示的是超时，下面演示上面service出错：同样走一样的回调方法 12345678910111213@HystrixCommand(fallbackMethod = &quot;paymentInfo_TimeOutHandler&quot;, commandProperties = &#123; @HystrixProperty(name=&quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value=&quot;3000&quot;)&#125;)public String paymentInfo_TimeOut(Integer id)&#123; int age = 10/0; return &quot;线程池: &quot;+Thread.currentThread().getName()+&quot; id: &quot;+id+&quot;\\t&quot;+&quot;O(∩_∩)O哈哈~&quot;+&quot; 耗时(秒): &quot;;&#125;public String paymentInfo_TimeOutHandler(Integer id)&#123; return &quot;线程池: &quot;+Thread.currentThread().getName()+&quot; 8001系统繁忙或者运行报错，请稍后再试,id: &quot;+id+&quot;\\t&quot;+&quot;o(╥﹏╥)o&quot;;&#125; 消费端降级上面的案例是服务端降级，现在我们服务端处理3s，然后返回。但是消费端等1s就等不住了，这时候就需要消费端也有降级方法 80的降级。原理是一样的，上面的@HystrixCommand降级可以放在服务端，也可以放在消费端。但一般放在客户端。 注意：我们自己配置过的热部署方式对java代码的改动明显，但对@HystrixCommand内属性的修改建议重启微服务。 123456789101112server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/feign: hystrix: enabled: true 12345678@SpringBootApplication@EnableFeignClients@EnableHystrixpublic class OrderHystrixMain80&#123; public static void main(String[] args)&#123; SpringApplication.run(OrderHystrixMain80.class,args); &#125;&#125; 然后对 80 进行服务降级：很明显 service 层是接口，所以我们对消费者，在它的 controller 层进行降级。继续使用 @HystrixCommand注解指定方法超时后的回调方法 controller 12345678910111213141516171819202122@RestController@Slf4jpublic class OrderHystirxController&#123; @Resource private PaymentHystrixService paymentHystrixService; @GetMapping(&quot;/consumer/payment/hystrix/timeout/&#123;id&#125;&quot;) @HystrixCommand(fallbackMethod = &quot;paymentTimeOutFallbackMethod&quot;, commandProperties = &#123; @HystrixProperty(name=&quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value=&quot;1500&quot;) &#125;) public String paymentInfo_TimeOut(@PathVariable(&quot;id&quot;) Integer id) &#123; String result = paymentHystrixService.paymentInfo_TimeOut(id); return result; &#125; public String paymentTimeOutFallbackMethod(@PathVariable(&quot;id&quot;) Integer id) &#123; return &quot;我是消费者80,对方支付系统繁忙请10秒钟后再试 或者 自己运行出错请检查自己,o(╥﹏╥)o&quot;; &#125;&#125; service 123456789@Component@FeignClient(value = &quot;CLOUD-PROVIDER-HYSTRIX-PAYMENT&quot; ,fallback = PaymentFallbackService.class)public interface PaymentHystrixService&#123; @GetMapping(&quot;/payment/hystrix/ok/&#123;id&#125;&quot;) public String paymentInfo_OK(@PathVariable(&quot;id&quot;) Integer id); @GetMapping(&quot;/payment/hystrix/timeout/&#123;id&#125;&quot;) public String paymentInfo_TimeOut(@PathVariable(&quot;id&quot;) Integer id);&#125; 目前问题： 每个业务方法对应一个兜底的方法，代码膨胀 同样和自定义分开 我们定义一个全局的兜底方法，这样就不用每个方法都得写兜底方法了。 全局兜底 @DefaultProperties1234567891011121314151617181920212223242526@RestController@Slf4j@DefaultProperties(defaultFallback = &quot;payment_Global_FallbackMethod&quot;)public class OrderHystirxController&#123; @Resource private PaymentHystrixService paymentHystrixService; @GetMapping(&quot;/consumer/payment/hystrix/timeout/&#123;id&#125;&quot;) @HystrixCommand(fallbackMethod = &quot;paymentTimeOutFallbackMethod&quot;, commandProperties = &#123; @HystrixProperty(name=&quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value=&quot;1500&quot;) &#125;) public String paymentInfo_TimeOut(@PathVariable(&quot;id&quot;) Integer id) &#123; String result = paymentHystrixService.paymentInfo_TimeOut(id); return result; &#125; public String paymentTimeOutFallbackMethod(@PathVariable(&quot;id&quot;) Integer id) &#123; return &quot;我是消费者80,对方支付系统繁忙请10秒钟后再试 或者 自己运行出错请检查自己,o(╥﹏╥)o&quot;; &#125; public String payment_Global_FallbackMethod()&#123; return &quot;Global异常处理信息，请稍后再试，/(ㄒoㄒ)/~~&quot;; &#125;&#125; service降级 @FeignClient下面解决业务逻辑混在一起的问题（解耦）：我们改在service层进行服务降级 服务降级，客户端去调用服务端，碰上服务端宕机或关闭。本次案例降级处理是在客户端80实现完成的，与服务端8001没有关系。只需要为Feign客户端定义的接口添加一个服务降级处理的实现类即可实现解耦。 在这种方式一般是在客户端，即消费者端，首先上面再controller中添加的 @HystrixCommand 和 @DefaultProperties 两个注解去掉。就是保持原来的controller 12345678910@Component@FeignClient(value = &quot;CLOUD-PROVIDER-HYSTRIX-PAYMENT&quot; , fallback = PaymentFallbackService.class)public interface PaymentHystrixService&#123; @GetMapping(&quot;/payment/hystrix/ok/&#123;id&#125;&quot;) public String paymentInfo_OK(@PathVariable(&quot;id&quot;) Integer id); @GetMapping(&quot;/payment/hystrix/timeout/&#123;id&#125;&quot;) public String paymentInfo_TimeOut(@PathVariable(&quot;id&quot;) Integer id);&#125; service回调方法：是service接口的实现类。此时就不需要在controller上写fallback方法了 123456789101112@Componentpublic class PaymentFallbackService implements PaymentHystrixService&#123; @Override public String paymentInfo_OK(Integer id)&#123; return &quot;-----PaymentFallbackService fall back-paymentInfo_OK ,o(╥﹏╥)o&quot;; &#125; @Override public String paymentInfo_TimeOut(Integer id)&#123; return &quot;-----PaymentFallbackService fall back-paymentInfo_TimeOut ,o(╥﹏╥)o&quot;; &#125;&#125; 此时的yml文件配置 123456789101112131415server: port: 80spring: application: name: cloud-customer-feign-hystrix-serviceeureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://eureka7001.com:7001/eureka/feign: hystrix: enabled: true 修改service 接口： 1234567891011@Component@FeignClient(value = &quot;CLOUD-PROVIDER-HYSTRIX-PAYMENT&quot;, fallback = OrderFallbackService.class)public interface OrderService &#123; @GetMapping(&quot;/payment/hystrix/&#123;id&#125;&quot;) public String paymentInfo_OK(@PathVariable(&quot;id&quot;)Integer id); @GetMapping(&quot;/payment/hystrix/timeout/&#123;id&#125;&quot;) public String paymentInfo_Timeout(@PathVariable(&quot;id&quot;)Integer id);&#125; fallback 指向的类： 123456789101112131415package com.dkf.springcloud.service;@Componentpublic class OrderFallbackService implements OrderService&#123; @Override public String paymentInfo_OK(Integer id) &#123; return &quot;OrderFallbackService --发生异常&quot;; &#125; @Override public String paymentInfo_Timeout(Integer id) &#123; return &quot;OrderFallbackService --发生异常--paymentInfo_Timeout&quot;; &#125;&#125; 新问题，这样配置如何设置超时时间？ 首先要知道 下面两个 yml 配置项： 1234567hystrix.command.default.execution.timeout.enable=true ## 默认值## 为false则超时控制有ribbon控制，为true则hystrix超时和ribbon超时都是用，但是谁小谁生效，默认为truehystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=1000 ## 默认值## 熔断器的超时时长默认1秒，最常修改的参数 看懂以后，所以：只需要在yml配置里面配置 Ribbon 的 超时时长即可。注意：hystrix 默认自带 ribbon包。 123ribbon:\tReadTimeout: xxxx\tConnectTimeout: xxx 服务熔断案例 实际上服务熔断 和 服务降级 没有任何关系，就像 java 和 javaScript服务熔断，有点自我恢复的味道参考：https://blog.csdn.net/www1056481167/article/details/81157171 服务雪崩多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C有调用其他的微服务，这就是所谓的”扇出”，如扇出的链路上某个微服务的调用响应式过长或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统雪崩，所谓的”雪崩效应”Hystrix：Hystrix是一个用于分布式系统的延迟和容错的开源库。在分布式系统里，许多依赖不可避免的调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整个服务失败，避免级联故障，以提高分布式系统的弹性。断路器：“断路器”本身是一种开关装置，当某个服务单元发生故障监控(类似熔断保险丝)，向调用方法返回一个符合预期的、可处理的备选响应(FallBack)，而不是长时间的等待或者抛出调用方法无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延。乃至雪崩。服务熔断：熔断机制是应对雪崩效应的一种微服务链路保护机制，当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回”错误”的响应信息。当检测到该节点微服务响应正常后恢复调用链路，在SpringCloud框架机制通过Hystrix实现，Hystrix会监控微服务见调用的状况，当失败的调用到一个阈值，默认是5秒内20次调用失败就会启动熔断机制，熔断机制的注解是 @HystrixCommand 熔断的状态： 熔断打开：请求不再进行调用当前服务，内部设置时钟一般为MTTR（平均故障处理时间），当打开时长达到所设时钟则进入半熔断状态 熔断关闭：熔断关闭不会对服务进行熔断 熔断半开： 部分请求根据规则调用当前服务，如果请求成功目符合规则，则认为当前服务恢复正常，关闭熔断。 修改cloud-provider-hystrix-payment8001模块 123456789101112131415161718192021222324252627282930package com.atguigu.springcloud.service;import cn.hutool.core.util.IdUtil;import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty;@Servicepublic class PaymentService&#123; @HystrixCommand(fallbackMethod = &quot;paymentCircuitBreaker_fallback&quot;, commandProperties = &#123; @HystrixProperty(name = &quot;circuitBreaker.enabled&quot;,value = &quot;true&quot;), @HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;,value = &quot;10&quot;), @HystrixProperty(name = &quot;circuitBreaker.sleepWindowInMilliseconds&quot;,value = &quot;10000&quot;), @HystrixProperty(name = &quot;circuitBreaker.errorThresholdPercentage&quot;,value = &quot;60&quot;), &#125;) public String paymentCircuitBreaker(@PathVariable(&quot;id&quot;) Integer id)&#123; if(id &lt; 0) &#123; throw new RuntimeException(&quot;******id 不能负数&quot;); &#125; String serialNumber = IdUtil.simpleUUID(); return Thread.currentThread().getName()+&quot;\\t&quot;+&quot;调用成功，流水号: &quot; + serialNumber; &#125; public String paymentCircuitBreaker_fallback(@PathVariable(&quot;id&quot;) Integer id)&#123; return &quot;id 不能负数，请稍后再试，/(ㄒoㄒ)/~~ id: &quot; +id; &#125;&#125; 涉及到断路器的三个重要参数快照时间窗、请求总数阀值、错误百分比阀值 1：快照时间窗：断路器确定是否打开需要统计一些请求和错误数据而统计的时间范围就是快照时间窗，默认为最近的10秒。 2：请求总数阀值：在快照时间窗内，必须满足请求总数阀值才有资格熔断。默认为20，意味着在10秒内，如果该hystrix命令的调用次数不足20次，即使所有的请求都超时或具他原因失败，断路器都不会打开。 3：错误百分比阀值：当请求总数在快照时间窗内超过了阀值，上日发生了30次调用，如果在这30次调用中，有15次发生了超时异常，也就是超过50％的错误百分比，在默认设定50％阀值情况，这时候就会将断路器打开。 The precise way that the circuit opening and closing occurs is as follows: Assuming the volume across a circuit meets a certain threshold (HystrixCommandProperties.circuitBreakerRequestVolumeThreshold())… And assuming that the error percentage exceeds the threshold error percentage (HystrixCommandProperties.circuitBreakerErrorThresholdPercentage())… Then the circuit-breaker transitions from CLOSED to OPEN. While it is open, it short-circuits all requests made against that circuit-breaker. After some amount of time (HystrixCommandProperties.circuitBreakerSleepWindowInMilliseconds()), the next single request is let through (this is the HALF-OPEN state). If the request fails, the circuit-breaker returns to the OPEN state for the duration of the sleep window. If the request succeeds, the circuit-breaker transitions to CLOSED and the logic in 1. takes over again.经过一段时间后，如果有1个尝试成功了，就慢慢尝试恢复 参考：https://github.com/Netflix/Hystrix/wiki/How-it-Works#CircuitBreaker controller: 12345@GetMapping(&quot;/payment/circuit/&#123;id&#125;&quot;)public String paymentCircuitBreaker(@PathVariable(&quot;id&quot;)Integer id)&#123; return paymentService.paymentCircuitBreaker(id);&#125; 实验效果为，多次出错调用fallback后，调用正常的也出错调用fallback。过了一会又自己恢复了。展望：以后用的是Sentinel代替。 关于解耦以后的全局配置说明： 例如上面提到的全局服务降级，并且是feign+hystrix整合，即 service 实现类的方式，如何做全局配置？ 上面有 做全局配置时，设置超时时间的方式，我们可以从中获得灵感，即在yml文件中 进行熔断配置： 12345678hystrix:command:default:circuitBreaker: enabled: true requestVolumeThreshold: 10 sleepWindowInMilliseconds: 10000 errorThresholdPercentage: 60 Hystrix DashBoard除了隔离依赖服务的调用以外，Hystrix还提供了准实时的调用监控(HystrixDashboard)，Hystrix会持续地记录所有通过Hystrix发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求多少成功，多少失败等。Netflix通过hystrix-metrics-event-stream实现了对以上指标的监控。SpringCloud也提供了HystrixDashboard的整合，对监控内容转化成可视化界面。 新建模块 cloud-hystrix-dashboard9001 ： pom 文件： 1234567891011121314151617181920212223242526272829303132333435363738&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboardartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; yml文件只需要配置端口号，主启动类加上这样注解：@EnableHystrixDashboard 启动测试：访问 http://ocalhost:9001/hystrix 监控实战 下面使用上面 9001 Hystrix Dashboard 项目，来监控 8001 项目 Hystrix 的实时情况： 注意8001被监控的时候pom里要actuator依赖，此外还要有 主启动类上加 @EnableCircuitBreaker，用于对豪猪熔断机制的支持 123456789@Beanpublic ServletRegistrationBean getServlet()&#123; HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(streamServlet); servletRegistrationBean.setLoadOnStartup(1); servletRegistrationBean.addUrlMappings(&quot;/hystrix.stream&quot;); servletRegistrationBean.setName(&quot;HystrixMetricsStreamServlet&quot;); return servletRegistrationBean;&#125; 然后就可以取页面里看熔断情况了。输入localhost:8001/hystrix.stream 服务网关 ; Gateway 内容过多，开发可参考 https://docs.spring.io/ 官网文档 简介SpringCloud Gateway是SpringCloud的一个全新项目，基于Spring5.O+Springboot 2.0和ProjectReactor等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的API路由管理方式。 SpringCloudGateway作为SpringCloud生态系统中的网关，目标是替代Zuul,在SpringCloud2.0以上版本中，没有对新版本的zuul2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 1.x非Reactor模式的老版本。而为了提升网关的性能， SpringCloud Gateway是基于WebFlux框架实现的，而webFlux框架底层则使用了高性能的Reactor模式通信框架Netty。 springCloudGateway的目标提供统一的路由方式且基于Filter链的方式提供了网关基本的功能，例如：安全，监控/指标，和限流。 一方面因为Zuul 1.0已经进入了维护阶段，而且Gateway是SpringCloud团队研发的是亲儿子产品，值得信赖。而且很多功能比zull用起来都简单便捷。 Gateway是基于异步非阻塞模型上进行开发的，性能方面不需要担心。虽然Netflix早就发布了最新的Zuul2.x，但Spring Cloud貌似没有整合计划。而且Netflix相关组件都宣布进入维护期；不知前景如何？ 多方面综合考虑Gateway是很理想的网关选择。 SpringCloudGateway与Zuul的区别： 在SpringCloudFinchley正式版之前，SpringCloud推荐的网关是Netflix提供的Zuul： 1、Zuul 1.x是一个基于 阻塞I/O的APIGateway2、Zuul 1.x基于ServIet2.5使用阻塞架构，它 不支持任何长连接（如WebSocket)，Zuul的设计模式和Nginx较像，每次I/O操作都是从工作线程中选择一个执行，请求线程阻塞到工作线程完成，但是差别是Nginx用C++实现，Zuul用Java实现，而JVM本身会有第一次加载较慢的情况，使得Zuul的性能相对较差。 3、Zuul 2.x理念更先进想基于Netty非阻塞和支持长连接，但SpringCloud目前还没有整合。Zuul2.x的性能较Zuul1.x有较大提升。在性能方面，根据官方提供的基准测试，SpringCloudGateway的RPS（每秒请求数）是Zuul的1.6倍。 4、SpringCloudGateway建立在SpringFramework5、ProjectReactor和SpringB00t2．之上，使用非阻塞API 5、SpringCloudGateway还支持WebSocket,并且与Spring紧密集成拥有更好的开发体验 Zuull.xspringcloud中所集成的zuul版本，采用的是tomcat容器，使用的是传统的servlet IO处理模型。 学过尚硅谷web中期课程都知道一个题目，Servlet的生命周期，servlet由servlet container进行生命周期管理 container启动时构造servlet对象并调用servlet init()进行初始化， container运行时接受请求，并为每个请求分配一个线程（一般从线程池中获取空闲线程）然后调用service() container关闭时调用servlet destory()销毁servlet 上述模式的缺点： servlete—个简单的网络IO模型，当请求进入servlet container时，servlet container就会为其绑定一个线程在并发不高的场景下这种模型是适用的。但是一旦高并发（比如抽风用jemeter压),线程数量就会上涨，而线程资源代价是昂贵的（上线文切换，内存消耗大）严重影响请求的处理时间。 在一些简单业务场景下，不希望为每个request分配一个线程，只需要1个或几个线程就能应对极大并发的请求，这种业务场景下servlet模型没有优势 所以Zuul 1.x是基于servlet之上的一个阻塞式处理模型，即spring实现了处理所有request请求的一个servlet(DispatcherServlet)并由该servlet阻塞式处理处理。所以springcloudzuul无法摆脱servlet模型的弊端。 传统的Web框架比如说：struts2,springmvc等都是基于Servlet API与Servlet容器基础之上运行的。 但是，在 Servlet3.1之后有了异步非阻塞的支持。而WebFlux是一个典型 非阻塞异步的框架，它的核心是基于Reactor的相关API实现的。相对于传统的web框架来说，它可以运行在诸如Netty，Undertow及支持Servlet3.1的容器上。非阻塞式+函数式编程(Spring5必须让你使用java8) SpringWebFlux是Spring5.0引入的新的响应式框架区别于SpringMVC,它不需要依赖ServletAPI，它是完全异步非阻塞的，并且基于Reactor来实现响应式流规范。 ; Gateway是什么Gateway特性： 基于SpringFramework5，ProjectReactor和SpringBoot 2.0进行构建； 动态路由：能够匹任何请求属性； 可以对路由指定Predicate（断言）和Filter（过滤器）· 集成Hystrix的断路器功能； 集成SpringCloud服务发现功能； 易于编写的Predicate（断言）和Filter（过滤器）· 请求限流功能； 支持路径重写。 GateWay的三大核心概念： Route(路由）：路由是构建网关的基本模块，它由ID、目标URI、一系列的断言和过滤器组成，如果断言为true则匹配该路由 Predicate(断言）：参考的是Java8的java.util.function.predicate。开发人员可以匹配HTTP请求中的所有内容（例如请求头或请求参数），如果请求与断言相匹配则进行路由 匹配条件 Filter(过滤）：指的是spring框架中GatewayFilter的实例，使用过滤器，可以在请求被路由前或者之后对请求进行修改。 例子：通过 断言虽然进来了，但老师要罚站10min（ 过滤器操作），然后才能正常坐下听课 web请求，通过一些匹配条件，定位到真正的服务节点。并在这个转发过程的前后，进行一些精细化控制。而filter，就可以理解为一个无所不能的拦截器。有了这两个元素，再加上目标uri，就可以实现一个具体的路由了 客户端向Spring Cloud Gateway发出请求。然后在Gateway HandlerMapping中找到与请求相匹配的路由，将其发送到Gateway Web Handler Handler再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。 过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（Pre）或之后（post）执行业务逻辑。 Filter在pre类型的过滤器可以做 参数校验，权限校验，流量监听，日志输出，协议转换等， 在post类型的过滤器中可以做响应内容、响应头的修改，日志的输出，流量监控等有着非常重要的作用。 入门配置新建模块 cloud-gateway-gateway9527 现在实现，通过Gateway (网关) 来访问其它项目，这里选择之前8001项目，要求注册进Eureka Server 。其它没要求。 pom文件： 12345678910111213141516171819202122232425262728293031323334&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-gatewayartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; yml文件： 12345678910111213141516171819202122232425server: port: 9527spring: application: name: cloud-gateway cloud: gateway: routes: - id: payment_routh uri: http://localhost:8001 predicates: - Path=/payment/get/** - id: payment_routh2 uri: http://localhost:8001 predicates: - Path=/payment/lb/**eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ register-with-eureka: true fetch-registry: true 如果IDEA出现了bug，yml配置文件没有变为小叶子，就去structure里设置下模块的spring，选择该yml 主启动类 1234567@SpringBootApplication@EnableEurekaClientpublic class GatewayMain9527 &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayMain9527.class,args); &#125;&#125; 8001看看controller的访问地址，我们目前不想暴露8001端口，希望在8001外面套一层9527。这样别人就攻击不了8001，有网关挡着 访问测试： 1 启动eureka Server， 2 启动 8001 项目， 3 启动 9527（Gateway项目） 可见，当我们访问 http://localhost:9527/payment/get/1 时，即访问网关地址时，会给我们转发到 8001 项目的请求地址，以此作出响应。加入网关前：http://localhost:8001/payment/get/1加入网关后：http://localhost:9527/payment/get/1 上面是以 yml 文件配置的路由，也有使用config类配置的方式： 12345678910111213@Configurationpublic class GateWayConfig&#123; @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder)&#123; RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); routes.route(&quot;path_route_atguigu&quot;, r -&gt; r.path(&quot;/guonei&quot;).uri(&quot;http://news.baidu.com/guonei&quot;) ).build(); return routes.build(); &#125;&#125; 123456789101112131415161718192021222324@Component@Slf4jpublic class MyLogGateWayFilter implements GlobalFilter,Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; log.info(&quot;***********come in MyLogGateWayFilter: &quot;+new Date()); String uname = exchange.getRequest().getQueryParams().getFirst(&quot;uname&quot;); if(uname == null) &#123; log.info(&quot;*******用户名为null，非法用户，o(╥﹏╥)o&quot;); exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE); return exchange.getResponse().setComplete(); &#125; return chain.filter(exchange); &#125; @Override public int getOrder() &#123; return 0; &#125;&#125; 动态配置 这里所谓的动态配置就是利用服务注册中心，来实现 负载均衡 的调用 多个微服务。默认情况下gateway会根据注册中心注册的服务列表，以注册中心上微服务名为路径创建动态路由进行转发，从而实现动态路由的功能注意，这是GateWay 的负载均衡 对yml进行配置：让其先通过gateway，再通过gateway去注册中心找提供者 1234567891011121314151617181920212223242526272829303132server: port: 9527spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true routes: - id: payment_routh uri: lb://CLOUD-PROVIDER-SERVICE predicates: - Path=/payment/get/** - id: payment_routh2 uri: lb://CLOUD-PROVIDER-SERVICE predicates: - Path=/payment/lb/**eureka: instance: hostname: cloud-gateway-service client: service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 下面可以开启 8002 模块，并将它与8001同微服务名，注册到 Eureka Server 进行测试。 Gateway:Predicate 注意到上面yml配置中，有个predicates 属性值。 1 After Route Predicate 2 Before Route Predicate 3 Between Route Predicate 4 Cookie Route Predicate 5 Header Route Predicate 6 Host Route Predicate 7 Method Route Predicate 8 Path Route Predicate 9 Query Route Predicate 具体使用： 123456789101112131415161718192021spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true routes: - id: payment_routh uri: lb://cloud-payment-service predicates: - Path=/payment/get/** - id: payment_routh2 uri: lb://cloud-payment-service predicates: - Path=/payment/lb/** predicates下面可以有多个属性，表示多个属性与操作为true这个路由才生效 predicates属性下的After属性 123predicates: - Path=/payment/lb/** - After=2020-02-21T15:51:37.485+08:00[Asia/Shanghai] predicates属性下的Cookie属性 123predicates:\t- Cookie=username,zzyy,ch.p predicates属性下的Header属性 12345678spring: cloud: gateway: routes: - id: header_route uri: https://example.org predicates: - Header=X-Request-Id, \\d+ 123456789101112spring: cloud: gateway: routes: - id: host_route uri: https://example.org predicates: - Host=**.somehost.org,**.anotherhost.org例如我加上： - Host=localhost:** ** 代表允许任何端口就只能是主机来访 更多属性可以参考：https://docs.spring.io/spring-cloud-gateway/docs/2.2.5.RELEASE/reference/html/#configuring-route-predicate-factories-and-gateway-filter-factories 需要注意的是value部分写的是正则表达式 高并发工具：jmeter、postman、curl 配置错误页面: 注意，springboot默认/static/error/ 下错误代码命名的页面为错误页面，即 404.html而且不需要导入额外的包，Gateway 里面都有。 Gateway:Filter生命周期： pre： post： 种类： GatewayFilter：https://docs.spring.io/spring-cloud-gateway/docs/2.2.5.RELEASE/reference/html/#gatewayfilter-factories GlobalFilter：https://docs.spring.io/spring-cloud-gateway/docs/2.2.5.RELEASE/reference/html/#global-filters 12345678spring: cloud: gateway: routes: - id: add_request_header_route uri: https://example.org filters: - AddRequestHeader=X-Request-red, blue 主要是配置全局自定义过滤器，其它的小配置具体看官网吧 2个主要接口： implements GlobalFilter,Ordered 场景： 全局日志记录 统一网关鉴权 。。。 自定义全局过滤器配置类： 12345678910111213141516171819202122232425262728@Component@Slf4jpublic class MyLogGateWayFilter implements GlobalFilter,Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; log.info(&quot;********** come in MyLogGateWayFilter: &quot;+new Date()); String uname = exchange.getRequest().getQueryParams().getFirst(&quot;uname&quot;); if(uname == null) &#123; log.info(&quot;*******用户名为null，非法用户，o(╥﹏╥)o，请求不被接受&quot;); exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE); return exchange.getResponse().setComplete(); &#125; return chain.filter(exchange); &#125; @Override public int getOrder() &#123; return 0; &#125;&#125; 服务配置 ; Config SpringCloud Config 分布式配置中心 概述微服务意味着要将单应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务。由于每个服务都需要必要的配置信息才能运行，所以一套集中式的、动态的配置管理设施是必不可少的。 springCloud提供了ConfigServer来解决这个问题，我们每一个微服务自己带着一个application.yml，上百个配置文件的管理。比如数据库的信息，我们可以写到一个统一的地方。 config+bus alibaba nacos 携程 阿波罗 SpringCloud Config是什么：Spring Cloud Config为微服务架构中的微服务提供集中化的外部配置支持，配置服务器为各个不同微服务应用的所有环境提供了一个 中心化的外部配置。 怎么玩：SpringCloud Config分为服务端和客户端两部分。 服务端也称为分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密/解密信息等访问接口 客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心取和加载配置信息配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理，并且可以通过git客户端工具来方便的管理和访问配置内容 能干嘛： 集中管理配置文件 不同环境不同配置， 动态化的配置更新，分环境部署比如dev/test/prod/beta/release 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息 当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置 将配置信息以REST接囗的形式暴露 ; config服务端配置这个服务端指的是消费端与github之间的桥接 首先在github上新建一个仓库 springcloud-config&#103;&#x69;&#116;&#64;&#103;&#105;&#x74;&#x68;&#x75;&#98;&#x2e;&#x63;&#x6f;&#109;:名字/项目.git然后使用git命令克隆到本地，命令：git clone https://github.com/LZXYF/springcloud-config注意上面的操作不是必须的，只要github上有就可以，克隆到本地只是修改文件。常用命令： git add git commit -m “标记” git push origin master 在git根目录下创建 开发环境：config-dev.yml 生产环境：config-pro.yml 测试环境：config-test.tml 注意格式 新建 cloud-config-center3344 模块： pom文件： 123456789101112131415161718192021222324252627282930313233&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-config-serverartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; yml 配置： 123456789101112131415161718192021server: port: 3344spring: application: name: cloud-config-center cloud: config: server: git: uri: git@github.com:zzyybs/springcloud-config.git search-paths: - springcloud-config label: mastereureka: client: service-url: defaultZone: http://localhost:7001/eureka 主启动类： 1234567@SpringBootApplication@EnableConfigServerpublic class ConfigCenterMain3344 &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigCenterMain3344.class,args); &#125;&#125; 添加模拟映射：【C:\\Windows\\System32\\drivers\\etc\\hosts】文件中添加： 127.0.0.1 config-3344.com 启动微服务3344，访问 http://config-3344.com:3344/master/config-dev.yml 文件（注意，要提前在git上弄一个这文件） 老师的配置中心地址：https://github.com/zzyybs/springcloud-config 文件命名和访问的规则： 不加分支名默认是master: 最后一个出的是json串 label：分支branch name：服务名 profiles：环境dev/test/prod config客户端配置 这里的客户端指的是，使用 Config Server 统一配置文件的项目。既有之前说的消费者，又有提供者 新建 cloud-config-client-3355 模块： pom文件： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-configartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; 要将Client模块下的application.yml文件改为bootstrap.yml，删掉application.yml这是很关键的 因为bootstrap.yml是比application.yml先加载的。bootstrap.yml优先级高于application.yml appllication.yml是用户级的资源配置项 bootstrap.ym1是系统级的，优先级更加高 SpringCloud会创建一个”Bootstrap Context”作为Spring应用的ApplicationContext的 父上下文。初始化的时候，Bootstrap Context负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的Environment Bootstrap 属性有高优先级，默认情况下，它们不会被本地配置覆盖。BootstrapContext和ApplicationContext、有着不同的约定，所以新增了一个bootstrap.yml文件，保证BootstrapContext和ApplicationContext配置的分离。 bootstrap.yml文件： 123456789101112131415161718server: port: 3355spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344eureka: client: service-url: defaultZone: http://localhost:7001/eureka 主启动类，极其普通： 1234567@SpringBootApplication@EnableEurekaClientpublic class ConfigClientMain3355 public static void main(String[] args) &#123; SpringApplication.run(ConfigClientMain3355.class, args); &#125;&#125; controller层，测试读取配置信息 12345678910111213package com.dkf.springcloud.controller;@RestControllerpublic class ConfigClientController &#123; @Value(&quot;$&#123;config.info&#125;&quot;) private String configInfo; @GetMapping(&quot;/configInfo&quot;) public String getConfigInfo()&#123; return configInfo; &#125;&#125; 启动测试完成！如果报错，注意github上的 yml 格式有没有写错！ 启动Config配置中心3344微服务并自测，启动3355作为client访问 localhost:3355/configInfo 修改config-dev.yml配置文件并提交到github中，比如加个变量age或者版本号version。更改消费者端的配置看看其他环境能不能用 动态刷新问题： Linux运维修改GitHub上的配置文件内容做调整：比如修改config-dev.yml提交 刷新3344，发现ConfigServer服务端配置中心立刻响应，得到最新值了 刷新3355，发现ConfigClient客户端没有任何响应，拿到的还是旧值 客户端3355没有变化除非自己重启或者重新加载，才能拿到最新值 难到每次运维修改配置文件， 客户端都需要重启？？噩梦 就是github上面配置更新了，config Server 项目上是动态更新的，但是，client端的项目中的配置，目前还是之前的，它不能动态更新，必须重启才行。 动态刷新问题解决： client端一定要有actuator依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt;dependency&gt; client 端增加 yml 配置如下，即在 bootstrap.yml 文件中： 123456789101112131415161718192021222324server: port: 3355spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344eureka: client: service-url: defaultZone: http://localhost:7001/eurekamanagement: endpoints: web: exposure: include: &quot;*&quot; 在controller 上添加注解 @RefreshScope： 1234567891011@RestController@RefreshScopepublic class ConfigClientController &#123; @Value(&quot;$&#123;config.info&#125;&quot;) private String configInfo; @GetMapping(&quot;/configInfo&quot;) public String getConfigInfo() &#123; return configInfo; &#125;&#125; 到此为止，配置已经完成，但是测试客户端 localhost:3355/configInfo 仍然不能动态刷新，还是旧值（也就是说环境变量里的还是旧值），需要下一步。 向 client 端发送一个 POST 请求 如 curl -X POST “http://localhost:3355/actuator/refresh&quot;两个必须：1.必须是 POST 请求，2.请求地址：http://localhost:3355/actuator/refresh 成功获得到最新值 但是又有一个问题，就是要向每个微服务客户端发送一次POST请求，当微服务数量庞大，又是一个新的问题。 能否广播，一次通知，处处生效？（还要求不要全广播，差异化管理，定点清除，20台只有18台更新） 就有下面的消息总线！ 消息总线消息总线的由来看上面一小节 Busspring cloud Bus配置spring cloud Config使用可以实现配置的动态刷新 spring cloud bus是用来将分布式系统的节点与轻量级消息系统链接起来的框架，它整合了java的事件处理机制和消息中间件的功能。 spring cloud bus目前支持RabbitMQ和Kafka（因为是主题订阅） 什么是总线 在微服务架构的系统中，通常会使用轻量级的消息代理来构建一个共用的消息主题，并让系统中所有微服务实例都连接上来。由于该主题中产生的消息会被所有实例 监听和消费，所以称它为消息总线。在总线上的各个实例，都可以方便地广播一些需要让貝他连接在该主题上的实例都知道的消息。 基本原理： ConfigClient实例都监听MQ中同一个topic主题(默认是 springCloud Bus)。当一个服务刷新数据的时候，它会把这个信息放入到Topic中，这样其它监听同一topic的服务就能得到通知，然后去更新自身的配置 下图原盈利是就是给其中一台发送我们的刷新POST，他刷新完后给Bus发消息，然后Bus通过消息中间件发送给BC进行更新 Bus能管理和传输分布式系统间的消息，就像一个分布式执行器，可用于广播状态更改、事件推送等，也可以当做微服务间的通信通道 ; RabbitMQ 在windows 上安装RabbitMQ 安装RabbitMQ的依赖环境 Erlang 下载地址： http://erlang.org/download/otp_win64_21.3.exe 安装RabbitMQ 下载地址： http://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.14/rabbitmq-server-3.7.14.exe 进入 rabbitMQ安装目录的sbin目录下，打开cmd窗口，执行 【 rabbitmq-plugins enable rabbitmq_management】 访问【http://localhost:15672/】，输入密码和账号：默认为guest 广播式刷新配置 必须先具有良好的RabbitMQ环境 演示广播效果，增加复杂度，再以3355为模板再制作一个3366 设计思想 1）利用消息总线触发一个客户端/bus/refresh，而刷新所有客户端的配置 2）利用消息总线触发一个服务端ConfigServer的/bus/refres端点，从而刷新所有客户端的配置 图二的架构显然更加适合，图一不适合的原因如下 打破了微服务的职责单一性，因为微服务本身是业务模块，它本不应该承担配置刷新的职责 破坏了微服务各节点的对等性。 有一定的局限性”例如，微服务在迁移时，它的网络地址常常会发生变化，此时如果想要做到自动刷新，那就会增加更多的 给cloud-config-center-3344配置中心服务端添加消息总线支持 给cloud-config-client-3355客户端添加消息总线支持 给cloud-config-client-3366客户端添加消息总线支持（以3355为模板） 测试 一次修改，广播通知，出处生效 但还是得发一个POST请求，只不过只给config发而已 首先给 config Server 和 config client 都添加如下依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqpartifactId&gt;dependency&gt; config Server 的yml文件增加如下rabbitmq配置： 123456789101112rabbitmq: host: localhost port: 5672 username: guest password: guestmanagement: endpoints: web: exposure: include: &#x27;bus-refresh&#x27; config Client 的yml文件修改成如下配置：（注意对齐方式，和config Server不一样） 12345678spring: cloud: config: label: master name: client-config profile: test uri: http://config-3344.com:3344 3355客户端的bootstrap.yml 123456789101112131415161718192021222324252627282930server: port: 3355spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344 rabbitmq: host: localhost port: 5672 username: guest password: guesteureka: client: service-url: defaultZone: http://localhost:7001/eurekamanagement: endpoints: web: exposure: include: &quot;*&quot; 3344注册中心的application.yml 123456789101112131415161718192021222324252627282930313233server: port: 3344spring: application: name: cloud-config-center cloud: config: server: git: uri: git@github.com:zzyybs/springcloud-config.git search-paths: - springcloud-config label: masterrabbitmq: host: localhost port: 5672 username: guest password: guesteureka: client: service-url: defaultZone: http://localhost:7001/eurekamanagement: endpoints: web: exposure: include: &#x27;bus-refresh&#x27; 可在github上修改yml文件进行测试，修改完文件，向 config server 发送 请求： 给3344发就能全局同步了【curl -X POST “http://localhost:3344/actuator/bus-refresh&quot;】 注意，之前是向config client 一个个发送请求，但是这次是向 config Server 发送请求，而所有的config client 的配置也都全部更新。 定点通知新的需求：指定具体某一个实例（的参数）生效而不是全部，一些是最新值，一些是旧值 公式： http://localhost:配置中心的端口号/actuator/bus-refresh/&#123;destination&#125; 例子：curl -X POST “http//localhost:3344/actuator/bus-refresh/config-client:3355 即微服务名称+端囗号 /bus/refresh请求不再发送到具体的服务实例上，而是发给configserver并通过destination参数类指定需要更新配置的服务或实例 我们这里以刷新运行在3355端口上的config-client为例 只通知3355 不通知3366 消息驱动Stream需求：消息中间件很多，希望向上抽象一个接口，我们不关心底层用的是什么消息中间件 屏蔽底层消息中间件的差异，降低切换成本，统一消息的编程模型 就像 JDBC 形成一种规范，统一不同数据库的接口 什么是SpringCloud Stream 官方定义SpringCloud Stream是一个构建消息驱动微服务的框架。https://spring.io/projects/spring-cloud-stream#overview 应用程序通过inputs或者outputs来与SpringCloud Stream中binder对象（绑定器）交互 涌过我们配置来binding（绑定）而SpringCloud Stream的binder对象负责与消息中间件交互。 所以，我们只需要搞清楚如何与springCloudstrearn交互就可以方便使用消息驱动的方式。 通过使用Spring Integration来连接消息代理中间件以实现消息事件驱动。 SpringCloud Stream为一些供应商的消息中间件产品提供了个性化的自动化配置实现，引用了发布-订阅、消费组、分区的三个核心概念 目前仅支持RabbitMQ、Kafka。 流程：pub生产者发送消息，BROKER接收消息放到队列中，订阅者接收到消息选修必须走特定的通道：下嘻嘻通道MessageChannel消息通道里的消息如何消费呢？谁负责收发处理：消息通道MessageChannel的子接口SubscribableChannel，由MessageHandler消息处理器所订阅比如java里用的是RabbitMQ，大数据里用的是kafka，来回切换麻烦，链各个消息中间件的架构上不同像RabbitMQ有exchange，kafka有Topic和Partitions分区这些中间件的差异导致我们实际项目开发给我们造成了一定的困难，我们如果用了两个消息队列的其中一种，后面的业务需求，我们想往另外一种消息队列进行迁移，这时候无疑就是一个灾难性的，一大堆东西都要重新推倒重新做，因为它跟我们的系统耦合了，这时候SpringCloud Stream给我们提供了一种解耦合的方式。 Stream的消息通信方式遵循了 发布-订阅模式 通过定义绑定器Binder作为中间层，实现了应用程序与消息中间件细节之间的隔离。INPUT对应于生产者，OUTPUT对应于消费者 Stream标准流程套路： binder：很方便的连接中间件，屏蔽差异 Channel：通道，是队列Queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过channel对队列进行配置 Source（生产）和sink（消费）：简单地可理解为参照对象是spring cloud stream自身，从stream发布消息就是输出，接收消息就是输入 常用注解： 组成说明Middleware中间件，目前只支FRabbitMQ和KafkaBinderBinder是应用与消息中间件之间的封装，目前实行了KafKa和RabbitMQ的Binder,通过 Binder可以很方便的连接中间件，可以动态的改变消息类型（对应kafka的topic， RabbitMQ的exchange)，这些都可以通过配置文件来实现@Input注解标识输入通道，通过该输入通接收到的消息息进入应用程序@Output注解标识输出通道，发布的消息将通过该通道离开应用程序@StreamListener监听队列，用于消费者的队列的消息接收@EnableBinding指信道channel和exchange绑定在一起 ; 消息生产者要新建3个子模块 cloud-stream-rabbitmq-provide8801：作为生产者进行发消息模块 cloud-stream-rabbitmq-consumer8802：作为消息接收模块 cloud-stream-rabbitmq-consumer8802：作为消息接收模块 新建模块 cloud-stream-rabbitmq-provider8801 8801 pom依赖： 123456789101112131415161718192021222324252627282930313233343536373839&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbitartifactId&gt;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-clientartifactId&gt;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt;dependency&gt; yml 配置： 123456789101112131415161718192021222324252627282930313233server: port: 8801spring: application: name: cloud-stream-provider cloud: stream: binders: defaultRabbit: type: rabbit environment: spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: output: destination: studyExchange content-type: application/json binder: defaultRabbiteureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ instance: lease-renewal-interval-in-seconds: 2 lease-expiration-duration-in-seconds: 5 instance-id: send-8801.com prefer-ip-address: true 主启动类没什么特殊的注解。 业务类：（此业务类不是以前的service，而实负责推送消息的服务类） 发送消息的接口类 发送消息接口类的实现类 controller 12345package com.atguigu.springcloud.service;public interface IMessageProvider &#123; public String send();&#125; 123456789101112131415161718192021222324package com.dkf.springcloud.service;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.messaging.Source;import org.springframework.messaging.MessageChannel;import org.springframework.messaging.support.MessageBuilder;import javax.annotation.Resource;import java.util.UUID;@EnableBinding(Source.class)public class IMessageProviderImpl implements IMessageProvider &#123; @Resource private MessageChannel output; @Override public String send() &#123; String serial = UUID.randomUUID().toString(); output.send(MessageBuilder.withPayload(serial).build()); System.out.println(&quot;******serial: &quot; + serial); return null; &#125;&#125; controller: 1234567891011@RestControllerpublic class SendMessageController &#123; @Resource private IMessageProvider messageProvider; @GetMapping(&quot;/sendMessage&quot;) public String sendMessage()&#123; return messageProvider.send(); &#125;&#125; 启动Eureka Server 7001，再启动8801，进行测试，看是否rabbitMQ中有我们发送的消息。 消息消费者新建模块 cloud-stream-rabbitmq-consumer8802 pom依赖和生产者一样。 yml配置: 在 stream的配置上，和生产者只有一处不同的地方，output 改成 input 12345678910111213141516171819202122232425262728293031server: port: 8802spring: application: name: cloud-stream-provider cloud: stream: binders: defaultRabbit: type: rabbit environment: spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: input: destination: studyExchange content-type: application/json binder: defaultRabbiteureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ instance: lease-renewal-interval-in-seconds: 2 lease-expiration-duration-in-seconds: 5 instance-id: receive-8802.com prefer-ip-address: true 接收消息的业务类： 1234567891011121314151617import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.cloud.stream.messaging.Sink;import org.springframework.messaging.Message;@Component@EnableBinding(Sink.class)public class ConsumerController &#123; @Value(&quot;$&#123;server.port&#125;&quot;) private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message)&#123; System.out.println(&quot;消费者1号，serverport: &quot; + serverPort + &quot;，接受到的消息：&quot; + message.getPayload()); &#125;&#125; 配置分组消费新建 cloud-stream-rabbitmq-consumer8802 模块： 8803 就是 8802 clone出来的。 当运行时，会有两个问题。 第一个问题，两个消费者都接收到了消息，这属于重复消费。例如，消费者进行订单创建，这样就创建了两份订单，会造成系统错误。 注意在stream中处同一个group中的多个消费者是竞争关系，就能保证消息只会被其中一个应用消费一次。 不同组是可以全面消费（重复消费）的 同一组内会发生竞争关系，只有其中一个可以消费。 Stream默认不同的微服务是不同的组 对于重复消费这种问题，导致的原因是默认每个微服务是不同的group，组流水号不一样，所以被认为是不同组，两个都可以消费。 解决的办法就是自定义配置分组： 消费者 yml 文件配置： 1234567891011121314bindings: input: destination: studyExchange content-type: application/json binder: defaultRabbit group: dkfAbindings: input: destination: studyExchange content-type: application/json binder: defaultRabbit group: dkfB [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-Uo13s2dc-1615737211158)(images\\1597732035990.png)] 当两个消费者配置的 group 都为 dkfA 时，就属于同一组，就不会被重复消费。（两个消费者消费同一队列） [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-ox51Z2Z5-1615737211160)(images\\1597732238270.png)] 消息持久化 加上group配置，就已经实现了消息的持久化。 Sleuth 分布式请求链路跟踪，超大型系统。需要在微服务模块极其多的情况下，比如80调用8001的，8001调用8002的，这样就形成了一个链路，如果链路中某环节出现了故障，我们可以使用Sleuth进行链路跟踪，从而找到出现故障的环节。 在微服务框架中，一个由客户端发起的请求在后端系统中会经过多个不同的的服务节点调用来协同产生最后的请求结果，每一个前段请求都会形成一条杂的分布式服务调用链路，链路中的亻刊可一环出现高延时或错误都会引起整个请求最后的失败。 sleuth 负责跟踪，而zipkin负责展示。zipkin 下载地址： http://dl.bintray.com/openzipkin/maven/io/zipkin/java/zipkin-server/2.12.9/zipkin-server-2.12.9-exec.jar使用 【java -jar】 命令运行下载的jar包，访问地址：【 http://localhost:9411/zipkin/ 】 案例 使用之前的 提供者8001 和 消费者80 分别给他们引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkinartifactId&gt;dependency&gt; yml增加配置： 1234567spring: zipkin: base-url: http://localhost:9411 sleuth: sampler: probability: 1 高级部分SpringCloud Alibaba alibaba 的 github上有中文文档 spring netflix进入维护模式。 什么是维护模式：spring cloud团队将不会再向模块添加新功能，我们将修复block级别的bug以及安全问题，我们也会考虑并审查社区的小型pull request。我们打算继续支持这些模块，知道Greenwich版本被普遍采用至少一年 SpringCloud Netflix将不再开发新的组件 以下spring cloud netflix模块和响应的starter将进入维护模式： spring-cloud-netflix-archaius spring-cloud-netflix-hystrix-contract spring-cloud-netflix-hystrix-dashboard spring-cloud-netflix-hystrix-stream spring-cloud-netflix-hystrix spring-cloud-netflix-ribbon spring-cloud-netflix-turbine-stream spring-cloud-netflix-turbine spring-cloud-netflix-zuul 这不包括Eureka或并发限制模块。 我们都知道SpringCloud版本迭代是比较快的，因而出现了很多重大ISSUE都还来不及Flix就又推另一个RELEASE了。进入维护模式意思就是目前以及以后一段时间SpingCloud Netflix提供的报务和功能就这么多了，不在开发新的组件和功能了。以后将以雏护和Merge分支Full Request为主 新组件功能将以具他替代平代替的方式实现 历史： alibaba出了dubbo，停更 spring结合netflix整出spring cloud。又停更了 alibaba又出马了得出springcloud alibaba spring cloud alibaba带来了什么？ 2018.10.31，spring cloud Alibaba正式入驻了Spring Cloud官方孵化器，并在Maven中央库发布了第一个版本 主要功能： 服务限流降级：默认支持 WebServlet、WebFlux, OpenFeign、RestTemplate、Spring Cloud Gateway, Zuul, Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。 分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新。 消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。 分布式事务：使用 @GlobalTransactional 注解， 高效并且对业务零侵入地解决分布式事务问题。。 阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。 分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。 阿里云短信服务：覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。 只需引入依赖： 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependenciesartifactId&gt; &lt;version&gt;2.2.3.RELEASEversion&gt; &lt;type&gt;pomtype&gt; &lt;scope&gt;importscope&gt; dependency&gt; dependencies&gt;dependencyManagement&gt; 组件： **Sentinel**：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 **Nacos**：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 **RocketMQ**：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 **Dubbo**：Apache Dubbo™ 是一款高性能 Java RPC 框架。 **Seata**：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。 Alibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。 Alibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。 Alibaba Cloud SMS: 覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。 https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md ; Nacosnacos(NAming COnfiguration Service)：服务注册和配置中心 Nacos = Eureka + Config + Bus替代Eureka做服务注册中心替代Config做服务配置中心 github地址： https://github.com/alibaba/NacosNacos 地址： https://nacos.io/zh-cn/ 服务注册与服务框架CAP模型控制台管理社区活跃度EurekaAP高可用支持低(2.x版本闭源)ZookeeperCP一致支持中ConsulCP支持高NacosAP（可以切换）支持高 nacos可以切换 AP 和 CP ,可使用如下命令切换成CP模式： 1curl -X PUT &#x27;$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&amp;value=CP&#x27; 下载 ： 下载地址： https://github.com/alibaba/nacos/releases/tag/1.1.4直接下载网址： https://github.com/alibaba/nacos/releases/download/1.1.4/nacos-server-1.1.4.zip下载压缩包以后解压，进入bin目录，打开dos窗口，执行startup命令启动它。端口号8848可访问 ： 【 http://localhost:8848/nacos/index.html】地址，默认账号密码都是nacos nacos服务中心https://nacos.io/zh-cn/docs/feature-list.html https://spring-cloud-alibaba-group.github.io/github-pages/hoxton/en-us/index.html#_spring_cloud_alibaba_nacos_discovery nacos提供者新建模块 cloudalibaba-provider-payment9001 父pom中 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependenciesartifactId&gt; &lt;version&gt;2.1.1.BUILD-SNAPSHOTversion&gt; &lt;type&gt;pomtype&gt; &lt;scope&gt;importscope&gt; dependency&gt; dependencies&gt;dependencyManagement&gt; 子pom依赖： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discoveryartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; yml 配置： 1234567891011121314server: port: 9001spring: application: name: nacos-provider cloud: nacos: discovery: server-addr: localhost:8848management: endpoints: web: exposure: include: &#x27;*&#x27; 1234567@EnableDiscoveryClient@SpringBootApplicationpublic class PaymentMain9001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain9001.class, args); &#125;&#125; 12345678910@RestControllerpublic class PaymentController &#123; @Value(&quot;$&#123;server.port&#125;&quot;) private String serverPort; @GetMapping(value = &quot;/payment/nacos/&#123;id&#125;&quot;) public String getPayment(@PathVariable(&quot;id&quot;) Integer id) &#123; return &quot;nacos registry, serverPort: &quot;+ serverPort+&quot;\\t id&quot;+id; &#125;&#125; Nacos 自带负载均衡机制，下面创建第二个提供者9003。也可以 -Dserver.port=9011 新建 cloudalibaba-provider-payment9003 提供者模块，clone 9001 就可以 nacos消费者新建消费者 模块： cloudalibaba-customer-nacos-order83 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discoveryartifactId&gt;dependency&gt; 12345678910111213server: port: 83spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: localhost:8848service-url: nacos-user-service: http://nacos-payment-provider 12345678@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; controller : 123456789101112131415@RestController@Slf4jpublic class OrderNacosController &#123; @Resource private RestTemplate restTemplate; @Value(&quot;$&#123;service-url.nacos-user-service&#125;&quot;) private String serverURL; @GetMapping(value = &quot;/consumer/payment/nacos/&#123;id&#125;&quot;) public String paymentInfo(@PathVariable(&quot;id&quot;) Long id) &#123; return restTemplate.getForObject(serverURL+&quot;/payment/nacos/&quot;+id,String.class); &#125;&#125; 各种服务中心对比服务注册与服务框架CAP模型控制台管理社区活跃度EurekaAP支持低(2.x版本闭源)ZookeeperCP支持中ConsulCP支持高NacosAP/CP支持高 组件名语言CAP服务健康检查对外暴露接口SpringCloud集合EurekajavaAP可配支持HTTP已集成ConsulGoCP支持HTTP/DNS已集成ZookeeperjavaCP支持客户端已集成 NACOS支持CP和AP切换 C要求一致性，A要求可用性。 何时选择使用何种模式？ 一般来说， 如果不需要存储服级的信息且服务实例是通过nacos-client注册，并能够保持心跳上报，那么就可以选择AP模式。当前主流的服务如Spring cloud和Dubbo服务，都适用于AP模式，AP模式为了服务的可用性而减弱了一致性，因此AP模式下只支持注册临时实例。 如果需要在服务级别编辑或者存储配置信息，那么CP是必须，K8S服务和DNS服务则适用于CP模式。 CP模式下则支持注册持久化实例，此时则是以Raft协议为集群运行模式，该模式下汪册实例之前须先注册服务，如果服务不存在，则会返回错误 切换命令： curl -X PUT &#39;$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&amp;value=CP&#39; ; nacos配置中心配置中心对比对比项目Spring Cloud ConfigApolloNacos配置实时推送支持(Spring Cloud Bus)支持(HTTP长轮询1s内)支持(HTTP长轮询1s内)版本管理支持(Git)支持支持配置回滚支持(Git)支持支持灰度发布支持支持不支持权限管理支持(依赖Git)支持不支持多集群支持支持支持多环境支持支持支持监听查询支持支持支持多语言只支持Java主流语言，提供了Open API主流语言，提供了Open API配置格式校验不支持支持支持单机读(QPS)7(限流所致)900015000单击写(QPS)5(限流所致)110018003节点读 (QPS)21(限流所致)27000450003节点写 (QPS)5(限流所致)33005600 从配置中心角度来看，性能方面Nacos的读写性能最高，Apollo次之，Spring Cloud Config依赖Git场景不适合开放的大规模自动化运维API。功能方面Apollo最为完善，nacos具有Apollo大部分配置管理功能，而Spring Cloud Config不带运维管理界面，需要自行开发。Nacos的一大优势是整合了注册中心、配置中心功能，部署和操作相比Apollo都要直观简单，因此它简化了架构复杂度，并减轻运维及部署工作。 nacos 还可以作为服务配置中心，下面是案例，创建一个模块，从nacos上读取配置信息。nacos 作为配置中心，不需要像springcloud config 一样做一个Server端模块。 新建模块 cloudalibaba-config-nacos-client3377 pom依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-configartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discoveryartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; 主启动类也是极其普通： 1234567@EnableDiscoveryClient@SpringBootApplicationpublic class NacosConfigClientMain3377&#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConfigClientMain3377.class, args); &#125;&#125; bootstrap.yml 配置： 1234567891011121314151617server: port: 3377spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 config: server-addr: localhost:8848 file-extension: yaml group: DEV_GROUP namespace: 7d8f0f5a-6a53-4785-9686-dd460158e5d4 application.yml 1234spring: profiles: active: dev controller 层进行读取配置测试： 123456789101112@RestController@RefreshScopepublic class ConfigClientController &#123; @Value(&quot;$&#123;config.info&#125;&quot;) private String configInfo; @GetMapping(&quot;configclient/getconfiginfo&quot;) public String getConfigInfo()&#123; return configInfo; &#125;&#125; nacos同springcloud-config一样，在项目初始化时，要先从配置中心进行配置拉取，拉取配置之后，才能保证项目的正常启动。 springboot的配置文件的加载是存在优先熟悉怒的，bootstrap优先级高于application。（bootstrap中放共性，application中放个性） nacos中的dataid的组成格式及与springboot配置文件中的匹配规则： 在nacos中，消费端要的文件怎么和nacos中的文件匹配呢？ 在 Nacos Spring Cloud 中， dataId 的完整格式如下：（就是说在nacos端我们怎么命名文件的） 1$&#123;prefix&#125;-$&#123;spring.profiles.active&#125;.$&#123;file-extension&#125; prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix来配置。 spring.profiles.active 即为当前环境对应的 profile，详情可以参考Spring Boot文档。 注意：当 spring.profiles.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 $&#123;prefix&#125;.$&#123;file-extension&#125; file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。（注意nacos里必须使用yaml） 从上面可以看到重要的一点，配置文件的名称第二项，spring.profiles.active 是依据当前环境的profile属性值的，也就是这个值如果是 dev，即开发环境，它就会读取 dev 的配置信息，如果是test，测试环境，它就会读取test的配置信息，就是从 spring.profile.active 值获取当前应该读取哪个环境下的配置信息。 所以要配置spring.profiles.active，新建application.yml文件，添加如下配置： 123spring: profiles: active: dev 综合以上说明，和下面的截图，Nacos 的dataid（类似文件名）应为： nacos-config-client-dev.yaml (必须是yaml) 注意nacos里不要写成yml，要写成yaml： 当修改配置值，会发现 3377 上也已经修改，Nacos自带自动刷新功能！ nacos的优势在哪： 问题1：实际开发者，通常一个系统会准备dev/test/prod环境。如何保证环境启动时服务能正确读取nacos上相应环境的配置文件 用namespace区分环境 问题2：一个大型分布式微服务系统有很多微服务子项目，每个微服务项目又都会有相应的开发环境、测试环境、预发环境、正式环境。那怎么对微服务配置进行管理呢？ 用group把不同的微服务划分到同一个分组里面去 默认：Namespace=,Cluster=DEFAULT namespace环境 group Service就是微服务，一个service可以包含多个cluster集群，nacos默认cluster是DEFAULT，Cluster是对指定微服务的一个虚拟划分。 比方说为了容灾，将service微服务分别部署在了杭州机房和广州机房，这是就可以给杭州机房的service微服务起一个集群名称HZ 给广州的service微服务起一个集群名称GZ，还可以尽量让同一个机房的微服务互相调用，以提升虚拟。 最后instance就是微服务的实例 dgn方案dataid方案（就是nacos的文件名）： 指定spring.profile.active和配置文件的dataID来使不太环境下读取不同的配置 配置空间+配置分组+新建dev和test两个dataid：就是创建-后不同的两个文件名 nacos-config-client-dev.yaml、 nacos-config-client-test.yaml 通过IDEA里的spring.profile.active属性就能进行多环境下配置文件的读取 Group方案（默认DEFAULT_GROUP）： 在nacos创建配置文件时，给文件指定分组。 在IDEA中该group内容 实现的功能：当修改开发环境时，只会从同一group中进行切换。 namespace方案（默认public）： 这个是不允许删除的，可以创建一个新的命名空间，会自动给创建的命名空间一个流水号。 在nacos新建命名空间，自动出现7d8f0f5a-6a53-4785-9686-dd460158e5d4 在IDEA的yml中指定命名空间namespace: 7d8f0f5a-6a53-4785-9686-dd460158e5d4 最后，dataid、group、namespace 三者关系如下：（不同的dataid，是相互独立的，不同的group是相互隔离的，不同的namespace也是相互独立的） 上面只是小打小闹，下面才是真正的高级操作。 搭建集群必须持久化，不然多台机器上的nacos的配置信息不同，造成系统错乱。它不同于单个springcloud config，没有集群一说，而且数据保存在github上，也不同于eureka，配置集群就完事了，没有需要保存的配置信息。 nacos集群/持久化nacos挂了怎么办？ https://nacos.io/zh-cn/docs/cluster-mode-quick-start.html 一台linux虚拟机：nginx服务器（虚拟ip），3个nacos服务，一个mysql数据库。nginx的安装参考之前学，使用 ContOs7 至少需要安装gcc库，不然无法编译安装【yum install gcc】nacos下载linux版本的 tar.gz 包：https://github.com/alibaba/nacos/releases/download/1.1.4/nacos-server-1.1.4.tar.gzmysql root用户密码为 Dkf!!2020 VIP是虚拟IP，即nginx nginx也该是集群 Nacos支持三种部署模式 https://nacos.io/zh-cn/docs/deployment.html 单机模式 - 用于测试和单机试用。 集群模式 - 用于生产环境，确保高可用。 多集群模式 - 用于多数据中心场景。 单机模式支持mysql：在0.7版本之前，在单机模式时nacos使用 嵌入式数据库（derby，他的pom里有这个依赖）实现数据的存储，不方便观察数据存储的基本情况。0.7版本增加了支持mysql数据源能力，具体的操作步骤： 1.安装数据库，版本要求：5.6.5+ 2.初始化mysql数据库，数据库初始化文件：nacos/conf/nacos-mysql.sql。创建个database数据库nacos_devtest 3.修改IDEA中nacos/conf/application.properties文件(切换数据库)，增加支持mysql数据源配置（目前只支持mysql），添加mysql数据源的url、用户名和密码。 1234567# 切换数据库spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://11.162.196.16:3306/nacos_devtest?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=123456 再以单机模式启动nacos(重启)，nacos所有写嵌入式数据库的数据都写到了mysql 单击的数据库都是独立的，我们得让他们共用一个数据库 Nacos集群配置 环境准备： 64 bit OS Linux/Unix/Mac，推荐使用Linux系统。 64 bit JDK 1.8+；下载. 配置。 Maven 3.2.x+；下载. 配置。 3个或3个以上Nacos节点才能构成集群。 开始配置集群： 首先对 nacos 进行持久化操作，操作如上面一致。 修改 nacos/conf 下的cluster.conf文件，添加如下内容: 12345# it is ip# 告诉这3个集群结点是一组的 # 不能写127.0.0.1，必须是linux hostname -i能够识别的ip192.168.1.2:3333192.168.1.2:4444192.168.1.2:5555 修改nacos/conf/application.properties文件，添加设置我们的数据库信息 模拟三台nacos服务，编辑nacos的startup.sh脚本，使他能够支持不同的端口启动多次。集群启动，我们希望可以类似其他软件的shell命令，传递不同的端口号启动不同的nacos实例。 vim startup.sh nohup $JAVA -Dserver.port=$&#123;PORT&#125; $&#123;JAVA_POT&#125; nacoas.nacos &gt;&gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp; 依次执行命令启动3个nacos集群： ./startup.sh -p 3333 表示启动端口号为3333的nacos服务器实例 ./startup.sh -p 4444 ./startup.sh -p 5555 ps -ef | grep nacos | grep -v grep | wc -l 修改nginx配置，把他作为负载均衡： 1vim ./nginx/conf/nginx.conf 启动nginx： ./nginx -c ../conf/nginx.conf 通过nginx访问：192.168.1.2:1111/nacos/#/login 使用 9002 模块注册进Nacos集群，并获取它上面配置文件的信息application.yml中的 server-addr: 192.168.1.2:1111，进行测试。 Sentinel sentinel在 springcloud Alibaba 中的作用是实现 熔断和 限流。类似于Hystrix豪猪 下载地址dashboard： https://github.com/alibaba/Sentinel/releases/download/1.7.1/sentinel-dashboard-1.7.1.jar下载jar包以后，使用【java -jar】命令启动即可。它使用 8080 端口，用户名和密码都为 ： sentinel 随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Sentinel 具有以下特征: 丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。 完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。 Sentinel 分为两个部分: 核心库（Java 客户端）不依赖任何框架/库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持。 控制台（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器。 ; Demo 先启动nacos新建模块 cloudalibaba-sentinel-service8401 ，使用nacos作为服务注册中心Sentinel可以对service进行监控、熔断、降级没访问时再sentinel里是看不到监控的应用的，因为是懒加载，需要访问一次 pom依赖： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cspgroupId&gt; &lt;artifactId&gt;sentinel-datasource-nacosartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinelartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discoveryartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; yml 配置： 12345678910111213141516171819202122server: port: 8401spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: dashboard: localhost:8080 port: 8719management: endpoints: web: exposure: include: &#x27;*&#x27; 写一个简单的主启动类，再写一个简单的controller测试sentinel的监控。 1234567891011121314151617181920212223242526272829303132333435363738394041@RestController@Slf4jpublic class FlowLimitController &#123; @GetMapping(&quot;/testA&quot;) public String testA() &#123; return &quot;------testA&quot;; &#125; @GetMapping(&quot;/testB&quot;) public String testB() &#123; log.info(Thread.currentThread().getName()+&quot;\\t&quot;+&quot;...testB&quot;); return &quot;------testB&quot;; &#125; @GetMapping(&quot;/testD&quot;) public String testD() &#123; log.info(&quot;testD 异常比例&quot;); int age = 10/0; return &quot;------testD&quot;; &#125; @GetMapping(&quot;/testE&quot;) public String testE() &#123; log.info(&quot;testE 测试异常数&quot;); int age = 10/0; return &quot;------testE 测试异常数&quot;; &#125; @GetMapping(&quot;/testHotKey&quot;) @SentinelResource(value = &quot;testHotKey&quot;,blockHandler = &quot;deal_testHotKey&quot;) public String testHotKey(@RequestParam(value = &quot;p1&quot;,required = false) String p1, @RequestParam(value = &quot;p2&quot;,required = false) String p2) &#123; return &quot;------testHotKey&quot;; &#125; public String deal_testHotKey (String p1, String p2, BlockException exception) &#123; return &quot;------deal_testHotKey,o(╥﹏╥)o&quot;; &#125;&#125; 12345678910111213141516171819202122232425@RestControllerpublic class RateLimitController &#123; @GetMapping(&quot;/byResource&quot;) @SentinelResource(value = &quot;byResource&quot;,blockHandler = &quot;handleException&quot;) public CommonResult byResource() &#123; return new CommonResult(200,&quot;按资源名称限流测试OK&quot;,new Payment(2020L,&quot;serial001&quot;)); &#125; public CommonResult handleException(BlockException exception) &#123; return new CommonResult(444,exception.getClass().getCanonicalName()+&quot;\\t 服务不可用&quot;); &#125; @GetMapping(&quot;/rateLimit/byUrl&quot;) @SentinelResource(value = &quot;byUrl&quot;) public CommonResult byUrl() &#123; return new CommonResult(200,&quot;按url限流测试OK&quot;,new Payment(2020L,&quot;serial002&quot;)); &#125; @GetMapping(&quot;/rateLimit/customerBlockHandler&quot;) @SentinelResource(value = &quot;customerBlockHandler&quot;, blockHandlerClass = CustomerBlockHandler.class, blockHandler = &quot;handlerException2&quot;) public CommonResult customerBlockHandler() &#123; return new CommonResult(200,&quot;按客戶自定义&quot;,new Payment(2020L,&quot;serial003&quot;)); &#125;&#125; 12345678910public class CustomerBlockHandler &#123; public static CommonResult handlerException(BlockException exception) &#123; return new CommonResult(4444,&quot;按客戶自定义,global handlerException----1&quot;); &#125; public static CommonResult handlerException2(BlockException exception) &#123; return new CommonResult(4444,&quot;按客戶自定义,global handlerException----2&quot;); &#125;&#125; 1234567@EnableDiscoveryClient@SpringBootApplicationpublic class MainApp8401 &#123; public static void main(String[] args) &#123; SpringApplication.run(MainApp8401.class, args); &#125;&#125; 流控规则 资源名：唯一名称，默认请求路径 针对来源：sentinel可以针对调用者进行限流，填写微服务名，默认default（不区分来源） 阈值类型/单机值： QPS（每秒钟的请求数量）：当调用该api就QPS达到阈值的时候，进行限流 线程数．当调用该api的线程数达到阈值的时候，进行限流 是否集群：不需要集群 流控模式： 直接：api达到限流条件时，直接限流。分为QPS和线程数 关联：当关联的资到阈值时，就限流自己。别人惹事，自己买单 链路：只记录指定链路上的流量（指定资源从入口资源进来的流量，如果达到阈值，就进行限流）【api级别的针对来源】 流控效果： 快速失败：直接抛异常 warm up：根据codeFactor（冷加载因子，默认3）的值，从阈值codeFactor，经过预热时长，才达到设置的QPS阈值 重要属性： Field说明默认值resource资源名，资源名是限流规则的作用对象count限流阈值grade限流阈值类型，QPS 模式（1）或并发线程数模式（0）QPS 模式limitApp流控针对的调用来源 default ，代表不区分调用来源strategy调用关系限流策略：直接、链路、关联根据资源本身（直接）controlBehavior流控效果（直接拒绝/WarmUp/匀速+排队等待），不支持按调用关系限流直接拒绝clusterMode是否集群限流否 我们先只针对/testA请求进行限制 流控模式–直接： 限流表现：当超过阀值，就会被降级。1s内多次刷新网页，localhost:8401/testA返回Blocked by Sentienl(flow limiting) 流控模式–关联： 当与A关联的资源B达到阀值后，就限流A自己 B惹事，A挂了。支付达到阈值，限流下单接口。B阈值达到1，A就挂 用post访问B让B忙，访问A发现挂了 流控效果–预热Warm up： 访问数量慢慢升高 阈值初一coldFactor（默认3），经过预热时长后才会达到阈值。 流控效果–排队等待： 匀速排队（Ru1eConstant.CONTROL_BEHAVIOR_RATE_LIMITER）方式会严格控制请求通过的间隔时间，即让请求以均匀的速度通过对应的是漏桶算法。详细文档可以参考流量控制-匀速器模式，具体的例子可以参见PaceFlowDemo 该方式的作用如下图所示 这种方式主要用于处理间隔性突发的流量，伊消息列。想象一下这样的场景，在某一秒有大量的请求到来，而接下来的月耖则处于空闲状态，我们希系统能够在接下来的空闲期间逐渐处理这些请求，而不是第一秒就拒绝多余的请求 ; 熔断降级新增降级规则：降低策略：RT RT（平均响应时间，秒级） 平均响应时间 超出阈值 且 在时间窗口内通过的请求&gt;=5，两个条件同时满足后触发降级 窗口期过后关闭断路器 RT最大4900（更大的需要通过-Dcsp.Sentinel.statistic.max.rt=XXXX才能生效） 异常比例（秒级）QPS&gt;=5且异常比例（秒级统计）超过阈值时，触发降级，时间窗口结束后，关闭降级 sentinel熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。 当资源被降级后，在接下来的降级时间窗囗之内，对该资源的调用都自动熔断（默认行为是抛出DegradeException)。 降级策略–RT 降级策略–异常比例： 异常比例（DEGRADE-GRADE-EXCEPTION-RATIO）：当资源的每秒请求量&gt;=5，并且每秒异常总数占通过的比值超过阈值（DegradeRule中的count）之后，资源进入降级状态，即在接下的时间窗口（DegradeRu1e中的timeWindow，，以s为单位）之内，对这个方法的调用都会自动地返回。异常b阈值范围是[0.0,l.0]，代表0％一100％。 降级测录–异常数： 异常数（DEGRADE-GRADE-EXCEPTION-COUNT）：当资源近1分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若timeWindow小于60s,则结束熔断状态后仍可能再进入熔断状态。 时间窗口一定要大于等于60秒。 时间窗口结束后关闭降级 localhost:8401/testE , 第一次访问绝对报错，因为除数不能为零，我们看到error窗口，但是达到5次报错后，进入熔断后降级。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-0uG4jp95-1615737211171)(images\\1597821618735.png)] 热点Key限流何为热点？热点即经常访问的数据。很多时候我们希望统计某个热点数据中访问频次最高的TopK数据，并对其访问进行限制。比如： 商品ID为参数，统计一段时间内最常购买的商品ID并进行限制 用户ID为参数，针对一段时间内频繁访问的用户ID进行限制 参数限流会统计传入参数中的参数，并根据配置流阈值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看做是一种特殊的流量控制，仅对包含热点参数的资源调用生效。 controller层写一个demo: 12345678910111213@GetMapping(&quot;/testhotkey&quot;) @SentinelResource(value = &quot;testhotkey&quot;, blockHandler = &quot;deal_testhotkey&quot;) public String testHotKey( @RequestParam(value=&quot;p1&quot;, required = false) String p1, @RequestParam(value = &quot;p2&quot;, required = false) String p2 )&#123; return &quot;testHotKey__success&quot;; &#125; public String deal_testhotkey(String p1, String p2, BlockException e)&#123; return &quot;testhotkey__fail&quot;; &#125; 说明： @SentinelResource ：处理的是Sentine1控制台配置的违规情况，有blockHandler方法配置的兜底处理 @RuntimeException：int age=10/0，这个是java运行时报出的运行时异异常RunTimeException，@Sentine1Resource不管 系统规则 一般配置在网关或者入口应用中，但是这个东西有点危险，不但值不合适，就相当于系统瘫痪。 系统自适应限流 Sentinel 系统自适应限流从整体维度对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 系统规则包含下面几个重要的属性： Field说明默认值highestSystemLoad load1 触发值，用于触发自适应控制阶段-1 (不生效)avgRt所有入口流量的平均响应时间-1 (不生效)maxThread入口流量的最大并发数-1 (不生效)qps所有入口资源的 QPS-1 (不生效)highestCpuUsage当前系统的 CPU 使用率（0.0-1.0）-1 (不生效) @SentinelResource配置 @SentinelResource 注解，主要是指定资源名（也可以用请求路径作为资源名），和指定降级处理方法的。 例如： 12345678910111213141516171819202122package com.dkf.springcloud.controller;import com.alibaba.csp.sentinel.annotation.SentinelResource;import com.alibaba.csp.sentinel.slots.block.BlockException;import com.dkf.springcloud.entities.CommonResult;import com.dkf.springcloud.entities.Payment;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class RateLimitController &#123; @GetMapping(&quot;/byResource&quot;) @SentinelResource(value = &quot;byResource&quot;, blockHandler = &quot;handleException&quot;) public CommonResult byResource()&#123; return new CommonResult(200, &quot;按照资源名限流测试0K&quot;, new Payment(2020L,&quot;serial001&quot;)); &#125; public CommonResult handleException(BlockException e)&#123; return new CommonResult(444, e.getClass().getCanonicalName() + &quot;\\t 服务不可用&quot;); &#125;&#125; 很明显，上面虽然自定义了兜底方法，但是耦合度太高，下面要解决这个问题。 自定义全局BlockHandler处理类写一个 CustomerBlockHandler 自定义限流处理类： [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-khnkVraZ-1615737211177)(images\\1597903188558.png)] 整合 openfeign 服务降级前奏 之前有 open-feign 和 hystrix 的整合，现在来实现sentinel 整合 ribbon + open-feign + fallback 进行服务熔断。新建三个模块，两个提供者 9004、9005，和一个消费者 84目的：fallback管运行异常blockHandIer管配置违规上面使用sentinel有一个很明显的问题，就是sentinel，对程序内部异常（各种异常，包括超时）这种捕捉，显得很乏力，它主要是针对流量控制，系统吞吐量，或者是异常比例这种，会发生降级或熔断，但是当程序内部发生异常，直接返回给用户错误页面，根本不会触发异常比例这种降级。所以才需要整合open-feign 来解决程序内部异常时，配置相应的兜底方法 ———————————————————–两个提供者模块一致，如下： pom依赖： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discoveryartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; yml配置： 1234567891011121314server: port: 9005spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: localhost:8848management: endpoints: web: exposure: include: &#x27;*&#x27; 主启动类只是启动，没有其它注解。 controller : 12345678910111213141516171819202122232425package com.dkf.sprIngcloud.controller;import com.dkf.springcloud.entities.CommonResult;import com.dkf.springcloud.entities.Payment;@RestControllerpublic class PaymentController &#123; @Value(&quot;$&#123;server.port&#125;&quot;) private String serverPort; public static HashMap&lt;Long, Payment&gt; hashMap = new HashMap&lt;&gt;(); static &#123; hashMap.put(1L, new Payment(1L, &quot;xcxcxcxcxcxcxcxcxcxcxcxcxc11111111&quot;)); hashMap.put(2L, new Payment(2L, &quot;xcxcxcxcggggggggg2222222222222222&quot;)); hashMap.put(3L, new Payment(3L, &quot;xcxcxcxccxxcxcfafdgdgdsgdsgds33333&quot;)); &#125; @GetMapping(&quot;/payment/get/&#123;id&#125;&quot;) public CommonResult paymentSql(@PathVariable(&quot;id&quot;)Long id)&#123; Payment payment = hashMap.get(id); CommonResult result = new CommonResult(200, &quot;from mysql, server port : &quot; + serverPort + &quot; ,查询成功&quot;, payment); return result; &#125;&#125; —消费者： pom依赖： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cspgroupId&gt; &lt;artifactId&gt;sentinel-datasource-nacosartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinelartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discoveryartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; yml配置： 12345678910111213server: port: 84spring: cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: dashboard: localhost:8080 port: 8719 application: name: nacos-order-consumer 主启动类不用说了。 config类里面注入 Resttemplate： 12345678@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced public RestTemplate getRestTemplate()&#123; return new RestTemplate(); &#125;&#125; controller 层： 1234567891011121314151617@RestControllerpublic class OrderController &#123; private static final String PAYMENT_URL=&quot;http://nacos-payment-provider&quot;; @Resource private RestTemplate restTemplate; @GetMapping(&quot;/consutomer/payment/get/&#123;id&#125;&quot;) public CommonResult getPayment(@PathVariable(&quot;id&quot;)Long id)&#123; if(id &gt;= 4)&#123; throw new IllegalArgumentException(&quot;非法参数异常...&quot;); &#125;else &#123; return restTemplate.getForObject(PAYMENT_URL + &quot;/payment/get/&quot; + id, CommonResult.class); &#125; &#125;&#125; 上面只实现了 以nacos 作为服务注册中心，消费者使用ribbon 实现负载均衡调用提供者的效果。 正式只配置 fallback: 12345678910111213@GetMapping(&quot;/consutomer/payment/get/&#123;id&#125;&quot;) @SentinelResource(value = &quot;fallback&quot;, fallback = &quot;handleFallback&quot;) public CommonResult getPayment(@PathVariable(&quot;id&quot;)Long id)&#123; if(id &gt;= 4)&#123; throw new IllegalArgumentException(&quot;非法参数异常...&quot;); &#125;else &#123; return restTemplate.getForObject(PAYMENT_URL + &quot;/payment/get/&quot; + id, CommonResult.class); &#125; &#125; public CommonResult handleFallback(@PathVariable(&quot;id&quot;)Long id, Throwable e)&#123; return new CommonResult(414, &quot;---非法参数异常--&quot;, e); &#125; 业务异常会被 fallback 处理，返回我们自定义的提示信息，而如果给它加上流控，并触发阈值，只能返回sentinel默认的提示信息。 只配置blockHandler: 1234567891011121314@GetMapping(&quot;/consutomer/payment/get/&#123;id&#125;&quot;)@SentinelResource(value = &quot;fallback&quot;, blockHandler = &quot;handleblockHandler&quot;)public CommonResult getPayment(@PathVariable(&quot;id&quot;)Long id)&#123; if(id &gt;= 4)&#123; throw new IllegalArgumentException(&quot;非法参数异常...&quot;); &#125;else &#123; return restTemplate.getForObject(PAYMENT_URL + &quot;/payment/get/&quot; + id, CommonResult.class); &#125;&#125;public CommonResult handleblockHandler(@PathVariable(&quot;id&quot;)Long id, BlockException e)&#123; return new CommonResult(414, &quot;---非法参数异常--&quot;, e);&#125; 这时候的效果就是，运行异常直接报错错误页面。在sentinel上添加一个降级规则，设置2s内触发异常2次，触发阈值以后，返回的是我们自定义的 blockhanlder 方法返回的内容。 两者都配置： 123456789101112131415161718@GetMapping(&quot;/consutomer/payment/get/&#123;id&#125;&quot;)@SentinelResource(value = &quot;fallback&quot;, blockHandler = &quot;handleblockHandler&quot;, fallback = &quot;handleFallback&quot;)public CommonResult getPayment(@PathVariable(&quot;id&quot;)Long id)&#123; if(id &gt;= 4)&#123; throw new IllegalArgumentException(&quot;非法参数异常...&quot;); &#125;else &#123; return restTemplate.getForObject(PAYMENT_URL + &quot;/payment/get/&quot; + id, CommonResult.class); &#125;&#125;public CommonResult handleFallback(@PathVariable(&quot;id&quot;)Long id, Throwable e)&#123; return new CommonResult(414, &quot;---非法参数异常--form fallback的提示&quot;, e);&#125;public CommonResult handleblockHandler(@PathVariable(&quot;id&quot;)Long id, BlockException e)&#123; return new CommonResult(414, &quot;---非法参数异常--&quot;, e);&#125; 明显两者都是有效的，可以同时配置。 全局降级 上面是单个进行 fallback 和 blockhandler 的测试，下面是整合 openfeign 实现把降级方法解耦。和Hystrix 几乎一摸一样！ 还是使用上面 84 这个消费者做测试： 先添加open-feign依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeignartifactId&gt;dependency&gt; yml 追加如下配置： 1234feign: sentinel: enabled: true 主启动类添加注解 ： @EnableFeignClients 激活open-feign service : 123456@FeignClient(value = &quot;nacos-payment-provider&quot;, fallback = PaymentServiceImpl.class)public interface PaymentService &#123; @GetMapping(&quot;/payment/get/&#123;id&#125;&quot;) public CommonResult paymentSql(@PathVariable(&quot;id&quot;)Long id);&#125; service 实现类： 12345678@Componentpublic class PaymentServiceImpl implements PaymentService &#123; @Override public CommonResult paymentSql(Long id) &#123; return new CommonResult(414, &quot;open-feign 整合 sentinel 实现的全局服务降级策略&quot;,null); &#125;&#125; controller 层代码没什么特殊的，和普通调用service 一样即可。 测试，关闭提供者的项目，会触发 service 实现类的方法。 总结: 这种全局熔断，是针对 “访问提供者” 这个过程的，只有访问提供者过程中发生异常才会触发降级，也就是这些降级，是给service接口上这些提供者的方法加的，以保证在远程调用时能顺利进行。而且这明显是 fallback ，而不是 blockHandler，注意区分。 fallback 和 blockHandler 肤浅的区别：F ： 不需要指定规则，程序内部异常均可触发（超时异常需要配置超时时间）B : 配上也没用，必须去 Sentinel 上指定规则才会被触发。 异常忽略 这是 @SentinelResource 注解的一个值：[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-0BTijmp8-1615737211178)(images\\1597909285814.png)] 持久化 目前的sentinel 当重启以后，数据都会丢失，和 nacos 类似原理。需要持久化。它可以被持久化到 nacos 的数据库中。 pom依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cspgroupId&gt; &lt;artifactId&gt;sentinel-datasource-nacosartifactId&gt;dependency&gt; yml配置： 1234567891011spring: cloud: sentinel: datasource: ds1: nacos: server-addr: localhost:8848 dataId: $&#123;spring.application.name&#125; group: DEFAULT_GROUP data-type: json rule-type: flow 去nacos上创建一个dataid ,名字和yml配置的一致，json格式，内容如下： 1234567891011[ &#123; &quot;resource&quot;: &quot;/testA&quot;, &quot;limitApp&quot;: &quot;default&quot;, &quot;grade&quot;: 1, &quot;count&quot;: 1, &quot;strategy&quot;: 0, &quot;controlBehavior&quot;: 0, &quot;clusterMode&quot;: false &#125;] resource：资源名称limitApp：来源应用grade：阈值类型，0表示线程数，1表示QPS，count：单机阈值，strategy：流控模式，0表示直接，1表示关联，2表示链路 controlBehavior:流控效果，0表示快速失败，1表示Warm Up,2表示排队等待； cIusterM0de是否集群。 启动应用，发现存在 关于 /testA 请求路径的流控规则。 总结: 就是在 sentinel 启动的时候，去 nacos 上读取相关规则配置信息，实际上它规则的持久化，就是第三步，粘贴到nacos上保存下来，就算以后在 sentinel 上面修改了，重启应用以后也是无效的。 Seata Seate 处理分布式事务。微服务模块，连接多个数据库，多个数据源，而数据库之间的数据一致性需要被保证。官网： http://seata.io/zh-cn/ Seata术语： 一 + 三 Transaction ID XID：全局唯一的事务ID 3组件概念 Transaction Coordinator(TC)：事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚， Transaction Manager™：控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议， Resource Manager(RM)：控制分支事务，负责分支汪册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务提交或回滚 1．TM向TC申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的XID;2，XID在微服务调用链路的上下文中传播；3，RM向TC汪册分支事务，将其纳入XID对应全局事务的管辖；4，TM向TC发起针对XID的全局提交或回滚决议；5，TC调度XID下管辖的全部分支事务完成提交或回请求。 下载安装 下载地址 ： https://github.com/seata/seata/releases/download/v1.0.0/seata-server-1.0.0.zip 我们只需要使用一个 @GlobalTransational注解在业务方法上 初始化操作 修改 conf/file.conf 文件： 主要修改自定义事务组名称 + 事务日志存储模式为db + 数据库连接信息 12345678910111213141516171819202122232425262728293031323334service &#123; #transaction service group mapping vgroup_mapping.dkf_tx_group = &quot;default&quot; # 修改这里 #only support when registry.type=file, please don&#x27;t set multiple addresses default.grouplist = &quot;127.0.0.1:8091&quot; #disable seata disableGlobalTransaction = false&#125;## transaction log store, only used in seata-serverstore &#123; ## store mode: file、db mode = &quot;db&quot; # 修改这里 ## file store property file &#123; ## store location dir dir = &quot;sessionStore&quot; &#125; ## database store property db &#123; ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = &quot;dbcp&quot; ## mysql/oracle/h2/oceanbase etc. db-type = &quot;mysql&quot; driver-class-name = &quot;com.mysql.jdbc.Driver&quot; url = &quot;jdbc:mysql://127.0.0.1:3306/seata&quot; user = &quot;root&quot; # 修改对 password = &quot;123456&quot; &#125;&#125; 创建名和 file.conf 指定一致的数据库。 在新建的数据库里面创建数据表，db_store.sql文件在 conf 目录下（1.0.0有坑，没有sql文件，下载0.9.0的，使用它的sql文件即可） 修改 conf/registry.conf 文件内容： 123456789registry &#123; # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa # 默认file type = &quot;nacos&quot; nacos &#123; # 修改nacos的端口8848 serverAddr = &quot;localhost:8848&quot; namespace = &quot;&quot; cluster = &quot;default&quot; &#125; 先启动 nacos Server 服务，再启动seata Server 。 启动 Seata Server 报错，在bin目录创建 /logs/seata_gc.log 文件。再次双击 bat文件启动。 案例数据库准备这里我们会创建三个服务，一个订单服务，一个库存服务，一个账户服务。 当用户下单时，会在订单服务中创建一个订单，然后通过远程调用库存服务来扣减下单商品的库存，再通过远程调用账户服务来扣减用户账户里面的余额，最后在订单服务中修改订单状态为已完成。 该操作跨越三个数据库，有两次远程调用，很明显会有分布式事务问题。 创建三个数据库： seata_account、seata_order、seata_storage 每个数据库创建数据表： order 库： [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-4onCJEJp-1615737211179)(images\\1597988061545.png)] account 库： [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-qJgDRh43-1615737211180)(images\\1597988768251.png)] storage 库： [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-HyAlOWpT-1615737211181)(images\\1597988262441.png)] 三个数据库都创建一个回滚日志表，seata/conf/ 有相应的sql文件（1.0.0没有，依然使用0.9.0中的）。 最终效果： seata branch_table global_table lock_table seata_account t_account undo_log seata_order t_order undo_log seata_storage t_storage undo_log 开发 实现 下订单-&gt; 减库存 -&gt; 扣余额 -&gt; 改（订单）状态需要注意的是，下面做了 seata 与 mybatis 的整合，所以注意一下，和以往的mybatis的使用不太一样。 新建模块 cloudalibaba-seata-order2001 ： pom依赖： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seataartifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-allartifactId&gt; &lt;groupId&gt;io.seatagroupId&gt; exclusion&gt; exclusions&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seatagroupId&gt; &lt;artifactId&gt;seata-allartifactId&gt; &lt;version&gt;1.0.0version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discoveryartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloudgroupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeignartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-webartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-actuatorartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibabagroupId&gt; &lt;artifactId&gt;druid-spring-boot-starterartifactId&gt; &lt;version&gt;1.1.10version&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysqlgroupId&gt; &lt;artifactId&gt;mysql-connector-javaartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbcartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.bootgroupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starterartifactId&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-devtoolsartifactId&gt; &lt;scope&gt;runtimescope&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombokgroupId&gt; &lt;artifactId&gt;lombokartifactId&gt; &lt;optional&gt;trueoptional&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.bootgroupId&gt; &lt;artifactId&gt;spring-boot-starter-testartifactId&gt; &lt;scope&gt;testscope&gt; dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dkf.cloudgroupId&gt; &lt;artifactId&gt;cloud-api-commonsartifactId&gt; &lt;version&gt;$&#123;project.version&#125;version&gt; dependency&gt; dependencies&gt; yml配置： 1234567891011121314151617181920212223242526server: port: 2001spring: application: name: seata-order-service cloud: alibaba: seata: tx-service-group: dkf_tx_group nacos: discovery: server-addr: localhost:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/seata_order username: root password: 123456mybatis: mapperLocations: classpath:mapper/*.xmllogging: level: io: seata: info 将 seata/conf/ 下的 file.conf 和 registry.cong 两个文件拷贝到 resource 目录下。 创建 domain 实体类 ： Order 和 CommonResult 两个实体类。 dao : 1234567891011121314package com.dkf.springcloud.dao;import org.apache.ibatis.annotations.Mapper;import com.dkf.springcloud.domain.Order;import org.apache.ibatis.annotations.Param;@Mapperpublic class OrderDao &#123; public void create(Order order); public void update(@Param(&quot;userId&quot;) Long userId, @Param(&quot;status&quot;) Integer status);&#125; Mapper文件： 123456789101112131415161718192021222324DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;&lt;mapper namespace=&quot;com.dkf.springcloud.dao.OrderDao&quot;&gt; &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.dkf.springcloud.domain.Order&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot; jdbcType=&quot;BIGINT&quot;&gt;id&gt; &lt;result column=&quot;user_id&quot; property=&quot;userId&quot; jdbcType=&quot;BIGINT&quot;&gt;result&gt; &lt;result column=&quot;product_id&quot; property=&quot;productId&quot; jdbcType=&quot;BIGINT&quot;&gt;result&gt; &lt;result column=&quot;count&quot; property=&quot;count&quot; jdbcType=&quot;INTEGER&quot;&gt;result&gt; &lt;result column=&quot;money&quot; property=&quot;money&quot; jdbcType=&quot;DECIMAL&quot;&gt;result&gt; &lt;result column=&quot;status&quot; property=&quot;status&quot; jdbcType=&quot;INTEGER&quot;&gt;result&gt; resultMap&gt; &lt;insert id=&quot;create&quot;&gt; insert into t_order(id, user_id, product_id, count, money, status) values (null, #&#123;userId&#125;,#&#123;productId&#125;,#&#123;count&#125;,#&#123;money&#125;,0) insert&gt; &lt;update id=&quot;update&quot;&gt; update t_order set status = 1 where user_id=#&#123;userId&#125; and status=#&#123;status&#125; update&gt;mapper&gt; 创建service ： 注意，红框标记的是通过 open-feign 远程调用微服务的service远程服务接口有AccountService、StorageServer而OrderServiceImpl实现我们的业务逻辑 serviceImpl : 123456789101112131415161718192021222324252627282930313233343536@Service@Slf4jpublic class OrderServiceImpl implements OrderService &#123; @Resource private OrderDao orderDao; @Resource private StorageService storageService; @Resource private AccountService accountService; @Override public void create(Order order) &#123; log.info(&quot;--------》 开始创建订单&quot;); orderDao.create(order); log.info(&quot;--------》 订单微服务开始调用库存，做扣减---Count-&quot;); storageService.decrease(order.getProductId(), order.getCount()); log.info(&quot;--------》 订单微服务开始调用库存，库存扣减完成！！&quot;); log.info(&quot;--------》 订单微服务开始调用账户，账户扣减---money-&quot;); accountService.decrease(order.getUserId(),order.getMoney()); log.info(&quot;--------》 订单微服务开始调用账户，账户扣减完成!!&quot;); log.info(&quot;--------》 订单微服务修改订单状态，start&quot;); orderDao.update(order.getUserId(),0); log.info(&quot;--------》 订单微服务修改订单状态，end&quot;); log.info(&quot;--订单结束--&quot;); &#125; @Override public void update(Long userId, Integer status) &#123; &#125;&#125; config （特殊点）: 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Configuration@MapperScan(&#123;&quot;com.dkf.springcloud.alibaba.dao&quot;&#125;)public class MybatisConfig &#123;&#125;package com.dkf.springcloud.config;import com.alibaba.druid.pool.DruidDataSource;import io.seata.rm.datasource.DataSourceProxy;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.transaction.SpringManagedTransactionFactory;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import javax.sql.DataSource;@Configurationpublic class DataSourceProxyConfig &#123; @Value(&quot;$&#123;mybatis.mapperLocations&#125;&quot;) private String mapperLocations; @Bean @ConfigurationProperties(prefix = &quot;spring.datasource&quot;) public DataSource druidDataSource()&#123; return new DruidDataSource(); &#125; @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource)&#123; return new DataSourceProxy(dataSource); &#125; @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); &#125;&#125; 主启动类： 12345678910@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@EnableFeignClients@EnableDiscoveryClientpublic class SeataOrderMain2001 &#123; public static void main(String[] args) &#123; SpringApplication.run(SeataOrderMain2001.class,args); &#125;&#125; controller 层调用 orderService 方法即可。 先启动 nacos –》 再启动 seata –&gt; 再启动此order服务，测试，可以启动。 仿照上面 创建 cloudalibaba-seata-storage2002 和 cloudalibaba-seata-account2003 两个模块，唯一大的区别就是这两个不需要导入 open-feign 远程调用其它模块。 操，累死老子啦，测试可以正常使用！ Seata使用12345678910111213141516171819@Override @GlobalTransactional(name = &quot;dkf-create-order&quot;, rollbackFor = Exception.class) public void create(Order order) &#123; log.info(&quot;--------》 开始创建订单&quot;); orderDao.create(order); log.info(&quot;--------》 订单微服务开始调用库存，做扣减---Count-&quot;); storageService.decrease(order.getProductId(), order.getCount()); log.info(&quot;--------》 订单微服务开始调用库存，库存扣减完成！！&quot;); log.info(&quot;--------》 订单微服务开始调用账户，账户扣减---money-&quot;); accountService.decrease(order.getUserId(),order.getMoney()); log.info(&quot;--------》 订单微服务开始调用账户，账户扣减完成!!&quot;); log.info(&quot;--------》 订单微服务修改订单状态，start&quot;); orderDao.update(order.getUserId(),0); log.info(&quot;--------》 订单微服务修改订单状态，end&quot;); log.info(&quot;--订单结束--&quot;); &#125; 12345 TC :seata 服务器 TM RM@GlobalTransational 事务的参与方事务的发起方 原理三个阶段： [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-mTEm1pDL-1615737211183)(images\\1597999156669.png)] [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-mbIA72pS-1615737211184)(images\\1597999227092.png)]","tags":["笔记"],"categories":["Java"]},{"title":"Idea-JenKins插件","path":"/2023/01/06/JenKinsidea/","content":"参考url: 10.10.10.10:8082/crumbIssuer/api/xml?tree=crumb#","tags":["笔记"],"categories":["Java"]},{"title":"JenKins配置参考","path":"/2023/01/05/JenKinssh/","content":"JenKins配置参考: 123cd /var/lib/jenkins/workspace/dev-gts-quote &amp;&amp; /usr/local/server/apache-maven-3.8.6/bin/mvn clean packagescp -r /var/lib/jenkins/workspace/dev-gts-quote/quote-server/target/quote-server-1.0.0.jar labor@10.10.10.4:/home/labor/run/gts-quote/ssh labor@10.10.10.4 &#x27;cp -f ~/run/start.sh /home/labor/run/gts-quote &amp;&amp;cd /home/labor/run/gts-quote/ &amp;&amp; /home/labor/run/gts-quote/start.sh restart&#x27; /home/labor/run路径下的start.sh文件内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/bin/sh## java env#export JAVA_HOME=/data/jdk1.8.0_121#export JRE_HOME=$JAVA_HOME/jre## service name#当前目录NOW_PATH=$(cd `dirname $0`; pwd)#jar包路径JAR_DIR=`ls -ltr $NOW_PATH/*.jar| tail -1`#jar包名字JAR_NAME=./$&#123;JAR_DIR##*/&#125;#日志名字LOG_NAME=$&#123;JAR_NAME%%.*&#125;PID=$LOG_NAME\\.pidcase &quot;$1&quot; in start)\tmkdir logs nohup /home/labor/jdk-11.0.16.1/bin/java -Xms256m -Xmx1024m -jar $JAR_NAME --spring.profiles.active=dev1 &gt; server.log 2&gt;&amp;1 &amp; echo $! &gt; $NOW_PATH/$PID echo &quot;=== start $JAR_NAME&quot;\t#tail -1000f logs/$LOG_NAME.log ;; stop) echo &quot;=== stop $JAR_NAME&quot;\tps -ef|grep $JAR_NAME |grep -v grep |awk &#x27;&#123;print $2&#125;&#x27;|xargs kill -9 ;; restart) $0 stop sleep 2 $0 start echo &quot;=== restart $LOG_NAME&quot; ;; *) echo &quot;Usage:$0 &#123;start|stop|restart&#125;&quot; ;;esacexit 0 start.sh文件是通用文件，但是JenKins配置里的代码需要改jar包名字和路径","tags":["笔记"],"categories":["Java"]},{"title":"SpringWeb调试入口","path":"/2023/01/04/SpringWebDebugging/","content":"DispatcherServlet-&gt;doService-&gt;doDispatch","tags":["笔记"],"categories":["Java"]},{"title":"has not been refreshed yet","path":"/2023/01/03/HasNotBeenRefreshedYet/","content":"本地导出的jar包运行正常，通过Jenkins打包部署到k8s上启动报错:has not been refreshed yet报错详细信息如下: 123456789101112131415161718192021222324252023-01-03 13:27:29.644|1672723649644|nioEventLoopGroup-7-28|WARN ||||||i.n.c.ChannelInitializer:97|Failed to initialize a channel. Closing: [id: 0x79bae2b1, L:/10.42.0.72:7121 - R:/10.42.0.1:58054]java.lang.IllegalStateException: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@bef2d72 has not been refreshed yet at org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:1096) at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1126) at io.btg.gts.quote.handler.MessageHandler.&lt;init&gt;(MessageHandler.java:95) at io.btg.gts.quote.server.WebSocketInitializer.initChannel(WebSocketInitializer.java:35) at io.btg.gts.quote.server.WebSocketInitializer.initChannel(WebSocketInitializer.java:17) at io.netty.channel.ChannelInitializer.initChannel(ChannelInitializer.java:129) at io.netty.channel.ChannelInitializer.handlerAdded(ChannelInitializer.java:112) at io.netty.channel.AbstractChannelHandlerContext.callHandlerAdded(AbstractChannelHandlerContext.java:938) at io.netty.channel.DefaultChannelPipeline.callHandlerAdded0(DefaultChannelPipeline.java:609) at io.netty.channel.DefaultChannelPipeline.access$100(DefaultChannelPipeline.java:46) at io.netty.channel.DefaultChannelPipeline$PendingHandlerAddedTask.execute(DefaultChannelPipeline.java:1463) at io.netty.channel.DefaultChannelPipeline.callHandlerAddedForAllHandlers(DefaultChannelPipeline.java:1115) at io.netty.channel.DefaultChannelPipeline.invokeHandlerAddedIfNeeded(DefaultChannelPipeline.java:650) at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:502) at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417) at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474) at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:829) 分析日志，感觉是程序启动的时候，获取类对象没有成功导致服务启动失败。而我没有改动其他代码，只是在上一版的基础上增加了新功能，从新增的代码入手，定位到了问题应该出现在getBean上。新增的代码里面有一个工厂类，负责管理和生产数据，但由于是单例，该例调用其他服务时我用的getBean给服务赋值。之所以没用依赖注入，因为用依赖注入会导致数据不正常，而现在由于用getBean有问题，所以只能回到依赖注入的解决方案上。修改代码，把getBean改为依赖注入，发现数据果然开始不对，打断点跟踪代码运行时发现，依赖注入，对象是成功的注入到了工厂类里，但是输出数据的时候，数据为空。当时有点懵逼，同样的代码，只不过服务赋值方式不一样，但可以肯定都是成功赋值了的，运行结果却不相同，问题出在哪里？一番分析后感觉框架底层在注入数据的时候操作的对象并不是该工厂的单例，所以打断点分析的时候各方面都是有值的，但是一到单例数据输出却为空。解决方案参考如下，把单例和当前操作对象进行一个关联。 1234567891011121314151617181920@Componentpublic class DBManager &#123; private static DBManager instance = new DBManager(); @Autowired public UserServiceImpl userService; private DBManager() &#123; &#125; public static DBManager getInstance() &#123; return instance; &#125; @PostConstruct public void init() &#123; instance = this; instance.userService = this.userService; &#125;&#125; 运行，测试，成功解决。","tags":["报错"],"categories":["Java"]},{"title":"jar启动脚本","path":"/2022/12/19/startfile/","content":"新建一个start.sh文件，编辑内容如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/bin/sh## java env#export JAVA_HOME=/data/jdk1.8.0_121#export JRE_HOME=$JAVA_HOME/jre## service name#当前目录NOW_PATH=$(cd `dirname $0`; pwd)#jar包路径JAR_DIR=`ls -ltr $NOW_PATH/*.jar| tail -1`#jar包名字JAR_NAME=$&#123;JAR_DIR##*/&#125;#日志名字LOG_NAME=$&#123;JAR_NAME%%.*&#125;PID=$LOG_NAME\\.pidcase &quot;$1&quot; in start) nohup java -Xms256m -Xmx1024m -jar $JAR_NAME --spring.profiles.active=test &gt; logs/$LOG_NAME.log 2&gt;&amp;1 &amp; #echo $! &gt; $NOW_PATH/$PID #echo &quot;=== start $JAR_NAME&quot;\t#tail -1000f logs/$LOG_NAME.log ;; stop) echo &quot;=== stop $JAR_NAME&quot;\tps -ef|grep $JAR_NAME |grep -v grep |awk &#x27;&#123;print $2&#125;&#x27;|xargs kill -9 ;; restart) $0 stop sleep 2 $0 start echo &quot;=== restart $LOG_NAME&quot; ;; *) echo &quot;Usage:$0 &#123;start|stop|restart&#125;&quot; ;;esacexit 0 该文件放在jar包同级目录下，并新建logs文件夹具体命令 如下： 启动 ./start.sh start 停止 ./start.sh stop 重启 ./start.sh restart一个服务对应一个脚本，用文件夹隔离，别用来批量启动jar，即一个文件夹里最好是只放一个jar 1234-Xms256m初始内存-Xmx1024m最大内存--spring.profiles.active=test 指定配置文件 例如指定application-test.yml#tail -1000f logs/$LOG_NAME.log 注释掉的这行是指启动后打印1000行日志然后停止打印 查看内存使用情况 1top -o %MEM -b -n 1 | grep java | awk &#x27;&#123;print &quot;PID: &quot;$1&quot; \\t 虚拟内存: &quot;$5&quot; \\t 物理内存: &quot;$6&quot; \\t 共享内存: &quot;$7&quot; \\t CPU使用率: &quot;$9&quot;% \\t 内存使用率: &quot;$10&quot;%&quot;&#125;&#x27; 查看服务是否启动的脚本 123456789101112131415161718#!/bin/bashservice_names=(&#x27;xx1&#x27;&#x27;xx2&#x27;&#x27;xx3&#x27;)for(( i=0;i&lt;$&#123;#service_names[@]&#125;;i++)) do result=$(jps | grep &quot;$&#123;service_names[i]&#125;&quot;)\tif [[ &quot;$result&quot; == &quot;&quot; ]]\tthen echo &quot;$&#123;service_names[i]&#125; is not started&quot;\tfidone;exit 0","tags":["笔记"],"categories":["Java"]},{"title":"Nginx配置文件","path":"/2022/11/11/Nginx-config/","content":"无证书 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128user root;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name xxx.xx.60.174; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root /home/centos/bank-v/h5; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; server &#123; listen 82; server_name xxx.xx.60.174; location / &#123; root /home/centos/bank-v/amd; index index.html index.htm; &#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 有证书 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788user root;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name www.xxxxx.com admin.xxxxx.com xxxxx.com; rewrite ^ https://$http_host$request_uri? permanent; &#125; server &#123; listen 443 ssl; server_name www.xxxxx.com xxxxx.com; ssl_certificate cert/xxxxx.com_chain.crt; ssl_certificate_key cert/xxxxx.com_key.key; location / &#123; root /home/centos/bank-v5/https/h5; index index.html index.htm; &#125; location ^~ /api/ &#123; #后端java反向代理 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8082; &#125; location ^~ /amd/ &#123; #后端java反向代理 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8082; &#125; location ^~ /ts/ &#123; #后端node反向代理 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:3000; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; server &#123; listen 443 ssl; server_name admin.xxxxx.com; ssl_certificate cert/xxxxx.com_chain.crt; ssl_certificate_key cert/xxxxx.com_key.key; location / &#123; root /home/centos/bank-v5/https/amd; index index.html index.htm; &#125; &#125;&#125;","tags":["环境"],"categories":["nginx"]},{"title":"其他笔记","path":"/2022/11/11/otherNote/","content":"数据库，多库搜索表 12# 多数据库搜索表select * from information_schema.TABLES where TABLE_NAME =&#x27;tb_api_key&#x27;","tags":["笔记"],"categories":["其他"]},{"title":"rs.getDate()获取日期 时分秒为0","path":"/2022/11/01/java-getTimestamp/","content":"12345import java.util.Date;//ResultSet rs 从数据库里获取date 类型值时，获取不到时分秒，即时分秒都为0。//解决办法：//rs应该用getTimestamp()而不用getDate()。这样就能解决。 上面处理之后读取出来的时间是:2022-10-30T21:22:08.000+00:00这样的 解决方案 12345678910//在实体类里面字段上方添加注释@JsonFormat(pattern = “yyyy-MM-dd HH:mm:ss”)\t@JsonFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;) @ApiModelProperty(value = &quot;创建时间&quot;) @TableField(value=&quot;created_at&quot; , fill = FieldFill.INSERT) private Date createdAt; @JsonFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;) @ApiModelProperty(value = &quot;更新时间&quot;) @TableField(value = &quot;updated_at&quot;,fill = FieldFill.INSERT_UPDATE) private Date updatedAt;","tags":["笔记"],"categories":["Java"]},{"title":"idea打开项目无法引入,解析包和类","path":"/2022/10/19/java-idea-ca/","content":"修改一些包结构后,或者重新打开项目，可能会出现无法将类引入的情况.通过清理缓存解决:","tags":["报错"],"categories":["Java"]},{"title":"java,统一接口异常","path":"/2022/10/19/java-RestControllerAdvice/","content":"在Controller包下添加 123456789101112131415import com.example.rcadmin.commonutils.R;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.RestControllerAdvice;@RestControllerAdvicepublic class BaseExceptionHandler &#123; @ExceptionHandler(value = Exception.class) public R exception(Exception e) &#123; e.printStackTrace(); return R.error().message(e.getMessage()); &#125;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"java,统一接口返回","path":"/2022/10/19/java-r/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import io.swagger.annotations.ApiModelProperty;import lombok.Data;import java.util.HashMap;import java.util.Map;@Datapublic class R &#123; @ApiModelProperty(value = &quot;是否成功&quot;) private Boolean success; @ApiModelProperty(value = &quot;返回码&quot;) private Integer code; @ApiModelProperty(value = &quot;返回消息&quot;) private String message; @ApiModelProperty(value = &quot;返回数据&quot;) private Map&lt;String, Object&gt; data = new HashMap&lt;String, Object&gt;(); private R() &#123; &#125; // 无参构造函数私有化，别人在使用类时就不能new了，只能使用 ok()、error() //成功静态方法 public static R ok() &#123; R r = new R(); // 自己可以new，别人不能new r.setSuccess(true); r.setCode(ResultCode.SUCCESS); r.setMessage(&quot;成功&quot;); return r; &#125; //失败静态方法 public static R error() &#123; R r = new R(); r.setSuccess(false); r.setCode(ResultCode.ERROR); return r; &#125; public static R res() &#123; R r = new R(); // 自己可以new，别人不能new r.setSuccess(false); r.setCode(ResultCode.RES); r.setMessage(&quot;该手机号已注册&quot;); return r; &#125; public static R end() &#123; R r = new R(); // 自己可以new，别人不能new r.setSuccess(false); r.setCode(ResultCode.END); r.setMessage(&quot;over&quot;); return r; &#125; public static R share(Integer type) &#123; R r = new R(); r.setSuccess(false); r.setCode(type); return r; &#125; public R success(Boolean success) &#123; this.setSuccess(success); return this; // this指当前调用本方法的对象（谁调用success，this就代表谁），这么做的目的是为了实现链式编程 &#125; public R message(String message) &#123; this.setMessage(message); return this; &#125; public R code(Integer code) &#123; this.setCode(code); return this; &#125; public R data(String key, Object value) &#123; this.data.put(key, value); return this; &#125; public R data(Map&lt;String, Object&gt; map) &#123; this.setData(map); return this; &#125;&#125; 12345678public interface ResultCode &#123; public static Integer SUCCESS = 20000; // 成功 public static Integer ERROR = 20001; // 失败 public static Integer RES = 20003; // 已注册 public static Integer END = 20005; // 流程结束 public static Integer LOGINFAIL = 20007; // 管理员登录失败 public static Integer ADMINOFFLINE = 20009; // 管理员被下线&#125; 1234return R.ok().data(&quot;list&quot;, list);return R.error();return R.error().message(e.getMessage());return R.ok().data(&quot;items&quot;, ad);","tags":["笔记"],"categories":["Java"]},{"title":"java,获取当前时间","path":"/2022/10/17/java-gettime - cur/","content":"123456789101112131415161718package com.example.rcadmin.commonutils;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;public class timeUtil &#123; public static Date getcurtime() &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd kk:mm:ss &quot;); Date ctime = null; try &#123; ctime = sdf.parse(sdf.format(new Date())); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return ctime; &#125;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"java,jdbcTemplate分页实现","path":"/2022/10/17/java-jdbcTemplate-page/","content":"PageList123456789101112131415161718192021222324252627282930package com.example.rcadmin.model;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.util.ArrayList;import java.util.List;@Data@AllArgsConstructor@NoArgsConstructorpublic class PageList&lt;T&gt; &#123; private int pageSize; //单页最大数据量 private int dataNumber; //Java类T 总的数据量 private int pageNumber; //总的页数 总的页数=(总的数据量%单页最大数据量)==0?(总的数据量/单页最大数据量):((总的数据量/单页最大数据量)+1) private int currentPage; //当前页 private List&lt;T&gt; dataList = new ArrayList&lt;T&gt;(); //当前页的全部数据 public PageList(int currentPage,int pageSize,int dataNumber)&#123; this.currentPage = currentPage; this.pageSize = pageSize; pageNumber = (dataNumber%pageSize==0?(dataNumber/pageSize):(dataNumber/pageSize+1)); &#125;&#125; pageTool123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.example.rcadmin.commonutils;import com.example.rcadmin.model.PageList;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.jdbc.core.RowMapper;import org.springframework.stereotype.Repository;import java.sql.ResultSet;import java.sql.SQLException;import java.util.List;@Repositorypublic class pageTool&lt;T&gt; &#123; @Autowired private JdbcTemplate jdbcTemplate; public List&lt;T&gt; findAll(String sql, String TableName, rstoobj re) &#123; if (sql.equals(&quot;&quot;)) sql = &quot;select * from &quot; + TableName; return jdbcTemplate.query(sql, new RowMapper&lt;T&gt;() &#123; @Override public T mapRow(ResultSet rs, int rowNum) throws SQLException &#123; return (T) re.rtodata(rs); &#125; &#125;); &#125; //分页功能实现，获取分页数据 public PageList&lt;T&gt; getListByPage(int currentPage, int pageSize, String findAllsql, String DataNumbersql, String ListByPagesql, String TableName, rstoobj re) &#123; if (DataNumbersql.equals(&quot;&quot;)) DataNumbersql = &quot;SELECT count(id) FROM &quot; + TableName; if (ListByPagesql.equals(&quot;&quot;)) ListByPagesql = &quot;SELECT * FROM &quot; + TableName + &quot; limit ?,?&quot;; //获取总数据量 List&lt;T&gt; dataList = findAll(findAllsql, TableName, re); int dataNumber = dataList.size(); //设置当前页面和每个页面的最大数据量 PageList&lt;T&gt; dataPageList = new PageList&lt;&gt;(currentPage, pageSize, dataNumber); //获取所有的数据，得出总的数据量 dataPageList.setDataNumber(jdbcTemplate.queryForObject(DataNumbersql, Integer.class)); //根据当前页的情况来确定当前页的展示数据列表 if (dataPageList.getCurrentPage() == dataPageList.getPageNumber()) &#123; dataPageList.setDataList(jdbcTemplate.query(ListByPagesql, new RowMapper&lt;T&gt;() &#123; @Override public T mapRow(ResultSet rs, int rowNum) throws SQLException &#123; return (T) re.rtodata(rs); &#125; &#125;, new Object[]&#123;(currentPage - 1) * pageSize, dataPageList.getDataNumber() - (currentPage - 1) * pageSize&#125;)); &#125; else &#123; dataPageList.setDataList(jdbcTemplate.query(ListByPagesql, new RowMapper&lt;T&gt;() &#123; @Override public T mapRow(ResultSet rs, int rowNum) throws SQLException &#123; return (T) re.rtodata(rs); &#125; &#125;, new Object[]&#123;(currentPage - 1) * pageSize, pageSize&#125;)); &#125; return dataPageList; &#125;&#125; rstoobj12345678package com.example.rcadmin.commonutils;import java.sql.ResultSet;import java.sql.SQLException;public interface rstoobj&lt;T&gt; &#123; T rtodata(ResultSet rs) throws SQLException;&#125; 实体类实现接口12345678910111213141516171819202122232425262728293031323334353637383940414243package com.example.rcadmin.model;import com.example.rcadmin.commonutils.rstoobj;import com.example.rcadmin.enums.bl_apply_to;import com.example.rcadmin.enums.bl_type;import io.swagger.annotations.ApiModel;import io.swagger.annotations.ApiModelProperty;import lombok.*;import java.sql.ResultSet;import java.sql.SQLException;import java.util.Date;//exrc数据库@Data@Builder@ToString@NoArgsConstructor //自动生成无参数构造函数。@AllArgsConstructor //自动生成全参数构造函数@ApiModel(&quot;未知&quot;)public class blacklist implements rstoobj &#123; @ApiModelProperty(&quot;id&quot;) private int id; @ApiModelProperty(&quot;未知属性&quot;) private bl_type type; @ApiModelProperty(&quot;未知属性&quot;) private String value; @ApiModelProperty(&quot;未知属性&quot;) private bl_apply_to apply_to; @ApiModelProperty(&quot;未知属性&quot;) private String exact_apply_to; @ApiModelProperty(&quot;应该是创建时间&quot;) private Date created_at; @ApiModelProperty(&quot;应该是更新时间&quot;) private Date updated_at; @Override public blacklist rtodata(ResultSet rs) throws SQLException &#123; return new blacklist(rs.getInt(&quot;id&quot;),bl_type.valueOfName(rs.getString(&quot;type&quot;)), rs.getString(&quot;value&quot;), bl_apply_to.valueOfName(rs.getString(&quot;apply_to&quot;)), rs.getString(&quot;exact_apply_to&quot;), rs.getDate(&quot;created_at&quot;), rs.getDate(&quot;updated_at&quot;)); &#125;&#125; service1234567891011121314151617181920package com.example.rcadmin.service;import com.example.rcadmin.commonutils.pageTool;import com.example.rcadmin.dao.blacklistDao;import com.example.rcadmin.model.PageList;import com.example.rcadmin.model.blacklist;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class blacklistService &#123; @Autowired private blacklistDao blacklistdao; @Autowired private pageTool pagetool; public PageList&lt;blacklist&gt; getListByPage(int currentPage, int pageSize) &#123; return pagetool.getListByPage(2,10,&quot;&quot;,&quot;&quot;,&quot;&quot;,&quot;blacklist&quot;,new blacklist()); &#125;&#125; controller12345@PostMapping(&quot;/list&quot;) public R list() &#123; blacklistservice.getListByPage(1,10); return null; &#125;","tags":["笔记"],"categories":["Java"]},{"title":"java,字符串转枚举","path":"/2022/10/17/java-enumtostring/","content":"在枚举中新增一个静态函数，枚举全部如下 12345678910111213141516171819202122232425public enum bl_type &#123; USER_ID(&quot;user_id&quot;), ACCOUNT_ID(&quot;account_id&quot;), ADDRESS(&quot;address&quot;); private String value; bl_type(String value) &#123; this.value = value; &#125; public String getValue() &#123; return this.value; &#125; public static bl_type valueOfName(String name) &#123; name=name.toLowerCase();//转为小写 Map&lt;String, bl_type&gt; MAP = new HashMap&lt;&gt;(); for (bl_type season : values()) &#123; MAP.put(season.value, season); &#125; bl_type em=MAP.get(name); if(em==null) em=MAP.get(name.toUpperCase());//转为大写 return MAP.get(name); &#125;&#125; 调用： 1bl_type.valueOfName(rs.getString(&quot;type&quot;))","tags":["笔记"],"categories":["Java"]},{"title":"centos7安装whmcs8.5.1","path":"/2022/10/15/centosiwhmcs/","content":"注意不要用centos8,8安装有点问题安装宝塔下载安装使用宝塔产品https://www.bt.cn/new/download.html 1yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh ed8484bec 按提示一步步完成即可 利用宝塔安装环境 注意，php必须安装7.2以上，建议安装7.4，mysql建议5.6，其他的可以按推荐的默认的 安装完成后，进入 软件管理 – 已安装-PHP 7.4 – 设置 – 安装扩展，安装ionCube 新建站点在宝塔后台添加站点，建议先解析好域名并在安全组里面开放好端口，添加域名站点并设置默认站点 进入网站目录，删除自动生成的4个文件 若有user.ini之类的文件也可以删除 远程下载whmcs 下载好后，解压到当前目录，然后浏览器输入 http://xxx.com/install , 按要求安装即可. 安装好之后，删除 install 目录 设置同步，宝塔 – 计划任务，添加 php -q /www/wwwroot/host.zhujiwiki.com/crons/cron.php 一切顺利的话，到这里就安装完毕了","tags":["环境"],"categories":["whmcs"]},{"title":"Linux安装nginx，并部署html网站","path":"/2022/10/13/centosinginx/","content":"先安装gcc-c++编译器12yum install gcc-c++yum install -y openssl openssl-devel 安装pcre包1yum install -y pcre pcre-devel 再安装zlib包1yum install -y zlib zlib-devel 开始nginx的安装1.在/usr/local/下创建文件nginx文件 1mkdir /usr/local/nginx 2.在网上下nginx包上传至Linux（https://nginx.org/download/），也可以直接下载 1wget https://nginx.org/download/nginx-1.19.9.tar.gz 3.解压并进入nginx目录 12tar -zxvf nginx-1.19.9.tar.gzcd nginx-1.19.9 4.使用nginx默认配置 1./configure 5.编译安装 12makemake install 如果报错 ：-bash: make: 未找到命令 1yum -y install gcc automake autoconf libtool make make再报错的话前面加 sudo 6.查找安装路径 1whereis nginx 7.进入sbin目录，可以看到有一个可执行文件nginx，直接**./nginx**执行就OK了。 1./nginx 8.查看是否启动成功 1ps -ef | grep nginx 注意如以上步骤都完成且没有问题的话，就做如下操作 12查看防火墙是否开启systemctl status firewalld 启动防火墙后，默认没有开启任何端口，需要手动开启端口。nginx默认是80端口 123手动开启端口命令firewall-cmd --zone=public --add-port=80/tcp --permanent命令含义： --zone #作用域 --add-port=80/tcp #添加端口，格式为：端口/通讯协议 --permanent #永久生效，没有此参数重启后失效 开启后需要重启防火墙才生效 1systemctl restart firewalld.service 查看防火墙是否开启了80端口的访问 1firewall-cmd --list-all 如果80端口被占用,可以用下面这个命令进行查看80端口被谁占用 1netstat -tunlp | grep 80 是被nginx.master或者nginx.woeker占用就不用管，如果不是这个的话那就把那个进程关闭掉 1kill -9 进程号 其他启动 12cd usr/local/nginx/sbin./nginx 更改配置重启nginx 1234kill -HUP 主进程号或进程号文件路径或者使用cd /usr/local/nginx/sbin./nginx -s reload 判断配置文件是否正确 1234nginx -t -c /usr/local/nginx/conf/nginx.conf或者cd /usr/local/nginx/sbin./nginx -t 部署 使用工具：MobaXterm_CHS.exe,其他工具也可以，看自己喜好 第一步：将html的项目放入服务器将自己做好的html或者纯html项目放入服务器。 上图详细流程：1.先在服务器中选好自己的目录或创建一个新目录； 1mkdir lanys #创建一个新目录命令 2.创建后进入新创建目录； 1cd lanys #进入lanys目录 3.获取目录的路径； 1pwd 4.工具路径在工具上搜索可视化目录； 5.直接在桌面将项目拉入服务器中(举例)； 到这已经还有最后一步（重点），在nginx中配置。 第二步,nginx配置1.直接去到Nginx目录下，默认安装Nginx，配置文件默认在： 1cd /usr/local/nginx 2.进入config： 1cd conf/ 3.编辑配置文件： 1vim nginx.conf 学过Nginx都知道80是它的默认访问端口，我建议直接建一个，基本配置 123456 server &#123; listen 8081; location / &#123; root /lanys/demo/demo; index index.html index.htm;&#125; 解释： listen 8081; 指向8081端口 location / 指的是 服务器/ root /lanys/demo/demo; root指向你的项目目录 index index.html index.htm; 指向目录下的index.html文件 完成，退出 wq 之后没启动的就启动，启动了的，刷新配置文件，给个大宝贝，nginx常用命令： 1234567891011cd /usr/local/nginx/sbin/./nginx 启动./nginx -s stop 停止./nginx -s quit 安全退出./nginx -s reload 重新加载配置文件ps aux|grep nginx 查看nginx进程 注意，这些启动须在 /usr/local/nginx/sbin/下进行。 启动之后，就可以在浏览器访问了！ 总结：博客写得有点长，但实际操作很简单，很快，有些老表可能会遇到一些问题，比如访问不到，可能是防火墙端口没开，或者配置有问题。防火墙，因为我的是腾讯云可以直接配也可以使用命令，由于自己比较勤奋，直接在腾讯云上配置。","tags":["环境"],"categories":["nginx"]},{"title":"Centos7下安装Node环境","path":"/2022/10/13/centosinode/","content":"安装步骤 在 root 目录下，下载Node.js安装包 1wget https://nodejs.org/dist/v14.15.1/node-v14.15.1-linux-x64.tar.xz 2.解压文件 1tar xvf node-v14.15.1-linux-x64.tar.xz 3.创建软链接，以便可以在任意目录下使用 node 和 npm 命令（类似在windows上配置全局环境变量） 12ln -s /root/node-v14.15.1-linux-x64/bin/node /usr/local/bin/nodeln -s /root/node-v14.15.1-linux-x64/bin/npm /usr/local/bin/npm 4.依次查看node和npm信息（验证安装是否成功） 12node -vnpm -v 5.安装 cnpm 并创建软链接，至此安装成功！ 12npm install -g cnpm --registry=https://registry.npm.taobao.orgln -s /root/node-v14.15.1-linux-x64/bin/cnpm /usr/local/bin/cnpm 6.部署测试项目,在LINUX中我们可以使用这种简单的方式让node.js在后台运行 1nohup node your_app.js &amp; 或者 1nohup node your_app.js &gt;temp.out &amp; 运行问题如果nohup node运行程序，退出服务器后，进行消失 1whereis node 1ps -ef | grep node 可以安装pm2或者forever 12345678 copy child:codeblock open:true color:yellow forever的安装 npm install forever -gforever start your_app.js #使用forever启动守护进程forever stop your_app.js #关闭守护进程forever restart your_app.js #重启守护进程forever start -l forever.log -o out.log -e err.log your_app.js #记录输出日志和错误forever list #查看正在运行的程序forever -h #查看forever帮助 安装pm2shell npm install pm2 -g sudo npm install pm2 -g #1 启动进程/应用 pm2 start bin/www 或 pm2 start app.js #2 重命名进程/应用 pm2 start app.js --name wb123 #3 添加进程/应用 watch pm2 start bin/www --watch #4 结束进程/应用 pm2 stop www #5 结束所有进程/应用 pm2 stop all #6 删除进程/应用 pm2 delete www #7 删除所有进程/应用 pm2 delete all #8 列出所有进程/应用 pm2 list #9 查看某个进程/应用具体情况 pm2 describe www #10 查看进程/应用的资源消耗情况 pm2 monit #11 查看pm2的日志 pm2 logs #12 若要查看某个进程/应用的日志,使用 pm2 logs www #13 重新启动进程/应用 pm2 restart www #14 重新启动所有进程/应用 pm2 restart all ``` 如果安装过程中报没有权限的错误，而使用 sudo npm 又报错找不到命令 ```shell child:codeblock open:true color:yellow 运行下面这些命令 sudo ln -s /usr/local/bin/node /usr/bin/node sudo ln -s /usr/local/lib/node /usr/lib/node sudo ln -s /usr/local/bin/npm /usr/bin/npm sudo ln -s /usr/local/bin/node-waf /usr/bin/node-waf ``` ```shell child:codeblock open:true color:yellow 执行pm2 start app.js启动node.js项目报错：-bash: pm2: command not found #原因,虽然安装了通过npm install pm2 -g安装了pm2，但是没有配制到全局，此时需要创建一个linux下的软连接。 #首先，我们需要找到pm2程序所在路径，通过 find / -name #pm2找到pm2安装后的所在路径，如下图 ``` ```shell image https://su3.cn/postimg/wx_20221014142339.png ``` ```shell quot ln报错的话前面加sudo icon:hashtag ``` ```shell child:codeblock open:true color:yellow 接着执行 ln -s /root/home/installation-packages/node.js/node.js/bin/pm2 /usr/local/bin #命令为pm2程序添加软链接。其中/root/home/installation-packages/node.js/node.js/bin/pm2就是上一步查找到pm2程序的所在路径，而/usr/local/bin是根据$PATH环境变量得到的路径，在这些目录下的程序可以在系统的任意位置直接调用执行，所以将软链接添加到此目录下。 #最后，在任意目录执行pm2 --version命令查看是否配置成功 ```","tags":["环境"],"categories":["Node"]},{"title":"Centos安装jdk18","path":"/2022/10/13/cenosijdk18/","content":"进入官网下载jdk18 1https://www.oracle.com/java/technologies/downloads/ 注意centos要选择x64 下载安装包 123mkdir /usr/java #创建java安装文件cd /usr/java #切换到目录wget https://download.oracle.com/java/18/latest/jdk-18_linux-x64_bin.rpm 安装 1rpm -ivh jdk-18_linux-x64_bin.rpm # 安装 验证安装 1java -version 不需要自己去添加环境变量，会自己设置","tags":["环境"],"categories":["Java"]},{"title":"导入数据库文件报1067错误","path":"/2022/10/13/mysql1067/","content":"临时修改该错误是由于时间的默认值不兼容，查看sql_mode 1show variables like &#x27;sql_mode&#x27;; 如果结果中含有NO_ZERO_IN_DATE, NO_ZERO_DATE 1set session sql_mode=&#x27;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZE 或者 1set session sql_mode=&#x27;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&#x27;; 当然，这个只是临时修改，很可能每导入一次需要重复一次上面的步骤，而且即使执行了上面的步骤，执行完成或者导入完毕后还是会出现1055之类的错误，但是可以不用管，基本是导入成功了的 永久修改编辑mysql的配配置文件 my.cnf 在[mysqld]下面添加如下列： 1sql_mode=ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 转储sql文件修改提取出sql文件，通过在sql文件中将“0000-00-00”修改为有效时间如“1970-12-31”，然后运行sql文件实现导入","tags":["报错"],"categories":["mysql"]},{"title":"笔记本外接显示器关闭笔记本屏幕？","path":"/2022/10/12/bijiben/","content":"由于笔记本的便捷性，大多数人都会使用笔记本进行办公，但是由于笔记本屏幕较小，为了向大家展示自己的项目或是其他，都会选择连接外接显示器，将屏幕变大。我们连接了外接显示器，不想笔记本仍然亮屏，那么，笔记本外接显示器怎么关闭笔记本屏幕呢？ 方法一 使用快捷键Windows+P，此时会出现四种投影模式：①“仅电脑屏幕”：即只有笔记本屏幕有显示，②“复制”，即两个显示器显示一样的内容，③“扩展”，适合大屏幕演示，相当于把画面在两个显示器中显示，④“仅第二屏幕”，这就我们想要的设置，点击这选项就可以关闭显示器屏幕。 方法二 在开始菜单中找到【控制面板】，将查看方式切换成“小图标”，点击【显示】，在左边选择【调整分辨率】，找到“多显示器设置”，选择【只在2上显示桌面】即可关闭笔记本屏幕。该方法也可以直接在桌面空白处右击，选择【显示设置】，按照上述方法进行设置。不过，“多显示器设置”需要在连接了外接显示器才能进行设置，未连接之前该设置不会显示出来。","tags":["其他"],"categories":["其他"]},{"title":"nodejs笔记二","path":"/2021/12/07/node_note2/","content":"Node.js基础一、Node.js是什么Node.js® is a JavaScript runtime built on Chrome’s V8 JavaScript engine. 1、特性Node.js 可以解析JS代码（没有浏览器安全级别的限制）提供很多系统级别的API，如： 文件的读写 (File System) 进程的管理 (Process) 网络通信 (HTTP/HTTPS) …… 2、举例2.1 浏览器安全级别的限制Ajax测试 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;browser-safe-sandbox&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;browser-safe-sandbox&lt;/div&gt; &lt;script&gt; const xhr = new XMLHttpRequest() xhr.open(&#x27;get&#x27;, &#x27;https://m.maoyan.com/ajax/moreClassicList?sortId=1&amp;showType=3&amp;limit=10&amp;offset=30&amp;optimus_uuid=A5518FF0AFEC11EAAB158D7AB0D05BBBD74C9789D9F649898982E6542C7DD479&amp;optimus_risk_level=71&amp;optimus_code=10&#x27;, false) xhr.send() &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 浏览器预览 1browser-sync start --server --files **/* --directory 2.2 文件的读写 (File System)12345const fs = require(&#x27;fs&#x27;)fs.readFile(&#x27;./ajax.png&#x27;, &#x27;utf-8&#x27;, (err, content) =&gt; &#123; console.log(content)&#125;) 2.3 进程的管理（Process）12345function main(argv) &#123; console.log(argv)&#125;main(process.argv.slice(2)) 运行 1node 2.3-process.js argv1 argv2 2.4 网络通信（HTTP/HTTPS）123456789const http = require(&quot;http&quot;)http.createServer((req,res) =&gt; &#123; res.writeHead(200, &#123; &quot;content-type&quot;: &quot;text/plain&quot; &#125;) res.write(&quot;hello nodejs&quot;) res.end()&#125;).listen(3000) 二、Node 相关工具1、NVM: Node Version Manager1.1 Mac 安装 nvm 1https://github.com/nvm-sh/nvm/blob/master/README.md 1.2 Windows 安装 nvm 12nvm-windowsnodist 2、NPM: Node Package Manager2.1 全局安装package1234$ npm install forever --global (-g)$ forever$ npm uninstall forever --global$ forever 全局安装包的目录 Mac 1/Users/felix/.nvm/versions/node/nvm各个版本/bin/ Windows 1C:\\Users\\你的用户名\\AppData\\Roaming pm ode_modules 2.2 本地安装package12345$ cd ~/desktop$ mkdir gp-project$ cd gp-project$ npm install underscore$ npm list (ls) 2.3 package.json初始化1234$ pwd$ npm init -y$ ls$ cat package.json 2.4 使用package.json12345678910$ npm install underscore --save$ cat package.json$ npm install lodash --save-dev$ cat package.json$ rm -rf node_modules$ ls$ npm install$ npm uninstall underscore --save$ npm list | grep underscore$ cat package.json 2.5 安装指定版本的包12345678$ pwd$ npm list$ npm info underscore$ npm view underscore versions$ npm install underscore@1.8.0$ npm list$ npm uninstall underscore$ npm list 2.6 更新本地安装的包1234567$ npm info underscore$ npm view underscore versions$ npm install underscore@1.4.4 --save-dev$ npm list | grep gulp$ npm outdated //~2.0.0表示patch, ^2.0.0表示minor * 表示xx最新版本$ npm list | grep gulp$ npm update 2.7 清除缓存1npm cache clean --force 2.8 上传自己的包2.8.1 编写模块保存为index.js 123exports.sayHello = function()&#123; return &#x27;Hello World&#x27;; &#125; 2.8.2 初始化包描述文件$ npm init package.json 12345678910111213141516171819202122&#123; &quot;name&quot;: &quot;gp19-npm&quot;, &quot;version&quot;: &quot;1.0.1&quot;, &quot;description&quot;: &quot;gp19 self module&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: &#123; &quot;test&quot;: &quot;make test&quot; &#125;, &quot;repository&quot;: &#123; &quot;type&quot;: &quot;Git&quot;, &quot;url&quot;: &quot;git+https://github.com/lurongtao/gp19-npm.git&quot; &#125;, &quot;keywords&quot;: [ &quot;demo&quot; ], &quot;author&quot;: &quot;Felixlu&quot;, &quot;license&quot;: &quot;ISC&quot;, &quot;bugs&quot;: &#123; &quot;url&quot;: &quot;https://github.com/lurongtao/gp19-npm/issues&quot; &#125;, &quot;homepage&quot;: &quot;https://github.com/lurongtao/gp19-npm#readme&quot;, &#125; 2.8.3 注册npm仓库账号123https://www.npmjs.com 上面的账号felix_lurt/qqmko09ijn$ npm adduser 2.8.4 上传包1$ npm publish 坑：403 Forbidden 123查看npm源：npm config get registry切换npm源方法一：npm config set registry http://registry.npmjs.org切换npm源方法二：nrm use npm 2.8.5 安装包1$ npm install gp19-npm 2.8.6 卸载包1234查看当前项目引用了哪些包 ：npm ls卸载包：npm unpublish --force 2.8.7 使用引入包12var hello = require(&#x27;gp19-npm&#x27;)hello.sayHello() 2.9 npm 脚本Node 开发离不开 npm，而脚本功能是 npm 最强大、最常用的功能之一。 一、什么是 npm 脚本？ npm 允许在 package.json 文件里面，使用 scripts 字段定义脚本命令。 123456&#123; // ... &quot;scripts&quot;: &#123; &quot;build&quot;: &quot;node build.js&quot; &#125;&#125; 二、执行顺序 如果 npm 脚本里面需要执行多个任务，那么需要明确它们的执行顺序。 script1.js 12var x = 0console.log(x) script2.js 123456var y = 0console.log(y)&quot;scripts&quot;: &#123; &quot;script1&quot;: &quot;node script1.js&quot;, &quot;script2&quot;: &quot;node script2.js&quot;&#125; 如果是并行执行（即同时的平行执行），可以使用 &amp; 符号。 1$ npm run script1 &amp; npm run script2 如果是继发执行（即只有前一个任务成功，才执行下一个任务），可以使用 &amp;&amp; 符号。 1$ npm run script1 &amp;&amp; npm run script2 三、简写形式 常用的 npm 脚本简写形式。 1npm start 是 npm run start 四、变量 npm 脚本有一个非常强大的功能，就是可以使用 npm 的内部变量。 首先，通过 npm_package_ 前缀，npm 脚本可以拿到 package.json 里面的字段。比如，下面是一个 package.json。 注意：一定要在 npm 脚本中运行（如：npm run view）才可以，直接在命令行中运行JS（如：node view.js）是拿不到值的 1234567&#123; &quot;name&quot;: &quot;foo&quot;, &quot;version&quot;: &quot;1.2.5&quot;, &quot;scripts&quot;: &#123; &quot;view&quot;: &quot;node view.js&quot; &#125;&#125; 那么，变量 npm_package_name 返回 foo，变量 npm_package_version 返回 1.2.5。 123// view.jsconsole.log(process.env.npm_package_name); // fooconsole.log(process.env.npm_package_version); // 1.2.5 上面代码中，我们通过环境变量 process.env 对象，拿到 package.json 的字段值。如果是 Bash 脚本，可以用$npm_package_name 和 $npm_package_version 取到这两个值。 npmpackage前缀也支持嵌套的package.json字段。 1234567&quot;repository&quot;: &#123; &quot;type&quot;: &quot;git&quot;, &quot;url&quot;: &quot;xxx&quot;&#125;,scripts: &#123; &quot;view&quot;: &quot;echo $npm_package_repository_type&quot;&#125; 上面代码中，repository 字段的 type 属性，可以通过 npm_package_repository_type 取到。 下面是另外一个例子。 123&quot;scripts&quot;: &#123; &quot;install&quot;: &quot;foo.js&quot;&#125; 上面代码中，npm_package_scripts_install 变量的值等于 foo.js。 然后，npm 脚本还可以通过 npmconfig 前缀，拿到 npm 的配置变量，即 npm config get xxx 命令返回的值。比如，当前模块的发行标签，可以通过 npm_config_tag 取到。 1&quot;view&quot;: &quot;echo $npm_config_tag&quot;, 注意，package.json 里面的 config 对象，可以被环境变量覆盖。 12345&#123; &quot;name&quot; : &quot;foo&quot;, &quot;config&quot; : &#123; &quot;port&quot; : &quot;8080&quot; &#125;, &quot;scripts&quot; : &#123; &quot;start&quot; : &quot;node server.js&quot; &#125;&#125; 上面代码中，npm_package_config_port 变量返回的是 8080。这个值可以用下面的方法覆盖。 1$ npm config set foo:port 80 最后，env命令可以列出所有环境变量。 “env”: “env” 2.10 npm 安装 git 上发布的包12345# 这样适合安装公司内部的git服务器上的项目npm install git+https://git@github.com:lurongtao/gp-project.git# 或者以ssh的方式npm install git+ssh://git@github.com:lurongtao/gp-project.git 2.11 cross-env 使用2.11.1 cross-env是什么运行跨平台设置和使用环境变量的脚本 2.11.2 出现原因当您使用 NODE_ENV=production, 来设置环境变量时，大多数 Windows 命令提示将会阻塞(报错)。（异常是Windows上的Bash，它使用本机Bash。）换言之，Windows 不支持 NODE_ENV=production 的设置方式。 2.11.3 解决cross-env 使得您可以使用单个命令，而不必担心为平台正确设置或使用环境变量。这个迷你的包(cross-env)能够提供一个设置环境变量的 scripts，让你能够以 Unix 方式设置环境变量，然后在 Windows 上也能兼容运行。 2.11.4 安装npm install –save-dev cross-env 2.11.5 使用12345&#123; &quot;scripts&quot;: &#123; &quot;build&quot;: &quot;cross-env NODE_ENV=production webpack --config build/webpack.config.js&quot; &#125;&#125; NODE_ENV环境变量将由 cross-env 设置 打印 process.env.NODE_ENV === ‘production’ 3、NRM: npm registry manager3.1 手工切换源3.1.1 查看当前源1npm config get registry 3.1.2 切换淘宝源1npm config set registry https://registry.npm.taobao.org 3.2 NRM 管理源NRM (npm registry manager)是npm的镜像源管理工具，有时候国外资源太慢，使用这个就可以快速地在 npm 源间切换。 3.2.1 安装 nrm在命令行执行命令，npm install -g nrm，全局安装nrm。 3.2.2 使用 nrm执行命令 nrm ls 查看可选的源。 其中，带*的是当前使用的源，上面的输出表明当前源是官方源。 3.2.3 切换 nrm如果要切换到taobao源，执行命令nrm use taobao。 3.2.4 测试速度你还可以通过 nrm test 测试相应源的响应时间。 1nrm test 4、NPX: npm package extentionnpm 从5.2版开始，增加了 npx 命令。它有很多用处，本文介绍该命令的主要使用场景。 Node 自带 npm 模块，所以可以直接使用 npx 命令。万一不能用，就要手动安装一下。 1$ npm install -g npx 4.1 调用项目安装的模块npx 想要解决的主要问题，就是调用项目内部安装的模块。比如，项目内部安装了Mocha。 1$ npm install -D mocha 一般来说，调用 Mocha ，只能在项目脚本和 package.json 的scripts字段里面，如果想在命令行下调用，必须像下面这样。 12# 项目的根目录下执行$ node-modules/.bin/mocha --version npx 就是想解决这个问题，让项目内部安装的模块用起来更方便，只要像下面这样调用就行了。 1$ npx mocha --version npx 的原理很简单，就是运行的时候，会到node_modules/.bin路径和环境变量$PATH里面，检查命令是否存在。 由于 npx 会检查环境变量$PATH，所以系统命令也可以调用。 12# 等同于 ls$ npx ls 注意，Bash 内置的命令不在$PATH里面，所以不能用。比如，cd是 Bash 命令，因此就不能用npx cd。 4.2 避免全局安装模块除了调用项目内部模块，npx 还能避免全局安装的模块。比如，create-react-app 这个模块是全局安装，npx 可以运行它，而且不进行全局安装。 1$ npx create-react-app my-react-app 上面代码运行时，npx 将 create-react-app 下载到一个临时目录，使用以后再删除。所以，以后再次执行上面的命令，会重新下载 create-react-app。 注意，只要 npx 后面的模块无法在本地发现，就会下载同名模块。比如，本地没有安装http-server模块，下面的命令会自动下载该模块，在当前目录启动一个 Web 服务。 1$ npx http-server 4.3 –no-install 参数和 –ignore-existing 参数如果想让 npx 强制使用本地模块，不下载远程模块，可以使用–no-install参数。如果本地不存在该模块，就会报错。 1$ npx --no-install http-server 反过来，如果忽略本地的同名模块，强制安装使用远程模块，可以使用–ignore-existing参数。比如，本地已经安装了http-server，但还是想使用远程模块，就用这个参数。 1$ npx --ignore-existing http-server 三、模块/包 与 CommonJS1、模块/包分类Node.js 有三类模块，即内置的模块、第三方的模块、自定义的模块。 1.1 内置的模块Node.js 内置模块又叫核心模块，Node.js安装完成可直接使用。如： 123const path = require(&#x27;path&#x27;)var extname = path.extname(&#x27;index.html&#x27;)console.log(extname) 1.2 第三方的Node.js模块第三方的Node.js模块指的是为了实现某些功能，发布的npmjs.org上的模块，按照一定的开源协议供社群使用。如： 123npm install chalkconst chalk = require(&#x27;chalk&#x27;)console.log(chalk.blue(&#x27;Hello world!&#x27;)) 1.3 自定义的Node.js模块自定义的Node.js模块，也叫文件模块，是我们自己写的供自己使用的模块。同时，这类模块发布到npmjs.org上就成了开源的第三方模块。 自定义模块是在运行时动态加载，需要完整的路径分析、文件定位、编译执行过程、速度相比核心模块稍微慢一些，但是用的非常多。 1.3.1 模块定义、接口暴露和引用接口我们可以把公共的功能 抽离成为一个单独的 js 文件 作为一个模块，默认情况下面这个模块里面的方法或者属性，外面是没法访问的。如果要让外部可以访问模块里面的方法或者属性，就必须在模块里面通过 exports 或者 module.exports 暴露属性或者方法。 m1.js： 1234567891011121314151617181920const name = &#x27;gp19&#x27;const sayName = () =&gt; &#123; console.log(name)&#125;console.log(&#x27;module 1&#x27;)// 接口暴露方法一：module.exports = &#123; say: sayName&#125;// 接口暴露方法二：exports.say = sayName// 错误！exports = &#123; say: sayName&#125; main.js： 12const m1 = require(&#x27;./m1&#x27;)m1.say() 1.3.2 模块的循环引用由于 exports 使用方式方式不对，会在两个不同 js 循环引用的情况下，导致其中一个 js 无法获取另外一个 js 的方法，从而导致执行报错。如： a.js 12345exports.done = falseconst b = require(&#x27;./b.js&#x27;)console.log(&#x27;in a, b.done = %j&#x27;, b.done)exports.done = trueconsole.log(&#x27;a done&#x27;) b.js 123456console.log(&#x27;b starting&#x27;)exports.done = falseconst a = require(&#x27;./a.js&#x27;)console.log(&#x27;in b, a.done = %j&#x27;, a.done)exports.done = trueconsole.log(&#x27;b done&#x27;) main.js 1234console.log(&#x27;main starting&#x27;)const a = require(&#x27;./a.js&#x27;)const b = require(&#x27;./b.js&#x27;)console.log(&#x27;in main, a.done = %j, b.done = %j&#x27;, a.done, b.done) main.js 首先会 load a.js, 此时执行到const b = require(‘./b.js’);的时候，程序会转去loadb.js, 在b.js中执行到const a = require(‘./a.js’); 为了防止无限循环，将a.jsexports的未完成副本返回到b.js模块。然后b.js完成加载，并将其导出对象提供给a.js模块。 我们知道nodeJs的对每个js文件进行了一层包装称为module，module中有一个属性exports，当调用require(‘a.js’)的时候其实返回的是module.exports对象，module.exports初始化为一个{}空的object，所以在上面的例子中，执行到b.js中const a = require(‘./a.js’);时不会load新的a module, 而是将已经load但是还未完成的a module的exports属性返回给b module，所以b.js拿到的是a module的exports对象，即：{done:false}, 虽然在a.js中exports.done被修改成了true，但是由于此时a.js未load完成，所以在b.js输出的a module的属性done为false，而在main.js中输出的a module的属性done为true. Nodejs通过上面这种返回未完成exports对象来解决循环引用的问题。 四、常用内置模块这里介绍几个常用的内置模块：url, querystring, http, events, fs, stream, readline, crypto, zlib 1、url1.1 parseurl.parse(urlString[, parseQueryString[, slashesDenoteHost]]) 1234const url = require(&#x27;url&#x27;)const urlString = &#x27;https://www.baidu.com:443/ad/index.html?id=8&amp;name=mouse#tag=110&#x27;const parsedStr = url.parse(urlString)console.log(parsedStr) 1.2 formaturl.format(urlObject) 1234567891011121314151617const url = require(&#x27;url&#x27;)const urlObject = &#123; protocol: &#x27;https:&#x27;, slashes: true, auth: null, host: &#x27;www.baidu.com:443&#x27;, port: &#x27;443&#x27;, hostname: &#x27;www.baidu.com&#x27;, hash: &#x27;#tag=110&#x27;, search: &#x27;?id=8&amp;name=mouse&#x27;, query: &#123; id: &#x27;8&#x27;, name: &#x27;mouse&#x27; &#125;, pathname: &#x27;/ad/index.html&#x27;, path: &#x27;/ad/index.html?id=8&amp;name=mouse&#x27;, href: &#x27;https://www.baidu.com:443/ad/index.html?id=8&amp;name=mouse#tag=110&#x27;&#125;const parsedObj = url.format(urlObject)console.log(parsedObj) 1.3 resolveurl.resolve(from, to) 12345const url = require(&#x27;url&#x27;)var a = url.resolve(&#x27;/one/two/three&#x27;, &#x27;four&#x27;)var b = url.resolve(&#x27;http://example.com/&#x27;, &#x27;/one&#x27;)var c = url.resolve(&#x27;http://example.com/one&#x27;, &#x27;/two&#x27;)console.log(a + &quot;,&quot; + b + &quot;,&quot; + c) 2、querystring2.1 parsequerystring.parse(str[, sep[, eq[, options]]]) 1234const querystring = require(&#x27;querystring&#x27;)var qs = &#x27;x=3&amp;y=4&#x27;var parsed = querystring.parse(qs)console.log(parsed) 2.2 stringifyquerystring.stringify(obj[, sep[, eq[, options]]]) 1234567const querystring = require(&#x27;querystring&#x27;)var qo = &#123; x: 3, y: 4&#125;var parsed = querystring.stringify(qo)console.log(parsed) 2.3 escape/unescapequerystring.escape(str) 1234const querystring = require(&#x27;querystring&#x27;)var str = &#x27;id=3&amp;city=北京&amp;url=https://www.baidu.com&#x27;var escaped = querystring.escape(str)console.log(escaped) querystring.unescape(str) 1234const querystring = require(&#x27;querystring&#x27;)var str = &#x27;id%3D3%26city%3D%E5%8C%97%E4%BA%AC%26url%3Dhttps%3A%2F%2Fwww.baidu.com&#x27;var unescaped = querystring.unescape(str)console.log(unescaped) 3、http/https3.1 get123456789101112131415161718192021222324252627282930313233var http = require(&#x27;http&#x27;)var https = require(&#x27;https&#x27;)// 1、接口 2、跨域const server = http.createServer((request, response) =&gt; &#123; var url = request.url.substr(1) var data = &#x27;&#x27; response.writeHeader(200, &#123; &#x27;content-type&#x27;: &#x27;application/json;charset=utf-8&#x27;, &#x27;Access-Control-Allow-Origin&#x27;: &#x27;*&#x27; &#125;) https.get(`https://m.lagou.com/listmore.json$&#123;url&#125;`, (res) =&gt; &#123; res.on(&#x27;data&#x27;, (chunk) =&gt; &#123; data += chunk &#125;) res.on(&#x27;end&#x27;, () =&gt; &#123; response.end(JSON.stringify(&#123; ret: true, data &#125;)) &#125;) &#125;)&#125;)server.listen(8080, () =&gt; &#123; console.log(&#x27;localhost:8080&#x27;)&#125;) 3.2 post：服务器提交（攻击）123456789101112131415161718192021222324252627282930313233343536373839404142434445const https = require(&#x27;https&#x27;)const querystring = require(&#x27;querystring&#x27;)const postData = querystring.stringify(&#123; province: &#x27;上海&#x27;, city: &#x27;上海&#x27;, district: &#x27;宝山区&#x27;, address: &#x27;同济支路199号智慧七立方3号楼2-4层&#x27;, latitude: 43.0, longitude: 160.0, message: &#x27;求购一条小鱼&#x27;, contact: &#x27;13666666&#x27;, type: &#x27;sell&#x27;, time: 1571217561&#125;)const options = &#123; protocol: &#x27;https:&#x27;, hostname: &#x27;ik9hkddr.qcloud.la&#x27;, method: &#x27;POST&#x27;, port: 443, path: &#x27;/index.php/trade/add_item&#x27;, headers: &#123; &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;, &#x27;Content-Length&#x27;: Buffer.byteLength(postData) &#125;&#125;function doPost() &#123; let data let req = https.request(options, (res) =&gt; &#123; res.on(&#x27;data&#x27;, chunk =&gt; data += chunk) res.on(&#x27;end&#x27;, () =&gt; &#123; console.log(data) &#125;) &#125;) req.write(postData) req.end()&#125;// setInterval(() =&gt; &#123;// doPost()// &#125;, 1000) 3.3 跨域：jsonp12345678910111213141516171819const http = require(&#x27;http&#x27;)const url = require(&#x27;url&#x27;)const app = http.createServer((req, res) =&gt; &#123; let urlObj = url.parse(req.url, true) switch (urlObj.pathname) &#123; case &#x27;/api/user&#x27;: res.end(`$&#123;urlObj.query.cb&#125;(&#123;&quot;name&quot;: &quot;gp145&quot;&#125;)`) break default: res.end(&#x27;404.&#x27;) break &#125;&#125;)app.listen(8080, () =&gt; &#123; console.log(&#x27;localhost:8080&#x27;)&#125;) 3.4 跨域：CORS1234567891011121314151617181920212223242526272829303132333435363738const http = require(&#x27;http&#x27;)const url = require(&#x27;url&#x27;)const querystring = require(&#x27;querystring&#x27;)const app = http.createServer((req, res) =&gt; &#123; let data = &#x27;&#x27; let urlObj = url.parse(req.url, true) res.writeHead(200, &#123; &#x27;content-type&#x27;: &#x27;application/json;charset=utf-8&#x27;, &#x27;Access-Control-Allow-Origin&#x27;: &#x27;*&#x27; &#125;) req.on(&#x27;data&#x27;, (chunk) =&gt; &#123; data += chunk &#125;) req.on(&#x27;end&#x27;, () =&gt; &#123; responseResult(querystring.parse(data)) &#125;) function responseResult(data) &#123; switch (urlObj.pathname) &#123; case &#x27;/api/login&#x27;: res.end(JSON.stringify(&#123; message: data &#125;)) break default: res.end(&#x27;404.&#x27;) break &#125; &#125;&#125;)app.listen(8080, () =&gt; &#123; console.log(&#x27;localhost:8080&#x27;)&#125;) 3.5 跨域：middleware（http-proxy-middware）12345678910111213141516171819202122232425262728293031323334const http = require(&#x27;http&#x27;)const proxy = require(&#x27;http-proxy-middleware&#x27;)http.createServer((req, res) =&gt; &#123; let url = req.url res.writeHead(200, &#123; &#x27;Access-Control-Allow-Origin&#x27;: &#x27;*&#x27; &#125;) if (/^\\/api/.test(url)) &#123; let apiProxy = proxy(&#x27;/api&#x27;, &#123; target: &#x27;https://m.lagou.com&#x27;, changeOrigin: true, pathRewrite: &#123; &#x27;^/api&#x27;: &#x27;&#x27; &#125; &#125;) // http-proy-middleware 在Node.js中使用的方法 apiProxy(req, res) &#125; else &#123; switch (url) &#123; case &#x27;/index.html&#x27;: res.end(&#x27;index.html&#x27;) break case &#x27;/search.html&#x27;: res.end(&#x27;search.html&#x27;) break default: res.end(&#x27;[404]page not found.&#x27;) &#125; &#125;&#125;).listen(8080) 3.6 爬虫1234567891011121314151617181920212223242526272829303132333435363738394041424344const https = require(&#x27;https&#x27;)const http = require(&#x27;http&#x27;)const cheerio = require(&#x27;cheerio&#x27;)http.createServer((request, response) =&gt; &#123; response.writeHead(200, &#123; &#x27;content-type&#x27;: &#x27;application/json;charset=utf-8&#x27; &#125;) const options = &#123; protocol: &#x27;https:&#x27;, hostname: &#x27;maoyan.com&#x27;, port: 443, path: &#x27;/&#x27;, method: &#x27;GET&#x27; &#125; const req = https.request(options, (res) =&gt; &#123; let data = &#x27;&#x27; res.on(&#x27;data&#x27;, (chunk) =&gt; &#123; data += chunk &#125;) res.on(&#x27;end&#x27;, () =&gt; &#123; filterData(data) &#125;) &#125;) function filterData(data) &#123; let $ = cheerio.load(data) let $movieList = $(&#x27;.movie-item&#x27;) let movies = [] $movieList.each((index, value) =&gt; &#123; movies.push(&#123; title: $(value).find(&#x27;.movie-title&#x27;).attr(&#x27;title&#x27;), score: $(value).find(&#x27;.movie-score i&#x27;).text(), &#125;) &#125;) response.end(JSON.stringify(movies)) &#125; req.end()&#125;).listen(9000) 4、Events123456789101112const EventEmitter = require(&#x27;events&#x27;)class MyEventEmitter extends EventEmitter &#123;&#125;const event = new MyEventEmitter()event.on(&#x27;play&#x27;, (movie) =&gt; &#123; console.log(movie)&#125;)event.emit(&#x27;play&#x27;, &#x27;我和我的祖国&#x27;)event.emit(&#x27;play&#x27;, &#x27;中国机长&#x27;) 5、File System123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111const fs = require(&#x27;fs&#x27;)const fsP = require(&#x27;fs&#x27;).promises// 创建文件夹fs.mkdir(&#x27;./logs&#x27;, (err) =&gt; &#123; console.log(&#x27;done.&#x27;)&#125;)// 文件夹改名fs.rename(&#x27;./logs&#x27;, &#x27;./log&#x27;, () =&gt; &#123; console.log(&#x27;done&#x27;)&#125;)// 删除文件夹fs.rmdir(&#x27;./log&#x27;, () =&gt; &#123; console.log(&#x27;done.&#x27;)&#125;)// 写内容到文件里fs.writeFile( &#x27;./logs/log1.txt&#x27;, &#x27;hello&#x27;, // 错误优先的回调函数 (err) =&gt; &#123; if (err) &#123; console.log(err.message) &#125; else &#123; console.log(&#x27;文件创建成功&#x27;) &#125; &#125;)// 给文件追加内容fs.appendFile(&#x27;./logs/log1.txt&#x27;, &#x27; world&#x27;, () =&gt; &#123; console.log(&#x27;done.&#x27;)&#125;)// 读取文件内容fs.readFile(&#x27;./logs/log1.txt&#x27;, &#x27;utf-8&#x27;, (err, data) =&gt; &#123; console.log(data)&#125;)// 删除文件fs.unlink(&#x27;./logs/log1.txt&#x27;, (err) =&gt; &#123; console.log(&#x27;done.&#x27;)&#125;)// 批量写文件for (var i = 0; i &lt; 10; i++) &#123; fs.writeFile(`./logs/log-$&#123;i&#125;.txt`, `log-$&#123;i&#125;`, (err) =&gt; &#123; console.log(&#x27;done.&#x27;) &#125;)&#125;// 读取文件/目录信息fs.readdir(&#x27;./&#x27;, (err, data) =&gt; &#123; data.forEach((value, index) =&gt; &#123; fs.stat(`./$&#123;value&#125;`, (err, stats) =&gt; &#123; // console.log(value + &#x27;:&#x27; + stats.size) console.log(value + &#x27; is &#x27; + (stats.isDirectory() ? &#x27;directory&#x27; : &#x27;file&#x27;)) &#125;) &#125;)&#125;)// 同步读取文件try &#123; const content = fs.readFileSync(&#x27;./logs/log-1.txt&#x27;, &#x27;utf-8&#x27;) console.log(content) console.log(0)&#125; catch (e) &#123; console.log(e.message)&#125;console.log(1)// 异步读取文件：方法一fs.readFile(&#x27;./logs/log-0.txt&#x27;, &#x27;utf-8&#x27;, (err, content) =&gt; &#123; console.log(content) console.log(0)&#125;)console.log(1)// 异步读取文件：方法二fs.readFile(&#x27;./logs/log-0.txt&#x27;, &#x27;utf-8&#x27;).then(result =&gt; &#123; console.log(result)&#125;)// 异步读取文件：方法三function getFile() &#123; return new Promise((resolve) =&gt; &#123; fs.readFile(&#x27;./logs/log-0.txt&#x27;, &#x27;utf-8&#x27;, (err, data) =&gt; &#123; resolve(data) &#125;) &#125;)&#125;;(async () =&gt; &#123; console.log(await getFile())&#125;)()// 异步读取文件：方法四const fsp = fsP.readFile(&#x27;./logs/log-1.txt&#x27;, &#x27;utf-8&#x27;).then((result) =&gt; &#123; console.log(result)&#125;)console.log(fsP)// watch 监测文件变化fs.watch(&#x27;./logs/log-0.txt&#x27;, () =&gt; &#123; console.log(0)&#125;) 6、Stream123456const fs = require(&#x27;fs&#x27;)const readstream = fs.createReadStream(&#x27;./note.txt&#x27;)const writestream = fs.createWriteStream(&#x27;./note2.txt&#x27;)writestream.write(readstream) 7、Zlib12345678910111213const fs = require(&#x27;fs&#x27;)const zlib = require(&#x27;zlib&#x27;)const gzip = zlib.createGzip()const readstream = fs.createReadStream(&#x27;./note.txt&#x27;)const writestream = fs.createWriteStream(&#x27;./note2.txt&#x27;)readstream .pipe(gzip) .pipe(writestream)writestream.write(readstream) 8、ReadLine12345678910111213const readline = require(&#x27;readline&#x27;)const rl = readline.createInterface(&#123; input: process.stdin, output: process.stdout&#125;)rl.question(&#x27;What do you think of Node.js? &#x27;, (answer) =&gt; &#123; // TODO: Log the answer in a database console.log(`Thank you for your valuable feedback: $&#123;answer&#125;`) rl.close()&#125;) 9、Crypto1234567const crypto = require(&#x27;crypto&#x27;)const secret = &#x27;abcdefg&#x27;const hash = crypto.createHmac(&#x27;sha256&#x27;, secret) .update(&#x27;I love you&#x27;) .digest(&#x27;hex&#x27;)console.log(hash) 四、路由1234567891011121314151617181920212223242526272829303132333435var http = require(&#x27;http&#x27;)var fs = require(&#x27;fs&#x27;)http.createServer( function ( req, res ) &#123; switch ( req.url ) &#123; case &#x27;/home&#x27;: res.write(&#x27;home&#x27;) res.end() break case &#x27;/mine&#x27;: res.write(&#x27;mine&#x27;) res.end() break case &#x27;/login&#x27;: fs.readFile( &#x27;./static/login.html&#x27;,function ( error , data ) &#123; if ( error ) throw error res.write( data ) res.end() &#125;) break case &#x27;/fulian.jpg&#x27;: fs.readFile( &#x27;./static/fulian.jpg&#x27;, &#x27;binary&#x27;, function( error , data ) &#123; if( error ) throw error res.write( data, &#x27;binary&#x27; ) res.end() &#125;) break default: break &#125; &#125;).listen( 8000, &#x27;localhost&#x27;, function () &#123; console.log( &#x27;服务器运行在： http://localhost:8000&#x27; ) &#125;) 五、静态资源服务5.1 readStaticFile/modules/readStaticFile.js 1234567891011121314151617181920212223242526272829303132333435// 引入依赖的模块var path = require(&#x27;path&#x27;)var fs = require(&#x27;fs&#x27;)var mime = require(&#x27;mime&#x27;)function readStaticFile(res, filePathname) &#123; var ext = path.parse(filePathname).ext var mimeType = mime.getType(ext) // 判断路径是否有后缀, 有的话则说明客户端要请求的是一个文件 if (ext) &#123; // 根据传入的目标文件路径来读取对应文件 fs.readFile(filePathname, (err, data) =&gt; &#123; // 错误处理 if (err) &#123; res.writeHead(404, &#123; &quot;Content-Type&quot;: &quot;text/plain&quot; &#125;) res.write(&quot;404 - NOT FOUND&quot;) res.end() &#125; else &#123; res.writeHead(200, &#123; &quot;Content-Type&quot;: mimeType &#125;) res.write(data) res.end() &#125; &#125;); // 返回 true 表示, 客户端想要的 是 静态文件 return true &#125; else &#123; // 返回 false 表示, 客户端想要的 不是 静态文件 return false &#125;&#125;// 导出函数module.exports = readStaticFile 5.2 server/server.js 123456789101112131415161718192021// 引入相关模块var http = require(&#x27;http&#x27;);var url = require(&#x27;url&#x27;);var path = require(&#x27;path&#x27;);var readStaticFile = require(&#x27;./modules/readStaticFile&#x27;);// 搭建 HTTP 服务器var server = http.createServer(function(req, res) &#123; var urlObj = url.parse(req.url); var urlPathname = urlObj.pathname; var filePathname = path.join(__dirname, &quot;/public&quot;, urlPathname); // 读取静态文件 readStaticFile(res, filePathname);&#125;);// 在 3000 端口监听请求server.listen(3000, function() &#123; console.log(&quot;服务器运行中.&quot;); console.log(&quot;正在监听 3000 端口:&quot;)&#125;) 5.3 最终目录结构 Yarn 入门Yarn 对你的代码来说是一个包管理器。它可以让你使用并分享全世界开发者的（例如 JavaScript）代码。 Yarn 能够快速、安全、并可靠地完成这些工作，所以你不用有任何担心。 通过Yarn你可以使用其他开发者针对不同问题的解决方案，使自己的开发过程更简单。 代码通过包（package） (或者称为 模块（module）) 的方式来共享。 一个包里包含所有需要共享的代码，以及描述包信息的文件，称为 package.json。 1、安装yarn 安装请进 传送门 2、Yarn 使用方法现在 Yarn 已经 安装完毕，可以开始使用了。 以下是一些你需要的最常用的命令： 2.1 初始化一个新项目1yarn init 2.2 添加依赖包123yarn add [package]yarn add [package]@[version]yarn add [package]@[tag] 2.3 将依赖项添加到不同依赖项类别中分别添加到 devDependencies、peerDependencies 和 optionalDependencies 类别中： 123yarn add [package] --devyarn add [package] --peeryarn add [package] --optional devDependencies、peerDependencies 和 optionalDependencies区别 在一个Node.js项目中，package.json几乎是一个必须的文件，它的主要作用就是管理项目中所使用到的外部依赖包，同时它也是npm命令的入口文件。 npm 目前支持以下几类依赖包管理： dependencies devDependencies peerDependencies optionalDependencies bundledDependencies / bundleDependencies dependencies 应用依赖，或者叫做业务依赖，这是我们最常用的依赖包管理对象！它用于指定应用依赖的外部包，这些依赖是应用发布后正常执行时所需要的，但不包含测试时或者本地打包时所使用的包。 devDependencies 开发环境依赖，仅次于dependencies的使用频率！它的对象定义和dependencies一样，只不过它里面的包只用于开发环境，不用于生产环境，这些包通常是单元测试或者打包工具等，例如gulp, grunt, webpack, moca, coffee等。 peerDependencies 同等依赖，或者叫同伴依赖，用于指定当前包（也就是你写的包）兼容的宿主版本。如何理解呢？ 试想一下，我们编写一个gulp的插件，而gulp却有多个主版本，我们只想兼容最新的版本，此时就可以用同等依赖（peerDependencies）来指定。 1234567&#123; &quot;name&quot;: &quot;gulp-my-plugin&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;peerDependencies&quot;: &#123; &quot;gulp&quot;: &quot;3.x&quot; &#125;&#125; optionalDependencies 可选依赖，如果有一些依赖包即使安装失败，项目仍然能够运行或者希望npm继续运行，就可以使用optionalDependencies。另外optionalDependencies会覆盖dependencies中的同名依赖包，所以不要在两个地方都写。 bundledDependencies / bundleDependencies 打包依赖，bundledDependencies是一个包含依赖包名的数组对象，在发布时会将这个对象中的包打包到最终的发布包里。 2.4 升级依赖包123yarn upgrade [package]yarn upgrade [package]@[version]yarn upgrade [package]@[tag] 2.5 移除依赖包1yarn remove [package] 2.6 安装项目的全部依赖1yarn 或者 1yarn install Express基于 Node.js 平台，快速、开放、极简的 web 开发框架。 1$ npm install express --save 一、特色1、Web 应用Express 是一个基于 Node.js 平台的极简、灵活的 web 应用开发框架，它提供一系列强大的特性，帮助你创建各种 Web 和移动设备应用。 2、API丰富的 HTTP 快捷方法和任意排列组合的 Connect 中间件，让你创建健壮、友好的 API 变得既快速又简单。 3、性能Express 不对 Node.js 已有的特性进行二次抽象，我们只是在它之上扩展了 Web 应用所需的基本功能。 二、安装首先假定你已经安装了 Node.js，接下来为你的应用创建一个目录，然后进入此目录并将其作为当前工作目录。 12$ mkdir myapp$ cd myapp 通过 npm init 命令为你的应用创建一个 package.json 文件。 欲了解 package.json 是如何起作用的，请参考 Specifics of npm’s package.json handling。 1$ npm init 此命令将要求你输入几个参数，例如此应用的名称和版本。 你可以直接按“回车”键接受默认设置即可，下面这个除外： 1entry point: (index.js) 键入 app.js 或者你所希望的名称，这是当前应用的入口文件。如果你希望采用默认的 index.js 文件名，只需按“回车”键即可。 接下来安装 Express 并将其保存到依赖列表中： 1$ npm install express --save 如果只是临时安装 Express，不想将它添加到依赖列表中，只需略去 –save 参数即可： 1$ npm install express 安装 Node 模块时，如果指定了 –save 参数，那么此模块将被添加到 package.json 文件中 dependencies 依赖列表中。 然后通过 npm install 命令即可自动安装依赖列表中所列出的所有模块。 三、Hello world 实例接下来，我们一起创建一个基本的 Express 应用。 注意：这里所创建是一个最最简单的 Express 应用，并且仅仅只有一个文件 — 和通过 Express 应用生成器 所创建的应用完全不一样，Express 应用生成器所创建的应用框架包含多 JavaScript 文件、Jade 模板和针对不同用途的子目录。 进入 myapp 目录，创建一个名为 app.js 的文件，然后将下列代码复制进去： 12345678910111213var express = require(&#x27;express&#x27;);var app = express();app.get(&#x27;/&#x27;, function (req, res) &#123; res.send(&#x27;Hello World!&#x27;);&#125;);var server = app.listen(3000, function () &#123; var host = server.address().address; var port = server.address().port; console.log(&#x27;Example app listening at http://%s:%s&#x27;, host, port);&#125;); 上面的代码启动一个服务并监听从 3000 端口进入的所有连接请求。他将对所有 (/) URL 或 路由 返回 “Hello World!” 字符串。对于其他所有路径全部返回 404 Not Found。 req (请求) 和 res (响应) 与 Node 提供的对象完全一致，因此，你可以调用 req.pipe()、req.on(‘data’, callback) 以及任何 Node 提供的方法。 通过如下命令启动此应用： 1$ node app.js 然后在浏览器中打开 http://localhost:3000/ 并查看输出结果。 四、路由路由是指如何定义应用的端点（URIs）以及如何响应客户端的请求。 路由是由一个 URI、HTTP 请求（GET、POST等）和若干个句柄组成，它的结构如下： app.METHOD(path, [callback…], callback)， app 是 express 对象的一个实例， METHOD 是一个 HTTP 请求方法， path 是服务器上的路径， callback 是当路由匹配时要执行的函数。 下面是一个基本的路由示例： 1234567var express = require(&#x27;express&#x27;);var app = express();// respond with &quot;hello world&quot; when a GET request is made to the homepageapp.get(&#x27;/&#x27;, function(req, res) &#123; res.send(&#x27;hello world&#x27;);&#125;); 1、路由方法路由方法源于 HTTP 请求方法，和 express 实例相关联。 下面这个例子展示了为应用跟路径定义的 GET 和 POST 请求： 1234567891011121314151617181920// GET method route// 对网站首页的访问返回 &quot;Hello World!&quot; 字样app.get(&#x27;/&#x27;, function (req, res) &#123; res.send(&#x27;Hello World!&#x27;)&#125;)// 网站首页接受 POST 请求app.post(&#x27;/&#x27;, function (req, res) &#123; res.send(&#x27;Got a POST request&#x27;)&#125;)// /user 节点接受 PUT 请求app.put(&#x27;/user&#x27;, function (req, res) &#123; res.send(&#x27;Got a PUT request at /user&#x27;)&#125;)// /user 节点接受 DELETE 请求app.delete(&#x27;/user&#x27;, function (req, res) &#123; res.send(&#x27;Got a DELETE request at /user&#x27;)&#125;) Express 定义了如下和 HTTP 请求对应的路由方法： get, post, put, head, delete, options, trace, copy, lock, mkcol, move, purge, propfind, proppatch, unlock, report, mkactivity, checkout, merge, m-search, notify, subscribe, unsubscribe, patch, search, 和 connect。 有些路由方法名不是合规的 JavaScript 变量名，此时使用括号记法，比如： app[‘m-search’](‘/‘, function … app.all() 是一个特殊的路由方法，没有任何 HTTP 方法与其对应，它的作用是对于一个路径上的所有请求加载中间件。 在下面的例子中，来自 “/secret” 的请求，不管使用 GET、POST、PUT、DELETE 或其他任何 http 模块支持的 HTTP 请求，句柄都会得到执行。 1234app.all(&#x27;/secret&#x27;, function (req, res, next) &#123; console.log(&#x27;Accessing the secret section ...&#x27;) next(); // pass control to the next handler&#125;) 2、路由路径路由路径和请求方法一起定义了请求的端点，它可以是字符串、字符串模式或者正则表达式。 Express 使用 path-to-regexp 匹配路由路径，请参考文档查阅所有定义路由路径的方法。 Express Route Tester 是测试基本 Express 路径的好工具，但不支持模式匹配。 查询字符串不是路由路径的一部分。 使用字符串的路由路径示例： 1234567891011121314// 匹配根路径的请求app.get(&#x27;/&#x27;, function (req, res) &#123; res.send(&#x27;root&#x27;);&#125;);// 匹配 /about 路径的请求app.get(&#x27;/about&#x27;, function (req, res) &#123; res.send(&#x27;about&#x27;);&#125;);// 匹配 /random.text 路径的请求app.get(&#x27;/random.text&#x27;, function (req, res) &#123; res.send(&#x27;random.text&#x27;);&#125;); 使用字符串模式的路由路径示例： 12345678910111213141516171819// 匹配 acd 和 abcdapp.get(&#x27;/ab?cd&#x27;, function(req, res) &#123; res.send(&#x27;ab?cd&#x27;);&#125;);// 匹配 abcd、abbcd、abbbcd等app.get(&#x27;/ab+cd&#x27;, function(req, res) &#123; res.send(&#x27;ab+cd&#x27;);&#125;);// 匹配 abcd、abxcd、abRABDOMcd、ab123cd等app.get(&#x27;/ab*cd&#x27;, function(req, res) &#123; res.send(&#x27;ab*cd&#x27;);&#125;);// 匹配 /abe 和 /abcdeapp.get(&#x27;/ab(cd)?e&#x27;, function(req, res) &#123; res.send(&#x27;ab(cd)?e&#x27;);&#125;); 字符 ?、+、* 和 () 是正则表达式的子集，- 和 . 在基于字符串的路径中按照字面值解释。 使用正则表达式的路由路径示例： 123456789// 匹配任何路径中含有 a 的路径：app.get(/a/, function(req, res) &#123; res.send(&#x27;/a/&#x27;);&#125;);// 匹配 butterfly、dragonfly，不匹配 butterflyman、dragonfly man等app.get(/.*fly$/, function(req, res) &#123; res.send(&#x27;/.*fly$/&#x27;);&#125;); 3、路由句柄可以为请求处理提供多个回调函数，其行为类似 中间件。唯一的区别是这些回调函数有可能调用 next(‘route’) 方法而略过其他路由回调函数。可以利用该机制为路由定义前提条件，如果在现有路径上继续执行没有意义，则可将控制权交给剩下的路径。 路由句柄有多种形式，可以是一个函数、一个函数数组，或者是两者混合，如下所示. 使用一个回调函数处理路由： 123app.get(&#x27;/example/a&#x27;, function (req, res) &#123; res.send(&#x27;Hello from A!&#x27;);&#125;); 使用多个回调函数处理路由（记得指定 next 对象）： 123456app.get(&#x27;/example/b&#x27;, function (req, res, next) &#123; console.log(&#x27;response will be sent by the next function ...&#x27;); next();&#125;, function (req, res) &#123; res.send(&#x27;Hello from B!&#x27;);&#125;); 使用回调函数数组处理路由： 123456789101112131415var cb0 = function (req, res, next) &#123; console.log(&#x27;CB0&#x27;) next()&#125;var cb1 = function (req, res, next) &#123; console.log(&#x27;CB1&#x27;) next()&#125;var cb2 = function (req, res) &#123; res.send(&#x27;Hello from C!&#x27;)&#125;app.get(&#x27;/example/c&#x27;, [cb0, cb1, cb2]) 混合使用函数和函数数组处理路由： 12345678910111213141516var cb0 = function (req, res, next) &#123; console.log(&#x27;CB0&#x27;) next()&#125;var cb1 = function (req, res, next) &#123; console.log(&#x27;CB1&#x27;) next()&#125;app.get(&#x27;/example/d&#x27;, [cb0, cb1], function (req, res, next) &#123; console.log(&#x27;response will be sent by the next function ...&#x27;) next()&#125;, function (req, res) &#123; res.send(&#x27;Hello from D!&#x27;)&#125;) 4、响应方法下表中响应对象（res）的方法向客户端返回响应，终结请求响应的循环。如果在路由句柄中一个方法也不调用，来自客户端的请求会一直挂起。 方法 描述 res.download() 提示下载文件。 res.end() 终结响应处理流程。 res.json() 发送一个 JSON 格式的响应。 res.jsonp() 发送一个支持 JSONP 的 JSON 格式的响应。 res.redirect() 重定向请求。 res.render() 渲染视图模板。 res.send() 发送各种类型的响应。 res.sendFile 以八位字节流的形式发送文件。 res.sendStatus() 设置响应状态代码，并将其以字符串形式作为响应体的一部分发送。 5、app.route()可使用 app.route() 创建路由路径的链式路由句柄。由于路径在一个地方指定，这样做有助于创建模块化的路由，而且减少了代码冗余和拼写错误。 下面这个示例程序使用 app.route() 定义了链式路由句柄。 12345678910app.route(&#x27;/book&#x27;) .get(function(req, res) &#123; res.send(&#x27;Get a random book&#x27;); &#125;) .post(function(req, res) &#123; res.send(&#x27;Add a book&#x27;); &#125;) .put(function(req, res) &#123; res.send(&#x27;Update the book&#x27;); &#125;); 6、express.Router可使用 express.Router 类创建模块化、可挂载的路由句柄。Router 实例是一个完整的中间件和路由系统，因此常称其为一个 “mini-app”。 下面的实例程序创建了一个路由模块，并加载了一个中间件，定义了一些路由，并且将它们挂载至应用的路径上。 在 app 目录下创建名为 birds.js 的文件，内容如下： 123456789101112131415161718var express = require(&#x27;express&#x27;);var router = express.Router();// 该路由使用的中间件router.use(function timeLog(req, res, next) &#123; console.log(&#x27;Time: &#x27;, Date.now()); next();&#125;);// 定义网站主页的路由router.get(&#x27;/&#x27;, function(req, res) &#123; res.send(&#x27;Birds home page&#x27;);&#125;);// 定义 about 页面的路由router.get(&#x27;/about&#x27;, function(req, res) &#123; res.send(&#x27;About birds&#x27;);&#125;);module.exports = router; 然后在应用中加载路由模块： 123var birds = require(&#x27;./birds&#x27;)...app.use(&#x27;/birds&#x27;, birds) 应用即可处理发自 /birds 和 /birds/about 的请求，并且调用为该路由指定的 timeLog 中间件。 五、利用 Express 托管静态文件通过 Express 内置的 express.static 可以方便地托管静态文件，例如图片、CSS、JavaScript 文件等。 将静态资源文件所在的目录作为参数传递给 express.static 中间件就可以提供静态资源文件的访问了。例如，假设在 public 目录放置了图片、CSS 和 JavaScript 文件，你就可以： 1app.use(express.static(&#x27;public&#x27;)) 现在，public 目录下面的文件就可以访问了。 12345http://localhost:3000/images/kitten.jpghttp://localhost:3000/css/style.csshttp://localhost:3000/js/app.jshttp://localhost:3000/images/bg.pnghttp://localhost:3000/hello.html 所有文件的路径都是相对于存放目录的，因此，存放静态文件的目录名不会出现在 URL 中。 如果你的静态资源存放在多个目录下面，你可以多次调用 express.static 中间件： 12app.use(express.static(&#x27;public&#x27;))app.use(express.static(&#x27;files&#x27;)) 访问静态资源文件时，express.static 中间件会根据目录添加的顺序查找所需的文件。 如果你希望所有通过 express.static 访问的文件都存放在一个“虚拟（virtual）”目录（即目录根本不存在）下面，可以通过为静态资源目录指定一个挂载路径的方式来实现，如下所示： 1app.use(&#x27;/static&#x27;, express.static(&#x27;public&#x27;)) 现在，你就可以通过带有 “/static” 前缀的地址来访问 public 目录下面的文件了。 12345http://localhost:3000/static/images/kitten.jpghttp://localhost:3000/static/css/style.csshttp://localhost:3000/static/js/app.jshttp://localhost:3000/static/images/bg.pnghttp://localhost:3000/static/hello.html 六、使用中间件Express 是一个自身功能极简，完全是由路由和中间件构成一个的 web 开发框架：从本质上来说，一个 Express 应用就是在调用各种中间件。 中间件（Middleware） 是一个函数，它可以访问请求对象（request object (req)）, 响应对象（response object (res)）, 和 web 应用中处于请求-响应循环流程中的中间件，一般被命名为 next 的变量。 中间件的功能包括： 执行任何代码。 修改请求和响应对象。 终结请求-响应循环。 调用堆栈中的下一个中间件。 如果当前中间件没有终结请求-响应循环，则必须调用 next() 方法将控制权交给下一个中间件，否则请求就会挂起。 Express 应用可使用如下几种中间件： 应用级中间件 路由级中间件 错误处理中间件 内置中间件 第三方中间件 使用可选则挂载路径，可在应用级别或路由级别装载中间件。另外，你还可以同时装在一系列中间件函数，从而在一个挂载点上创建一个子中间件栈。 1、应用级中间件应用级中间件绑定到 app 对象 使用 app.use() 和 app.METHOD()， 其中， METHOD 是需要处理的 HTTP 请求的方法，例如 GET, PUT, POST 等等，全部小写。例如： 123456789101112131415161718var app = express()// 没有挂载路径的中间件，应用的每个请求都会执行该中间件app.use(function (req, res, next) &#123; console.log(&#x27;Time:&#x27;, Date.now()) next()&#125;)// 挂载至 /user/:id 的中间件，任何指向 /user/:id 的请求都会执行它app.use(&#x27;/user/:id&#x27;, function (req, res, next) &#123; console.log(&#x27;Request Type:&#x27;, req.method) next()&#125;)// 路由和句柄函数(中间件系统)，处理指向 /user/:id 的 GET 请求app.get(&#x27;/user/:id&#x27;, function (req, res, next) &#123; res.send(&#x27;USER&#x27;)&#125;) 下面这个例子展示了在一个挂载点装载一组中间件。 12345678// 一个中间件栈，对任何指向 /user/:id 的 HTTP 请求打印出相关信息app.use(&#x27;/user/:id&#x27;, function(req, res, next) &#123; console.log(&#x27;Request URL:&#x27;, req.originalUrl) next()&#125;, function (req, res, next) &#123; console.log(&#x27;Request Type:&#x27;, req.method) next()&#125;) 作为中间件系统的路由句柄，使得为路径定义多个路由成为可能。在下面的例子中，为指向 /user/:id 的 GET 请求定义了两个路由。第二个路由虽然不会带来任何问题，但却永远不会被调用，因为第一个路由已经终止了请求-响应循环。 123456789101112// 一个中间件栈，处理指向 /user/:id 的 GET 请求app.get(&#x27;/user/:id&#x27;, function (req, res, next) &#123; console.log(&#x27;ID:&#x27;, req.params.id) next()&#125;, function (req, res, next) &#123; res.send(&#x27;User Info&#x27;)&#125;)// 处理 /user/:id， 打印出用户 idapp.get(&#x27;/user/:id&#x27;, function (req, res, next) &#123; res.end(req.params.id)&#125;) 如果需要在中间件栈中跳过剩余中间件，调用 next(‘route’) 方法将控制权交给下一个路由。 注意： next(‘route’) 只对使用 app.VERB() 或 router.VERB() 加载的中间件有效。 123456789101112131415// 一个中间件栈，处理指向 /user/:id 的 GET 请求app.get(&#x27;/user/:id&#x27;, function (req, res, next) &#123; // 如果 user id 为 0, 跳到下一个路由 if (req.params.id == 0) next(&#x27;route&#x27;) // 否则将控制权交给栈中下一个中间件 else next() //&#125;, function (req, res, next) &#123; // 渲染常规页面 res.render(&#x27;regular&#x27;)&#125;);// 处理 /user/:id， 渲染一个特殊页面app.get(&#x27;/user/:id&#x27;, function (req, res, next) &#123; res.render(&#x27;special&#x27;)&#125;) 2、路由级中间件路由级中间件和应用级中间件一样，只是它绑定的对象为 express.Router()。 1var router = express.Router() 路由级使用 router.use() 或 router.VERB() 加载。 上述在应用级创建的中间件系统，可通过如下代码改写为路由级： 12345678910111213141516171819202122232425262728293031323334353637var app = express()var router = express.Router()// 没有挂载路径的中间件，通过该路由的每个请求都会执行该中间件router.use(function (req, res, next) &#123; console.log(&#x27;Time:&#x27;, Date.now()) next()&#125;)// 一个中间件栈，显示任何指向 /user/:id 的 HTTP 请求的信息router.use(&#x27;/user/:id&#x27;, function(req, res, next) &#123; console.log(&#x27;Request URL:&#x27;, req.originalUrl) next()&#125;, function (req, res, next) &#123; console.log(&#x27;Request Type:&#x27;, req.method) next()&#125;)// 一个中间件栈，处理指向 /user/:id 的 GET 请求router.get(&#x27;/user/:id&#x27;, function (req, res, next) &#123; // 如果 user id 为 0, 跳到下一个路由 if (req.params.id == 0) next(&#x27;route&#x27;) // 负责将控制权交给栈中下一个中间件 else next() //&#125;, function (req, res, next) &#123; // 渲染常规页面 res.render(&#x27;regular&#x27;)&#125;)// 处理 /user/:id， 渲染一个特殊页面router.get(&#x27;/user/:id&#x27;, function (req, res, next) &#123; console.log(req.params.id) res.render(&#x27;special&#x27;)&#125;)// 将路由挂载至应用app.use(&#x27;/&#x27;, router) 3、错误处理中间件 错误处理中间件有 4 个参数，定义错误处理中间件时必须使用这 4 个参数。即使不需要 next 对象，也必须在签名中声明它，否则中间件会被识别为一个常规中间件，不能处理错误。 错误处理中间件和其他中间件定义类似，只是要使用 4 个参数，而不是 3 个，其签名如下： (err, req, res, next)。 1234app.use(function(err, req, res, next) &#123; console.error(err.stack) res.status(500).send(&#x27;Something broke!&#x27;)&#125;) 4、内置中间件从 4.x 版本开始，, Express 已经不再依赖 Connect 了。除了 express.static, Express 以前内置的中间件现在已经全部单独作为模块安装使用了。请参考 中间件列表。 express.static(root, [options]) express.static 是 Express 唯一内置的中间件。它基于 serve-static，负责在 Express 应用中提托管静态资源。 参数 root 指提供静态资源的根目录。 可选的 options 参数拥有如下属性。 属性 描述 类型 缺省值 dotfiles 是否对外输出文件名以点（.）开头的文件。可选值为 “allow”、“deny” 和 “ignore” String “ignore” etag 是否启用 etag 生成 Boolean true extensions 设置文件扩展名备份选项 Array [] index 发送目录索引文件，设置为 false 禁用目录索引。 Mixed “index.html” lastModified 设置 Last-Modified 头为文件在操作系统上的最后修改日期。可能值为 true 或 false。 Boolean true maxAge 以毫秒或者其字符串格式设置 Cache-Control 头的 max-age 属性。 Number 0 redirect 当路径为目录时，重定向至 “/”。 Boolean true setHeaders 设置 HTTP 头以提供文件的函数。 Function 下面的例子使用了 express.static 中间件，其中的 options 对象经过了精心的设计。 12345678910111213var options = &#123; dotfiles: &#x27;ignore&#x27;, etag: false, extensions: [&#x27;htm&#x27;, &#x27;html&#x27;], index: false, maxAge: &#x27;1d&#x27;, redirect: false, setHeaders: function (res, path, stat) &#123; res.set(&#x27;x-timestamp&#x27;, Date.now()) &#125;&#125;app.use(express.static(&#x27;public&#x27;, options)) 每个应用可有多个静态目录。 123app.use(express.static(&#x27;public&#x27;))app.use(express.static(&#x27;uploads&#x27;))app.use(express.static(&#x27;files&#x27;)) 5、第三方中间件通过使用第三方中间件从而为 Express 应用增加更多功能。 安装所需功能的 node 模块，并在应用中加载，可以在应用级加载，也可以在路由级加载。 下面的例子安装并加载了一个解析 cookie 的中间件： cookie-parser 1234567$ npm install cookie-parservar express = require(&#x27;express&#x27;)var app = express()var cookieParser = require(&#x27;cookie-parser&#x27;)// 加载用于解析 cookie 的中间件app.use(cookieParser()) 七、在 Express 中使用模板引擎需要在应用中进行如下设置才能让 Express 渲染模板文件： views, 放模板文件的目录，比如： app.set(‘views’, ‘./views’) view engine, 模板引擎，比如： app.set(‘view engine’, ‘ejs’) art-templateart-template for express 4.x. 1、Install12npm install --save art-templatenpm install --save express-art-template 2、Example1234567891011121314151617181920var express = require(&#x27;express&#x27;)var app = express()// view engine setupapp.engine(&#x27;art&#x27;, require(&#x27;express-art-template&#x27;))app.set(&#x27;view&#x27;, &#123; debug: process.env.NODE_ENV !== &#x27;production&#x27;&#125;)app.set(&#x27;views&#x27;, path.join(__dirname, &#x27;views&#x27;))app.set(&#x27;view engine&#x27;, &#x27;art&#x27;)// routesapp.get(&#x27;/&#x27;, function (req, res) &#123; res.render(&#x27;index.art&#x27;, &#123; user: &#123; name: &#x27;aui&#x27;, tags: [&#x27;art&#x27;, &#x27;template&#x27;, &#x27;nodejs&#x27;] &#125; &#125;)&#125;) Koa2一、koa2 快速开始1、环境准备因为node.js v7.6.0开始完全支持async/await，不需要加flag，所以node.js环境都要7.6.0以上 node.js环境 版本v7.6以上 npm 版本3.x以上 2、快速开始2.1 安装koa212345# 初始化package.jsonnpm init# 安装koa2 npm install koa 2.2 hello world 代码123456789const Koa = require(&#x27;koa&#x27;)const app = new Koa()app.use( async ( ctx ) =&gt; &#123; ctx.body = &#x27;hello koa2&#x27;&#125;)app.listen(3000)console.log(&#x27;[demo] start-quick is starting at port 3000&#x27;) 2.3 启动demo由于koa2是基于async/await操作中间件，目前node.js 7.x的harmony模式下才能使用，所以启动的时的脚本如下： 1node index.js 二、async/await使用1、快速上手理解先复制以下这段代码，在粘贴在chrome的控制台console中，按回车键执行 123456789101112131415161718192021222324252627function getSyncTime() &#123; return new Promise((resolve, reject) =&gt; &#123; try &#123; let startTime = new Date().getTime() setTimeout(() =&gt; &#123; let endTime = new Date().getTime() let data = endTime - startTime resolve( data ) &#125;, 500) &#125; catch ( err ) &#123; reject( err ) &#125; &#125;)&#125;async function getSyncData() &#123; let time = await getSyncTime() let data = `endTime - startTime = $&#123;time&#125;` return data&#125;async function getData() &#123; let data = await getSyncData() console.log( data )&#125;getData() 2、从上述例子可以看出 async/await 的特点： 可以让异步逻辑用同步写法实现 最底层的await返回需要是Promise对象 可以通过多层 async function 的同步写法代替传统的callback嵌套 三、koa2简析结构1、源码文件├── lib │ ├── application.js │ ├── context.js │ ├── request.js │ └── response.js └── package.json 这个就是 GitHub https://github.com/koajs/koa上开源的koa2源码的源文件结构，核心代码就是lib目录下的四个文件 application.js 是整个koa2 的入口文件，封装了context，request，response，以及最核心的中间件处理流程。 context.js 处理应用上下文，里面直接封装部分request.js和response.js的方法 request.js 处理http请求 response.js 处理http响应 2、koa2特性 只提供封装好http上下文、请求、响应，以及基于async/await的中间件容器。 利用ES7的async/await的来处理传统回调嵌套问题和代替koa@1的generator，但是需要在node.js 7.x的harmony模式下才能支持async/await。 中间件只支持 async/await 封装的，如果要使用koa@1基于generator中间件，需要通过中间件koa-convert封装一下才能使用。 四、koa中间件开发和使用 koa v1和v2中使用到的中间件的开发和使用 generator 中间件开发在koa v1和v2中使用 async await 中间件开发和只能在koa v2中使用 1、generator中间件开发1.1 generator中间件开发 generator中间件返回的应该是function * () 函数 12345678910111213141516/* ./middleware/logger-generator.js */function log( ctx ) &#123; console.log( ctx.method, ctx.header.host + ctx.url )&#125;module.exports = function () &#123; return function * ( next ) &#123; // 执行中间件的操作 log( this ) if ( next ) &#123; yield next &#125; &#125;&#125; 1.2 generator中间件在koa@1中的使用 generator 中间件在koa v1中可以直接use使用 123456789101112const koa = require(&#x27;koa&#x27;) // koa v1const loggerGenerator = require(&#x27;./middleware/logger-generator&#x27;)const app = koa()app.use(loggerGenerator())app.use(function *( ) &#123; this.body = &#x27;hello world!&#x27;&#125;)app.listen(3000)console.log(&#x27;the server is starting at port 3000&#x27;) 1.3 generator中间件在koa@2中的使用 generator 中间件在koa v2中需要用koa-convert封装一下才能使用 12345678910111213const Koa = require(&#x27;koa&#x27;) // koa v2const convert = require(&#x27;koa-convert&#x27;)const loggerGenerator = require(&#x27;./middleware/logger-generator&#x27;)const app = new Koa()app.use(convert(loggerGenerator()))app.use(( ctx ) =&gt; &#123; ctx.body = &#x27;hello world!&#x27;&#125;)app.listen(3000)console.log(&#x27;the server is starting at port 3000&#x27;) 2、async中间件开发2.1 async 中间件开发123456789101112/* ./middleware/logger-async.js */function log( ctx ) &#123; console.log( ctx.method, ctx.header.host + ctx.url )&#125;module.exports = function () &#123; return async function ( ctx, next ) &#123; log(ctx); await next() &#125;&#125; 2.2 async 中间件在koa@2中使用 async 中间件只能在 koa v2中使用 123456789101112const Koa = require(&#x27;koa&#x27;) // koa v2const loggerAsync = require(&#x27;./middleware/logger-async&#x27;)const app = new Koa()app.use(loggerAsync())app.use(( ctx ) =&gt; &#123; ctx.body = &#x27;hello world!&#x27;&#125;)app.listen(3000)console.log(&#x27;the server is starting at port 3000&#x27;) Ⅱ、路由一、koa2 原生路由实现1、简单例子12345678const Koa = require(&#x27;koa&#x27;)const app = new Koa()app.use( async ( ctx ) =&gt; &#123; let url = ctx.request.url ctx.body = url&#125;)app.listen(3000) 访问 http://localhost:3000/hello/world 页面会输出 /hello/world，也就是说上下文的请求request对象中url之就是当前访问的路径名称，可以根据ctx.request.url 通过一定的判断或者正则匹配就可以定制出所需要的路由。 2、定制化的路由demo源码 https://github.com/ChenShenhai/koa2-note/tree/master/demo/route-simple 2.1 源码文件目录1234567.├── index.js├── package.json└── view ├── 404.html ├── index.html └── todo.html 2.2 demo源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657const Koa = require(&#x27;koa&#x27;)const fs = require(&#x27;fs&#x27;)const app = new Koa()/** * 用Promise封装异步读取文件方法 * @param &#123;string&#125; page html文件名称 * @return &#123;promise&#125; */function render( page ) &#123; return new Promise(( resolve, reject ) =&gt; &#123; let viewUrl = `./view/$&#123;page&#125;` fs.readFile(viewUrl, &quot;binary&quot;, ( err, data ) =&gt; &#123; if ( err ) &#123; reject( err ) &#125; else &#123; resolve( data ) &#125; &#125;) &#125;)&#125;/** * 根据URL获取HTML内容 * @param &#123;string&#125; url koa2上下文的url，ctx.url * @return &#123;string&#125; 获取HTML文件内容 */async function route( url ) &#123; let view = &#x27;404.html&#x27; switch ( url ) &#123; case &#x27;/&#x27;: view = &#x27;index.html&#x27; break case &#x27;/index&#x27;: view = &#x27;index.html&#x27; break case &#x27;/todo&#x27;: view = &#x27;todo.html&#x27; break case &#x27;/404&#x27;: view = &#x27;404.html&#x27; break default: break &#125; let html = await render( view ) return html&#125;app.use( async ( ctx ) =&gt; &#123; let url = ctx.request.url let html = await route( url ) ctx.body = html&#125;)app.listen(3000)console.log(&#x27;[demo] route-simple is starting at port 3000&#x27;) 2.3 运行demo执行运行脚本 1node -harmony index.js 二、koa-router中间件如果依靠ctx.request.url去手动处理路由，将会写很多处理代码，这时候就需要对应的路由的中间件对路由进行控制，这里介绍一个比较好用的路由中间件koa-router 1、安装koa-router中间件12# koa2 对应的版本是 7.xnpm install --save koa-router@7 2、快速使用koa-router1234567891011121314151617181920212223242526272829303132333435363738const Koa = require(&#x27;koa&#x27;)const fs = require(&#x27;fs&#x27;)const app = new Koa()const Router = require(&#x27;koa-router&#x27;)let home = new Router()// 子路由1home.get(&#x27;/&#x27;, async ( ctx )=&gt;&#123; let html = ` &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/page/helloworld&quot;&gt;/page/helloworld&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/page/404&quot;&gt;/page/404&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; ` ctx.body = html&#125;)// 子路由2let page = new Router()page.get(&#x27;/404&#x27;, async ( ctx )=&gt;&#123; ctx.body = &#x27;404 page!&#x27;&#125;).get(&#x27;/helloworld&#x27;, async ( ctx )=&gt;&#123; ctx.body = &#x27;helloworld page!&#x27;&#125;)// 装载所有子路由let router = new Router()router.use(&#x27;/&#x27;, home.routes(), home.allowedMethods())router.use(&#x27;/page&#x27;, page.routes(), page.allowedMethods())// 加载路由中间件app.use(router.routes()).use(router.allowedMethods())app.listen(3000, () =&gt; &#123; console.log(&#x27;[demo] route-use-middleware is starting at port 3000&#x27;)&#125;) Ⅲ、请求数据获取一、GET请求数据获取1、使用方法在koa中，获取GET请求数据源头是koa中request对象中的query方法或querystring方法，query返回是格式化好的参数对象，querystring返回的是请求字符串，由于ctx对request的API有直接引用的方式，所以获取GET请求数据有两个途径。 是从上下文中直接获取 请求对象ctx.query，返回如 { a:1, b:2 } 请求字符串 ctx.querystring，返回如 a=1&amp;b=2 是从上下文的request对象中获取 请求对象ctx.request.query，返回如 { a:1, b:2 } 请求字符串 ctx.request.querystring，返回如 a=1&amp;b=2 2、举个例子2.1 例子代码1234567891011121314151617181920212223242526const Koa = require(&#x27;koa&#x27;)const app = new Koa()app.use( async ( ctx ) =&gt; &#123; let url = ctx.url // 从上下文的request对象中获取 let request = ctx.request let req_query = request.query let req_querystring = request.querystring // 从上下文中直接获取 let ctx_query = ctx.query let ctx_querystring = ctx.querystring ctx.body = &#123; url, req_query, req_querystring, ctx_query, ctx_querystring &#125;&#125;)app.listen(3000, () =&gt; &#123; console.log(&#x27;[demo] request get is starting at port 3000&#x27;)&#125;) 2.2 执行程序1node get.js 二、POST请求参数获取1、原理对于POST请求的处理，koa2没有封装获取参数的方法，需要通过解析上下文context中的原生node.js请求对象req，将POST表单数据解析成query string（例如：a=1&amp;b=2&amp;c=3），再将query string 解析成JSON格式（例如：{“a”:”1”, “b”:”2”, “c”:”3”}） 注意：ctx.request是context经过封装的请求对象，ctx.req是context提供的node.js原生HTTP请求对象，同理ctx.response是context经过封装的响应对象，ctx.res是context提供的node.js原生HTTP请求对象。 解析出POST请求上下文中的表单数据1234567891011121314151617181920212223242526272829// 解析上下文里node原生请求的POST参数function parsePostData( ctx ) &#123; return new Promise((resolve, reject) =&gt; &#123; try &#123; let postdata = &quot;&quot;; ctx.req.addListener(&#x27;data&#x27;, (data) =&gt; &#123; postdata += data &#125;) ctx.req.addListener(&quot;end&quot;,function()&#123; let parseData = parseQueryStr( postdata ) resolve( parseData ) &#125;) &#125; catch ( err ) &#123; reject(err) &#125; &#125;)&#125;// 将POST请求参数字符串解析成JSONfunction parseQueryStr( queryStr ) &#123; let queryData = &#123;&#125; let queryStrList = queryStr.split(&#x27;&amp;&#x27;) console.log( queryStrList ) for ( let [ index, queryStr ] of queryStrList.entries() ) &#123; let itemList = queryStr.split(&#x27;=&#x27;) queryData[ itemList[0] ] = decodeURIComponent(itemList[1]) &#125; return queryData&#125; 2、举个例子2.1 例子代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263const Koa = require(&#x27;koa&#x27;)const app = new Koa()app.use( async ( ctx ) =&gt; &#123; if ( ctx.url === &#x27;/&#x27; &amp;&amp; ctx.method === &#x27;GET&#x27; ) &#123; // 当GET请求时候返回表单页面 let html = ` &lt;h1&gt;koa2 request post demo&lt;/h1&gt; &lt;form method=&quot;POST&quot; action=&quot;/&quot;&gt; &lt;p&gt;userName&lt;/p&gt; &lt;input name=&quot;userName&quot; /&gt;&lt;br/&gt; &lt;p&gt;nickName&lt;/p&gt; &lt;input name=&quot;nickName&quot; /&gt;&lt;br/&gt; &lt;p&gt;email&lt;/p&gt; &lt;input name=&quot;email&quot; /&gt;&lt;br/&gt; &lt;button type=&quot;submit&quot;&gt;submit&lt;/button&gt; &lt;/form&gt; ` ctx.body = html &#125; else if ( ctx.url === &#x27;/&#x27; &amp;&amp; ctx.method === &#x27;POST&#x27; ) &#123; // 当POST请求的时候，解析POST表单里的数据，并显示出来 let postData = await parsePostData( ctx ) ctx.body = postData &#125; else &#123; // 其他请求显示404 ctx.body = &#x27;&lt;h1&gt;404！！！ o(╯□╰)o&lt;/h1&gt;&#x27; &#125;&#125;)// 解析上下文里node原生请求的POST参数function parsePostData( ctx ) &#123; return new Promise((resolve, reject) =&gt; &#123; try &#123; let postdata = &quot;&quot;; ctx.req.addListener(&#x27;data&#x27;, (data) =&gt; &#123; postdata += data &#125;) ctx.req.addListener(&quot;end&quot;,function()&#123; let parseData = parseQueryStr( postdata ) resolve( parseData ) &#125;) &#125; catch ( err ) &#123; reject(err) &#125; &#125;)&#125;// 将POST请求参数字符串解析成JSONfunction parseQueryStr( queryStr ) &#123; let queryData = &#123;&#125; let queryStrList = queryStr.split(&#x27;&amp;&#x27;) console.log( queryStrList ) for ( let [ index, queryStr ] of queryStrList.entries() ) &#123; let itemList = queryStr.split(&#x27;=&#x27;) queryData[ itemList[0] ] = decodeURIComponent(itemList[1]) &#125; return queryData&#125;app.listen(3000, () =&gt; &#123; console.log(&#x27;[demo] request post is starting at port 3000&#x27;)&#125;) 2.2 启动例子1node post.js 三、koa-bodyparser中间件1、原理对于POST请求的处理，koa-bodyparser中间件可以把koa2上下文的formData数据解析到ctx.request.body中 安装koa2版本的koa-bodyparser@3中间件1npm install --save koa-bodyparser@3 2、举个例子2.1 例子代码12345678910111213141516171819202122232425262728293031323334353637const Koa = require(&#x27;koa&#x27;)const app = new Koa()const bodyParser = require(&#x27;koa-bodyparser&#x27;)// 使用ctx.body解析中间件app.use(bodyParser())app.use( async ( ctx ) =&gt; &#123; if ( ctx.url === &#x27;/&#x27; &amp;&amp; ctx.method === &#x27;GET&#x27; ) &#123; // 当GET请求时候返回表单页面 let html = ` &lt;h1&gt;koa2 request post demo&lt;/h1&gt; &lt;form method=&quot;POST&quot; action=&quot;/&quot;&gt; &lt;p&gt;userName&lt;/p&gt; &lt;input name=&quot;userName&quot; /&gt;&lt;br/&gt; &lt;p&gt;nickName&lt;/p&gt; &lt;input name=&quot;nickName&quot; /&gt;&lt;br/&gt; &lt;p&gt;email&lt;/p&gt; &lt;input name=&quot;email&quot; /&gt;&lt;br/&gt; &lt;button type=&quot;submit&quot;&gt;submit&lt;/button&gt; &lt;/form&gt; ` ctx.body = html &#125; else if ( ctx.url === &#x27;/&#x27; &amp;&amp; ctx.method === &#x27;POST&#x27; ) &#123; // 当POST请求的时候，中间件koa-bodyparser解析POST表单里的数据，并显示出来 let postData = ctx.request.body ctx.body = postData &#125; else &#123; // 其他请求显示404 ctx.body = &#x27;&lt;h1&gt;404！！！ o(╯□╰)o&lt;/h1&gt;&#x27; &#125;&#125;)app.listen(3000, () =&gt; &#123; console.log(&#x27;[demo] request post is starting at port 3000&#x27;)&#125;) 2.2 启动例子1node post-middleware.js Ⅳ、静态资源加载koa-static中间件使用1、使用例子123456789101112131415161718192021const Koa = require(&#x27;koa&#x27;)const path = require(&#x27;path&#x27;)const static = require(&#x27;koa-static&#x27;)const app = new Koa()// 静态资源目录对于相对入口文件index.js的路径const staticPath = &#x27;./static&#x27;app.use(static( path.join( __dirname, staticPath)))app.use( async ( ctx ) =&gt; &#123; ctx.body = &#x27;hello world&#x27;&#125;)app.listen(3000, () =&gt; &#123; console.log(&#x27;[demo] static-use-middleware is starting at port 3000&#x27;)&#125;) Ⅴ、模板引擎koa2加载模板引擎1、快速开始1.1 安装模块12345# 安装koa模板使用中间件npm install --save koa-views# 安装ejs模板引擎npm install --save ejs 1.2 使用模板引擎文件目录 1234├── package.json├── index.js└── view └── index.ejs ./index.js文件 123456789101112131415161718const Koa = require(&#x27;koa&#x27;)const views = require(&#x27;koa-views&#x27;)const path = require(&#x27;path&#x27;)const app = new Koa()// 加载模板引擎app.use(views(path.join(__dirname, &#x27;./view&#x27;), &#123; extension: &#x27;ejs&#x27;&#125;))app.use( async ( ctx ) =&gt; &#123; let title = &#x27;hello koa2&#x27; await ctx.render(&#x27;index&#x27;, &#123; title, &#125;)&#125;)app.listen(3000) ./view/index.ejs 模板 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;%= title %&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;&lt;%= title %&gt;&lt;/h1&gt; &lt;p&gt;EJS Welcome to &lt;%= title %&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; MongoDB一、安装数据库https://docs.mongodb.com/manual/administration/install-community/ 二、启动数据库1、windows12mongod --dbpath d:/data/dbmongo 2、mac12mongod --config /usr/local/etc/mongod.confmongo 三、数据库操作12345678use gp145db/db.getName()show dbsdb.createCollection(&#x27;movies&#x27;)db.stats()db.version()db.getMongo() //connection to 127.0.0.1:27017db.dropDatabase() 四、集合操作12db.createCollection(&#x27;users&#x27;)db.getCollectionNames() 五、文档的操作5.1 添加123456db.users.insertOne(&#123;username: &#x27;yangli&#x27;, password: &#x27;abc123&#x27;&#125;)db.users.insertOne(&#123;username: &#x27;haozeliang&#x27;, email: &#x27;hzl@126.com&#x27;&#125;)db.users.insertOne(&#123;&quot;username&quot;: 1, password: 123&#125;)db.users.insertMany([&#123;username: &#x27;gaojie&#x27;, password: &#x27;gj&#x27;, email: &#x27;gj@126.com&#x27;&#125;, &#123;username: &#x27;xinyi&#x27;, password: 123, email: 123&#125;])db.users.insert([&#123;username: &#x27;yangli&#x27;&#125;, &#123;useranme: &#x27;zeliang&#x27;&#125;])db.users.save() 5.2 修改123456789101112131415161718192021db.users.update(&#123;username: &#x27;yangli&#x27;&#125;, &#123;username: &#x27;yl&#x27;&#125;)// 1、如果第二个参数是一个对象，后边两个参数无效// 2、如果第二个参数是通过$set设置的话， 后两个参数才有效// 3、后两个参数的第一个参数：true/如果数据查询不到，就创建 false/如果数据查询不到，就什么都不做// 4、后两个参数第第二个参数：true/更新多条，false/更新一条db.users.update(&#123;username: &#x27;gp145&#x27;&#125;, &#123;$set: &#123;username: &#x27;yl&#x27;&#125;&#125;, true, true)// 5、如果使用updateMany, 就不需要传递后两个参数第二个了db.users.updateMany(&#123;username: &#x27;yl&#x27;&#125;, &#123;$set: &#123;username: &#x27;yangli&#x27;&#125;&#125;) db.collection.update( &lt;query&gt;, &lt;update&gt;, &#123; upsert: &lt;boolean&gt;, multi: &lt;boolean&gt;, writeConcern: &lt;document&gt;, collation: &lt;document&gt;, arrayFilters: [ &lt;filterdocument1&gt;, ... ], hint: &lt;document|string&gt; // Available starting in MongoDB 4.2 &#125;) 参考文档：https://docs.mongodb.com/manual/reference/method/db.collection.update/#db.collection.update 5.3 删除1db.users.remove(&#123;username: &#x27;xinyi&#x27;&#125;, true) 参考文档：https://docs.mongodb.com/manual/reference/method/db.collection.remove/ 5.4 查找12345678910db.movies.find(&#123;&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;)db.movies.find(&#123;&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;).sort(&#123;rt: -1&#125;)db.movies.find(&#123;&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;).limit(10)db.movies.find(&#123;&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;).sort(&#123;rt: -1&#125;).limit(10)db.movies.find(&#123;&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;).sort(&#123;rt: -1&#125;).limit(3).skip(6)db.movies.find(&#123;rt: &#123;$gte: &#x27;2019-10-14&#x27;&#125;&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;)db.movies.find(&#123;rt: &#123;$gte: &#x27;2019-10-14&#x27;&#125;&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;)db.movies.find(&#123;rt: &#123;$gte: &#x27;2019-10-14&#x27;&#125;&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;).count()db.movies.find(&#123;rt: &#123;$lte: &#x27;2019-10-14&#x27;&#125;&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;).count()db.movies.find(&#123;nm: /小/&#125;, &#123;nm: 1, _id: 0, rt: 1&#125;).sort(&#123;rt: -1&#125;) 六、数据库管理工具robo 3T Ⅱ、Mongoose1、数据库连接1234567891011const mongoose = require(&#x27;mongoose&#x27;)mongoose.connect(&#x27;mongodb://localhost:27017/lagou-admin&#x27;, &#123; useUnifiedTopology: true, useNewUrlParser: true &#125;)const Users = mongoose.model(&#x27;users&#x27;, &#123; username: String, password: String&#125;)module.exports = &#123; Users&#125; 2、Route12345678var express = require(&#x27;express&#x27;)var router = express.Router()const &#123; signup, hasUsername &#125; = require(&#x27;../controllers/users&#x27;)router.post(&#x27;/signup&#x27;, hasUsername, signup)module.exports = router 3、Model123456789101112131415const &#123; Users &#125; = require(&#x27;../utils/db&#x27;)const save = (data) =&gt; &#123; const users = new Users(data) return users.save()&#125;const findOne = (conditions) =&gt; &#123; return Users.findOne(conditions)&#125;module.exports = &#123; save, findOne&#125; 4、Viewart-template + express 1234&#123; &quot;ret&quot;: true, &quot;data&quot;: &#123;&#123;data&#125;&#125;&#125; 5、Controller12345678910111213141516171819202122232425262728293031323334353637383940414243444546const usersModel = require(&#x27;../models/users&#x27;)const signup = async function(req, res, next) &#123; res.set(&#x27;Content-Type&#x27;, &#x27;application/json; charset=utf-8&#x27;) let &#123; username, password &#125; = req.body let result = await usersModel.save(&#123; username, password: hash &#125;) if (result) &#123; res.render(&#x27;succ&#x27;, &#123; data: JSON.stringify(&#123; message: &#x27;用户注册成功.&#x27; &#125;) &#125;) &#125; else &#123; res.render(&#x27;fail&#x27;, &#123; data: JSON.stringify(&#123; message: &#x27;用户注册失败.&#x27; &#125;) &#125;) &#125;&#125;const hasUsername = async function(req, res, next) &#123; res.set(&#x27;Content-Type&#x27;, &#x27;application/json; charset=utf-8&#x27;) let &#123; username &#125; = req.body let result = await usersModel.findOne(&#123;username&#125;) if (result) &#123; res.render(&#x27;fail&#x27;, &#123; data: JSON.stringify(&#123; message: &#x27;用户名已经存在.&#x27; &#125;) &#125;) &#125; else &#123; next() &#125;&#125;module.exports = &#123; signup, hasUsername&#125; Socket 编程一、基于 Net 模块的 Socket 编程1.1 ServerSocket.js12345678910111213141516171819202122232425262728293031323334const net = require(&#x27;net&#x27;)const server = new net.createServer()let clients = &#123;&#125;let clientName = 0server.on(&#x27;connection&#x27;, (client) =&gt; &#123; client.name = ++clientName clients[client.name] = client client.on(&#x27;data&#x27;, (msg) =&gt; &#123; // console.log(&#x27;客户端传来：&#x27; + msg); broadcast(client, msg.toString()) &#125;) client.on(&#x27;error&#x27;, (e) =&gt; &#123; console.log(&#x27;client error&#x27; + e); client.end() &#125;) client.on(&#x27;close&#x27;, (data) =&gt; &#123; delete clients[client.name] console.log(client.name + &#x27; 下线了&#x27;); &#125;)&#125;)function broadcast(client, msg) &#123; for (var key in clients) &#123; clients[key].write(client.name + &#x27; 说：&#x27; + msg) &#125;&#125;server.listen(9000, &#x27;localhost&#x27;) 1.2 ClientSocket.js123456789101112131415161718192021222324252627282930313233343536373839404142var net = require(&#x27;net&#x27;)const readline = require(&#x27;readline&#x27;)var port = 9000var host = &#x27;127.0.0.1&#x27;var socket = new net.Socket()socket.setEncoding = &#x27;UTF-8&#x27;socket.connect(port, host, () =&gt; &#123; socket.write(&#x27;hello.&#x27;)&#125;)socket.on(&#x27;data&#x27;, (msg) =&gt; &#123; console.log(msg.toString()) say()&#125;)socket.on(&#x27;error&#x27;, function (err) &#123; console.log(&#x27;error&#x27; + err);&#125;)socket.on(&#x27;close&#x27;, function () &#123; console.log(&#x27;connection closeed&#x27;);&#125;)const r1 = readline.createInterface(&#123; input: process.stdin, output: process.stdout&#125;)function say() &#123; r1.question(&#x27;请输入： &#x27;, (inputMsg) =&gt; &#123; if (inputMsg != &#x27;bye&#x27;) &#123; // socket.write(inputMsg + &#x27; &#x27;) &#125; else &#123; socket.destroy() r1.close() &#125; &#125;)&#125; 二、基于 WebSocket 的 Socket 编程2.1 WebSocketServer.js1234567891011121314151617181920212223242526const WebSocket = require(&#x27;ws&#x27;)const ws = new WebSocket.Server(&#123; port: 8081 &#125;)let clients = &#123;&#125;let clientName = 0ws.on(&#x27;connection&#x27;, (client) =&gt; &#123; client.name = ++clientName clients[client.name] = client client.on(&#x27;message&#x27;, (msg) =&gt; &#123; broadcast(client, msg) &#125;) client.on(&#x27;close&#x27;, () =&gt; &#123; delete clients[client.name] console.log(client.name + &#x27; 离开了~&#x27;) &#125;)&#125;)function broadcast(client, msg) &#123; for (var key in clients) &#123; clients[key].send(client.name + &#x27; 说：&#x27; + msg) &#125;&#125; 2.2 index.html123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;WebSocket&lt;/title&gt; &lt;script src=&quot;WsClient.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;gp 交流区&lt;/h1&gt; &lt;div id=&quot;content&quot; name=&quot;name&quot; style=&quot;overflow-y: scroll; width: 400px; height: 300px; border: solid 1px #000&quot;&gt;&lt;/div&gt; &lt;br /&gt; &lt;div&gt; &lt;input type=&quot;text&quot; id=&quot;msg&quot; style=&quot;width: 200px;&quot;&gt; &lt;/div&gt; &lt;button id=&quot;submit&quot;&gt;提交&lt;/button&gt; &lt;script&gt; document.querySelector(&#x27;#submit&#x27;) .addEventListener(&#x27;click&#x27;, function () &#123; var msg2 = msg.value ws.send(msg2) // 核心代码，将表单里的数据提交给server端 msg.value = &#x27;&#x27; &#125;, false) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 2.3 WsClient.js123456789101112131415161718const ws = new WebSocket(&#x27;ws://localhost:8081/&#x27;)ws.onopen = () =&gt; &#123; ws.send(&#x27;大家好!&#x27;)&#125;ws.onmessage = (msg) =&gt; &#123; const content = document.getElementById(&#x27;content&#x27;) content.innerHTML += msg.data + &#x27;&lt;br/&gt;&#x27;&#125;ws.onerror = (err) =&gt; &#123; console.log(err);&#125;ws.onclose = () =&gt; &#123; console.log(&#x27;closed~&#x27;);&#125; 三、基于 Socket.io 的 Socket 编程3.1 SocketIoServer.js12345678910111213141516171819202122var express = require(&#x27;express&#x27;);var app = express();var server = require(&#x27;http&#x27;).Server(app);var io = require(&#x27;socket.io&#x27;)(server);// app.use(express.static(__dirname + &#x27;/client&#x27;))io.on(&#x27;connection&#x27;, function (socket) &#123; // setInterval(function () &#123; // socket.emit(&#x27;list&#x27;, &#x27;abc&#x27;) // &#125;, 1000) // socket.broadcast.emit(&#x27;list&#x27;, &#x27;test&#x27;); // socket.on(&#x27;backend&#x27;, (msg) =&gt; &#123; // console.log(msg); // &#125;) socket.on(&#x27;receive&#x27;, (msg) =&gt; &#123; socket.broadcast.emit(&#x27;message&#x27;, msg); &#125;)&#125;);server.listen(8082, &#x27;10.9.49.156&#x27;); 3.2 index.html12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;socket.io&lt;/title&gt; &lt;script src=&quot;socket.io.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;gp 交流区&lt;/h1&gt; &lt;div id=&quot;content&quot; name=&quot;name&quot; style=&quot;overflow-y: scroll; width: 400px; height: 300px; border: solid 1px #000&quot;&gt;&lt;/div&gt; &lt;br /&gt; &lt;div&gt; &lt;input type=&quot;text&quot; id=&quot;msg&quot; style=&quot;width: 200px;&quot;&gt; &lt;/div&gt; &lt;button id=&quot;submit&quot;&gt;提交&lt;/button&gt; &lt;script&gt; var socket = io.connect(&#x27;http://10.9.49.156:8082&#x27;); const content = document.getElementById(&#x27;content&#x27;) document.querySelector(&#x27;#submit&#x27;) .addEventListener(&#x27;click&#x27;, function () &#123; var msg2 = msg.value socket.emit(&#x27;receive&#x27;, msg2) // 核心代码 msg.value = &#x27;&#x27; content.innerHTML += msg2 + &#x27;&lt;br/&gt;&#x27; &#125;, false) socket.on(&#x27;message&#x27;, function(msg)&#123; content.innerHTML += msg + &#x27;&lt;br/&gt;&#x27; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; socket.io.js123# 安装包npm i socket.io# 在 node_modules/socket.io-client/dist/ 找到 socket.io.js Node 中间件机制理解 Node.js 中间件机制核心代码的实现，加深对中间件机制的理解，有助于更好的使用和编写中间件。 一、中间件概念在 Node.js 中，中间件主要是指封装所有 Http 请求细节处理的方法。一次 Http 请求通常包含很多工作，如记录日志、ip 过滤、查询字符串、请求体解析、Cookie 处理、权限验证、参数验证、异常处理等，但对于 Web 应用而言，并不希望接触到这么多细节性的处理，因此引入中间件来简化和隔离这些基础设施与业务逻辑之间的细节，让开发者能够关注在业务的开发上，以达到提升开发效率的目的。 中间件的行为比较类似 Java 中过滤器的工作原理，就是在进入具体的业务处理之前，先让过滤器处理。它的工作模型下图所示。 二、中间件机制核心实现中间件是从 Http 请求发起到响应结束过程中的处理方法，通常需要对请求和响应进行处理，因此一个基本的中间件的形式如下： 1234const middleware = (req, res, next) =&gt; &#123; // TODO next()&#125; 以下通过两种方式的中间件机制的实现来理解中间件是如何工作的。 1、方式一如下定义三个简单的中间件： 1234567891011121314const middleware1 = (req, res, next) =&gt; &#123; console.log(&#x27;middleware1 start&#x27;) next()&#125;const middleware2 = (req, res, next) =&gt; &#123; console.log(&#x27;middleware2 start&#x27;) next()&#125;const middleware3 = (req, res, next) =&gt; &#123; console.log(&#x27;middleware3 start&#x27;) next()&#125; 通过递归的形式，将后续中间件的执行方法传递给当前中间件，在当前中间件执行结束，通过调用 next() 方法执行后续中间件的调用。 12345678910111213// 中间件数组const middlewares = [middleware1, middleware2, middleware3]function run (req, res) &#123; const next = () =&gt; &#123; // 获取中间件数组中第一个中间件 const middleware = middlewares.shift() if (middleware) &#123; middleware(req, res, next) &#125; &#125; next()&#125;run() // 模拟一次请求发起 执行以上代码，可以看到如下结果： 123middleware1 startmiddleware2 startmiddleware3 start 如果中间件中有异步操作，需要在异步操作的流程结束后再调用 next() 方法，否则中间件不能按顺序执行。改写 middleware2 中间件： 12345678const middleware2 = (req, res, next) =&gt; &#123; console.log(&#x27;middleware2 start&#x27;) new Promise(resolve =&gt; &#123; setTimeout(() =&gt; resolve(), 1000) &#125;).then(() =&gt; &#123; next() &#125;)&#125; 执行结果与之前一致，不过middleware3会在middleware2异步完成后执行。 2、方式二有些中间件不止需要在业务处理前执行，还需要在业务处理后执行，比如统计时间的日志中间件。在方式一情况下，无法在 next() 为异步操作时再将当前中间件的其他代码作为回调执行。因此可以将next() 方法的后续操作封装成一个 Promise 对象，中间件内部就可以使用 next.then()形式完成业务处理结束后的回调。改写 run() 方法如下： 12345678910function run (req, res) &#123; const next = () =&gt; &#123; const middleware = middlewares.shift() if (middleware) &#123; // 将middleware(req, res, next)包装为Promise对象 return Promise.resolve(middleware(req, res, next)) &#125; &#125; next()&#125; 中间件的调用方式需改写为： 12345678const middleware1 = (req, res, next) =&gt; &#123; console.log(&#x27;middleware1 start&#x27;) // 所有的中间件都应返回一个Promise对象 // Promise.resolve()方法接收中间件返回的Promise对象，供下层中间件异步控制 return next().then(() =&gt; &#123; console.log(&#x27;middleware1 end&#x27;) &#125;)&#125; 得益于 async 函数的自动异步流程控制，中间件也可以用如下方式来实现： 123456789101112131415// async函数自动返回Promise对象const middleware2 = async (req, res, next) =&gt; &#123; console.log(&#x27;middleware2 start&#x27;) await new Promise(resolve =&gt; &#123; setTimeout(() =&gt; resolve(), 1000) &#125;) await next() console.log(&#x27;middleware2 end&#x27;)&#125;const middleware3 = async (req, res, next) =&gt; &#123; console.log(&#x27;middleware3 start&#x27;) await next() console.log(&#x27;middleware3 end&#x27;)&#125; 执行结果如下： 以上描述了中间件机制中多个异步中间件的调用流程，实际中间件机制的实现还需要考虑异常处理、路由等。 在 express 框架中，中间件的实现方式为方式一，并且全局中间件和内置路由中间件中根据请求路径定义的中间件共同作用，不过无法在业务处理结束后再调用当前中间件中的代码。koa2 框架中中间件的实现方式为方式二，将 next() 方法返回值封装成一个 Promise，便于后续中间件的异步流程控制，实现了 koa2 框架提出的洋葱圈模型，即每一层中间件相当于一个球面，当贯穿整个模型时，实际上每一个球面会穿透两次。 koa2 框架的中间件机制实现得非常简洁和优雅，这里学习一下框架中组合多个中间件的核心代码。 1234567891011121314151617181920212223242526function compose (middleware) &#123; if (!Array.isArray(middleware)) throw new TypeError(&#x27;Middleware stack must be an array!&#x27;) for (const fn of middleware) &#123; if (typeof fn !== &#x27;function&#x27;) throw new TypeError(&#x27;Middleware must be composed of functions!&#x27;) &#125; return function (context, next) &#123; let index = -1 return dispatch(0) function dispatch (i) &#123; // index会在next()方法调用后累加，防止next()方法重复调用 if (i &lt;= index) return Promise.reject(new Error(&#x27;next() called multiple times&#x27;)) index = i let fn = middleware[i] if (i === middleware.length) fn = next if (!fn) return Promise.resolve() try &#123; // 核心代码 // 包装next()方法返回值为Promise对象 return Promise.resolve(fn(context, dispatch.bind(null, i + 1))); &#125; catch (err) &#123; // 遇到异常中断后续中间件的调用 return Promise.reject(err) &#125; &#125; &#125;&#125; 三、中间件社区在后续 Node.js 学习和应用中，建议使用 koa2 框架作为基础框架，这里列出了一些使用比较多的中间件。 koa-router：路由中间件 koa-bodyparser：http请求主体解析 koa-static：代理静态文件 koa-compress：gzip压缩 koa-logger：日志记录 koa-convert：转换koa1.x版本的中间件 kcors：跨域中间件 koa中间件列表地址：https://github.com/koajs/koa/wiki 四、总结本文主要介绍了中间件的概念、为何引入中间件以及中间件机制的核心实现。中间件机制使得 Web 应用具备良好的可扩展性和组合性。 在实现中间件时，单个中间件应该足够简单，职责单一。由于每个请求都会调用中间件相关代码，中间件的代码应该高效，必要的时候可以缓存重复获取的数据。在对不同的路由使用中间件时，还应该考虑到不同的中间件应用到不同的路由上。 Node中的事件循环和异步API1、介绍单线程编程会因阻塞I/O导致硬件资源得不到更优的使用。多线程编程也因为编程中的死锁、状态同步等问题让开发人员头痛。 Node在两者之间给出了它的解决方案：利用单线程，远离多线程死锁、状态同步等问题；利用异步I/O，让单线程远离阻塞，以好使用CPU。 实际上，node只是在应用层属于单线程，底层其实通过libuv维护了一个阻塞I/O调用的线程池。 但是：在应用层面，JS是单线程的，业务代码中不能存在耗时过长的代码，否则可能会严重拖后续代码（包括回调）的处理。如果遇到需要复杂的业务计算时，应当想办法启用独立进程或交给其他服务进行处理。 1.1 异步I/O在Node中，JS是在单线程中执行的没错，但是内部完成I/O工作的另有线程池，使用一个主进程和多个I/O线程来模拟异步I/O。 当主线程发起I/O调用时，I/O操作会被放在I/O线程来执行，主线程继续执行下面的任务，在I/O线程完成操作后会带着数据通知主线程发起回调。 1.2 事件循环事件循环是Node的执行模型，正是这种模型使得回调函数非常普遍。 在进程启动时，Node便会创建一个类似while(true)的循环，执行每次循环的过程就是判断有没有待处理的事件，如果有，就取出事件及其相关的回调并执行他们，然后进入下一个循环。如果不再有事件处理，就退出进程。 Event loop是一种程序结构，是实现异步的一种机制。Event loop可以简单理解为： 所有任务都在主线程上执行，形成一个执行栈（execution context stack）。 主线程之外，还存在一个”任务队列”（task queue）。系统把异步任务放到”任务队列”之中，然后主线程继续执行后续的任务。 一旦”执行栈”中的所有任务执行完毕，系统就会读取”任务队列”。如果这个时候，异步任务已经结束了等待状态，就会从”任务队列”进入执行栈，恢复执行。 主线程不断重复上面的第三步。 Node中事件循环阶段解析: 123456789101112131415161718 ┌───────────────────────┐┌─&gt;│ timers ││ └──────────┬────────────┘│ ┌──────────┴────────────┐│ │ I/O callbacks ││ └──────────┬────────────┘│ ┌──────────┴────────────┐│ │ idle, prepare ││ └──────────┬────────────┘ ┌───────────────┐│ ┌──────────┴────────────┐ │ incoming: ││ │ poll │&lt;─────┤ connections, ││ └──────────┬────────────┘ │ data, etc. ││ ┌──────────┴────────────┐ └───────────────┘│ │ check ││ └──────────┬────────────┘│ ┌──────────┴────────────┐└──┤ close callbacks │ └───────────────────────┘ 每个阶段都有一个FIFO的回调队列（queue）要执行。而每个阶段有自己的特殊之处，简单说，就是当event loop进入某个阶段后，会执行该阶段特定的（任意）操作，然后才会执行这个阶段的队列里的回调。当队列被执行完，或者执行的回调数量达到上限后，event loop会进入下个阶段。 Phases Overview 阶段总览 timers: 这个阶段执行setTimeout()、setInterval()设定的回调。 I/O callbacks: 执行几乎所有的回调，除了close callbacks、setTimeout()、setInterval()、setImmediate()的回调。 idle, prepare: 仅内部使用。 poll: 获取新的I/O事件；node会在适当条件下阻塞在这里。 check: 执行setImmediate()设定的回调。 close callbacks: 执行比如socket.on(‘close’, …)的回调。 1. timers 一个timer指定一个下限时间而不是准确时间，定时器setTimeout()和setInterval()在达到这个下限时间后执行回调。在指定的时间过后，timers会尽早的执行回调，但是系统调度或者其他回调的执行可能会延迟它们。 从技术上来说，poll阶段控制timers什么时候执行，而执行的具体位置在timers。 下限的时间有一个范围：[1, 2147483647]，如果设定的时间不在这个范围，将被设置为1。 2. I/O callbacks 执行除了close callbacks、setTimeout()、setInterval()、setImmediate()回调之外几乎所有回调，比如说TCP连接发生错误。 3. idle, prepare 系统内部的一些调用。 4. poll 这是最复杂的一个阶段。poll会检索新的I/O events，并且会在合适的时候阻塞，等待回调被加入。 poll阶段有两个主要的功能：一是执行下限时间已经达到的timers的回调，一是处理poll队列里的事件。 注：Node很多API都是基于事件订阅完成的，这些API的回调应该都在poll阶段完成。 当事件循环进入poll阶段： poll队列不为空的时候，事件循环肯定是先遍历队列并同步执行回调，直到队列清空或执行回调数达到系统上限。 poll队列为空的时候，这里有两种情况。 如果代码已经被setImmediate()设定了回调，那么事件循环直接结束poll阶段进入check阶段来执行check队列里的回调。 如果代码没有被设定setImmediate()设定回调： 如果有被设定的timers，那么此时事件循环会检查timers，如果有一个或多个timers下限时间已经到达，那么事件循环将绕回timers阶段，并执行timers的有效回调队列。 如果没有被设定timers，这个时候事件循环是阻塞在poll阶段等待事件回调被加入poll队列。 Node的很多API都是基于事件订阅完成的，比如fs.readFile，这些回调应该都在poll阶段完成。 5. check setImmediate()在这个阶段执行。 这个阶段允许在poll阶段结束后立即执行回调。如果poll阶段空闲，并且有被setImmediate()设定的回调，那么事件循环直接跳到check执行而不是阻塞在poll阶段等待poll 事件们 (poll events)被加入。 注意：如果进行到了poll阶段，setImmediate()具有最高优先级，只要poll队列为空且注册了setImmediate()，无论是否有timers达到下限时间，setImmediate()的代码都先执行。 6. close callbacks 如果一个socket或handle被突然关掉（比如socket.destroy()），close事件将在这个阶段被触发，否则将通过process.nextTick()触发。 1.3 请求对象对于Node中的异步I/O调用而言，回调函数不由开发者来调用，从JS发起调用到I/O操作完成，存在一个中间产物，叫请求对象。 在JS发起调用后，JS调用Node的核心模块，核心模块调用C++内建模块，內建模块通过libuv判断平台并进行系统调用。在进行系统调用时，从JS层传入的方法和参数都被封装在一个请求对象中，请求对象被放在线程池中等待执行。JS立即返回继续后续操作。 1.4 执行回调在线程可用时，线程会取出请求对象来执行I/O操作，执行完后将结果放在请求对象中，并归还线程。 在事件循环中，I/O观察者会不断的找到线程池中已经完成的请求对象，从中取出回调函数和数据并执行。 跑完当前执行环境下能跑完的代码。每一个事件消息都被运行直到完成为止，在此之前，任何其他事件都不会被处理。这和C等一些语言不通，它们可能在一个线程里面，函数跑着跑着突然停下来，然后其他线程又跑起来了。JS这种机制的一个典型的坏处，就是当某个事件处理耗时过长时，后面的事件处理都会被延后，直到这个事件处理结束，在浏览器环境中运行时，可能会出现某个脚本运行时间过长，页面无响应的提示。Node环境则可能出现大量用户请求被挂起，不能及时响应的情况。 2、非I/O的异步APINode中除了异步I/O之外，还有一些与I/O无关的异步API，分别是：setTimeout()、setInterval()、process.nextTick()、setImmediate()，他们并不是像普通I/O操作那样真的需要等待事件异步处理结束再进行回调，而是出于定时或延迟处理的原因才设计的。 2.1 setTimeout()与setInterval()这两个方法实现原理与异步I/O相似，只不过不用I/O线程池的参与。 使用它们创建的定时器会被放入timers队列的一个红黑树中，每次事件循环执行时会从相应队列中取出并判断是否超过定时时间，超过就形成一个事件，回调立即执行。 所以，和浏览器中一样，这个并不精确，会被长时间的同步事件阻塞。 值得一提的是，在Node的setTimeout的源码中： 12345678// Node源码after *= 1; // coalesce to number or NaNif (!(after &gt;= 1 &amp;&amp; after &lt;= TIMEOUT_MAX)) &#123; if (after &gt; TIMEOUT_MAX) &#123; process.emitWarning(...); &#125; after = 1; // schedule on next tick, follows browser behavior&#125; 意思是如果没有设置这个after，或者小于1，或者大于TIMEOUT_MAX（2^31-1），都会被强制设置为1ms。也就是说setTimeout(xxx,0)其实等同于setTimeout(xxx,1)。 2.2 setImmediate()setImmediate()是放在check阶段执行的，实际上是一个特殊的timer，跑在event loop中一个独立的阶段。它使用libuv的API来设定在 poll 阶段结束后立即执行回调。 来看看这个例子： 123456setTimeout(function() &#123; console.log(&#x27;setTimeout&#x27;)&#125;, 0)setImmediate(function() &#123; console.log(&#x27;setImmediate&#x27;)&#125;) // 输出不稳定 setTimeout与setImmediate先后入队之后，首先进入的是timers阶段，如果我们的机器性能一般或者加入了一个同步长耗时操作，那么进入timers阶段，1ms已经过去了，那么setTimeout的回调会首先执行。 如果没有到1ms，那么在timers阶段的时候，超时时间没到，setTimeout回调不执行，事件循环来到了poll阶段，这个时候队列为空，此时有代码被setImmediate()，于是先执行了setImmediate()的回调函数，之后在下一个事件循环再执行setTimemout的回调函数。 12345678setTimeout(function() &#123; console.log(&#x27;set timeout&#x27;)&#125;, 0)setImmediate(function() &#123; console.log(&#x27;set Immediate&#x27;)&#125;)for (let i = 0; i &lt; 100000; i++) &#123;&#125; // 可以保证执行时间超过1ms// 稳定输出： setTimeout setImmediate 这样就可以稳定输出了。 再一个栗子： 1234567const fs = require(&#x27;fs&#x27;)fs.readFile(&#x27;./filePath.js&#x27;, (err, data) =&gt; &#123; setTimeout(() =&gt; console.log(&#x27;setTimeout&#x27;) , 0) setImmediate(() =&gt; console.log(&#x27;setImmediate&#x27;)) console.log(&#x27;开始了&#x27;) for (let i = 0; i &lt; 100000; i++) &#123;&#125; &#125;) // 输出 开始了 setImmediate setTimeout 这里我们就会发现，setImmediate永远先于setTimeout执行。 fs.readFile的回调是在poll阶段执行的，当其回调执行完毕之后，setTimeout与setImmediate先后入了timers与check的队列，继续到poll，poll队列为空，此时发现有setImmediate，于是事件循环先进入check阶段执行回调，之后在下一个事件循环再在timers阶段中执行setTimeout回调，虽然这个setTimeout已经到了超时时间。 再来个栗子： 同样的，这段代码也是一样的道理： 1234setTimeout(() =&gt; &#123; setImmediate(() =&gt; console.log(&#x27;setImmediate&#x27;) ) setTimeout(() =&gt; console.log(&#x27;setTimeout&#x27;) , 0)&#125;, 0) 以上的代码在timers阶段执行外部的setTimeout回调后，内层的setTimeout和setImmediate入队，之后事件循环继续往后面的阶段走，走到poll阶段的时候发现队列为空，此时有代码被setImmedate()，所以直接进入check阶段执行响应回调（注意这里没有去检测timers队列中是否有成员到达超时事件，因为setImmediate()优先）。之后在下一个事件循环的timers阶段中再去执行相应的回调。 2.3 process.nextTick()与Promise对于这两个，我们可以把它们理解成一个微任务。也就是说，它们其实不属于事件循环的一部分。 有时我们想要立即异步执行一个任务，可能会使用延时为0的定时器，但是这样开销很大。我们可以换而使用process.nextTick()，它会将传入的回调放入nextTickQueue队列中，下一轮Tick之后取出执行，不管事件循环进行到什么地步，都在当前执行栈的操作结束的时候调用，参见Nodejs官网。 process.nextTick方法指定的回调函数，总是在当前执行队列的尾部触发，多个process.nextTick语句总是一次执行完（不管它们是否嵌套），递归调用process.nextTick，将会没完没了，主线程根本不会去读取事件队列，导致阻塞后续调用，直至达到最大调用限制。 相比于在定时器中采用红黑树树的操作时间复杂度为0(lg(n))，而process.nextTick()的时间复杂度为0(1)，相比之下更高效。 来举一个复杂的栗子，这个栗子搞懂基本上就全部理解了： 12345678910111213141516171819setTimeout(() =&gt; &#123; process.nextTick(() =&gt; console.log(&#x27;nextTick1&#x27;)) setTimeout(() =&gt; &#123; console.log(&#x27;setTimout1&#x27;) process.nextTick(() =&gt; &#123; console.log(&#x27;nextTick2&#x27;) setImmediate(() =&gt; console.log(&#x27;setImmediate1&#x27;)) process.nextTick(() =&gt; console.log(&#x27;nextTick3&#x27;)) &#125;) setImmediate(() =&gt; console.log(&#x27;setImmediate2&#x27;)) process.nextTick(() =&gt; console.log(&#x27;nextTick4&#x27;)) console.log(&#x27;sync2&#x27;) setTimeout(() =&gt; console.log(&#x27;setTimout2&#x27;), 0) &#125;, 0) console.log(&#x27;sync1&#x27;)&#125;, 0) // 输出： sync1 nextTick1 setTimout1 sync2 nextTick2 nextTick4 nextTick3 setImmediate2 setImmediate1 setTimout2 2.4 结论 process.nextTick()，效率最高，消费资源小，但会阻塞CPU的后续调用； setTimeout()，精确度不高，可能有延迟执行的情况发生，且因为动用了红黑树，所以消耗资源大； setImmediate()，消耗的资源小，也不会造成阻塞，但效率也是最低的。","tags":["笔记"],"categories":["Nodejs"]},{"title":"nodejs笔记","path":"/2021/12/02/node_note/","content":"Node.js是什么 Node.js是JavaScript 运行时 通俗易懂的讲，Node.js是JavaScript的运行平台 Node.js既不是语言，也不是框架，它是一个平台 浏览器中的JavaScript EcmaScript 基本语法 if var function Object Array Bom Dom Node.js中的JavaScript 没有Bom，Dom EcmaScript 在Node中这个JavaScript执行环境为JavaScript提供了一些服务器级别的API 例如文件的读写 网络服务的构建 网络通信 http服务器 构建与Chrome的V8引擎之上 代码只是具有特定格式的字符串 引擎可以认识它，帮你解析和执行 Google Chrome的V8引擎是目前公认的解析执行JavaScript代码最快的 Node.js的作者把Google Chrome中的V8引擎移植出来，开发了一个独立的JavaScript运行时环境 Node.js uses an envent-driven,non-blocking I/O mode that makes it lightweight and efficent. envent-driven 事件驱动 non-blocking I/O mode 非阻塞I/O模型（异步） ightweight and efficent. 轻量和高效 Node.js package ecosystem,npm,is the larget scosystem of open sourcr libraries in the world npm 是世界上最大的开源生态系统 绝大多数JavaScript相关的包都存放在npm上，这样做的目的是为了让开发人员更方便的去下载使用 npm install jquery Node能做什么 web服务器后台 命令行工具 npm(node) git(c语言) hexo（node） … 对于前端工程师来讲，接触最多的是它的命令行工具 自己写的很少，主要是用别人第三方的 webpack gulp npm 起步安装Node环境 查看Node环境的版本号 下载：https://nodejs.org/en/ 安装： 傻瓜式安装，一路next 安装过再次安装会升级 确认Node环境是否安装成功 查看node的版本号：node --version 或者node -v 配置环境变量 解析执行JavaScript 创建编写JavaScript脚本文件 打开终端，定位脚本文件的所属目录 输入node 文件名执行对应的文件 注意：文件名不要用node.js来命名，也就是说除了node这个名字随便起，最好不要使用中文。 文件的读写文件读取: 12345678910111213141516171819//浏览器中的JavaScript是没有文件操作能力的//但是Node中的JavaScript具有文件操作能力//fs是file-system的简写，就是文件系统的意思//在Node中如果想要进行文件的操作就必须引用fs这个核心模块//在fs这个和兴模块中，就提供了人所有文件操作相关的API//例如 fs.readFile就是用来读取文件的// 1.使用fs核心模块var fs = require(&#x27;fs&#x27;);// 2.读取文件fs.readFile(&#x27;./data/a.txt&#x27;,function(err,data)&#123; if(err)&#123; console.log(&#x27;文件读取失败&#x27;); &#125; else&#123; console.log(data.toString()); &#125;&#125;) 文件写入： 123456789101112// 1.使用fs核心模块var fs = require(&#x27;fs&#x27;);// 2.将数据写入文件fs.writeFile(&#x27;./data/a.txt&#x27;,&#x27;我是文件写入的信息&#x27;,function(err,data)&#123; if(err)&#123; console.log(&#x27;文件写入失败&#x27;); &#125; else&#123; console.log(data.toString()); &#125;&#125;) http服务器： 12345678910111213141516171819202122// 1.加载http核心模块var http = require(&#x27;http&#x27;);// 2.使用http.createServer()创建一个web服务器var server = http.createServer();// 3.服务器要做的事儿// 提供服务：对数据服务// 发请求//\t接收请求//\t处理请求//\t反馈（发送响应）//\t当客户端请求过来，就会自动触发服务器的request请求事件，然后执行第二个参数：回调处理函数server.on(&#x27;request&#x27;,function()&#123; console.log(&#x27;收到客户的请求了&#x27;)&#125;)// 4.绑定端口号，启动服务server.listen(3000,function()&#123; console.log(&#x27;runing...&#x27;)&#125;) Node中的模块系统使用Node编写应用程序主要就是在使用： EcmaScript语言 和浏览器一样，在Node中没有Bom和Dom 核心模块 文件操作的fs http服务操作的http url路径操作模块 path路径处理模块 os操作系统信息 第三方模块 art-template 必须通过npm来下载才可以使用 自己写的模块 自己创建的文件 什么是模块化 文件作用域(模块是独立的，在不同的文件使用必须要重新引用)【在node中没有全局作用域，它是文件模块作用域】 通信规则 加载require 导出exports CommonJS模块规范在Node中的JavaScript还有一个重要的概念，模块系统。 模块作用域 使用require方法来加载模块 使用exports接口对象来导出模板中的成员 加载require语法： 1var 自定义变量名 = require(&#x27;模块&#x27;) 作用： 执行被加载模块中的代码 得到被加载模块中的exports导出接口对象 导出exports Node中是模块作用域，默认文件中所有的成员只在当前模块有效 对于希望可以被其他模块访问到的成员，我们需要把这些公开的成员都挂载到exports接口对象中就可以了 导出多个成员（必须在对象中）： 12345678exports.a = 123;exports.b = function()&#123; console.log(&#x27;bbb&#x27;)&#125;;exports.c = &#123; foo:&quot;bar&quot;&#125;;exports.d = &#x27;hello&#x27;; 导出单个成员（拿到的就是函数，字符串）： 1module.exports = &#x27;hello&#x27;; 以下情况会覆盖： 12345module.exports = &#x27;hello&#x27;;//后者会覆盖前者module.exports = function add(x,y) &#123; return x+y;&#125; 也可以通过以下方法来导出多个成员： 123456module.exports = &#123; foo = &#x27;hello&#x27;, add:function()&#123; return x+y; &#125;&#125;; 模块原理exports和module.exports的一个引用： 123456console.log(exports === module.exports);\t//trueexports.foo = &#x27;bar&#x27;;//等价于module.exports.foo = &#x27;bar&#x27;; 当给exports重新赋值后，exports！= module.exports. 最终return的是module.exports,无论exports中的成员是什么都没用。 123真正去使用的时候：\t导出单个成员：exports.xxx = xxx;\t导出多个成员：module.exports 或者 modeule.exports = &#123;&#125;; 总结12345678910111213141516171819202122232425262728293031323334// 引用服务var http = require(&#x27;http&#x27;);var fs = require(&#x27;fs&#x27;);// 引用模板var template = require(&#x27;art-template&#x27;);// 创建服务var server = http.createServer();// 公共路径var wwwDir = &#x27;D:/app/www&#x27;;server.on(&#x27;request&#x27;, function (req, res) &#123; var url = req.url; // 读取文件 fs.readFile(&#x27;./template-apche.html&#x27;, function (err, data) &#123; if (err) &#123; return res.end(&#x27;404 Not Found&#x27;); &#125; fs.readdir(wwwDir, function (err, files) &#123; if (err) &#123; return res.end(&#x27;Can not find www Dir.&#x27;) &#125; // 使用模板引擎解析替换data中的模板字符串 // 去xmpTempleteList.html中编写模板语法 var htmlStr = template.render(data.toString(), &#123; title: &#x27;D:/app/www/ 的索引&#x27;, files:files &#125;); // 发送响应数据 res.end(htmlStr); &#125;) &#125;)&#125;);server.listen(3000, function () &#123; console.log(&#x27;running....&#x27;);&#125;) 1234567891011121314151617181.jQuery中的each 和 原生JavaScript方法forEach的区别：\t提供源头： 原生js是es5提供的（不兼容IE8）, jQuery的each是jQuery第三方库提供的（如果要使用需要用2以下的版本也就是1.版本）,它的each方法主要用来遍历jQuery实例对象（伪数组）,同时也可以做低版本forEach的替代品,jQuery的实例对象不能使用forEach方法，如果想要使用必须转为数组（[].slice.call(jQuery实例对象)）才能使用2.模块中导出多个成员和导出单个成员3.301和302的区别：\t301永久重定向,浏览器会记住 302临时重定向4.exports和module.exports的区别:\t每个模块中都有一个module对象 module对象中有一个exports对象 我们可以把需要导出的成员都挂载到module.exports接口对象中\t也就是`module.exports.xxx = xxx`的方式 但是每次写太多了就很麻烦，所以Node为了简化代码，就在每一个模块中都提供了一个成员叫`exports` `exports === module.exports`结果为true,所以完全可以`exports.xxx = xxx` 当一个模块需要导出单个成员的时候必须使用`module.exports = xxx`的方式，=,使用`exports = xxx`不管用,因为每个模块最终return的是module.exports,而exports只是module.exports的一个引用,所以`exports`即使重新赋值,也不会影响`module.exports`。 有一种赋值方式比较特殊：`exports = module.exports`这个用来新建立引用关系的。 require的加载规则 核心模块 模块名 第三方模块 模块名 用户自己写的 路径 require的加载规则： 优先从缓存加载 判断模块标识符 核心模块 自己写的模块（路径形式的模块） 第三方模块（node_modules） 第三方模块的标识就是第三方模块的名称（不可能有第三方模块和核心模块的名字一致） npm 开发人员可以把写好的框架库发布到npm上 使用者通过npm命令来下载 使用方式：var 名称 = require(&#39;npm install【下载包】 的包名&#39;) node_modules/express/package.json main 如果package.json或者main不成立，则查找被选择项：index.js 如果以上条件都不满足，则继续进入上一级目录中的node_modules按照上面的规则依次查找，直到当前文件所属此盘根目录都找不到最后报错 12345678910111213141516171819202122232425262728293031323334// 如果非路径形式的标识// 路径形式的标识： // ./ 当前目录 不可省略 // ../ 上一级目录 不可省略 // /xxx也就是D:/xxx // 带有绝对路径几乎不用（D:/a/foo.js）// 首位表示的是当前文件模块所属磁盘根目录// require(&#x27;./a&#x27;); // 核心模块// 核心模块本质也是文件，核心模块文件已经被编译到了二进制文件中了，我们只需要按照名字来加载就可以了require(&#x27;fs&#x27;); // 第三方模块// 凡是第三方模块都必须通过npm下载（npm i node_modules），使用的时候就可以通过require(&#x27;包名&#x27;)来加载才可以使用// 第三方包的名字不可能和核心模块的名字是一样的// 既不是核心模块，也不是路径形式的模块// 先找到当前文所述目录的node_modules// 然后找node_modules/art-template目录// node_modules/art-template/package.json// node_modules/art-template/package.json中的main属性// main属性记录了art-template的入口模块// 然后加载使用这个第三方包// 实际上最终加载的还是文件// 如果package.json不存在或者mian指定的入口模块不存在// 则node会自动找该目录下的index.js// 也就是说index.js是一个备选项，如果main没有指定，则加载index.js文件// // 如果条件都不满足则会进入上一级目录进行查找// 注意：一个项目只有一个node_modules，放在项目根目录中，子目录可以直接调用根目录的文件var template = require(&#x27;art-template&#x27;); 模块标识符中的/和文件操作路径中的/文件操作路径： 1234567891011121314// 咱们所使用的所有文件操作的API都是异步的// 就像ajax请求一样// 读取文件// 文件操作中 ./ 相当于当前模块所处磁盘根目录// ./index.txt 相对于当前目录// /index.txt 相对于当前目录// /index.txt 绝对路径,当前文件模块所处根目录// d:express/index.txt 绝对路径fs.readFile(&#x27;./index.txt&#x27;,function(err,data)&#123; if(err)&#123; return console.log(&#x27;读取失败&#x27;); &#125; console.log(data.toString());&#125;) 模块操作路径： 123// 在模块加载中，相对路径中的./不能省略// 这里省略了.也是磁盘根目录require(&#x27;./index&#x27;)(&#x27;hello&#x27;) npm node package manage(node包管理器) 通过npm命令安装jQuery包（npm install –save jquery），在安装时加上–save会主动生成说明书文件信息（将安装文件的信息添加到package.json里面） npm网站 npmjs.com 网站 是用来搜索npm包的 npm命令行工具npm是一个命令行工具，只要安装了node就已经安装了npm。 npm也有版本概念，可以通过npm --version来查看npm的版本 升级npm(自己升级自己)： 1npm install --global npm 常用命令 npm init(生成package.json说明书文件) npm init -y(可以跳过向导，快速生成) npm install 一次性把dependencies选项中的依赖项全部安装 简写（npm i） npm install 包名 只下载 简写（npm i 包名） npm install –save 包名 下载并且保存依赖项（package.json文件中的dependencies选项） 简写（npm i 包名） npm uninstall 包名 只删除，如果有依赖项会依然保存 简写（npm un 包名） npm uninstall –save 包名 删除的同时也会把依赖信息全部删除 简写（npm un 包名） npm help 查看使用帮助 npm 命令 –help 查看具体命令的使用帮助（npm uninstall –help） 解决npm被墙问题npm存储包文件的服务器在国外，有时候会被墙，速度很慢，所以需要解决这个问题。 https://developer.aliyun.com/mirror/NPM?from=tnpm淘宝的开发团队把npm在国内做了一个镜像（也就是一个备份）。 安装淘宝的cnpm： 1npm install -g cnpm --registry=https://registry.npm.taobao.org; 1234#在任意目录执行都可以#--global表示安装到全局，而非当前目录#--global不能省略，否则不管用npm install --global cnpm 安装包的时候把以前的npm替换成cnpm。 12345#走国外的npm服务器下载jQuery包，速度比较慢npm install jQuery;#使用cnpm就会通过淘宝的服务器来下载jQuerycnpm install jQuery; 如果不想安装cnpm又想使用淘宝的服务器来下载： 1npm install jquery --registry=https://npm.taobao.org; 但是每次手动加参数就很麻烦，所以我们可以把这个选项加入到配置文件中： 1234npm config set registry https://npm.taobao.org;#查看npm配置信息npm config list; 只要经过上面的配置命令，则以后所有的npm install都会通过淘宝的服务器来下载 package.json每一个项目都要有一个package.json文件（包描述文件，就像产品的说明书一样） 这个文件可以通过npm init自动初始化出来 1234567891011121314151617181920212223242526272829303132333435363738D:\\code ode中的模块系统&gt;npm initThis utility will walk you through creating a package.json file.It only covers the most common items, and tries to guess sensible defaults.See `npm help json` for definitive documentation on these fieldsand exactly what they do.Use `npm install &lt;pkg&gt;` afterwards to install a package andsave it as a dependency in the package.json file.Press ^C at any time to quit.package name: (node中的模块系统)Sorry, name can only contain URL-friendly characters.package name: (node中的模块系统) clsversion: (1.0.0)description: 这是一个测试项目entry point: (main.js)test command:git repository:keywords:author: xiaochenlicense: (ISC)About to write to D:\\code ode中的模块系统\\package.json:&#123; &quot;name&quot;: &quot;cls&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;这是一个测试项目&quot;, &quot;main&quot;: &quot;main.js&quot;, &quot;scripts&quot;: &#123; &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; &#125;, &quot;author&quot;: &quot;xiaochen&quot;, &quot;license&quot;: &quot;ISC&quot;&#125;Is this OK? (yes) yes 对于目前来讲，最有用的是dependencies选项，可以用来帮助我们保存第三方包的依赖信息。 如果node_modules删除了也不用担心，只需要在控制面板中npm install就会自动把package.json中的dependencies中所有的依赖项全部都下载回来。 建议每个项目的根目录下都有一个package.json文件 建议执行npm install 包名的时候都加上--save选项，目的是用来保存依赖信息 package.json和package-lock.jsonnpm 5以前是不会有package-lock.json这个文件 npm5以后才加入这个文件 当你安装包的时候，npm都会生成或者更新package-lock.json这个文件 npm5以后的版本安装都不要加--save参数，它会自动保存依赖信息 当你安装包的时候，会自动创建或者更新package-lock.json文件 package-lock.json这个文件会包含node_modules中所有包的信息（版本，下载地址。。。） 这样的话重新npm install的时候速度就可以提升 从文件来看，有一个lock称之为锁 这个lock使用来锁版本的 如果项目依赖了1.1.1版本 如果你重新install其实会下载最细版本，而不是1.1.1 package-lock.json的另外一个作用就是锁定版本号，防止自动升级 path路径操作模块 参考文档：https://nodejs.org/docs/latest-v13.x/api/path.html path.basename：获取路径的文件名，默认包含扩展名 path.dirname：获取路径中的目录部分 path.extname：获取一个路径中的扩展名部分 path.parse：把路径转换为对象 root：根路径 dir：目录 base：包含后缀名的文件名 ext：后缀名 name：不包含后缀名的文件名 path.join：拼接路径 path.isAbsolute：判断一个路径是否为绝对路径 Node中的其它成员(__dirname,__filename)在每个模块中，除了require,exports等模块相关的API之外，还有两个特殊的成员： __dirname，是一个成员，可以用来动态获取当前文件模块所属目录的绝对路径 __filename，可以用来动态获取当前文件的绝对路径（包含文件名） __dirname和filename是不受执行node命令所属路径影响的 在文件操作中，使用相对路径是不可靠的，因为node中文件操作的路径被设计为相对于执行node命令所处的路径。 所以为了解决这个问题，只需要把相对路径变为绝对路径（绝对路径不受任何影响）就可以了。 就可以使用__dirname或者__filename来帮助我们解决这个问题 在拼接路径的过程中，为了避免手动拼接带来的一些低级错误，推荐使用path.join()来辅助拼接 1234567891011var fs = require(&#x27;fs&#x27;);var path = require(&#x27;path&#x27;);// console.log(__dirname + &#x27;a.txt&#x27;);// path.join方法会将文件操作中的相对路径都统一的转为动态的绝对路径fs.readFile(path.join(__dirname + &#x27;/a.txt&#x27;),&#x27;utf8&#x27;,function(err,data)&#123;\tif(err)&#123; throw err\t&#125;\tconsole.log(data);&#125;); 补充：模块中的路径标识和这里的路径没关系，不受影响（就是相对于文件模块） 注意： 模块中的路径标识和文件操作中的相对路径标识不一致 模块中的路径标识就是相对于当前文件模块，不受node命令所处路径影响 Express（快速的）作者：Tj 原生的http在某些方面表现不足以应对我们的开发需求，所以就需要使用框架来加快我们的开发效率，框架的目的就是提高效率，让我们的代码高度统一。 在node中有很多web开发框架。主要学习express http://expressjs.com/,其中主要封装的是http。 ```javascript// 1 安装// 2 引包var express = require(‘express’);// 3 创建服务器应用程序// 也就是原来的http.createServer();var app = express(); // 公开指定目录// 只要通过这样做了，就可以通过/public/xx的方式来访问public目录中的所有资源// 在Express中开放资源就是一个API的事app.use(‘/public/‘,express.static(‘/public/‘)); //模板引擎在Express中开放模板也是一个API的事 // 当服务器收到get请求 / 的时候，执行回调处理函数app.get(‘/‘,function(req,res){ res.send(&#39;hello express&#39;); }) // 相当于server.listenapp.listen(3000,function(){ console.log(&#39;app is runing at port 3000&#39;); }) 12345678910### 学习Express#### 起步##### 安装：&#123;% image C:\\Users\\A\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200310123723079.png %&#125;```javascriptcnpm install express hello world:1234567891011121314151617181920212223// 引入expressvar express = require(&#x27;express&#x27;);// 1. 创建appvar app = express();// 2. app.get(&#x27;/&#x27;,function(req,res)&#123; // 1 // res.write(&#x27;Hello&#x27;); // res.write(&#x27;World&#x27;); // res.end() // 2 // res.end(&#x27;hello world&#x27;); // 3 res.send(&#x27;hello world&#x27;);&#125;)app.listen(3000,function()&#123; console.log(&#x27;express app is runing...&#x27;);&#125;) 基本路由路由： 请求方法 请求路径 请求处理函数 get: 1234//当你以get方法请求/的时候，执行对应的处理函数app.get(&#x27;/&#x27;,function(req,res)&#123; res.send(&#x27;hello world&#x27;);&#125;) post: 1234//当你以post方法请求/的时候，执行对应的处理函数app.post(&#x27;/&#x27;,function(req,res)&#123; res.send(&#x27;hello world&#x27;);&#125;) Express静态服务API123456// app.use不仅仅是用来处理静态资源的，还可以做很多工作(body-parser的配置)app.use(express.static(&#x27;public&#x27;));app.use(express.static(&#x27;files&#x27;));app.use(&#x27;/stataic&#x27;,express.static(&#x27;public&#x27;)); 123456789101112131415161718192021222324252627// 引入expressvar express = require(&#x27;express&#x27;);// 创建appvar app = express();// 开放静态资源// 1.当以/public/开头的时候，去./public/目录中找对应资源// 访问：http://127.0.0.1:3000/public/login.htmlapp.use(&#x27;/public/&#x27;,express.static(&#x27;./public/&#x27;)); // 2.当省略第一个参数的时候，可以通过省略/public的方式来访问// 访问：http://127.0.0.1:3000/login.html// app.use(express.static(&#x27;./public/&#x27;)); // 3.访问：http://127.0.0.1:3000/a/login.html// a相当于public的别名// app.use(&#x27;/a/&#x27;,express.static(&#x27;./public/&#x27;)); // app.get(&#x27;/&#x27;,function(req,res)&#123; res.end(&#x27;hello world&#x27;);&#125;);app.listen(3000,function()&#123; console.log(&#x27;express app is runing...&#x27;);&#125;); 在Express中配置使用art-templete模板引擎 art-template官方文档 在node中，有很多第三方模板引擎都可以使用，不是只有art-template 还有ejs，jade（pug），handlebars，nunjucks 安装： 12345npm install --save art-templatenpm install --save express-art-template//两个一起安装npm i --save art-template express-art-template 配置： 1app.engine(&#x27;html&#x27;, require(&#x27;express-art-template&#x27;)); 使用： 123456app.get(&#x27;/&#x27;,function(req,res)&#123; // express默认会去views目录找index.html res.render(&#x27;index.html&#x27;,&#123; title:&#x27;hello world&#x27; &#125;);&#125;) 如果希望修改默认的views视图渲染存储目录，可以： 12// 第一个参数views千万不要写错app.set(&#x27;views&#x27;,目录路径); 在Express中获取表单请求数据获取get请求数据：Express内置了一个api，可以直接通过req.query来获取数据 123// 通过requery方法获取用户输入的数据// req.query只能拿到get请求的数据 var comment = req.query; 获取post请求数据：在Express中没有内置获取表单post请求体的api，这里我们需要使用一个第三方包body-parser来获取数据。 安装： 1npm install --save body-parser; 配置： // 配置解析表单 POST 请求体插件（注意：一定要在 app.use(router) 之前 ） 1234567891011121314var express = require(&#x27;express&#x27;)// 引包var bodyParser = require(&#x27;body-parser&#x27;)var app = express()// 配置body-parser// 只要加入这个配置，则在req请求对象上会多出来一个属性：body// 也就是说可以直接通过req.body来获取表单post请求数据// parse application/x-www-form-urlencodedapp.use(bodyParser.urlencoded(&#123; extended: false &#125;))// parse application/jsonapp.use(bodyParser.json()) 使用： 123456app.use(function (req, res) &#123; res.setHeader(&#x27;Content-Type&#x27;, &#x27;text/plain&#x27;) res.write(&#x27;you posted: &#x27;) // 可以通过req.body来获取表单请求数据 res.end(JSON.stringify(req.body, null, 2))&#125;) 在Express中配置使用express-session插件操作 参考文档：https://github.com/expressjs/session 安装： 1npm install express-session 配置： 1234567891011//该插件会为req请求对象添加一个成员:req.session默认是一个对象//这是最简单的配置方式//Session是基于Cookie实现的app.use(session(&#123; //配置加密字符串，他会在原有的基础上和字符串拼接起来去加密 //目的是为了增加安全性，防止客户端恶意伪造 secret: &#x27;keyboard cat&#x27;, resave: false, saveUninitialized: true,//无论是否适用Session，都默认直接分配一把钥匙 cookie: &#123; secure: true &#125;&#125;)) 使用： 123456789101112// 读//添加Session数据//session就是一个对象req.session.foo = &#x27;bar&#x27;;//写//获取session数据req.session.foo//删req.session.foo = null;delete req.session.foo 提示： 默认Session数据时内存储数据，服务器一旦重启，真正的生产环境会把Session进行持久化存储。 利用Express实现ADUS项目模块化思想模块如何划分: 模块职责要单一 javascript模块化： Node 中的 CommonJS 浏览器中的： AMD require.js CMD sea.js es6中增加了官方支持 起步 初始化 模板处理 路由设计 请求方法 请求路径 get参数 post参数 备注 GET /students 渲染首页 GET /students/new 渲染添加学生页面 POST /students/new name,age,gender,hobbies 处理添加学生请求 GET /students/edit id 渲染编辑页面 POST /students/edit id,name,age,gender,hobbies 处理编辑请求 GET /students/delete id 处理删除请求 提取路由模块router.js: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * router.js路由模块 * 职责： * 处理路由 * 根据不同的请求方法+请求路径设置具体的请求函数 * 模块职责要单一，我们划分模块的目的就是增强代码的可维护性，提升开发效率 */var fs = require(&#x27;fs&#x27;);// Express专门提供了一种更好的方式// 专门用来提供路由的var express = require(&#x27;express&#x27;);// 1 创建一个路由容器var router = express.Router();// 2 把路由都挂载到路由容器中router.get(&#x27;/students&#x27;, function(req, res) &#123; // res.send(&#x27;hello world&#x27;); // readFile的第二个参数是可选的，传入utf8就是告诉他把读取到的文件直接按照utf8编码，直接转成我们认识的字符 // 除了这样来转换，也可以通过data.toString（）来转换 fs.readFile(&#x27;./db.json&#x27;, &#x27;utf8&#x27;, function(err, data) &#123; if (err) &#123; return res.status(500).send(&#x27;Server error.&#x27;) &#125; // 读取到的文件数据是string类型的数据 // console.log(data); // 从文件中读取到的数据一定是字符串，所以一定要手动转换成对象 var students = JSON.parse(data).students; res.render(&#x27;index.html&#x27;, &#123; // 读取文件数据 students:students &#125;) &#125;)&#125;);router.get(&#x27;/students/new&#x27;,function(req,res)&#123; res.render(&#x27;new.html&#x27;)&#125;);router.get(&#x27;/students/edit&#x27;,function(req,res)&#123; &#125;);router.post(&#x27;/students/edit&#x27;,function(req,res)&#123; &#125;);router.get(&#x27;/students/delete&#x27;,function(req,res)&#123; &#125;);// 3 把router导出module.exports = router; app.js: 123456var router = require(&#x27;./router&#x27;);// router(app);// 把路由容器挂载到app服务中// 挂载路由app.use(router); 设计操作数据的API文件模块es6中的find和findIndex： find接受一个方法作为参数，方法内部返回一个条件 find会便利所有的元素，执行你给定的带有条件返回值的函数 符合该条件的元素会作为find方法的返回值 如果遍历结束还没有符合该条件的元素，则返回undefined 1234567891011121314151617181920212223242526272829303132333435/** * student.js * 数据操作文件模块 * 职责：操作文件中的数据，只处理数据，不关心业务 */var fs = require(&#x27;fs&#x27;); /** * 获取所有学生列表 * return [] */exports.find = function()&#123; &#125; /** * 获取添加保存学生 */exports.save = function()&#123; &#125;/** * 更新学生 */exports.update = function()&#123; &#125; /** * 删除学生 */exports.delete = function()&#123; &#125; 步骤 处理模板 配置静态开放资源 配置模板引擎 简单的路由，/studens渲染静态页出来 路由设计 提取路由模块 由于接下来的一系列业务操作都需要处理文件数据，所以我们需要封装Student.js’ 先写好student.js文件结构 查询所有学生列别哦的API findById save updateById deleteById 实现具体功能 通过路由收到请求 接受请求中的参数（get，post） req.query req.body 调用数据操作API处理数据 根据操作结果给客户端发送请求 业务功能顺序 列表 添加 编辑 删除 子模板和模板的继承（模板引擎高级语法）【include，extend，block】注意: 模板页： 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang=&quot;zh&quot;&gt;&lt;head&gt;\t&lt;meta charset=&quot;UTF-8&quot;&gt;\t&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\t&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;\t&lt;title&gt;模板页&lt;/title&gt;\t&lt;link rel=&quot;stylesheet&quot; href=&quot;/node_modules/bootstrap/dist/css/bootstrap.css&quot;/&gt;\t&#123;&#123; block &#x27;head&#x27; &#125;&#125;&#123;&#123; /block &#125;&#125;&lt;/head&gt;&lt;body&gt;\t&lt;!-- 通过include导入公共部分 --&gt;\t&#123;&#123;include &#x27;./header.html&#x27;&#125;&#125; &lt;!-- 留一个位置 让别的内容去填充 --&gt;\t&#123;&#123; block &#x27;content&#x27; &#125;&#125; &lt;h1&gt;默认内容&lt;/h1&gt;\t&#123;&#123; /block &#125;&#125; &lt;!-- 通过include导入公共部分 --&gt;\t&#123;&#123;include &#x27;./footer.html&#x27;&#125;&#125; &lt;!-- 公共样式 --&gt;\t&lt;script src=&quot;/node_modules/jquery/dist/jquery.js&quot; &gt;&lt;/script&gt;\t&lt;script src=&quot;/node_modules/bootstrap/dist/js/bootstrap.js&quot; &gt;&lt;/script&gt;\t&#123;&#123; block &#x27;script&#x27; &#125;&#125;&#123;&#123; /block &#125;&#125;&lt;/body&gt;&lt;/html&gt; 模板的继承： header页面： 123&lt;div id=&quot;&quot;&gt;\t&lt;h1&gt;公共的头部&lt;/h1&gt;&lt;/div&gt; footer页面： 123&lt;div id=&quot;&quot;&gt;\t&lt;h1&gt;公共的底部&lt;/h1&gt;&lt;/div&gt; 模板页的使用： 12345678910111213141516171819202122232425&lt;!-- 继承(extend:延伸，扩展)模板也layout.html --&gt;&lt;!-- 把layout.html页面的内容都拿进来作为index.html页面的内容 --&gt;&#123;&#123;extend &#x27;./layout.html&#x27;&#125;&#125;&lt;!-- 向模板页面填充新的数据 --&gt;&lt;!-- 填充后就会替换掉layout页面content中的数据 --&gt;&lt;!-- style样式方面的内容 --&gt;&#123;&#123; block &#x27;head&#x27; &#125;&#125;\t&lt;style type=&quot;text/css&quot;&gt; body&#123; background-color: skyblue; &#125;\t&lt;/style&gt;&#123;&#123; /block &#125;&#125;&#123;&#123; block &#x27;content&#x27; &#125;&#125;\t&lt;div id=&quot;&quot;&gt; &lt;h1&gt;Index页面的内容&lt;/h1&gt;\t&lt;/div&gt;&#123;&#123; /block &#125;&#125;&lt;!-- js部分的内容 --&gt;&#123;&#123; block &#x27;script&#x27; &#125;&#125;\t&lt;script type=&quot;text/javascript&quot;&gt; &lt;/script&gt;&#123;&#123; /block &#125;&#125; 最终的显示效果： MongoDB关系型和非关系型数据库关系型数据库（表就是关系，或者说表与表之间存在关系）。 所有的关系型数据库都需要通过sql语言来操作 所有的关系型数据库在操作之前都需要设计表结构 而且数据表还支持约束 唯一的 主键 默认值 非空 非关系型数据库 非关系型数据库非常的灵活 有的关系型数据库就是key-value对儿 但MongDB是长得最像关系型数据库的非关系型数据库 数据库 -》 数据库 数据表 -》 集合（数组） 表记录 -》文档对象 一个数据库中可以有多个数据库，一个数据库中可以有多个集合（数组），一个集合中可以有多个文档（表记录） 1234567&#123; qq:&#123; user:[ &#123;&#125;,&#123;&#125;,&#123;&#125;... ] &#125;&#125; 也就是说你可以任意的往里面存数据，没有结构性这么一说 安装 下载 下载地址：https://www.mongodb.com/download-center/community 安装 1npm i mongoose 配置环境变量 最后输入mongod --version测试是否安装成功 启动和关闭数据库启动： 123# mongodb 默认使用执行mongod 命令所处盼复根目录下的/data/db作为自己的数据存储目录# 所以在第一次执行该命令之前先自己手动新建一个 /data/dbmongod 如果想要修改默认的数据存储目录，可以： 1mongod --dbpath = 数据存储目录路径 停止： 12在开启服务的控制台，直接Ctrl+C;或者直接关闭开启服务的控制台。 连接数据库连接： 12# 该命令默认连接本机的 MongoDB 服务mongo 退出： 12# 在连接状态输入 exit 退出连接exit 基本命令 show dbs 查看数据库列表(数据库中的所有数据库) db 查看当前连接的数据库 use 数据库名称 切换到指定的数据库，（如果没有会新建） show collections 查看当前目录下的所有数据表 db.表名.find() 查看表中的详细信息 在Node中如何操作MongoDB数据库使用官方的MongoDB包来操作 http://mongodb.github.io/node-mongodb-native/ 使用第三方包mongoose来操作MongoDB数据库第三方包：`mongoose`基于MongoDB官方的`mongodb`包再一次做了封装，名字叫`mongoose`，是WordPress项目团队开发的。 12npm i mongooseexit https://mongoosejs.com/ 学习指南（步骤）官方学习文档：https://mongoosejs.com/docs/index.html 设计Scheme 发布Model (创建表)1234567891011121314151617181920212223242526272829303132333435// 1.引包// 注意：按照后才能require使用var mongoose = require(&#x27;mongoose&#x27;);// 拿到schema图表var Schema = mongoose.Schema;// 2.连接数据库// 指定连接数据库后不需要存在，当你插入第一条数据库后会自动创建数据库mongoose.connect(&#x27;mongodb://localhost/test&#x27;);// 3.设计集合结构（表结构）// 用户表var userSchema = new Schema(&#123;\tusername: &#123; //姓名 type: String, require: true //添加约束，保证数据的完整性，让数据按规矩统一\t&#125;,\tpassword: &#123; type: String, require: true\t&#125;,\temail: &#123; type: String\t&#125;&#125;);// 4.将文档结构发布为模型// mongoose.model方法就是用来将一个架构发布为 model// 第一个参数：传入一个大写名词单数字符串用来表示你的数据库的名称// mongoose 会自动将大写名词的字符串生成 小写复数 的集合名称// 例如 这里会变成users集合名称// 第二个参数：架构// 返回值：模型构造函数var User = mongoose.model(&#x27;User&#x27;, userSchema); 添加数据（增）123456789101112131415// 5.通过模型构造函数对User中的数据进行操作var user = new User(&#123;\tusername: &#x27;admin&#x27;,\tpassword: &#x27;123456&#x27;,\temail: &#x27;xiaochen@qq.com&#x27;&#125;);user.save(function(err, ret) &#123;\tif (err) &#123; console.log(&#x27;保存失败&#x27;);\t&#125; else &#123; console.log(&#x27;保存成功&#x27;); console.log(ret);\t&#125;&#125;); 删除（删）根据条件删除所有： 12345678910User.remove(&#123;\tusername: &#x27;xiaoxiao&#x27;&#125;, function(err, ret) &#123;\tif (err) &#123; console.log(&#x27;删除失败&#x27;);\t&#125; else &#123; console.log(&#x27;删除成功&#x27;); console.log(ret);\t&#125;&#125;); 根据条件删除一个： 1Model.findOneAndRemove(conditions,[options],[callback]); 根据id删除一个： 1User.findByIdAndRemove(id,[options],[callback]); 更新（改）更新所有： 1User.remove(conditions,doc,[options],[callback]); 根据指定条件更新一个： 1User.FindOneAndUpdate([conditions],[update],[options],[callback]); 根据id更新一个： 12345678910// 更新\t根据id来修改表数据User.findByIdAndUpdate(&#x27;5e6c5264fada77438c45dfcd&#x27;, &#123;\tusername: &#x27;junjun&#x27;&#125;, function(err, ret) &#123;\tif (err) &#123; console.log(&#x27;更新失败&#x27;);\t&#125; else &#123; console.log(&#x27;更新成功&#x27;);\t&#125;&#125;); 查询（查）查询所有： 12345678// 查询所有User.find(function(err,ret)&#123;\tif(err)&#123; console.log(&#x27;查询失败&#x27;);\t&#125;else&#123; console.log(ret);\t&#125;&#125;); 条件查询所有： 12345678// 根据条件查询User.find(&#123; username:&#x27;xiaoxiao&#x27; &#125;,function(err,ret)&#123;\tif(err)&#123; console.log(&#x27;查询失败&#x27;);\t&#125;else&#123; console.log(ret);\t&#125;&#125;); 条件查询单个： 1234567891011// 按照条件查询单个，查询出来的数据是一个对象（&#123;&#125;）// 没有条件查询使用findOne方法，查询的是表中的第一条数据User.findOne(&#123;\tusername: &#x27;xiaoxiao&#x27;&#125;, function(err, ret) &#123;\tif (err) &#123; console.log(&#x27;查询失败&#x27;);\t&#125; else &#123; console.log(ret);\t&#125;&#125;); 使用Node操作MySQL数据库文档：https://www.npmjs.com/package/mysql 安装： 1npm install --save mysql 1234567891011121314151617181920212223// 引入mysql包var mysql = require(&#x27;mysql&#x27;);// 创建连接var connection = mysql.createConnection(&#123; host : &#x27;localhost&#x27;,\t//本机 user : &#x27;me&#x27;, //账号root password : &#x27;secret&#x27;,\t//密码12345 database : &#x27;my_db&#x27;\t//数据库名&#125;); // 连接数据库\t（打开冰箱门）connection.connect(); //执行数据操作\t（把大象放到冰箱）connection.query(&#x27;SELECT * FROM `users` &#x27;, function (error, results, fields) &#123; if (error) throw error;//抛出异常阻止代码往下执行 // 没有异常打印输出结果 console.log(&#x27;The solution is: &#x27;,results);&#125;);//关闭连接\t（关闭冰箱门）connection.end(); 异步编程回调函数不成立的情况下： 12345678910111213function add(x,y)&#123; console.log(1); setTimeout(function()&#123; console.log(2); var ret = x + y; return ret; &#125;,1000); console.log(3); //到这里执行就结束了，不会i等到前面的定时器，所以直接返回了默认值 undefined&#125;console.log(add(2,2));// 结果是 1 3 undefined 4 使用回调函数解决： 回调函数：通过一个函数，获取函数内部的操作。（根据输入得到输出结果） 12345678910111213141516var ret;function add(x,y,callback)&#123; // callback就是回调函数 // var x = 10; // var y = 20; // var callback = function(ret)&#123;console.log(ret);&#125; console.log(1); setTimeout(function()&#123; var ret = x + y; callback(ret); &#125;,1000); console.log(3);&#125;add(10,20,function(ret)&#123; console.log(ret);&#125;); 注意： 凡是需要得到一个函数内部异步操作的结果（setTimeout,readFile,writeFile,ajax,readdir） 这种情况必须通过 回调函数 (异步API都会伴随着一个回调函数) ajax: 基于原生XMLHttpRequest封装get方法： 1234567var oReq = new XMLHttpRequest();// 当请求加载成功要调用指定的函数oReq.onload = function()&#123; console.log(oReq.responseText);&#125;oReq.open(&quot;GET&quot;, &quot;请求路径&quot;,true);oReq.send(); 12345678910111213function get(url,callback)&#123; var oReq = new XMLHttpRequest(); // 当请求加载成功要调用指定的函数 oReq.onload = function()&#123; //console.log(oReq.responseText); callback(oReq.responseText); &#125; oReq.open(&quot;GET&quot;, url,true); oReq.send();&#125;get(&#x27;data.json&#x27;,function(data)&#123; console.log(data);&#125;); Promisecallback hell（回调地狱）: 文件的读取无法判断执行顺序（文件的执行顺序是依据文件的大小来决定的）(异步api无法保证文件的执行顺序) 12345678910111213141516171819202122232425var fs = require(&#x27;fs&#x27;);fs.readFile(&#x27;./data/a.text&#x27;,&#x27;utf8&#x27;,function(err,data)&#123;\tif(err)&#123; // 1 读取失败直接打印输出读取失败 return console.log(&#x27;读取失败&#x27;); // 2 抛出异常 // 阻止程序的执行 // 把错误信息打印到控制台 throw err;\t&#125;\tconsole.log(data);&#125;);fs.readFile(&#x27;./data/b.text&#x27;,&#x27;utf8&#x27;,function(err,data)&#123;\tif(err)&#123; // 1 读取失败直接打印输出读取失败 return console.log(&#x27;读取失败&#x27;); // 2 抛出异常 // 阻止程序的执行 // 把错误信息打印到控制台 throw err;\t&#125;\tconsole.log(data);&#125;); 通过回调嵌套的方式来保证顺序： 1234567891011121314151617181920212223242526272829303132333435var fs = require(&#x27;fs&#x27;);fs.readFile(&#x27;./data/a.text&#x27;,&#x27;utf8&#x27;,function(err,data)&#123;\tif(err)&#123; // 1 读取失败直接打印输出读取失败 return console.log(&#x27;读取失败&#x27;); // 2 抛出异常 // 阻止程序的执行 // 把错误信息打印到控制台 throw err;\t&#125;\tconsole.log(data);\tfs.readFile(&#x27;./data/b.text&#x27;,&#x27;utf8&#x27;,function(err,data)&#123; if(err)&#123; // 1 读取失败直接打印输出读取失败 return console.log(&#x27;读取失败&#x27;); // 2 抛出异常 // 阻止程序的执行 // 把错误信息打印到控制台 throw err; &#125; console.log(data); fs.readFile(&#x27;./data/a.text&#x27;,&#x27;utf8&#x27;,function(err,data)&#123; if(err)&#123; // 1 读取失败直接打印输出读取失败 return console.log(&#x27;读取失败&#x27;); // 2 抛出异常 // 阻止程序的执行 // 把错误信息打印到控制台 throw err; &#125; console.log(data); &#125;);\t&#125;);&#125;); 为了解决以上编码方式带来的问题（回调地狱嵌套），所以在EcmaScript6新增了一个API:`Promise`。 Promise：承诺，保证 Promise本身不是异步的，但往往都是内部封装一个异步任务 基本语法： 12345678910111213141516171819202122232425262728// 在EcmaScript 6中新增了一个API Promise// Promise 是一个构造函数var fs = require(&#x27;fs&#x27;);// 1 创建Promise容器 resolve:解决 reject：失败var p1 = new Promise(function(resolve, reject) &#123;\tfs.readFile(&#x27;./a.text&#x27;, &#x27;utf8&#x27;, function(err, data) &#123; if (err) &#123; // console.log(err); // 把容器的Pending状态变为rejected reject(err); &#125; else &#123; // console.log(data); // 把容器的Pending状态变为resolve resolve(1234); &#125;\t&#125;);&#125;);// 当p1成功了，然后就（then）做指定的操作// then方法接收的function就是容器中的resolve函数p1\t.then(function(data) &#123; console.log(data);\t&#125;, function(err) &#123; console.log(&#x27;读取文件失败了&#x27;, err);\t&#125;); 链式循环： 封装Promise的readFile： 123456789101112131415161718192021222324252627var fs = require(&#x27;fs&#x27;);function pReadFile(filePath) &#123;\treturn new Promise(function(resolve, reject) &#123; fs.readFile(filePath, &#x27;utf8&#x27;, function(err, data) &#123; if (err) &#123; reject(err); &#125; else &#123; resolve(data); &#125; &#125;);\t&#125;);&#125;pReadFile(&#x27;./a.txt&#x27;)\t.then(function(data) &#123; console.log(data); return pReadFile(&#x27;./b.txt&#x27;);\t&#125;)\t.then(function(data) &#123; console.log(data); return pReadFile(&#x27;./a.txt&#x27;);\t&#125;)\t.then(function(data) &#123; console.log(data);\t&#125;) mongoose所有的API都支持Promise： 12345// 查询所有User.find()\t.then(function(data)&#123; console.log(data) &#125;) 注册： 12345678910111213User.findOne(&#123;username:&#x27;admin&#x27;&#125;,function(user)&#123; if(user)&#123; console.log(&#x27;用户已存在&#x27;) &#125; else &#123; new User(&#123; username:&#x27;aaa&#x27;, password:&#x27;123&#x27;, email:&#x27;fffff&#x27; &#125;).save(function()&#123; console.log(&#x27;注册成功&#x27;); &#125;) &#125;&#125;) 1234567891011121314151617181920User.findOne(&#123; username:&#x27;admin&#x27;&#125;) .then(function(user)&#123; if(user)&#123; // 用户已经存在不能注册 console.log(&#x27;用户已存在&#x27;); &#125; else&#123; // 用户不存在可以注册 return new User(&#123; username:&#x27;aaa&#x27;, password:&#x27;123&#x27;, email:&#x27;fffff&#x27; &#125;).save(); &#125; &#125;) .then(funciton(ret)&#123; console.log(&#x27;注册成功&#x27;); &#125;) Generatorasync函数 其他修改完代码自动重启我们在这里可以使用一个第三方命名行工具：nodemon来帮助我们解决频繁修改代码重启服务器的问题。 nodemon是一个基于Node.js开发的一个第三方命令行工具，我们使用的时候需要独立安装： 1234567#在任意目录执行该命令都可以#也就是说，所有需要 --global安装的包都可以在任意目录执行npm install --global nodemonnpm install -g nodemon#如果安装不成功的话，可以使用cnpm安装cnpm install -g nodemon 安装完毕之后使用： 1234node app.js#使用nodemonnodemon app.js 只要是通过nodemon启动的服务，则他会监视你的文件变化，当文件发生变化的时候，会自动帮你重启服务器。 封装异步API回调函数：获取异步操作的结果 1234567891011function fn(callback)&#123; // var callback = funtion(data)&#123; console.log(data); &#125;\tsetTimeout(function()&#123; var data = &#x27;hello&#x27;; callback(data); &#125;,1000);&#125;// 如果需要获取一个函数中异步操作的结果，则必须通过回调函数的方式来获取fn(function(data)&#123; console.log(data);&#125;) 数组的遍历方法，都是对函数作为一种参数 EcmaScript 6 参考文档：https://es6.ruanyifeng.com/ 项目案例目录结构12345678910.app.js\t项目的入口文件controllersmodels\t存储使用mongoose设计的数据模型node_modules\t第三方包package.json\t包描述文件package-lock.json\t第三方包版本锁定文件（npm5之后才有）public\t公共静态资源routesviews\t存储视图目录 模板页 子模板 模板继承 路由设计 路由 方法 get参数 post参数 是否需要登录 备注 / get 渲染首页 /register(登录) get 渲染注册页面 /register post email,nickname,password 处理注册请求 /login get 渲染登陆界面 /login post email,password 处理登录请求 /loginout get 处理退出请求 模型设计功能实现步骤 创建目录结构 整合静态也-模板页 include block extend 设计用户登陆，退出，注册的路由 用户注册 先处理客户端页面的内容（表单控件的name，收集表单数据，发起请求） 服务端 获取从客户端收到的数据 操作数据库 如果有错，发送500告诉客户端服务器错了‘ 其他的根据业务发送不同的响应数据 登录 退出 Express中间件中间件的概念 参考文档：http://expressjs.com/en/guide/using-middleware.html 中间件：把很复杂的事情分割成单个，然后依次有条理的执行。就是一个中间处理环节，有输入，有输出。 说的通俗易懂点儿，中间件就是一个（从请求到响应调用的方法）方法。 把数据从请求到响应分步骤来处理，每一个步骤都是一个中间处理环节。 123456789101112131415161718192021222324252627var http = require(&#x27;http&#x27;);var url = require(&#x27;url&#x27;);var cookie = require(&#x27;./expressPtoject/cookie&#x27;);var query = require(&#x27;./expressPtoject/query&#x27;);var postBody = require(&#x27;./expressPtoject/post-body&#x27;);var server = http.createServer(function()&#123;\t// 解析请求地址中的get参数\t// var obj = url.parse(req.url,true);\t// req.query = obj.query;\tquery(req,res);\t//中间件 // 解析请求地址中的post参数\treq.body = &#123; foo:&#x27;bar&#x27;\t&#125;&#125;);if(req.url === &#x27;xxx&#x27;)&#123;\t// 处理请求\t...&#125;server.listen(3000,function()&#123;\tconsole.log(&#x27;3000 runing...&#x27;);&#125;); 同一个请求对象所经过的中间件都是同一个请求对象和响应对象。 12345678910111213141516171819202122var express = require(&#x27;express&#x27;);var app = express();app.get(&#x27;/abc&#x27;,function(req,res,next)&#123;\t// 同一个请求的req和res是一样的，\t// 可以前面存储下面调用\tconsole.log(&#x27;/abc&#x27;);\t// req.foo = &#x27;bar&#x27;;\treq.body = &#123; name:&#x27;xiaoxiao&#x27;, age:18\t&#125;\tnext();&#125;);app.get(&#x27;/abc&#x27;,function(req,res,next)&#123;\t// console.log(req.foo);\tconsole.log(req.body);\tconsole.log(&#x27;/abc&#x27;);&#125;);app.listen(3000, function() &#123;\tconsole.log(&#x27;app is running at port 3000.&#x27;);&#125;); 中间件的分类:应用程序级别的中间件万能匹配（不关心任何请求路径和请求方法的中间件）： 1234app.use(function(req,res,next)&#123; console.log(&#x27;Time&#x27;,Date.now()); next();&#125;); 关心请求路径和请求方法的中间件： 1234app.use(&#x27;/a&#x27;,function(req,res,next)&#123; console.log(&#x27;Time&#x27;,Date.now()); next();&#125;); 路由级别的中间件严格匹配请求路径和请求方法的中间件 get: 123app.get(&#x27;/&#x27;,function(req,res)&#123;\tres.send(&#x27;get&#x27;);&#125;); post： 123app.post(&#x27;/a&#x27;,function(req,res)&#123;\tres.send(&#x27;post&#x27;);&#125;); put: 123app.put(&#x27;/user&#x27;,function(req,res)&#123;\tres.send(&#x27;put&#x27;);&#125;); delete: 123app.delete(&#x27;/delete&#x27;,function(req,res)&#123;\tres.send(&#x27;delete&#x27;);&#125;); 总12345678910111213141516171819202122232425262728293031323334353637383940414243var express = require(&#x27;express&#x27;);var app = express();// 中间件：处理请求，本质就是个函数// 在express中，对中间件有几种分类// 1 不关心任何请求路径和请求方法的中间件// 也就是说任何请求都会进入这个中间件// 中间件本身是一个方法，该方法接收三个参数// Request 请求对象// Response 响应对象// next 下一个中间件// // 全局匹配中间件// app.use(function(req, res, next) &#123;// console.log(&#x27;1&#x27;);// // 当一个请求进入中间件后// // 如果需要请求另外一个方法则需要使用next（）方法// next();// // next是一个方法，用来调用下一个中间件// // 注意：next（）方法调用下一个方法的时候，也会匹配（不是调用紧挨着的哪一个）// &#125;);// app.use(function(req, res, next) &#123;// console.log(&#x27;2&#x27;);// &#125;);// // 2 关心请求路径的中间件// // 以/xxx开头的中间件// app.use(&#x27;/a&#x27;,function(req, res, next) &#123;// console.log(req.url);// &#125;);// 3 严格匹配请求方法和请求路径的中间件app.get(&#x27;/&#x27;,function()&#123;\tconsole.log(&#x27;/&#x27;);&#125;);app.post(&#x27;/a&#x27;,function()&#123;\tconsole.log(&#x27;/a&#x27;);&#125;);app.listen(3000, function() &#123;\tconsole.log(&#x27;app is running at port 3000.&#x27;);&#125;); 错误处理中间件1234app.use(function(err,req,res,next)&#123; console.error(err,stack); res.status(500).send(&#x27;Something broke&#x27;);&#125;); 配置使用404中间件： 123app.use(function(req,res)&#123; res.render(&#x27;404.html&#x27;);&#125;); 配置全局错误处理中间件: 1234567891011121314151617app.get(&#x27;/a&#x27;, function(req, res, next) &#123;\tfs.readFile(&#x27;.a/bc&#x27;, funtion() &#123; if (err) &#123; // 当调用next()传参后，则直接进入到全局错误处理中间件方法中 // 当发生全局错误的时候，我们可以调用next传递错误对象 // 然后被全局错误处理中间件匹配到并进行处理 next(err); &#125;\t&#125;)&#125;);//全局错误处理中间件app.use(function(err,req,res,next)&#123; res.status(500).json(&#123; err_code:500, message:err.message &#125;);&#125;); 内置中间件 express.static(提供静态文件) http://expressjs.com/en/starter/static-files.html#serving-static-files-in-express 第三方中间件 参考文档：http://expressjs.com/en/resources/middleware.html body-parser compression cookie-parser mogran response-time server-static session","tags":["笔记"],"categories":["Nodejs"]},{"title":"springcloud-更换电脑后报错无法解析插件","path":"/2021/11/26/ideabaocuo/","content":"springcloud-更换电脑后报错Cannot resolve plugin org.springframework.boot:spring-boot-maven-plugin 或者 无法解析插件 Cannot resolve plugin org.springframework.boot:spring-boot-maven-plugin idea导入之后就报错Cannot resolve plugin org.springframework.boot:spring-boot-maven-plugin 原因是新项目的配置中使用的是默认的maven配置文件和默认本地仓库地址，本次是下的最新版，没发现特别的版本要求 下载文件https://maven.apache.org/index.htmlhttps://maven.apache.org/index.html 改成自定义之后的就可以了，参考下图","tags":["报错"],"categories":["Java"]},{"title":"org.apache.maven.plugins:maven-site-plugin:3.3","path":"/2021/11/15/maven3/","content":"新的环境idea创建springboot时遇到这个错误，首先排除maven继承路径不一致的问题，这个配置环境的时候必须是基本操作，这种环境都不去先配好，写个锤子手动导入依赖吧 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;version&gt;3.6.3&lt;/version&gt; &lt;/dependency&gt;","tags":["报错"],"categories":["Java"]},{"title":"Vue详细笔记","path":"/2021/11/12/vuenote/","content":"Vue实战1. Vue 引言 渐进式 JavaScript 框架 —摘自官网 123456789101112# 渐进式 1. 易用 html css javascript 2. 高效 开发前端页面 非常高效 3. 灵活 开发灵活 多样性# 总结 Vue 是一个javascript 框架# 后端服务端开发人员: Vue 渐进式javascript框架: 让我们通过操作很少的DOM,甚至不需要操作页面中任何DOM元素,就很容易的完成数据和视图绑定 双向绑定 MVVM 注意: 日后在使用Vue过程中页面中不要在引入Jquery框架 htmlcss---&gt;javascript -----&gt;jquery----&gt;angularjs -----&gt; Vue # Vue 作者 尤雨溪 国内的 2. Vue入门2.1 下载Vuejs123456//开发版本: &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt;//生产版本: &lt;!-- 生产环境版本，优化了尺寸和速度 --&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue&quot;&gt;&lt;/script&gt; 2.2 Vue第一个入门应用1234567891011121314151617181920212223242526&lt;div id=&quot;app&quot;&gt; &#123; &#123; msg &#125;&#125; &#123; &#123;username&#125;&#125; &#123; &#123;pwd&#125;&#125; &lt;br&gt; &lt;span&gt; &#123; &#123; username &#125;&#125; &lt;h1&gt;&#123; &#123; msg &#125;&#125;&lt;/h1&gt; &lt;/span&gt; &lt;/div&gt; &lt;!--引入vue.js--&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, //element 用来给Vue实例定义一个作用范围 data:&#123; //用来给Vue实例定义一些相关数据 msg:&quot;haust欢迎你,期待你的加入!&quot;, username:&quot;hello Vue!&quot;, pwd :&quot;12345&quot;, &#125;, &#125;); &lt;/script&gt; 12345678# 总结: 1.vue实例(对象)中el属性: 代表Vue的作用范围 日后在Vue的作用范围内都可以使用Vue的语法 2.vue实例(对象)中data属性: 用来给Vue实例绑定一些相关数据, 绑定的数据可以通过&#123; &#123;变量名&#125;&#125;在Vue作用范围内取出 3.在使用&#123; &#123;&#125;&#125;进行获取data中数据时,可以在&#123; &#123;&#125;&#125;中书写表达式,运算符,调用相关方法,以及逻辑运算等 4.el属性中可以书写任意的CSS选择器[jquery选择器],但是在使用Vue开发是推荐使用 id选择器 3. v-text和v-html3.1 v-text v-text:用来获取data中数据将数据以文本的形式渲染到指定标签内部 类似于javascript 中 innerText 123456789101112131415&lt;div id=&quot;app&quot; class=&quot;aa&quot;&gt; &lt;span &gt;&#123; &#123; message &#125;&#125;&lt;/span&gt; &lt;span v-text=&quot;message&quot;&gt;&lt;/span&gt; &lt;/div&gt; &lt;!--引入vue.js--&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, data:&#123; message:&quot;haust欢迎您&quot; &#125; &#125;) &lt;/script&gt; 12345# 总结 1.&#123; &#123;&#125;&#125;(插值表达式)和v-text获取数据的区别在于 a.使用v-text取值会将标签中原有的数据覆盖 使用插值表达式的形式不会覆盖标签原有的数据 b.使用v-text可以避免在网络环境较差的情况下出现插值闪烁 3.2 v-html v-html:用来获取data中数据将数据中含有的html标签先解析在渲染到指定标签的内部 类似于javascript中 innerHTML 123456789101112131415161718&lt;div id=&quot;app&quot; class=&quot;aa&quot;&gt; &lt;span&gt;&#123; &#123;message&#125;&#125;&lt;/span&gt; &lt;br&gt; &lt;span v-text=&quot;message&quot;&gt;&lt;/span&gt; &lt;br&gt; &lt;span v-html=&quot;message&quot;&gt;xxxxxx&lt;/span&gt; &lt;/div&gt; &lt;!--引入vue.js--&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, data:&#123; message:&quot;&lt;a href=&#x27;&#x27;&gt;百知欢迎您&lt;/a&gt;&quot; &#125; &#125;) &lt;/script&gt; 4.vue中事件绑定(v-on)4.1 绑定事件基本语法1234567891011121314151617181920212223242526&lt;div id=&quot;app&quot;&gt; &lt;h2&gt;&#123; &#123;message&#125;&#125;&lt;/h2&gt; &lt;h2 v-text=&quot;message&quot;&gt;&lt;/h2&gt; &lt;h2&gt;年龄:&#123; &#123; age &#125;&#125;&lt;/h2&gt; &lt;br&gt; &lt;input type=&quot;button&quot; value=&quot;点我改变年龄&quot; v-on:click=&quot;changeage&quot;&gt; &lt;/div&gt; &lt;!--引入vue.js--&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, data:&#123; message:&quot;hello 欢迎来到百知课堂!&quot;, age:23, &#125;, methods:&#123; //methods 用来定义vue中时间 changeage:function()&#123; alert(&#x27;点击触发&#x27;); &#125; &#125; &#125;) &lt;/script&gt; 123456# 总结: 事件 事件源:发生事件dom元素 事件: 发生特定的动作 click.... 监听器 发生特定动作之后的事件处理程序 通常是js中函数 1.在vue中绑定事件是通过v-on指令来完成的 v-on:事件名 如 v-on:click 2.在v-on:事件名的赋值语句中是当前时间触发调用的函数名 3.在vue中事件的函数统一定义在Vue实例的methods属性中 4.在vue定义的事件中this指的就是当前的Vue实例,日后可以在事件中通过使用this获取Vue实例中相关数据 4.2 Vue中事件的简化语法123456789101112131415161718192021222324&lt;div id=&quot;app&quot;&gt; &lt;h2&gt;&#123; &#123; age &#125;&#125;&lt;/h2&gt; &lt;input type=&quot;button&quot; value=&quot;通过v-on事件修改年龄每次+1&quot; v-on:click=&quot;changeage&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;通过@绑定时间修改年龄每次-1&quot; @click=&quot;editage&quot;&gt; &lt;/div&gt; &lt;!--引入vue.js--&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, //element: 用来指定vue作用范围 data:&#123; age:23, &#125;, //data : 用来定义vue实例中相关数据 methods:&#123; changeage:function()&#123; this.age++; &#125;, editage:function()&#123; this.age--; &#125; &#125; //methods: 用来定义事件的处理函数 &#125;); &lt;/script&gt; 12# 总结: 1.日后在vue中绑定事件时可以通过@符号形式 简化 v-on 的事件绑定 4.3 Vue事件函数两种写法123456789101112131415161718192021222324&lt;div id=&quot;app&quot;&gt; &lt;h2&gt;&#123; &#123; age &#125;&#125;&lt;/h2&gt; &lt;input type=&quot;button&quot; value=&quot;通过v-on事件修改年龄每次+1&quot; v-on:click=&quot;changeage&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;通过@绑定时间修改年龄每次-1&quot; @click=&quot;editage&quot;&gt; &lt;/div&gt; &lt;!--引入vue.js--&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, //element: 用来指定vue作用范围 data:&#123; age:23, &#125;, //data : 用来定义vue实例中相关数据 methods:&#123; changeage:function()&#123; this.age++; &#125;, editage:function()&#123; this.age--; &#125; &#125; //methods: 用来定义事件的处理函数 &#125;); &lt;/script&gt; 12# 总结: 1.在Vue中事件定义存在两种写法 一种是 函数名:function()&#123;&#125; 一种是函数名:()&#123;&#125; 4.4 Vue事件参数传递12345678910111213141516171819202122&lt;div id=&quot;app&quot;&gt; &lt;span&gt;&#123; &#123;count&#125;&#125;&lt;/span&gt; &lt;input type=&quot;button&quot; value=&quot;改变count为指定的值&quot; @click=&quot;changecount(23,&#x27;xiaohei&#x27;)&quot;&gt; &lt;/div&gt; &lt;!--引入vue.js--&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt; &lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, data:&#123; count:1, &#125;, methods:&#123; //定义changecount changecount(count,name)&#123; this.count = count; alert(name); &#125; &#125; &#125;); &lt;/script&gt; 12# 总结: 1.在使用事件时,可以直接在事件调用出给事件进行参数传递,在事件定义出通过定义对应变量接收传递的参数 5.v-show v-if v-bind5.1 v-show v-show:用来控制页面中某个标签元素是否展示 底层使用控制是 display 属性 123456789101112131415161718192021222324&lt;div id=&quot;app&quot;&gt; &lt;!-- v-show: 用来控制标签展示还是隐藏的 --&gt; &lt;h2 v-show=&quot;false&quot;&gt;百知教育欢迎你的加入!&lt;/h2&gt; &lt;h2 v-show=&quot;show&quot;&gt;百知教育欢迎你的加入这是vue中定义变量true!&lt;/h2&gt; &lt;input type=&quot;button&quot; value=&quot;展示隐藏标签&quot; @click=&quot;showmsg&quot;&gt;&lt;/div&gt;&lt;!--引入vue.js--&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, data:&#123; show:false, &#125;, methods:&#123; //定义时间 showmsg()&#123; this.show = !this.show; &#125; &#125; &#125;)&lt;/script&gt; 123# 总结 1.在使用v-show时可以直接书写boolean值控制元素展示,也可以通过变量控制标签展示和隐藏 2.在v-show中可以通过boolean表达式控制标签的展示课隐藏 5.2 v-if v-if: 用来控制页面元素是否展示 底层控制是DOM元素 操作DOM 12345678910111213141516&lt;div id=&quot;app&quot;&gt; &lt;h2 v-if=&quot;false&quot;&gt;百知教育&lt;/h2&gt; &lt;h2 v-if=&quot;show&quot;&gt;百知教育欢迎你的加入&lt;/h2&gt;&lt;/div&gt;&lt;!--引入vue.js--&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, data:&#123; show:false &#125;, methods:&#123; &#125; &#125;);&lt;/script&gt; 5.3 v-bind v-bind: 用来绑定标签的属性从而通过vue动态修改标签的属性 12345678910111213141516&lt;div id=&quot;app&quot;&gt; &lt;img width=&quot;300&quot; v-bind:title=&quot;msg&quot; v-bind:class=&quot;&#123;aa:showCss&#125;&quot; src=&quot;baizhilogo.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;!--引入vue.js--&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, data:&#123; msg:&quot;csp!!!!&quot;, showCss:true, &#125;, methods:&#123; &#125; &#125;)&lt;/script&gt; 5.4 v-bind 简化写法 vue为了方便我们日后绑定标签的属性提供了对属性绑定的简化写法如 v-bind:属性名 简化之后 :属性名 12345678910111213141516171819202122232425&lt;div id=&quot;app&quot;&gt; &lt;img width=&quot;300&quot; :title=&quot;msg&quot; :class=&quot;&#123;aa:showCss&#125;&quot; :src=&quot;src&quot; alt=&quot;&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;动态控制加入样式&quot; @click=&quot;addCss&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;改变图片&quot; @click=&quot;changeSrc&quot;&gt;&lt;/div&gt;&lt;!--引入vue.js--&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el:&quot;#app&quot;, data:&#123; msg:&quot;hello&quot;, showCss:true, src:&quot;https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1583490365568&amp;di=52a82bd614cd4030f97ada9441bb2d0e&amp;imgtype=0&amp;src=http%3A%2F%2Fimg.kanzhun.com%2Fimages%2Flogo%2F20160714%2F820a68f65b4e4a3634085055779c000c.jpg&quot; &#125;, methods:&#123; addCss()&#123; this.showCss= !this.showCss; &#125;, changeSrc()&#123; this.src = &quot;https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=1925088662,1336364220&amp;fm=26&amp;gp=0.jpg&quot;; &#125; &#125; &#125;)&lt;/script&gt; 6.v-for的使用 v-for: 作用就是用来对对象进行遍历的(数组也是对象的一种) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;div id=&quot;app&quot;&gt; &lt;span&gt;&#123; &#123; user.name &#125;&#125; &#123; &#123; user.age &#125;&#125;&lt;/span&gt; &lt;br&gt; &lt;!-- 通过v-for遍历对象 --&gt; &lt;span v-for=&quot;(value,key,index) in user&quot;&gt; &#123; &#123;index&#125;&#125; : &#123; &#123;key&#125;&#125; : &#123; &#123;value&#125;&#125; &lt;/span&gt; &lt;!-- 通过v-for遍历数组 --&gt; &lt;ul&gt; &lt;li v-for=&quot;a,index in arr&quot; &gt; &#123; &#123;index&#125;&#125; &#123; &#123;a&#125;&#125; &lt;/li&gt; &lt;/ul&gt; &lt;!-- 通过v-for遍历数组中对象 :key 便于vue内部做重用和排序 --&gt; &lt;ul&gt; &lt;li v-for=&quot;user,index in users&quot; :key=&quot;user.id&quot;&gt; &#123; &#123;index+1&#125;&#125; &#123; &#123; user.name &#125;&#125; === &#123; &#123; user.age &#125;&#125; ==== &#123; &#123; user.content &#125;&#125; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;!--引入vue--&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; user:&#123; name:&quot;csp&quot;,age:22&#125;, arr:[&quot;西苑校区&quot;, &quot;开元校区&quot;, &quot;河科大&quot;], users:[ &#123; id:&quot;1&quot;,name:&quot;csp&quot;,age:23,content:&quot;我还是哪个充钱的少年!&quot;&#125;, &#123; id:&quot;2&quot;,name:&quot;java小白&quot;,age:23,content:&quot;没有一丝丝改变!&quot;&#125;, ] &#125;, methods: &#123; &#125; &#125;);&lt;/script&gt; 7 .v-model 双向绑定 v-model: 作用用来绑定标签元素的值与vue实例对象中data数据保持一致,从而实现双向的数据绑定机制 12345678910111213141516171819202122&lt;div id=&quot;app&quot;&gt; &lt;input type=&quot;text&quot; v-model=&quot;message&quot;&gt; &lt;span&gt;&#123; &#123;message&#125;&#125;&lt;/span&gt; &lt;hr&gt; &lt;input type=&quot;button&quot; value=&quot;改变Data中值&quot; @click=&quot;changeValue&quot;&gt;&lt;/div&gt;&lt;!--引入vue--&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; message:&quot;&quot; &#125;, methods: &#123; changeValue()&#123; this.message=&#x27;hello!&#x27;; &#125; &#125; &#125;);&lt;/script&gt; 12345678# 总结 1.使用v-model指令可以实现数据的双向绑定 2.所谓双向绑定 表单中数据变化导致vue实例data数据变化 vue实例中data数据的变化导致表单中数据变化 称之为双向绑定# MVVM架构 双向绑定机制 Model: 数据 Vue实例中绑定数据 VM: ViewModel 监听器 View: 页面 页面展示的数据 8. 事件修饰符 修饰符: 作用用来和事件连用,用来决定事件触发条件或者是阻止事件的触发机制 1234567# 1.常用的事件修饰符 .stop .prevent .capture .self .once .passive 8.1 stop事件修饰符 用来阻止事件冒泡 1234567891011121314151617181920212223&lt;div id=&quot;app&quot;&gt; &lt;div class=&quot;aa&quot; @click=&quot;divClick&quot;&gt; &lt;!--用来阻止事件冒泡--&gt; &lt;input type=&quot;button&quot; value=&quot;按钮&quot; @click.stop=&quot;btnClick&quot;&gt; &lt;/div&gt;&lt;/div&gt;&lt;!--引入vue--&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; &#125;, methods: &#123; btnClick()&#123; alert(&#x27;button被点击了&#x27;); &#125;, divClick()&#123; alert(&#x27;div被点击了&#x27;); &#125; &#125; &#125;);&lt;/script&gt; 8.2 prevent 事件修饰符 用来阻止标签的默认行为 12&lt;!--用来阻止事件的默认行为--&gt; &lt;a href=&quot;http://www.baizhibest.com/&quot; @click.prevent=&quot;aClick&quot;&gt;Hello World&lt;/a&gt; 8.3 self 事件修饰符 用来针对于当前标签的事件触发 ===========&gt; 只触发自己标签的上特定动作的事件 只关心自己标签上触发的事件 不监听事件冒泡 123456&lt;!--只触发标签自身的事件--&gt; &lt;div class=&quot;aa&quot; @click.self=&quot;divClick&quot;&gt; &lt;!--用来阻止事件冒泡--&gt; &lt;input type=&quot;button&quot; value=&quot;按钮&quot; @click.stop=&quot;btnClick&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;按钮1&quot; @click=&quot;btnClick1&quot;&gt; &lt;/div&gt; 8.4 once 事件修饰符 once 一次 作用: 就是让指定事件只触发一次 12345&lt;!-- .prevent : 用来阻止事件的默认行为 .once : 用来只执行一次特定的事件 --&gt; &lt;a href=&quot;http://www.baizhibest.com/&quot; @click.prevent.once=&quot;aClick&quot;&gt;Hello World&lt;/a&gt; 9. 按键修饰符 作用: 用来与键盘中按键事件绑定在一起,用来修饰特定的按键事件的修饰符 12345678910# 按键修饰符 .enter .tab .delete (捕获“删除”和“退格”键) .esc .space .up .down .left .right 9.1 enter 回车键 用来在触发回车按键之后触发的事件 1&lt;input type=&quot;text&quot; v-model=&quot;msg&quot; @keyup.enter=&quot;keyups&quot;&gt; 9.2 tab 键 用来捕获到tab键执行到当前标签是才会触发 1&lt;input type=&quot;text&quot; @keyup.tab=&quot;keytabs&quot;&gt; 10. Axios 基本使用10.1 引言 Axios 是一个异步请求技术,核心作用就是用来在页面中发送异步请求,并获取对应数据在页面中渲染 页面局部更新技术 Ajax 10.2 Axios 第一个程序中文网站:https://www.kancloud.cn/yunye/axios/234845 安装: https://unpkg.com/axios/dist/axios.min.js 10.2.1 GET方式的请求123456//发送GET方式请求 axios.get(&quot;http://localhost:8989/user/findAll?name=xiaochen&quot;).then(function(response)&#123; console.log(response.data); &#125;).catch(function(err)&#123; console.log(err); &#125;); 10.2.2 POST方式请求1234567891011//发送POST方式请求 axios.post(&quot;http://localhost:8989/user/save&quot;,&#123; username:&quot;xiaochen&quot;, age:23, email:&quot;xiaochen@zparkhr.com&quot;, phone:13260426185 &#125;).then(function(response)&#123; console.log(response.data); &#125;).catch(function(err)&#123; console.log(err); &#125;); 10.2.3 axios并发请求 并发请求: 将多个请求在同一时刻发送到后端服务接口,最后在集中处理每个请求的响应结果 123456789101112131415161718192021//1.创建一个查询所有请求 function findAll()&#123; return axios.get(&quot;http://localhost:8989/user/findAll?name=csp&quot;); &#125; //2.创建一个保存的请求 function save()&#123; return axios.post(&quot;http://localhost:8989/user/save&quot;,&#123; username:&quot;csp&quot;, age:22, email:&quot;1165680007@qq.com&quot;, phone:13260426185 &#125;); &#125; //3.并发执行 axios.all([findAll(),save()]).then( axios.spread(function(res1,res2)&#123; //用来将一组函数的响应结果汇总处理 console.log(res1.data); console.log(res2.data); &#125;) );//用来发送一组并发请求 11. Vue 生命周期 1生命周期钩子` ====&gt; `生命周期函数 123456789101112131415161718192021222324252627282930313233343536# Vue生命周期总结 1.初始化阶段 beforeCreate()&#123; //1.生命周期中第一个函数,该函数在执行时Vue实例仅仅完成了自身事件的绑定和生命周期函数的初始化工作,Vue实例中还没有 Data el methods相关属性 console.log(&quot;beforeCreate: &quot;+this.msg); &#125;, created()&#123; //2.生命周期中第二个函数,该函数在执行时Vue实例已经初始化了data属性和methods中相关方法 console.log(&quot;created: &quot;+this.msg); &#125;, beforeMount()&#123; //3.生命周期中第三个函数,该函数在执行时Vue将El中指定作用范围作为模板编译 console.log(&quot;beforeMount: &quot;+document.getElementById(&quot;sp&quot;).innerText); &#125;, mounted()&#123; //4.生命周期中第四个函数,该函数在执行过程中,已经将数据渲染到界面中并且已经更新页面 console.log(&quot;Mounted: &quot;+document.getElementById(&quot;sp&quot;).innerText); &#125; 2.运行阶段 beforeUpdate()&#123; //5.生命周期中第五个函数,该函数是data中数据发生变化时执行 这个事件执行时仅仅是Vue实例中data数据变化页面显示的依然是原始数据 console.log(&quot;beforeUpdate:&quot;+this.msg); console.log(&quot;beforeUpdate:&quot;+document.getElementById(&quot;sp&quot;).innerText); &#125;, updated()&#123; //6.生命周期中第六个函数,该函数执行时data中数据发生变化,页面中数据也发生了变化 页面中数据已经和data中数据一致 console.log(&quot;updated:&quot;+this.msg); console.log(&quot;updated:&quot;+document.getElementById(&quot;sp&quot;).innerText); &#125;, 3.销毁阶段 beforeDestory()&#123; //7.生命周期第七个函数,该函数执行时,Vue中所有数据 methods componet 都没销毁 &#125;, destoryed()&#123; //8.生命周期的第八个函数,该函数执行时,Vue实例彻底销毁 &#125; 12. Vue中组件(Component)12.1 组件作用组件作用: 用来减少Vue实例对象中代码量,日后在使用Vue开发过程中,可以根据 不能业务功能将页面中划分不同的多个组件,然后由多个组件去完成整个页面的布局,便于日后使用Vue进行开发时页面管理,方便开发人员维护。 12.2 组件使用12.2.1 全局组件注册123456//1.开发全局组件 Vue.component(&#x27;login&#x27;,&#123; template:&#x27;&lt;div&gt;&lt;h1&gt;用户登录&lt;/h1&gt;&lt;/div&gt;&#x27; &#125;);//2.使用全局组件 在Vue实例范围内 &lt;login&gt;&lt;/login&gt; 1234# 注意: 1.Vue.component用来开发全局组件 参数1: 组件的名称 参数2: 组件配置&#123;&#125; template:&#x27;&#x27;用来书写组件的html代码 template中必须有且只有一个root元素 2.使用时需要在Vue的作用范围内根据组件名使用全局组件 3.如果在注册组件过程中使用 驼峰命名组件的方式 在使用组件时 必须将驼峰的所有单词小写加入-线进行使用 12.2.2 局部组件注册1说明:通过将组件注册给对应Vue实例中一个components属性来完成组件注册,这种方式不会对Vue实例造成累加 第一种开发方式 123456789101112131415161718//局部组件登录模板声明 let login =&#123; //具体局部组件名称 template:&#x27;&lt;div&gt;&lt;h2&gt;用户登录&lt;/h2&gt;&lt;/div&gt;&#x27; &#125;; const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; &#125;, methods: &#123; &#125;, components:&#123; //用来注册局部组件 login:login //注册局部组件 &#125; &#125;); //局部组件使用 在Vue实例范围内 &lt;login&gt;&lt;/login&gt; 第二种开发方式 1234567891011121314151617181920212223//1.声明局部组件模板 template 标签 注意:在Vue实例作用范围外声明 &lt;template id=&quot;loginTemplate&quot;&gt; &lt;h1&gt;用户登录&lt;/h1&gt; &lt;/template&gt;//2.定义变量用来保存模板配置对象 let login =&#123; //具体局部组件名称 template:&#x27;#loginTemplate&#x27; //使用自定义template标签选择器即可 &#125;;//3.注册组件 const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; &#125;, methods: &#123; &#125;, components:&#123; //用来注册局部组件 login:login //注册局部组件 &#125; &#125;); //4.局部组件使用 在Vue实例范围内 &lt;login&gt;&lt;/login&gt; 12.3 Prop的使用1作用:props用来给组件传递相应静态数据或者是动态数据的 12.3.1 通过在组件上声明静态数据传递给组件内部1234567891011121314151617181920//1.声明组件模板配置对象 let login = &#123; template:&quot;&lt;div&gt;&lt;h1&gt;欢迎:&#123; &#123; userName &#125;&#125; 年龄:&#123; &#123; age &#125;&#125;&lt;/h1&gt;&lt;/div&gt;&quot;, props:[&#x27;userName&#x27;,&#x27;age&#x27;] //props作用 用来接收使用组件时通过组件标签传递的数据 &#125;//2.注册组件 const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; &#125;, methods: &#123; &#125;, components:&#123; login //组件注册 &#125; &#125;);//3.通过组件完成数据传递 &lt;login user-name=&quot;csp&quot; age=&quot;22&quot;&gt;&lt;/login&gt; 1234# 总结: 1.使用组件时可以在组件上定义多个属性以及对应数据 2.在组件内部可以使用props数组生命多个定义在组件上的属性名 日后可以在组件中通过&#123; &#123; 属性名 &#125;&#125; 方式获取组件中属性值 12.3.2 通过在组件上声明动态数据传递给组件内部12345678910111213141516171819202122//1.声明组件模板对象 const login = &#123; template:&#x27;&lt;div&gt;&lt;h2&gt;欢迎: &#123; &#123; name &#125;&#125; 年龄:&#123; &#123; age &#125;&#125;&lt;/h2&gt;&lt;/div&gt;&#x27;, props:[&#x27;name&#x27;,&#x27;age&#x27;] &#125;//2.注册局部组件 const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; username:&quot;csp&quot;, age:22 &#125;, methods: &#123; &#125;, components:&#123; login //注册组件 &#125; &#125;);//3.使用组件 &lt;login :name=&quot;username&quot; :age=&quot;age&quot;&gt;&lt;/login&gt; //使用v-bind形式将数据绑定Vue实例中data属性,日后data属性发生变化,组件内部数据跟着变化 12.3.3 prop的单向数据流1单向数据流:所有的 prop 都使得其父子 prop 之间形成了一个**单向下行绑定**：父级 prop 的更新会向下流动到子组件中，但是反过来则不行。 所有的 prop 都使得其父子 prop 之间形成了一个单向下行绑定：父级 prop 的更新会向下流动到子组件中，但是反过来则不行。这样会防止从子组件意外改变父级组件的状态，从而导致你的应用的数据流向难以理解。 额外的，每次父级组件发生更新时，子组件中所有的 prop 都将会刷新为最新的值。这意味着你不应该在一个子组件内部改变 prop。如果你这样做了，Vue 会在浏览器的控制台中发出警告。—摘自官网 12.4 组件中定义数据和事件使用1. 组件中定义属于组件的数据1234567891011121314//组件声明的配置对象 const login = &#123; template:&#x27;&lt;div&gt;&lt;h1&gt;&#123; &#123; msg &#125;&#125; Hello World&lt;/h1&gt;&lt;ul&gt;&lt;li v-for=&quot;item,index in lists&quot;&gt;&#123; &#123; index &#125;&#125;&#123; &#123; item &#125;&#125;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&#x27;, data()&#123; //使用data函数方式定义组件的数据 在templatehtml代码中通过插值表达式直接获取 return &#123; msg:&quot;hello&quot;, lists:[&#x27;java&#x27;,&#x27;spring&#x27;,&#x27;springboot&#x27;] &#125;//组件自己内部数据 &#125; &#125; 2.组件中事件定义1234567891011121314const login=&#123; template:&#x27;&lt;div&gt;&lt;input type=&quot;button&quot; value=&quot;点我触发组件中事件&quot; @click=&quot;change&quot;&gt;&lt;/div&gt;&#x27;, data()&#123; return &#123; name:&#x27;csp&#x27; &#125;; &#125;, methods:&#123; change()&#123; alert(this.name) alert(&#x27;触发事件&#x27;); &#125; &#125; &#125; 123# 总结 1.组件中定义事件和直接在Vue中定义事件基本一致 直接在组件内部对应的html代码上加入@事件名=函数名方式即可 2.在组件内部使用methods属性用来定义对应的事件函数即可,事件函数中this 指向的是当前组件的实例 12.5 向子组件中传递事件并在子组件中调用改事件1234567891011121314151617181920212223242526272829303132333435//1.声明组件 const login = &#123; template:&quot;&lt;div&gt;&lt;h1&gt;Hello World &#123; &#123; uname &#125;&#125;&lt;/h1&gt; &lt;input type=&#x27;button&#x27; value=&#x27;点我&#x27; @click=&#x27;change&#x27;&gt;&lt;/div&gt;&quot;, data()&#123; return &#123; uname:this.name &#125; &#125;, props:[&#x27;name&#x27;], methods:&#123; change()&#123; //调用vue实例中函数 this.$emit(&#x27;aaa&#x27;); //调用组件传递过来的其他函数时需要使用 this.$emit(&#x27;函数名调用&#x27;) &#125; &#125; &#125; //2.注册组件 const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; username:&quot;csp&quot; &#125;, methods: &#123; findAll()&#123; //一个事件函数 将这个函数传递给子组件 alert(&#x27;Vue 实例中定义函数&#x27;); &#125; &#125;, components:&#123; login,//组件的注册 &#125; &#125;);//3.使用组件 &lt;login @find=&quot;findAll&quot;&gt;&lt;/login&gt; //=====&gt; 在组件内部使用 this.$emit(&#x27;find&#x27;) 13.Vue中路由(VueRouter)13.1 路由1路由:根据请求的路径按照一定的路由规则进行请求的转发从而帮助我们实现统一请求的管理 13.2 作用1用来在vue中实现组件之间的动态切换 13.3 使用路由 引入路由12&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://unpkg.com/vue-router/dist/vue-router.js&quot;&gt;&lt;/script&gt; //vue 路由js 创建组件对象1234567//声明组件模板const login = &#123; template:&#x27;&lt;h1&gt;登录&lt;/h1&gt;&#x27;&#125;;const register = &#123; template:&#x27;&lt;h1&gt;注册&lt;/h1&gt;&#x27;&#125;; 定义路由对象的规则123456789//创建路由对象const router = new VueRouter(&#123; routes:[ &#123; path:&#x27;/login&#x27;,component:login&#125;, //path: 路由的路径 component:路径对应的组件 &#123; path:&#x27;/register&#x27;,component:register&#125; ]&#125;); 将路由对象注册到vue实例123456789const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; username:&quot;csp&quot;, &#125;, methods: &#123; &#125;, router:router //设置路由对象&#125;); 在页面中显示路由的组件12&lt;!--显示路由的组件--&gt;&lt;router-view&gt;&lt;/router-view&gt; 根据连接切换路由12&lt;a href=&quot;#/login&quot;&gt;点我登录&lt;/a&gt;&lt;a href=&quot;#/register&quot;&gt;点我注册&lt;/a&gt; 13.4 router-link使用1234567891011const router = new VueRouter(&#123; routes:[ //&#123; path:&#x27;/&#x27;,component:login&#125;, &#123; path:&#x27;/&#x27;,redirect:&#x27;/login&#x27;&#125;, //redirect: 用来当访问的是默认路由 &quot;/&quot; 时 跳转到指定的路由展示 推荐使用 &#123; path:&#x27;/login&#x27;, component:login&#125;, &#123; path:&#x27;/register&#x27;, component:register&#125;, ]&#125;); 13.5 默认路由12作用:用来在第一次进入界面是显示一个默认的组件const router = new VueRouter(&#123; routes:[ //&#123; path:&#x27;/&#x27;,component:login&#125;, &#123; path:&#x27;/&#x27;,redirect:&#x27;/login&#x27;&#125;, //redirect: 用来当访问的是默认路由 &quot;/&quot; 时 跳转到指定的路由展示 推荐使用 &#123; path:&#x27;/login&#x27;, component:login&#125;, &#123; path:&#x27;/register&#x27;, component:register&#125;, ]&#125;); 13.6 路由中参数传递 第一种方式传递参数 传统方式 通过?号形式拼接参数 1&lt;router-link to=&quot;/login?id=21&amp;name=zhangsan&quot;&gt;我要登录&lt;/router-link&gt; 组件中获取参数 1234567891011const login = &#123; template:&#x27;&lt;h1&gt;用户登录&lt;/h1&gt;&#x27;, data()&#123; return &#123; &#125;&#125;, methods:&#123; &#125;, created()&#123; console.log(&quot;=============&gt;&quot;+this.$route.query.id+&quot;======&gt;&quot;+this.$route.query.name); &#125;&#125;; 第二种方式传递参数 restful 通过使用路径方式传递参数 1234567&lt;router-link to=&quot;/register/24/csp&quot;&gt;我要注册&lt;/router-link&gt;var router = new VueRouter(&#123; routes:[ &#123; path:&#x27;/register/:id/:name&#x27;,component:register&#125; //定义路径中获取对应参数 ]&#125;); 组件中获取参数 1234567const register = &#123; template:&#x27;&lt;h1&gt;用户注册&#123; &#123; $route.params.name &#125;&#125;&lt;/h1&gt;&#x27;, created()&#123; console.log(&quot;注册组件中id: &quot;+this.$route.params.id+this.$route.params.name); &#125;&#125;; 13.7 嵌套路由 声明最外层和内层路由123456789101112131415161718&lt;template id=&quot;product&quot;&gt; &lt;div&gt; &lt;h1&gt;商品管理&lt;/h1&gt; &lt;router-link to=&quot;/product/add&quot;&gt;商品添加&lt;/router-link&gt; &lt;router-link to=&quot;/product/edit&quot;&gt;商品编辑&lt;/router-link&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;/div&gt;&lt;/template&gt;//声明组件模板const product=&#123; template:&#x27;#product&#x27;&#125;;const add = &#123; template:&#x27;&lt;h4&gt;商品添加&lt;/h4&gt;&#x27;&#125;;const edit = &#123; template:&#x27;&lt;h4&gt;商品编辑&lt;/h4&gt;&#x27;&#125;; 创建路由对象含有嵌套路由1234567891011121314const router = new VueRouter(&#123; routes:[ &#123; path:&#x27;/product&#x27;, component:product, children:[ &#123; path:&#x27;add&#x27;,component: add&#125;, &#123; path:&#x27;edit&#x27;,component: edit&#125;, ] &#125;, ] &#125;); 注册路由对象12345678const app = new Vue(&#123; el: &quot;#app&quot;, data: &#123; &#125;, methods: &#123; &#125;, router,//定义路由对象&#125;); 测试路由 12&lt;router-link to=&quot;/product&quot;&gt;商品管理&lt;/router-link&gt;&lt;router-view&gt;&lt;/router-view&gt; 14. Vue CLI 脚手架14.1 什么是CLI命令行界面（英语：command-line interface，缩写：CLI）是在图形用户界面得到普及之前使用最为广泛的用户界面，它通常不支持鼠标，用户通过键盘输入指令，计算机接收到指令后，予以执行。也有人称之为字符用户界面（CUI） 14.2 什么是Vue CLIVue CLI 是一个基于 Vue.js 进行快速开发的完整系统。使用Vue 脚手架之后我们开发的页面将是一个完整系统(项目)。 14.3 Vue CLI优势 通过 vue-cli 搭建交互式的项目脚手架。bootstrap css js jquery js 通过执行命令方式下载相关依赖 通过 @vue/cli + @vue/cli-service-global 快速开始零配置原型开发 vue页面 vuejs vuerouter axios(一条命令) 一个运行时依赖 (@vue/cli-service)，该依赖： 可升级； 一条命令 基于 webpack 构建，并带有合理的默认配置； webpack 项目打包方式 编译好的项目源码===&gt;部署到服务器上直接使用 可以通过项目内的配置文件进行配置； 默认配置文件,通过修改默认配置文件达到自己想要的项目环境 可以通过插件进行扩展。 vue v-charts elementui 一个丰富的官方插件集合，集成了前端生态中最好的工具。Nodejs(tomcat) Vue VueRouter webpack yarn 一套完全图形化的创建和管理 Vue.js 项目的用户界面 14.4 Vue CLI安装1. 环境准备123456789101112131415161718192021222324252627282930313233#1.下载nodejs http://nodejs.cn/download/ windows系统: .msi 安装包(exe)指定安装位置 .zip(压缩包)直接解压缩指定目录 mac os 系统: .pkg 安装包格式自动配置环境变量 .tar.gz(压缩包)解压缩安装到指定名#2.配置nodejs环境变量 windows系统: 1.计算上右键属性----&gt; 高级属性 ----&gt;环境变量 添加如下配置: NODE_HOME= nodejs安装目录 PATH = xxxx;%NODE_HOME% 2.macos 系统 推荐使用.pkg安装直接配置node环境#3.验证nodejs环境是否成功 node -v #4.npm介绍 node package mangager nodejs包管理工具 前端主流技术 npm 进行统一管理 maven 管理java后端依赖 远程仓库(中心仓库) 阿里云镜像 npm 管理前端系统依赖 远程仓库(中心仓库) 配置淘宝镜像#5.配置淘宝镜像 npm config set registry https://registry.npm.taobao.org npm config get registry#6.配置npm下载依赖位置 windows: npm config set cache &quot;D: odereps pm-cache&quot; npm config set prefix &quot;D: odereps pm_global&quot; mac os: npm config set cache &quot;/Users/chenyannan/dev/nodereps&quot; npm config set prefix &quot;/Users/chenyannan/dev/nodereps&quot;#7.验证nodejs环境配置 npm config ls ; userconfig /Users/chenyannan/.npmrc cache = &quot;/Users/chenyannan/dev/nodereps&quot; prefix = &quot;/Users/chenyannan/dev/nodereps&quot; registry = &quot;https://registry.npm.taobao.org/&quot; 2.安装脚手架1234567#0.卸载脚手架 npm uninstall -g @vue/cli //卸载3.x版本脚手架 npm uninstall -g vue-cli //卸载2.x版本脚手架#1.Vue Cli官方网站 https://cli.vuejs.org/zh/guide/#2.安装vue Cli npm install -g vue-cli 3.第一个vue脚手架项目123456789101112131415161718192021222324252627282930# 1.创建vue脚手架第一个项目 vue init webpack 项目名# 2.创建第一个项目 hello -------------&gt;项目名 -build -------------&gt;用来使用webpack打包使用build依赖 -config -------------&gt;用来做整个项目配置目录 -node_modules ------&gt;用来管理项目中使用依赖 -src ------&gt;用来书写vue的源代码[重点] +assets ------&gt;用来存放静态资源 [重点] components ------&gt;用来书写Vue组件 [重点] router ------&gt;用来配置项目中路由[重点] App.vue ------&gt;项目中根组件[重点] main.js ------&gt;项目中主入口[重点] -static ------&gt;其它静态 -.babelrc ------&gt; 将es6语法转为es5运行 -.editorconfig ------&gt; 项目编辑配置 -.gitignore ------&gt; git版本控制忽略文件 -.postcssrc.js ------&gt; 源码相关js -index.html ------&gt; 项目主页 -package.json ------&gt; 类似与pom.xml 依赖管理 jquery 不建议手动修改 -package-lock.json ----&gt; 对package.json加锁 -README.md ----&gt; 项目说明文件# 3.如何运行在项目的根目录中执行 npm start 运行前端系统# 4.如何访问项目 http://localhost:8081 # 5.Vue Cli中项目开发方式 注意: 一切皆组件 一个组件中 js代码 html代码 css样式 1. VueCli开发方式是在项目中开发一个一个组件对应一个业务功能模块,日后可以将多个组件组合到一起形成一个前端系统 2. 日后在使用vue Cli进行开发时不再书写html,编写的是一个个组件(组件后缀.vue结尾的文件),日后打包时vue cli会将组件编译成运行的html文件 4.如何开发Vue脚手架1注意:在Vue cli 中一切皆组件 15.在脚手架中使用axios15.1 安装axios12345678# 1.安装axios npm install axios --save-dev npm install vue# 2.配置main.js中引入axios import axios from &#x27;axios&#x27;; Vue.prototype.$http=axios;# 3.使用axios 在需要发送异步请求的位置:this.$http.get(&quot;url&quot;).then((res)=&gt;&#123;&#125;) this.$http.post(&quot;url&quot;).then((res)=&gt;&#123;&#125;) 16.Vue Cli脚手架项目打包和部署123456# 1.在项目根目录中执行如下命令: vue run build 注意:vue脚手架打包的项目必须在服务器上运行不能直接双击运行# 2.打包之后当前项目中变化 在打包之后项目中出现dist目录,dist目录就是vue脚手架项目生产目录或者说是直接部署目录# 3.","tags":["笔记"],"categories":["Vue"]},{"title":"Docker学习笔记2","path":"/2021/11/12/Docker-jinjie/","content":"容器数据卷什么是容器数据卷将应用和环境打包成一个镜像！ 数据？如果数据都在容器中，那么我们容器删除，数据就会丢失！需求：数据可以持久化 MySQL，容器删除了，删库跑路！需求：MySQL数据可以存储在本地！ 容器之间可以有一个数据共享的技术！Docker容器中产生的数据，同步到本地！ 这就是卷技术！目录的挂载，将我们容器内的目录，挂载到Linux上面！ 总结一句话：容器的持久化和同步操作！容器间也是可以数据共享的！ 使用数据卷 方式一 ：直接使用命令挂载 -v 1234567-v, --volume list Bind mount a volumedocker run -it -v 主机目录:容器内目录 -p 主机端口:容器内端口# /home/ceshi：主机home目录下的ceshi文件夹 映射：centos容器中的/home[root@iz2zeak7 home]# docker run -it -v /home/ceshi:/home centos /bin/bash#这时候主机的/home/ceshi文件夹就和容器的/home文件夹关联了,二者可以实现文件或数据同步了#通过 docker inspect 容器id 查看[root@iz2zeak7sgj6i7hrb2g862z home]# docker inspect 6064c490c371 测试文件的同步 再来测试！ 1、停止容器 2、宿主机修改文件 3、启动容器 4、容器内的数据依旧是同步的 好处：我们以后修改只需要在本地修改即可，容器内会自动同步！ 实战：安装MySQL思考：MySQL的数据持久化的问题 123456789101112131415# 获取mysql镜像[root@iz2zeak7sgj6i7hrb2g862z home]# docker pull mysql:5.7# 运行容器,需要做数据挂载 #安装启动mysql，需要配置密码的，这是要注意点！# 参考官网hub docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag#启动我们得-d 后台运行-p 端口映射-v 卷挂载-e 环境配置-- name 容器名字$ docker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql03 mysql:5.7# 启动成功之后，我们在本地使用sqlyog来测试一下# sqlyog-连接到服务器的3306--和容器内的3306映射 # 在本地测试创建一个数据库，查看一下我们映射的路径是否ok！ 测试连接：注意3310端口要在阿里云服务器的安全组中打开，否则无法连接。 当我们在本地用SQLyog新建名称为test的数据库时候，容器容器也会创建 假设我们将包含mysql的容器删除时， 发现，我们挂载到本地的数据卷依旧没有丢失，这就实现了容器数据持久化功能。 具名和匿名挂载1234567891011121314151617181920212223242526272829303132# 匿名挂载-v 容器内路径!$ docker run -d -P --name nginx01 -v /etc/nginx nginx# 查看所有的volume(卷)的情况$ docker volume ls DRIVER VOLUME NAME # 容器内的卷名(匿名卷挂载)local 21159a8518abd468728cdbe8594a75b204a10c26be6c36090cde1ee88965f0d0local b17f52d38f528893dd5720899f555caf22b31bf50b0680e7c6d5431dbda2802c# 这里发现，这种就是匿名挂载，我们在 -v只写了容器内的路径，没有写容器外的路径！# 具名挂载 -P:表示随机映射端口$ docker run -d -P --name nginx02 -v juming-nginx:/etc/nginx nginx9663cfcb1e5a9a1548867481bfddab9fd7824a6dc4c778bf438a040fe891f0ee# 查看所有的volume(卷)的情况$ docker volume ls DRIVER VOLUME NAMElocal 21159a8518abd468728cdbe8594a75b204a10c26be6c36090cde1ee88965f0d0local b17f52d38f528893dd5720899f555caf22b31bf50b0680e7c6d5431dbda2802clocal juming-nginx #多了一个名字# 通过 -v 卷名：查看容器内路径# 查看一下这个卷$ docker volume inspect juming-nginx[ &#123; &quot;CreatedAt&quot;: &quot;2020-05-23T13:55:34+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: null, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/juming-nginx/_data&quot;, #默认目录 &quot;Name&quot;: &quot;juming-nginx&quot;, &quot;Options&quot;: null, &quot;Scope&quot;: &quot;local&quot; &#125;] 所有的docker容器内的卷，没有指定目录的情况下都是在**/var/lib/docker/volumes/自定义的卷名/_data**下，如果指定了目录，docker volume ls 是查看不到的。 区分三种挂载方式 1234# 三种挂载： 匿名挂载、具名挂载、指定路径挂载-v 容器内路径 #匿名挂载-v 卷名：容器内路径 #具名挂载-v /宿主机路径：容器内路径 #指定路径挂载 docker volume ls 是查看不到的 拓展： 123456# 通过 -v 容器内路径： ro rw 改变读写权限ro #readonly 只读rw #readwrite 可读可写$ docker run -d -P --name nginx05 -v juming:/etc/nginx:ro nginx$ docker run -d -P --name nginx05 -v juming:/etc/nginx:rw nginx# ro 只要看到ro就说明这个路径只能通过宿主机来操作，容器内部是无法操作！ 初始DockerfileDockerfile 就是用来构建docker镜像的构建文件！命令脚本！先体验一下！ 通过这个脚本可以生成镜像，镜像是一层一层的，脚本是一个个的命令，每个命令都是一层！ 1234567891011121314151617181920212223242526272829303132333435363738# 创建一个dockerfile文件，名字可以随便 建议Dockerfile# 文件中的内容： 指令(大写) + 参数$ vim dockerfile1 FROM centos # 当前这个镜像是以centos为基础的 VOLUME [&quot;volume01&quot;,&quot;volume02&quot;] # 挂载卷的卷目录列表(多个目录) CMD echo &quot;-----end-----&quot; # 输出一下用于测试 CMD /bin/bash # 默认走bash控制台# 这里的每个命令，就是镜像的一层！# 构建出这个镜像 -f dockerfile1 # f代表file，指这个当前文件的地址(这里是当前目录下的dockerfile1)-t caoshipeng/centos # t就代表target，指目标目录(注意caoshipeng镜像名前不能加斜杠‘/’). # 表示生成在当前目录下$ docker build -f dockerfile1 -t caoshipeng/centos .Sending build context to Docker daemon 2.56kBStep 1/4 : FROM centoslatest: Pulling from library/centos8a29a15cefae: Already exists Digest: sha256:fe8d824220415eed5477b63addf40fb06c3b049404242b31982106ac204f6700Status: Downloaded newer image for centos:latest ---&gt; 470671670cacStep 2/4 : VOLUME [&quot;volume01&quot;,&quot;volume02&quot;] # 卷名列表 ---&gt; Running in c18eefc2c233Removing intermediate container c18eefc2c233 ---&gt; 623ae1d40fb8Step 3/4 : CMD echo &quot;-----end-----&quot; # 输出 脚本命令 ---&gt; Running in 70e403669f3cRemoving intermediate container 70e403669f3c ---&gt; 0eba1989c4e6Step 4/4 : CMD /bin/bash ---&gt; Running in 4342feb3a05bRemoving intermediate container 4342feb3a05b ---&gt; f4a6b0d4d948Successfully built f4a6b0d4d948Successfully tagged caoshipeng/centos:latest# 查看自己构建的镜像$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcaoshipeng/centos latest f4a6b0d4d948 About a minute ago 237MB 启动自己写的容器镜像 12$ docker run -it f4a6b0d4d948 /bin/bash # 运行自己写的镜像$ ls -l # 查看目录 这个卷和外部一定有一个同步的目录 查看一下卷挂载 12# docker inspect 容器id$ docker inspect ca3b45913df5 测试一下刚才的文件是否同步出去了！ 这种方式使用的十分多，因为我们通常会构建自己的镜像！ 假设构建镜像时候没有挂载卷，要手动镜像挂载 -v 卷名：容器内路径！ 数据卷容器多个MySQL同步数据！ 命名的容器挂载数据卷！ 1234567891011121314151617# 测试 启动3个容器，通过刚才自己写的镜像启动# 创建docker01：因为我本机是最新版，故这里用latest，狂神老师用的是1.0如下图$ docker run -it --name docker01 caoshipeng/centos:latest# 查看容器docekr01内容$ lsbin home lost+found opt run sys vardev lib media proc sbin tmp volume01etc lib64 mnt root srv usr volume02# 不关闭该容器退出CTRL + Q + P # 创建docker02: 并且让docker02 继承 docker01$ docker run -it --name docker02 --volumes-from docker01 caoshipeng/centos:latest# 查看容器docker02内容$ lsbin home lost+found opt run sys vardev lib media proc sbin tmp volume01etc lib64 mnt root srv usr volume02 1234567# 再新建一个docker03同样继承docker01$ docker run -it --name docker03 --volumes-from docker01 caoshipeng/centos:latest$ cd volume01 #进入volume01 查看是否也同步docker01的数据$ ls docker01.txt# 测试：可以删除docker01，查看一下docker02和docker03是否可以访问这个文件# 测试发现：数据依旧保留在docker02和docker03中没有被删除 多个mysql实现数据共享 123$ docker run -d -p 3306:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7$ docker run -d -p 3310:3306 -e MYSQL_ROOT_PASSWORD=123456 --name mysql02 --volumes-from mysql01 mysql:5.7# 这个时候，可以实现两个容器数据同步！ 结论： 容器之间的配置信息的传递，数据卷容器的生命周期一直持续到没有容器使用为止。 但是一旦你持久化到了本地，这个时候，本地的数据是不会删除的！ DockerFileDockerFile介绍dockerfile是用来构建docker镜像的文件！命令参数脚本！ 构建步骤： 1、 编写一个dockerfile文件 2、 docker build 构建称为一个镜像 3、 docker run运行镜像 4、 docker push发布镜像（DockerHub 、阿里云仓库) 点击后跳到一个Dockerfile 很多官方镜像都是基础包，很多功能没有，我们通常会自己搭建自己的镜像！ 官方既然可以制作镜像，那我们也可以！ DockerFile构建过程基础知识： 1、每个保留关键字(指令）都是必须是大写字母 2、执行从上到下顺序 3、#表示注释 4、每一个指令都会创建提交一个新的镜像曾，并提交！ Dockerfile是面向开发的，我们以后要发布项目，做镜像，就需要编写dockerfile文件，这个文件十分简单！ Docker镜像逐渐成企业交付的标准，必须要掌握！ DockerFile：构建文件，定义了一切的步骤，源代码 DockerImages：通过DockerFile构建生成的镜像，最终发布和运行产品。 Docker容器：容器就是镜像运行起来提供服务。 DockerFile的指令123456789101112FROM # from:基础镜像，一切从这里开始构建MAINTAINER # maintainer:镜像是谁写的， 姓名+邮箱RUN # run:镜像构建的时候需要运行的命令ADD # add:步骤，tomcat镜像，这个tomcat压缩包！添加内容 添加同目录WORKDIR # workdir:镜像的工作目录VOLUME # volume:挂载的目录EXPOSE # expose:保留端口配置CMD # cmd:指定这个容器启动的时候要运行的命令，只有最后一个会生效，可被替代ENTRYPOINT # entrypoint:指定这个容器启动的时候要运行的命令，可以追加命令ONBUILD # onbuild:当构建一个被继承DockerFile这个时候就会运行onbuild的指令，触发指令COPY # copy:类似ADD，将我们文件拷贝到镜像中ENV # env:构建的时候设置环境变量！ 实战测试scratch 镜像 12345678910111213FROM scratchADD centos-7-x86_64-docker.tar.xz /LABEL \\ org.label-schema.schema-version=&quot;1.0&quot; \\ org.label-schema.name=&quot;CentOS Base Image&quot; \\ org.label-schema.vendor=&quot;CentOS&quot; \\ org.label-schema.license=&quot;GPLv2&quot; \\ org.label-schema.build-date=&quot;20200504&quot; \\ org.opencontainers.image.title=&quot;CentOS Base Image&quot; \\ org.opencontainers.image.vendor=&quot;CentOS&quot; \\ org.opencontainers.image.licenses=&quot;GPL-2.0-only&quot; \\ org.opencontainers.image.created=&quot;2020-05-04 00:00:00+01:00&quot;CMD [&quot;/bin/bash&quot;] Docker Hub 中 99%的镜像都是从这个基础镜像过来的 FROM scratch，然后配置需要的软件和配置来进行构建。 创建一个自己的centos 12345678910111213141516171819# 1./home下新建dockerfile目录$ mkdir dockerfile# 2. dockerfile目录下新建mydockerfile-centos文件$ vim mydockerfile-centos# 3.编写Dockerfile配置文件FROM centos # 基础镜像是官方原生的centosMAINTAINER cao&lt;1165680007@qq.com&gt; # 作者ENV MYPATH /usr/local # 配置环境变量的目录 WORKDIR $MYPATH # 将工作目录设置为 MYPATHRUN yum -y install vim # 给官方原生的centos 增加 vim指令RUN yum -y install net-tools # 给官方原生的centos 增加 ifconfig命令EXPOSE 80 # 暴露端口号为80CMD echo $MYPATH # 输出下 MYPATH 路径CMD echo &quot;-----end----&quot; CMD /bin/bash # 启动后进入 /bin/bash# 4.通过这个文件构建镜像# 命令： docker build -f 文件路径 -t 镜像名:[tag] .$ docker build -f mydockerfile-centos -t mycentos:0.1 .# 5.出现下图后则构建成功 1234567891011$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEmycentos 0.1 cbf5110a646d 2 minutes ago 311MB# 6.测试运行$ docker run -it mycentos:0.1 # 注意带上版本号，否则每次都回去找最新版latest$ pwd /usr/local # 与Dockerfile文件中 WORKDIR 设置的 MYPATH 一致$ vim # vim 指令可以使用$ ifconfig # ifconfig 指令可以使用# docker history 镜像id 查看镜像构建历史步骤$ docker history 镜像id 我们可以列出本地进行的变更历史 我们平时拿到一个镜像，可以用 “docker history 镜像id” 研究一下是什么做的 CMD 和 ENTRYPOINT区别 12CMD # 指定这个容器启动的时候要运行的命令，只有最后一个会生效，可被替代。ENTRYPOINT # 指定这个容器启动的时候要运行的命令，可以追加命令 测试cmd 123456789101112131415161718192021# 编写dockerfile文件$ vim dockerfile-test-cmdFROM centosCMD [&quot;ls&quot;,&quot;-a&quot;] # 启动后执行 ls -a 命令# 构建镜像$ docker build -f dockerfile-test-cmd -t cmd-test:0.1 .# 运行镜像$ docker run cmd-test:0.1 # 由结果可得，运行后就执行了 ls -a 命令....dockerenvbindevetchome# 想追加一个命令 -l 成为ls -al：展示列表详细数据$ docker run cmd-test:0.1 -ldocker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused &quot;exec: \\&quot;-l\\&quot;:executable file not found in $PATH&quot;: unknown.ERRO[0000] error waiting for container: context canceled # cmd的情况下 -l 替换了CMD[&quot;ls&quot;,&quot;-l&quot;] 而 -l 不是命令所以报错 测试ENTRYPOINT 123456789101112131415161718192021222324252627282930# 编写dockerfile文件$ vim dockerfile-test-entrypointFROM centosENTRYPOINT [&quot;ls&quot;,&quot;-a&quot;]# 构建镜像$ docker build -f dockerfile-test-entrypoint -t cmd-test:0.1 .# 运行镜像$ docker run entrypoint-test:0.1....dockerenvbindevetchomeliblib64lost+found ...# 我们的命令，是直接拼接在我们得ENTRYPOINT命令后面的$ docker run entrypoint-test:0.1 -ltotal 56drwxr-xr-x 1 root root 4096 May 16 06:32 .drwxr-xr-x 1 root root 4096 May 16 06:32 ..-rwxr-xr-x 1 root root 0 May 16 06:32 .dockerenvlrwxrwxrwx 1 root root 7 May 11 2019 bin -&gt; usr/bindrwxr-xr-x 5 root root 340 May 16 06:32 devdrwxr-xr-x 1 root root 4096 May 16 06:32 etcdrwxr-xr-x 2 root root 4096 May 11 2019 homelrwxrwxrwx 1 root root 7 May 11 2019 lib -&gt; usr/liblrwxrwxrwx 1 root root 9 May 11 2019 lib64 -&gt; usr/lib64 .... Dockerfile中很多命令都十分的相似，我们需要了解它们的区别，我们最好的学习就是对比他们然后测试效果！ 实战：Tomcat镜像1、准备镜像文件1准备tomcat 和 jdk 到当前目录，编写好README 2、编写dokerfile1234567891011121314151617$ vim dockerfileFROM centos # 基础镜像centosMAINTAINER cao&lt;1165680007@qq.com&gt; # 作者COPY README /usr/local/README # 复制README文件ADD jdk-8u231-linux-x64.tar.gz /usr/local/ # 添加jdk，ADD 命令会自动解压ADD apache-tomcat-9.0.35.tar.gz /usr/local/ # 添加tomcat，ADD 命令会自动解压RUN yum -y install vim # 安装 vim 命令ENV MYPATH /usr/local # 环境变量设置 工作目录WORKDIR $MYPATHENV JAVA_HOME /usr/local/jdk1.8.0_231 # 环境变量： JAVA_HOME环境变量ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV CATALINA_HOME /usr/local/apache-tomcat-9.0.35 # 环境变量： tomcat环境变量ENV CATALINA_BASH /usr/local/apache-tomcat-9.0.35# 设置环境变量 分隔符是：ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin EXPOSE 8080 # 设置暴露的端口CMD /usr/local/apache-tomcat-9.0.35/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat-9.0.35/logs/catalina.out # 设置默认命令 3、构建镜像12# 因为dockerfile命名使用默认命名 因此不用使用-f 指定文件$ docker build -t mytomcat:0.1 . 4、run镜像1234# -d:后台运行 -p:暴露端口 --name:别名 -v:绑定路径 $ docker run -d -p 8080:8080 --name tomcat01 -v /home/kuangshen/build/tomcat/test:/usr/local/apache-tomcat-9.0.35/webapps/test -v /home/kuangshen/build/tomcat/tomcatlogs/:/usr/local/apache-tomcat-9.0.35/logs mytomcat:0.1 5、访问测试12$ docker exec -it 自定义容器的id /bin/bash$ cul localhost:8080 6、发布项目(由于做了卷挂载，我们直接在本地编写项目就可以发布了！) 发现：项目部署成功，可以直接访问！ 我们以后开发的步骤：需要掌握Dockerfile的编写！我们之后的一切都是使用docker镜像来发布运行！ 发布自己的镜像 发布到 Docker Hub 1、地址 https://hub.docker.com/ 2、确定这个账号可以登录 3、登录 123456789$ docker login --helpUsage: docker login [OPTIONS] [SERVER]Log in to a Docker registry.If no server is specified, the default is defined by the daemon.Options: -p, --password string Password --password-stdin Take the password from stdin -u, --username string Username$ docker login -u 你的用户名 -p 你的密码 4、提交 push镜像 1234567# 会发现push不上去，因为如果没有前缀的话默认是push到 官方的library# 解决方法：# 第一种 build的时候添加你的dockerhub用户名，然后在push就可以放到自己的仓库了$ docker build -t kuangshen/mytomcat:0.1 .# 第二种 使用docker tag #然后再次push$ docker tag 容器id kuangshen/mytomcat:1.0 #然后再次push$ docker push kuangshen/mytomcat:1.0 发布到 阿里云镜像服务上 看官网 很详细https://cr.console.aliyun.com/repository/ 123456$ sudo docker login --username=zchengx registry.cn-shenzhen.aliyuncs.com$ sudo docker tag [ImageId] registry.cn-shenzhen.aliyuncs.com/dsadxzc/cheng:[镜像版本号]# 修改id 和 版本sudo docker tag a5ef1f32aaae registry.cn-shenzhen.aliyuncs.com/dsadxzc/cheng:1.0# 修改版本$ sudo docker push registry.cn-shenzhen.aliyuncs.com/dsadxzc/cheng:[镜像版本号] 小结 Docker 网络理解Docker 0学习之前清空下前面的docker 镜像、容器 1234# 删除全部容器$ docker rm -f $(docker ps -aq)# 删除全部镜像$ docker rmi -f $(docker images -aq) 测试 三个网络 问题： docker 是如果处理容器网络访问的？ 12345678910111213141516171819# 测试 运行一个tomcat$ docker run -d -P --name tomcat01 tomcat# 查看容器内部网络地址$ docker exec -it 容器id ip addr# 发现容器启动的时候会得到一个 eth0@if91 ip地址，docker分配！$ ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever261: eth0@if91: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0 valid_lft forever preferred_lft forever# 思考？ linux能不能ping通容器内部！ 可以 容器内部可以ping通外界吗？ 可以！$ ping 172.18.0.2PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data.64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.069 ms64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.074 ms 原理 1、我们每启动一个docker容器，docker就会给docker容器分配一个ip，我们只要按照了docker，就会有一个docker0桥接模式，使用的技术是veth-pair技术！ https://www.cnblogs.com/bakari/p/10613710.html 再次测试 ip addr 2 、再启动一个容器测试，发现又多了一对网络 1234# 我们发现这个容器带来网卡，都是一对对的# veth-pair 就是一对的虚拟设备接口，他们都是成对出现的，一端连着协议，一端彼此相连# 正因为有这个特性 veth-pair 充当一个桥梁，连接各种虚拟网络设备的# OpenStac,Docker容器之间的连接，OVS的连接，都是使用evth-pair技术 3、我们来测试下tomcat01和tomcat02是否可以ping通 123456789101112# 获取tomcat01的ip 172.17.0.2$ docker-tomcat docker exec -it tomcat01 ip addr 550: eth0@if551: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# 让tomcat02 ping tomcat01 $ docker-tomcat docker exec -it tomcat02 ping 172.17.0.2PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.098 ms64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.071 ms# 结论：容器和容器之间是可以互相ping通 网络模型图 结论：tomcat01和tomcat02公用一个路由器，docker0。 所有的容器不指定网络的情况下，都是docker0路由的，docker会给我们的容器分配一个默认的可用ip。 小结 Docker使用的是Linux的桥接，宿主机是一个Docker容器的网桥 docker0 Docker中所有网络接口都是虚拟的，虚拟的转发效率高（内网传递文件） 只要容器删除，对应的网桥一对就没了！ 思考一个场景：我们编写了一个微服务，database url=ip: 项目不重启，数据ip换了，我们希望可以处理这个问题，可以通过名字来进行访问容器？ –-link12345678910111213$ docker exec -it tomcat02 ping tomca01 # ping不通ping: tomca01: Name or service not known# 运行一个tomcat03 --link tomcat02 $ docker run -d -P --name tomcat03 --link tomcat02 tomcat5f9331566980a9e92bc54681caaac14e9fc993f14ad13d98534026c08c0a9aef# 3连接2# 用tomcat03 ping tomcat02 可以ping通$ docker exec -it tomcat03 ping tomcat02PING tomcat02 (172.17.0.3) 56(84) bytes of data.64 bytes from tomcat02 (172.17.0.3): icmp_seq=1 ttl=64 time=0.115 ms64 bytes from tomcat02 (172.17.0.3): icmp_seq=2 ttl=64 time=0.080 ms# 2连接3# 用tomcat02 ping tomcat03 ping不通 探究： docker network inspect 网络id 网段相同 docker inspect tomcat03 查看tomcat03里面的/etc/hosts发现有tomcat02的配置 –link 本质就是在hosts配置中添加映射 现在使用Docker已经不建议使用–link了！ 自定义网络，不适用docker0！ docker0问题：不支持容器名连接访问！ 自定义网络12345678docker networkconnect -- Connect a container to a networkcreate -- Creates a new network with a name specified by thedisconnect -- Disconnects a container from a networkinspect -- Displays detailed information on a networkls -- Lists all the networks created by the userprune -- Remove all unused networksrm -- Deletes one or more networks 查看所有的docker网络 网络模式 bridge ：桥接 docker（默认，自己创建也是用bridge模式） none ：不配置网络，一般不用 host ：和所主机共享网络 container ：容器网络连通（用得少！局限很大） 测试 1234567# 我们直接启动的命令 --net bridge,而这个就是我们得docker0# bridge就是docker0$ docker run -d -P --name tomcat01 tomcat等价于 =&gt; docker run -d -P --name tomcat01 --net bridge tomcat# docker0，特点：默认，域名不能访问。 --link可以打通连接，但是很麻烦！# 我们可以 自定义一个网络$ docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet 1$ docker network inspect mynet; 启动两个tomcat,再次查看网络情况 在自定义的网络下，服务可以互相ping通，不用使用–link 我们自定义的网络docker当我们维护好了对应的关系，推荐我们平时这样使用网络！ 好处： redis -不同的集群使用不同的网络，保证集群是安全和健康的 mysql-不同的集群使用不同的网络，保证集群是安全和健康的 网络连通 1234# 测试两个不同的网络连通 再启动两个tomcat 使用默认网络，即docker0$ docker run -d -P --name tomcat01 tomcat$ docker run -d -P --name tomcat02 tomcat# 此时ping不通 12# 要将tomcat01 连通 tomcat—net-01 ，连通就是将 tomcat01加到 mynet网络# 一个容器两个ip（tomcat01） 12# 01连通 ，加入后此时，已经可以tomcat01 和 tomcat-01-net ping通了# 02是依旧不通的 结论：假设要跨网络操作别人，就需要使用docker network connect 连通！ 实战：部署Redis集群 123456789101112131415161718192021222324252627# 创建网卡docker network create redis --subnet 172.38.0.0/16# 通过脚本创建六个redis配置for port in $(seq 1 6);\\do \\mkdir -p /mydata/redis/node-$&#123;port&#125;/conftouch /mydata/redis/node-$&#123;port&#125;/conf/redis.confcat &lt;&lt; EOF &gt;&gt; /mydata/redis/node-$&#123;port&#125;/conf/redis.confport 6379bind 0.0.0.0cluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000cluster-announce-ip 172.38.0.1$&#123;port&#125;cluster-announce-port 6379cluster-announce-bus-port 16379appendonly yesEOFdone# 通过脚本运行六个redisfor port in $(seq 1 6);\\docker run -p 637$&#123;port&#125;:6379 -p 1667$&#123;port&#125;:16379 --name redis-$&#123;port&#125; \\-v /mydata/redis/node-$&#123;port&#125;/data:/data \\-v /mydata/redis/node-$&#123;port&#125;/conf/redis.conf:/etc/redis/redis.conf \\-d --net redis --ip 172.38.0.1$&#123;port&#125; redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.confdocker exec -it redis-1 /bin/sh #redis默认没有bashredis-cli --cluster create 172.38.0.11:6379 172.38.0.12:6379 172.38.0.13:6379 172.38.0.14:6379 172.38.0.15:6379 172.38.0.16:6379 --cluster-replicas 1 docker搭建redis集群完成！ 我们使用docker之后，所有的技术都会慢慢变得简单起来！ SpringBoot微服务打包Docker镜像1、构建SpringBoot项目 2、打包运行 1mvn package 3、编写dockerfile 12345FROM java:8COPY *.jar /app.jarCMD [&quot;--server.port=8080&quot;]EXPOSE 8080ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;app.jar&quot;] 4、构建镜像 123# 1.复制jar和DockerFIle到服务器# 2.构建镜像$ docker build -t xxxxx:xx . 5、发布运行 以后我们使用了Docker之后，给别人交付就是一个镜像即可！","tags":["笔记"],"categories":["Docker"]},{"title":"Docker学习笔记1","path":"/2021/11/12/Docker-rumen/","content":"Docker 入门笔记整理来源 B站UP主狂神说Javahttps://space.bilibili.com/95256449/ Docker概述Docker为什么出现？ 一款产品： 开发–上线 两套环境！应用环境，应用配置！ 开发 — 运维。 问题：我在我的电脑上可以允许！版本更新，导致服务不可用！对于运维来说考验十分大？ 环境配置是十分的麻烦，每一个及其都要部署环境(集群Redis、ES、Hadoop…) !费事费力。 发布一个项目( jar + (Redis MySQL JDK ES) ),项目能不能带上环境安装打包！ 之前在服务器配置一个应用的环境 Redis MySQL JDK ES Hadoop 配置超麻烦了，不能够跨平台。 开发环境Windows，最后发布到Linux！ 传统：开发jar，运维来做！ 现在：开发打包部署上线，一套流程做完！ 安卓流程：java — apk —发布（应用商店）一 张三使用apk一安装即可用！ docker流程： java-jar（环境） — 打包项目帯上环境（镜像） — ( Docker仓库：商店）——- Docker给以上的问题，提出了解决方案！ Docker的思想就来自于集装箱！ JRE – 多个应用(端口冲突) – 原来都是交叉的！隔离：Docker核心思想！打包装箱！每个箱子是互相隔离的。 Docker通过隔离机制，可以将服务器利用到极致！ 本质：所有的技术都是因为出现了一些问题，我们需要去解决，才去学习！ Docker历史2010年，几个的年轻人，就在美国成立了一家公司 dotcloud 做一些pass的云计算服务！LXC（Linux Container容器）有关的容器技术！ Linux Container容器是一种内核虚拟化技术，可以提供轻量级的虚拟化，以便隔离进程和资源。 他们将自己的技术（容器化技术）命名就是 DockerDocker刚刚延生的时候，没有引起行业的注意！dotCloud，就活不下去！ 开源 2013年，Docker开源！ 越来越多的人发现docker的优点！火了。Docker每个月都会更新一个版本！ 2014年4月9日，Docker1.0发布！ docker为什么这么火？十分的轻巧！ 在容器技术出来之前，我们都是使用虚拟机技术！ 虚拟机：在window中装一个VMware，通过这个软件我们可以虚拟出来一台或者多台电脑！笨重！ 虚拟机也属于虚拟化技术，Docker容器技术，也是一种虚拟化技术！ 12VMware : linux centos 原生镜像（一个电脑！） 隔离、需要开启多个虚拟机！ 几个G 几分钟docker: 隔离，镜像（最核心的环境 4m + jdk + mysql）十分的小巧，运行镜像就可以了！小巧！ 几个M 秒级启动！ 聊聊Docker Docker基于Go语言开发的！开源项目！ docker官网：https://www.docker.com/ 文档：https://docs.docker.com/ Docker的文档是超级详细的！ 仓库：https://hub.docker.com/ ocker能干嘛 之前的虚拟机技术 虚拟机技术缺点： 1、 资源占用十分多 2、 冗余步骤多 3、 启动很慢！ 容器化技术 容器化技术不是模拟一个完整的操作系统 比较Docker和虚拟机技术的不同： 传统虚拟机，虚拟出一条硬件，运行一个完整的操作系统，然后在这个系统上安装和运行软件 容器内的应用直接运行在宿主机的内容，容器是没有自己的内核的，也没有虚拟我们的硬件，所以就轻便了 每个容器间是互相隔离，每个容器内都有一个属于自己的文件系统，互不影响 DevOps（开发、运维） 应用更快速的交付和部署 传统：一对帮助文档，安装程序。 Docker：打包镜像发布测试一键运行。 更便捷的升级和扩缩容 使用了 Docker之后，我们部署应用就和搭积木一样项目打包为一个镜像，扩展服务器A！服务器B 更简单的系统运维在容器化之后，我们的开发，测试环境都是高度一致的 更高效的计算资源利用 Docker是内核级别的虚拟化，可以在一个物理机上可以运行很多的容器实例！服务器的性能可以被压榨到极致。 Docker安装Docker的基本组成 镜像（image)： docker镜像就好比是一个目标，可以通过这个目标来创建容器服务，tomcat镜像==&gt;run==&gt;容器（提供服务器），通过这个镜像可以创建多个容器（最终服务运行或者项目运行就是在容器中的）。 容器(container)： Docker利用容器技术，独立运行一个或者一组应用，通过镜像来创建的.启动，停止，删除，基本命令目前就可以把这个容器理解为就是一个简易的 Linux系统。 仓库(repository)： 仓库就是存放镜像的地方！仓库分为公有仓库和私有仓库。(很类似git)Docker Hub是国外的。阿里云…都有容器服务器(配置镜像加速!) 安装Docker 环境准备 1.Linux要求内核3.0以上 2.CentOS 7 1234567891011121314151617[root@iz2zeak7sgj6i7hrb2g862z ~]# uname -r3.10.0-514.26.2.el7.x86_64 # 要求3.0以上[root@iz2zeak7sgj6i7hrb2g862z ~]# cat /etc/os-release NAME=&quot;CentOS Linux&quot;VERSION=&quot;7 (Core)&quot;ID=&quot;centos&quot;ID_LIKE=&quot;rhel fedora&quot;VERSION_ID=&quot;7&quot;PRETTY_NAME=&quot;CentOS Linux 7 (Core)&quot;ANSI_COLOR=&quot;0;31&quot;CPE_NAME=&quot;cpe:/o:centos:centos:7&quot;HOME_URL=&quot;https://www.centos.org/&quot;BUG_REPORT_URL=&quot;https://bugs.centos.org/&quot;CENTOS_MANTISBT_PROJECT=&quot;CentOS-7&quot;CENTOS_MANTISBT_PROJECT_VERSION=&quot;7&quot;REDHAT_SUPPORT_PRODUCT=&quot;centos&quot;REDHAT_SUPPORT_PRODUCT_VERSION=&quot;7&quot; 安装 帮助文档：https://docs.docker.com/engine/install/卸载与安装 123456789101112131415161718192021222324252627282930#1.卸载旧版本yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine#2.需要的安装包yum install -y yum-utils#3.设置镜像的仓库yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo#上述方法默认是从国外的，不推荐#推荐使用国内的yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo#更新yum软件包索引yum makecache fast#4.安装docker相关的 docker-ce 社区版 而ee是企业版yum install docker-ce docker-ce-cli containerd.io # 这里我们使用社区版即可#5.启动dockersystemctl start docker#6. 使用docker version查看是否按照成功docker version#7. 测试docker run hello-world 1234#8.查看已经下载的镜像(从这里可以查看已有镜像的id)[root@iz2zeak7sgj6i7hrb2g862z ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest bf756fb1ae65 4 months ago 13.3kB 卸载docker 12345#1. 卸载依赖yum remove docker-ce docker-ce-cli containerd.io#2. 删除资源rm -rf /var/lib/docker# /var/lib/docker 是docker的默认工作路径！ 阿里云镜像加速1、登录阿里云找到容器服务 2、找到镜像加速器 3、配置使用1234567891011#1.创建一个目录sudo mkdir -p /etc/docker#2.编写配置文件sudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [&quot;https://t2wwyxhb.mirror.aliyuncs.com&quot;]&#125;EOF#3.重启服务sudo systemctl daemon-reloadsudo systemctl restart docker 回顾HelloWorld流程 docker run 流程图 底层原理Docker是怎么工作的？ Docker是一个Client-Server结构的系统，Docker的守护进程运行在主机上。通过Socket从客户端访问！ Docker-Server接收到Docker-Client的指令，就会执行这个命令！ 为什么Docker比Vm快1、docker有着比虚拟机更少的抽象层。由于docker不需要Hypervisor实现硬件资源虚拟化,运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有明显优势。2、docker利用的是宿主机的内核,而不需要Guest OS。 1GuestOS： VM（虚拟机）里的的系统（OS）HostOS：物理机里的系统（OS） 因此,当新建一个 容器时,docker不需要和虚拟机一样重新加载一个操作系统内核。仍而避免引导、加载操作系统内核返个比较费时费资源的过程,当新建一个虚拟机时,虚拟机软件需要加载GuestOS,返个新建过程是分钟级别的。而docker由于直接利用宿主机的操作系统,则省略了这个复杂的过程,因此新建一个docker容器只需要几秒钟。 Docker的常用命令1.帮助命令123docker version #显示docker的版本信息。docker info #显示docker的系统信息，包括镜像和容器的数量docker 命令 --help #帮助命令 帮助文档的地址：https://docs.docker.com/engine/reference/commandline/build/ 2.镜像命令1234docker images #查看所有本地主机上的镜像 可以使用docker image ls代替docker search #搜索镜像docker pull #下载镜像 docker image pulldocker rmi #删除镜像 docker image rm docker images查看所有本地的主机上的镜像1234567891011121314151617181920[root@iz2zeak7sgj6i7hrb2g862z ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest bf756fb1ae65 4 months ago 13.3kBmysql 5.7 b84d68d0a7db 6 days ago 448MB# 解释#REPOSITORY # 镜像的仓库源#TAG # 镜像的标签(版本) ---lastest 表示最新版本#IMAGE ID # 镜像的id#CREATED # 镜像的创建时间#SIZE # 镜像的大小# 可选项Options: -a, --all Show all images (default hides intermediate images) #列出所有镜像 -q, --quiet Only show numeric IDs # 只显示镜像的id[root@iz2zeak7sgj6i7hrb2g862z ~]# docker images -a #列出所有镜像详细信息[root@iz2zeak7sgj6i7hrb2g862z ~]# docker images -aq #列出所有镜像的idd5f28a0bb0d0f19c56ce92a81b6b1fe7261e1b6b1fe7261e docker search 搜索镜像 1234567891011[root@iz2zeak7sgj6i7hrb2g862z ~]# docker search mysql# --filter=STARS=3000 #过滤，搜索出来的镜像收藏STARS数量大于3000的Options: -f, --filter filter Filter output based on conditions provided --format string Pretty-print search using a Go template --limit int Max number of search results (default 25) --no-trunc Don&#x27;t truncate output[root@iz2zeak7sgj6i7hrb2g862z ~]# docker search mysql --filter=STARS=3000NAME DESCRIPTION STARS OFFICIAL AUTOMATEDmysql MySQL IS ... 9520 [OK] mariadb MariaDB IS ... 3456 [OK] docker pull 下载镜像12345678910111213141516171819# 下载镜像 docker pull 镜像名[:tag][root@iz2zeak7sgj6i7hrb2g862z ~]# docker pull tomcat:88: Pulling from library/tomcat #如果不写tag，默认就是latest90fe46dd8199: Already exists #分层下载： docker image 的核心 联合文件系统35a4f1977689: Already exists bbc37f14aded: Already exists 74e27dc593d4: Already exists 93a01fbfad7f: Already exists 1478df405869: Pull complete 64f0dd11682b: Pull complete 68ff4e050d11: Pull complete f576086003cf: Pull complete 3b72593ce10e: Pull complete Digest: sha256:0c6234e7ec9d10ab32c06423ab829b32e3183ba5bf2620ee66de866df # 签名防伪Status: Downloaded newer image for tomcat:8docker.io/library/tomcat:8 #真实地址#等价于docker pull tomcat:8docker pull docker.io/library/tomcat:8 docker rmi 删除镜像1234docker rmi -f 镜像id #删除指定id的镜像[root@iz2zeak7sgj6i7hrb2g862z ~]# docker rmi -f f19c56ce92a8docker rmi -f $(docker images -aq) #删除全部的镜像[root@iz2zeak7sgj6i7hrb2g862z ~]# docker stop $(docker ps -a -q) 3.容器命令说明：我们有了镜像才可以创建容器，Linux，下载centos镜像来学习 镜像下载12#docker中下载centosdocker pull centos 1234567docker run 镜像id #新建容器并启动docker ps 列出所有运行的容器 docker container listdocker rm 容器id #删除指定容器docker start 容器id #启动容器docker restart 容器id #重启容器docker stop 容器id #停止当前正在运行的容器docker kill 容器id #强制停止当前容器 1[root@iz2zeak7sgj6i7hrb2g862z ~]# docker container list #h和docker ps相同 新建容器并启动123456789101112131415161718docker run [可选参数] image | docker container run [可选参数] image #参书说明--name=&quot;Name&quot; #容器名字 tomcat01 tomcat02 用来区分容器-d #后台方式运行-it #使用交互方式运行，进入容器查看内容-p #指定容器的端口 -p 8080(宿主机):8080(容器) -p ip:主机端口:容器端口 -p 主机端口:容器端口(常用) -p 容器端口 容器端口-P(大写) 随机指定端口# 测试、启动并进入容器[root@iz2zeak7sgj6i7hrb2g[root@iz2zeak7sgj6i7hrb2g862z ~]# docker run -it centos /bin/bash[root@241b5abce65e /]# lsbin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var[root@241b5abce65e /]# exit #从容器退回主机exit 列出所有运行的容器1234docker ps 命令 #列出当前正在运行的容器 -a, --all #列出当前正在运行的容器 + 带出历史运行过的容器 -n=?, --last int #列出最近创建的?个容器 ?为1则只列出最近创建的一个容器,为2则列出2个 -q, --quiet #只列出容器的编号 退出容器12exit #容器直接退出ctrl +P +Q #容器不停止退出 ---注意：这个很有用的操作 删除容器123docker rm 容器id #删除指定的容器，不能删除正在运行的容器，如果要强制删除 rm -rfdocker rm -f $(docker ps -aq) #删除所有的容器docker ps -a -q|xargs docker rm #删除所有的容器 启动和停止容器的操作1234docker start 容器id #启动容器docker restart 容器id #重启容器docker stop 容器id #停止当前正在运行的容器docker kill 容器id #强制停止当前容器 4.常用其他命令后台启动命令12345678# 命令 docker run -d 镜像名[root@iz2zeak7sgj6i7hrb2g862z ~]# docker run -d centosa8f922c255859622ac45ce3a535b7a0e8253329be4756ed6e32265d2dd2fac6c[root@iz2zeak7sgj6i7hrb2g862z ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES# 问题docker ps. 发现centos 停止了# 常见的坑，docker容器使用后台运行，就必须要有要一个前台进程，docker发现没有应用，就会自动停止# nginx，容器启动后，发现自己没有提供服务，就会立刻停止，就是没有程序了 查看日志1234567891011121314docker logs --helpOptions: --details Show extra details provided to logs * -f, --follow Follow log output --since string Show logs since timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m for 42 minutes)* --tail string Number of lines to show from the end of the logs (default &quot;all&quot;)* -t, --timestamps Show timestamps --until string Show logs before a timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m for 42 minutes)➜ ~ docker run -d centos /bin/sh -c &quot;while true;do echo 6666;sleep 1;done&quot; #模拟日志 #显示日志-tf #显示日志信息（一直更新）--tail number #需要显示日志条数docker logs -t --tail n 容器id #查看n行日志docker logs -ft 容器id #跟着日志 查看容器中进程信息ps1# 命令 docker top 容器id 查看镜像的元数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218# 命令docker inspect 容器id#测试➜ ~ docker inspect 55321bcae33d[ &#123; &quot;Id&quot;: &quot;55321bcae33d15da8280bcac1d2bc1141d213bcc8f8e792edfd832ff61ae5066&quot;, &quot;Created&quot;: &quot;2020-05-15T05:22:05.515909071Z&quot;, &quot;Path&quot;: &quot;/bin/sh&quot;, &quot;Args&quot;: [ &quot;-c&quot;, &quot;while true;do echo 6666;sleep 1;done&quot; ], &quot;State&quot;: &#123; &quot;Status&quot;: &quot;running&quot;, &quot;Running&quot;: true, &quot;Paused&quot;: false, &quot;Restarting&quot;: false, &quot;OOMKilled&quot;: false, &quot;Dead&quot;: false, &quot;Pid&quot;: 22973, &quot;ExitCode&quot;: 0, &quot;Error&quot;: &quot;&quot;, &quot;StartedAt&quot;: &quot;2020-05-15T05:22:06.165904633Z&quot;, &quot;FinishedAt&quot;: &quot;0001-01-01T00:00:00Z&quot; &#125;, &quot;Image&quot;: &quot;sha256:470671670cac686c7cf0081e0b37da2e9f4f768ddc5f6a26102ccd1c6954c1ee&quot;, &quot;ResolvConfPath&quot;: &quot;/var/lib/docker/containers/55321bcae33d15da8280bcac1d2bc1141d213bcc8f8e792edfd832ff61ae5066/resolv.conf&quot;, &quot;HostnamePath&quot;: &quot;/var/lib/docker/containers/55321bcae33d15da8280bcac1d2bc1141d213bcc8f8e792edfd832ff61ae5066/hostname&quot;, &quot;HostsPath&quot;: &quot;/var/lib/docker/containers/55321bcae33d15da8280bcac1d2bc1141d213bcc8f8e792edfd832ff61ae5066/hosts&quot;, &quot;LogPath&quot;: &quot;/var/lib/docker/containers/55321bcae33d15da8280bcac1d2bc1141d213bcc8f8e792edfd832ff61ae5066/55321bcae33d15da8280bcac1d2bc1141d213bcc8f8e792edfd832ff61ae5066-json.log&quot;, &quot;Name&quot;: &quot;/bold_bell&quot;, &quot;RestartCount&quot;: 0, &quot;Driver&quot;: &quot;overlay2&quot;, &quot;Platform&quot;: &quot;linux&quot;, &quot;MountLabel&quot;: &quot;&quot;, &quot;ProcessLabel&quot;: &quot;&quot;, &quot;AppArmorProfile&quot;: &quot;docker-default&quot;, &quot;ExecIDs&quot;: null, &quot;HostConfig&quot;: &#123; &quot;Binds&quot;: null, &quot;ContainerIDFile&quot;: &quot;&quot;, &quot;LogConfig&quot;: &#123; &quot;Type&quot;: &quot;json-file&quot;, &quot;Config&quot;: &#123; &#125; &#125;, &quot;NetworkMode&quot;: &quot;default&quot;, &quot;PortBindings&quot;: &#123; &#125;, &quot;RestartPolicy&quot;: &#123; &quot;Name&quot;: &quot;no&quot;, &quot;MaximumRetryCount&quot;: 0 &#125;, &quot;AutoRemove&quot;: false, &quot;VolumeDriver&quot;: &quot;&quot;, &quot;VolumesFrom&quot;: null, &quot;CapAdd&quot;: null, &quot;CapDrop&quot;: null, &quot;Capabilities&quot;: null, &quot;Dns&quot;: [], &quot;DnsOptions&quot;: [], &quot;DnsSearch&quot;: [], &quot;ExtraHosts&quot;: null, &quot;GroupAdd&quot;: null, &quot;IpcMode&quot;: &quot;private&quot;, &quot;Cgroup&quot;: &quot;&quot;, &quot;Links&quot;: null, &quot;OomScoreAdj&quot;: 0, &quot;PidMode&quot;: &quot;&quot;, &quot;Privileged&quot;: false, &quot;PublishAllPorts&quot;: false, &quot;ReadonlyRootfs&quot;: false, &quot;SecurityOpt&quot;: null, &quot;UTSMode&quot;: &quot;&quot;, &quot;UsernsMode&quot;: &quot;&quot;, &quot;ShmSize&quot;: 67108864, &quot;Runtime&quot;: &quot;runc&quot;, &quot;ConsoleSize&quot;: [ 0, 0 ], &quot;Isolation&quot;: &quot;&quot;, &quot;CpuShares&quot;: 0, &quot;Memory&quot;: 0, &quot;NanoCpus&quot;: 0, &quot;CgroupParent&quot;: &quot;&quot;, &quot;BlkioWeight&quot;: 0, &quot;BlkioWeightDevice&quot;: [], &quot;BlkioDeviceReadBps&quot;: null, &quot;BlkioDeviceWriteBps&quot;: null, &quot;BlkioDeviceReadIOps&quot;: null, &quot;BlkioDeviceWriteIOps&quot;: null, &quot;CpuPeriod&quot;: 0, &quot;CpuQuota&quot;: 0, &quot;CpuRealtimePeriod&quot;: 0, &quot;CpuRealtimeRuntime&quot;: 0, &quot;CpusetCpus&quot;: &quot;&quot;, &quot;CpusetMems&quot;: &quot;&quot;, &quot;Devices&quot;: [], &quot;DeviceCgroupRules&quot;: null, &quot;DeviceRequests&quot;: null, &quot;KernelMemory&quot;: 0, &quot;KernelMemoryTCP&quot;: 0, &quot;MemoryReservation&quot;: 0, &quot;MemorySwap&quot;: 0, &quot;MemorySwappiness&quot;: null, &quot;OomKillDisable&quot;: false, &quot;PidsLimit&quot;: null, &quot;Ulimits&quot;: null, &quot;CpuCount&quot;: 0, &quot;CpuPercent&quot;: 0, &quot;IOMaximumIOps&quot;: 0, &quot;IOMaximumBandwidth&quot;: 0, &quot;MaskedPaths&quot;: [ &quot;/proc/asound&quot;, &quot;/proc/acpi&quot;, &quot;/proc/kcore&quot;, &quot;/proc/keys&quot;, &quot;/proc/latency_stats&quot;, &quot;/proc/timer_list&quot;, &quot;/proc/timer_stats&quot;, &quot;/proc/sched_debug&quot;, &quot;/proc/scsi&quot;, &quot;/sys/firmware&quot; ], &quot;ReadonlyPaths&quot;: [ &quot;/proc/bus&quot;, &quot;/proc/fs&quot;, &quot;/proc/irq&quot;, &quot;/proc/sys&quot;, &quot;/proc/sysrq-trigger&quot; ] &#125;, &quot;GraphDriver&quot;: &#123; &quot;Data&quot;: &#123; &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/1f347949ba49c4dbee70cea9ff3af39a14e602bc8fac8331c46347bf6708757a-init/diff:/var/lib/docker/overlay2/5afcd8220c51854a847a36f52775b4ed0acb16fe6cfaec3bd2e5df59863835ba/diff&quot;, &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/1f347949ba49c4dbee70cea9ff3af39a14e602bc8fac8331c46347bf6708757a/merged&quot;, &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/1f347949ba49c4dbee70cea9ff3af39a14e602bc8fac8331c46347bf6708757a/diff&quot;, &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/1f347949ba49c4dbee70cea9ff3af39a14e602bc8fac8331c46347bf6708757a/work&quot; &#125;, &quot;Name&quot;: &quot;overlay2&quot; &#125;, &quot;Mounts&quot;: [], &quot;Config&quot;: &#123; &quot;Hostname&quot;: &quot;55321bcae33d&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; ], &quot;Cmd&quot;: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;while true;do echo 6666;sleep 1;done&quot; ], &quot;Image&quot;: &quot;centos&quot;, &quot;Volumes&quot;: null, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: null, &quot;OnBuild&quot;: null, &quot;Labels&quot;: &#123; &quot;org.label-schema.build-date&quot;: &quot;20200114&quot;, &quot;org.label-schema.license&quot;: &quot;GPLv2&quot;, &quot;org.label-schema.name&quot;: &quot;CentOS Base Image&quot;, &quot;org.label-schema.schema-version&quot;: &quot;1.0&quot;, &quot;org.label-schema.vendor&quot;: &quot;CentOS&quot;, &quot;org.opencontainers.image.created&quot;: &quot;2020-01-14 00:00:00-08:00&quot;, &quot;org.opencontainers.image.licenses&quot;: &quot;GPL-2.0-only&quot;, &quot;org.opencontainers.image.title&quot;: &quot;CentOS Base Image&quot;, &quot;org.opencontainers.image.vendor&quot;: &quot;CentOS&quot; &#125; &#125;, &quot;NetworkSettings&quot;: &#123; &quot;Bridge&quot;: &quot;&quot;, &quot;SandboxID&quot;: &quot;63ed0c837f35c12453bae9661859f37a08541a0749afb86e881869bf6fd9031b&quot;, &quot;HairpinMode&quot;: false, &quot;LinkLocalIPv6Address&quot;: &quot;&quot;, &quot;LinkLocalIPv6PrefixLen&quot;: 0, &quot;Ports&quot;: &#123; &#125;, &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/63ed0c837f35&quot;, &quot;SecondaryIPAddresses&quot;: null, &quot;SecondaryIPv6Addresses&quot;: null, &quot;EndpointID&quot;: &quot;b129d9a5a2cbb92722a2101244bd81a9e3d8af034e83f338c13790a1a94552a1&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;IPAddress&quot;: &quot;172.17.0.4&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:04&quot;, &quot;Networks&quot;: &#123; &quot;bridge&quot;: &#123; &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;NetworkID&quot;: &quot;ad5ada6a106f5ba3dda9ce4bc1475a4bb593bf5f7fbead72196e66515e8ac36a&quot;, &quot;EndpointID&quot;: &quot;b129d9a5a2cbb92722a2101244bd81a9e3d8af034e83f338c13790a1a94552a1&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.4&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:04&quot;, &quot;DriverOpts&quot;: null &#125; &#125; &#125; &#125;] 进入当前正在运行的容器我们通常容器都是使用后台方式运行的，需要进入容器，修改一些配置命令docker exec -it 容器id bashshell #测试➜ ~ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES55321bcae33d centos “/bin/sh -c ‘while t…” 10 minutes ago Up 10 minutes bold_bella7215824a4db centos “/bin/sh -c ‘while t…” 13 minutes ago Up 13 minutes zen_kepler55a31b3f8613 centos “/bin/bash” 15 minutes ago Up 15 minutes lucid_clarke➜ ~ docker exec -it 55321bcae33d /bin/bash[root@55321bcae33d /]# 12345678# 方式二docker attach 容器id#测试docker attach 55321bcae33d 正在执行当前的代码...区别#docker exec #进入当前容器后开启一个新的终端，可以在里面操作。（常用）#docker attach # 进入容器正在执行的终端 从容器内拷贝到主机上 12345678910111213141516171819202122docker cp 容器id:容器内路径 主机目的路径[root@iz2zeak7sgj6i7hrb2g862z ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES56a5583b25b4 centos &quot;/bin/bash&quot; 7seconds ago Up 6 seconds #1. 进入docker容器内部[root@iz2zeak7sgj6i7hrb2g862z ~]# docker exec -it 56a5583b25b4 /bin/bash[root@55321bcae33d /]# lsbin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var#新建一个文件[root@55321bcae33d /]# echo &quot;hello&quot; &gt; java.java[root@55321bcae33d /]# cat hello.java hello[root@55321bcae33d /]# exitexit#hello.java拷贝到home文件加下[root@iz2zeak7sgj6i7hrb2g862z /]# docker cp 56a5583b25b4:/hello.java /home [root@iz2zeak7sgj6i7hrb2g862z /]# cd /home[root@iz2zeak7sgj6i7hrb2g862z home]# ls -l #可以看见java.java存在total 8-rw-r--r-- 1 root root 0 May 19 22:09 haust.java-rw-r--r-- 1 root root 6 May 22 11:12 java.javadrwx------ 3 www www 4096 May 8 12:14 www 学习方式：将我的所有笔记敲一遍，自己记录笔记！ 小结： 命令大全 1234567891011121314151617181920212223242526272829303132333435363738394041attach Attach local standard input, output, and error streams to a running container #当前shell下 attach连接指定运行的镜像 build Build an image from a Dockerfile # 通过Dockerfile定制镜像 commit Create a new image from a container&#x27;s changes #提交当前容器为新的镜像 cp Copy files/folders between a container and the local filesystem #拷贝文件 create Create a new container #创建一个新的容器 diff Inspect changes to files or directories on a container&#x27;s filesystem #查看docker容器的变化 events Get real time events from the server # 从服务获取容器实时时间 exec Run a command in a running container # 在运行中的容器上运行命令 export Export a container&#x27;s filesystem as a tar archive #导出容器文件系统作为一个tar归档文件[对应import] history Show the history of an image # 展示一个镜像形成历史 images List images #列出系统当前的镜像 import Import the contents from a tarball to create a filesystem image #从tar包中导入内容创建一个文件系统镜像 info Display system-wide information # 显示全系统信息 inspect Return low-level information on Docker objects #查看容器详细信息 kill Kill one or more running containers # kill指定docker容器 load Load an image from a tar archive or STDIN #从一个tar包或标准输入中加载一个镜像[对应save] login Log in to a Docker registry # logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codes 作业练习 作业一：Docker 安装Nginx 12345678910111213141516171819202122232425262728293031#1. 搜索镜像 search 建议大家去docker搜索，可以看到帮助文档[root@iz2zeak7sgj6i7hrb2g862z ~]# docker search nginx#2. 拉取下载镜像 pull[root@iz2zeak7sgj6i7hrb2g862z ~]# docker pull nginx#3. 查看是否下载成功镜像[root@iz2zeak7sgj6i7hrb2g862z ~]# docker images#3. 运行测试# -d 后台运行# --name 给容器命名# -p 宿主机端口：容器内部端口[root@iz2zeak7sgj6i7hrb2g862z ~]# docker run -d --name nginx01 -p 3344:80 nginxaa664b0c8ed98f532453ce1c599be823bcc1f3c9209e5078615af416ccb454c2#4. 查看正在启动的镜像[root@iz2zeak7sgj6i7hrb2g862z ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES75943663c116 nginx &quot;nginx -g &#x27;daemon of…&quot; 41 seconds ago Up 40 seconds 0.0.0.0:82-&gt;80/tcp nginx00#5. 进入容器[root@iz2zeak7sgj6i7hrb2g862z ~]# docker exec -it nginx01 /bin/bash #进入root@aa664b0c8ed9:/# whereis nginx #找到nginx位置nginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginxroot@aa664b0c8ed9:/# cd /etc/nginx/root@aa664b0c8ed9:/etc/nginx# lsconf.d fastcgi_params koi-utf koi-win mime.types modules nginx.conf scgi_params uwsgi_params win-utf#6. 退出容器root@aa664b0c8ed9:/etc/nginx# exitexit#7. 停止容器[root@iz2zeak7sgj6i7hrb2g862z ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESaa664b0c8ed9 nginx &quot;nginx -g &#x27;daemon of…&quot; 10 minutes ago Up 10 minutes 0.0.0.0:3344-&gt;80/tcp nginx01[root@iz2zeak7sgj6i7hrb2g862z ~]# docker stop aa664b0c8ed9 宿主机端口 和 容器内部端口 以及端口暴露： 问题：我们每次改动nginx配置文件，都需要进入容器内部？十分麻烦，我要是可以在容器外部提供一个映射路径，达到在容器外部修改文件名，容器内部就可以自动修改？-v 数据卷 技术！ 作业二：用docker 来装一个tomcat 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 下载 tomcat9.0# 之前的启动都是后台，停止了容器，容器还是可以查到， docker run -it --rm 镜像名 一般是用来测试，用完就删除[root@iz2zeak7sgj6i7hrb2g862z ~]# docker run -it --rm tomcat:9.0--rm Automatically remove the container when it exits 用完即删#下载 最新版[root@iz2zeak7sgj6i7hrb2g862z ~]# docker pull tomcat#查看下载的镜像[root@iz2zeak7sgj6i7hrb2g862z ~]# docker images#以后台方式，暴露端口方式，启动运行[root@iz2zeak7sgj6i7hrb2g862z ~]# docker run -d -p 8080:8080 --name tomcat01 tomcat#测试访问有没有问题curl localhost:8080#根据容器id进入tomcat容器[root@iz2zeak7sgj6i7hrb2g862z ~]# docker exec -it 645596565d3f /bin/bashroot@645596565d3f:/usr/local/tomcat# #查看tomcat容器内部内容：root@645596565d3f:/usr/local/tomcat# ls -ltotal 152-rw-r--r-- 1 root root 18982 May 5 20:40 BUILDING.txt-rw-r--r-- 1 root root 5409 May 5 20:40 CONTRIBUTING.md-rw-r--r-- 1 root root 57092 May 5 20:40 LICENSE-rw-r--r-- 1 root root 2333 May 5 20:40 NOTICE-rw-r--r-- 1 root root 3255 May 5 20:40 README.md-rw-r--r-- 1 root root 6898 May 5 20:40 RELEASE-NOTES-rw-r--r-- 1 root root 16262 May 5 20:40 RUNNING.txtdrwxr-xr-x 2 root root 4096 May 16 12:05 bindrwxr-xr-x 1 root root 4096 May 21 11:04 confdrwxr-xr-x 2 root root 4096 May 16 12:05 libdrwxrwxrwx 1 root root 4096 May 21 11:04 logsdrwxr-xr-x 2 root root 4096 May 16 12:05 native-jni-libdrwxrwxrwx 2 root root 4096 May 16 12:05 tempdrwxr-xr-x 2 root root 4096 May 16 12:05 webappsdrwxr-xr-x 7 root root 4096 May 5 20:37 webapps.distdrwxrwxrwx 2 root root 4096 May 5 20:36 workroot@645596565d3f:/usr/local/tomcat# #进入webapps目录root@645596565d3f:/usr/local/tomcat# cd webappsroot@645596565d3f:/usr/local/tomcat/webapps# lsroot@645596565d3f:/usr/local/tomcat/webapps# # 发现问题：1、linux命令少了。 2.webapps目录为空 # 原因：阿里云镜像的原因，阿里云默认是最小的镜像，所以不必要的都剔除掉# 保证最小可运行的环境！# 解决方案：# 将webapps.dist下的文件都拷贝到webapps下即可root@645596565d3f:/usr/local/tomcat# ls 找到webapps.distBUILDING.txt LICENSE README.md RUNNING.txt conf logs temp webapps.distCONTRIBUTING.md NOTICE RELEASE-NOTES bin lib native-jni-lib webapps workroot@645596565d3f:/usr/local/tomcat# cd webapps.dist/ # 进入webapps.dist root@645596565d3f:/usr/local/tomcat/webapps.dist# ls # 查看内容ROOT docs examples host-manager managerroot@645596565d3f:/usr/local/tomcat/webapps.dist# cd ..root@645596565d3f:/usr/local/tomcat# cp -r webapps.dist/* webapps # 拷贝webapps.dist 内容给webappsroot@645596565d3f:/usr/local/tomcat# cd webapps #进入webappsroot@645596565d3f:/usr/local/tomcat/webapps# ls #查看拷贝结果ROOT docs examples host-manager manager 这样docker部署tomcat就可以访问了 问题:我们以后要部署项目，如果每次都要进入容器是不是十分麻烦？要是可以在容器外部提供一个映射路径，比如webapps，我们在外部放置项目，就自动同步内部就好了！ 作业三：部署elasticsearch+kibana 1234567891011121314151617181920212223242526272829# es 暴露的端口很多！# es 十分耗内存# es 的数据一般需要放置到安全目录！挂载# --net somenetwork ? 网络配置# 启动elasticsearch[root@iz2zeak7sgj6i7hrb2g862z ~]# docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch:7.6.2# 测试一下es是否成功启动➜ ~ curl localhost:9200&#123; &quot;name&quot; : &quot;d73ad2f22dd3&quot;, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;cluster_uuid&quot; : &quot;atFKgANxS8CzgIyCB8PGxA&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.6.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;docker&quot;, &quot;build_hash&quot; : &quot;ef48eb35cf30adf4db14086e8aabd07ef6fb113f&quot;, &quot;build_date&quot; : &quot;2020-03-26T06:34:37.794943Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.4.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125;#测试成功就关掉elasticSearch，防止耗内存[root@iz2zeak7sgj6i7hrb2g862z ~]# docker stop d834ce2bd306d834ce2bd306[root@iz2zeak7sgj6i7hrb2g862z ~]# docker stats # 查看docker容器使用内存情况 123#测试成功就关掉elasticSearch，可以添加内存的限制，修改配置文件 -e 环境配置修改➜ ~ docker rm -f d73ad2f22dd3 # stop命令也行 ➜ ~ docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -e ES_JAVA_OPTS=&quot;-Xms64m -Xmx512m&quot; elasticsearch:7.6.2 123456789101112131415161718➜ ~ curl localhost:9200&#123; &quot;name&quot; : &quot;b72c9847ec48&quot;, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;cluster_uuid&quot; : &quot;yNAK0EORSvq3Wtaqe2QqAg&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.6.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;docker&quot;, &quot;build_hash&quot; : &quot;ef48eb35cf30adf4db14086e8aabd07ef6fb113f&quot;, &quot;build_date&quot; : &quot;2020-03-26T06:34:37.794943Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.4.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 作业三：使用kibana连接es (elasticSearch)？思考网络如何才能连接 Portainer 可视化面板安装 portainer(先用这个) 12docker run -d -p 8080:9000 \\--restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer Rancher(CI/CD再用)什么是portainer？ Docker图形化界面管理工具！提供一个后台面板供我们操作！ 12345678910# 安装命令[root@iz2zeak7sgj6i7hrb2g862z ~]# docker run -d -p 8080:9000 \\&gt; --restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainerUnable to find image &#x27;portainer/portainer:latest&#x27; locallylatest: Pulling from portainer/portainerd1e017099d17: Pull complete a7dca5b5a9e8: Pull complete Digest: sha256:4ae7f14330b56ffc8728e63d355bc4bc7381417fa45ba0597e5dd32682901080Status: Downloaded newer image for portainer/portainer:latest81753869c4fd438cec0e31659cbed0d112ad22bbcfcb9605483b126ee8ff306d 测试访问： 外网：8080 ：http://123.56.247.59:8080/ 进入之后的面板 镜像原理之联合文件系统镜像是什么镜像是一种轻量级、可执行的独立软件保，用来打包软件运行环境和基于运行环境开发的软件，他包含运行某个软件所需的所有内容，包括代码、运行时库、环境变量和配置文件。 所有应用，直接打包docker镜像，就可以直接跑起来！ 如何得到镜像 从远程仓库下载 别人拷贝给你 自己制作一个镜像 DockerFile Docker镜像加载原理 UnionFs （联合文件系统） UnionFs（联合文件系统）：Union文件系统（UnionFs）是一种分层、轻量级并且高性能的文件系统，他支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下（ unite several directories into a single virtual filesystem)。Union文件系统是 Docker镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。 Docker镜像加载原理 docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。boots(boot file system）主要包含 bootloader和 Kernel, bootloader主要是引导加 kernel, Linux刚启动时会加bootfs文件系统，在 Docker镜像的最底层是 boots。这一层与我们典型的Linux/Unix系统是一样的，包含boot加載器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由 bootfs转交给内核，此时系统也会卸载bootfs。rootfs（root file system),在 bootfs之上。包含的就是典型 Linux系统中的/dev,/proc,/bin,/etc等标准目录和文件。 rootfs就是各种不同的操作系统发行版，比如 Ubuntu, Centos等等。 平时我们安装进虚拟机的CentOS都是好几个G，为什么Docker这里才200M？ 对于个精简的OS,rootfs可以很小，只需要包合最基本的命令，工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就可以了。由此可见对于不同的Linux发行版， boots基本是一致的， rootfs会有差別，因此不同的发行版可以公用bootfs. 虚拟机是分钟级别，容器是秒级！ 分层理解 分层的镜像 我们可以去下载一个镜像，注意观察下载的日志输出，可以看到是一层层的在下载 思考：为什么Docker镜像要采用这种分层的结构呢？ 最大的好处，我觉得莫过于资源共享了！比如有多个镜像都从相同的Base镜像构建而来，那么宿主机只需在磁盘上保留一份base镜像，同时内存中也只需要加载一份base镜像，这样就可以为所有的容器服务了，而且镜像的每一层都可以被共享。 查看镜像分层的方式可以通过docker image inspect 命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123➜ / docker image inspect redis [ &#123; &quot;Id&quot;: &quot;sha256:f9b9909726890b00d2098081642edf32e5211b7ab53563929a47f250bcdc1d7c&quot;, &quot;RepoTags&quot;: [ &quot;redis:latest&quot; ], &quot;RepoDigests&quot;: [ &quot;redis@sha256:399a9b17b8522e24fbe2fd3b42474d4bb668d3994153c4b5d38c3dafd5903e32&quot; ], &quot;Parent&quot;: &quot;&quot;, &quot;Comment&quot;: &quot;&quot;, &quot;Created&quot;: &quot;2020-05-02T01:40:19.112130797Z&quot;, &quot;Container&quot;: &quot;d30c0bcea88561bc5139821227d2199bb027eeba9083f90c701891b4affce3bc&quot;, &quot;ContainerConfig&quot;: &#123; &quot;Hostname&quot;: &quot;d30c0bcea885&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;ExposedPorts&quot;: &#123; &quot;6379/tcp&quot;: &#123; &#125; &#125;, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;, &quot;GOSU_VERSION=1.12&quot;, &quot;REDIS_VERSION=6.0.1&quot;, &quot;REDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-6.0.1.tar.gz&quot;, &quot;REDIS_DOWNLOAD_SHA=b8756e430479edc162ba9c44dc89ac394316cd482f2dc6b91bcd5fe12593f273&quot; ], &quot;Cmd&quot;: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;#(nop) &quot;, &quot;CMD [\\&quot;redis-server\\&quot;]&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:704c602fa36f41a6d2d08e49bd2319ccd6915418f545c838416318b3c29811e0&quot;, &quot;Volumes&quot;: &#123; &quot;/data&quot;: &#123; &#125; &#125;, &quot;WorkingDir&quot;: &quot;/data&quot;, &quot;Entrypoint&quot;: [ &quot;docker-entrypoint.sh&quot; ], &quot;OnBuild&quot;: null, &quot;Labels&quot;: &#123; &#125; &#125;, &quot;DockerVersion&quot;: &quot;18.09.7&quot;, &quot;Author&quot;: &quot;&quot;, &quot;Config&quot;: &#123; &quot;Hostname&quot;: &quot;&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;ExposedPorts&quot;: &#123; &quot;6379/tcp&quot;: &#123; &#125; &#125;, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;, &quot;GOSU_VERSION=1.12&quot;, &quot;REDIS_VERSION=6.0.1&quot;, &quot;REDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-6.0.1.tar.gz&quot;, &quot;REDIS_DOWNLOAD_SHA=b8756e430479edc162ba9c44dc89ac394316cd482f2dc6b91bcd5fe12593f273&quot; ], &quot;Cmd&quot;: [ &quot;redis-server&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:704c602fa36f41a6d2d08e49bd2319ccd6915418f545c838416318b3c29811e0&quot;, &quot;Volumes&quot;: &#123; &quot;/data&quot;: &#123; &#125; &#125;, &quot;WorkingDir&quot;: &quot;/data&quot;, &quot;Entrypoint&quot;: [ &quot;docker-entrypoint.sh&quot; ], &quot;OnBuild&quot;: null, &quot;Labels&quot;: null &#125;, &quot;Architecture&quot;: &quot;amd64&quot;, &quot;Os&quot;: &quot;linux&quot;, &quot;Size&quot;: 104101893, &quot;VirtualSize&quot;: 104101893, &quot;GraphDriver&quot;: &#123; &quot;Data&quot;: &#123; &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/adea96bbe6518657dc2d4c6331a807eea70567144abda686588ef6c3bb0d778a/diff:/var/lib/docker/overlay2/66abd822d34dc6446e6bebe73721dfd1dc497c2c8063c43ffb8cf8140e2caeb6/diff:/var/lib/docker/overlay2/d19d24fb6a24801c5fa639c1d979d19f3f17196b3c6dde96d3b69cd2ad07ba8a/diff:/var/lib/docker/overlay2/a1e95aae5e09ca6df4f71b542c86c677b884f5280c1d3e3a1111b13644b221f9/diff:/var/lib/docker/overlay2/cd90f7a9cd0227c1db29ea992e889e4e6af057d9ab2835dd18a67a019c18bab4/diff&quot;, &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/afa1de233453b60686a3847854624ef191d7bc317fb01e015b4f06671139fb11/merged&quot;, &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/afa1de233453b60686a3847854624ef191d7bc317fb01e015b4f06671139fb11/diff&quot;, &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/afa1de233453b60686a3847854624ef191d7bc317fb01e015b4f06671139fb11/work&quot; &#125;, &quot;Name&quot;: &quot;overlay2&quot; &#125;, &quot;RootFS&quot;: &#123; &quot;Type&quot;: &quot;layers&quot;, &quot;Layers&quot;: [ &quot;sha256:c2adabaecedbda0af72b153c6499a0555f3a769d52370469d8f6bd6328af9b13&quot;, &quot;sha256:744315296a49be711c312dfa1b3a80516116f78c437367ff0bc678da1123e990&quot;, &quot;sha256:379ef5d5cb402a5538413d7285b21aa58a560882d15f1f553f7868dc4b66afa8&quot;, &quot;sha256:d00fd460effb7b066760f97447c071492d471c5176d05b8af1751806a1f905f8&quot;, &quot;sha256:4d0c196331523cfed7bf5bafd616ecb3855256838d850b6f3d5fba911f6c4123&quot;, &quot;sha256:98b4a6242af2536383425ba2d6de033a510e049d9ca07ff501b95052da76e894&quot; ] &#125;, &quot;Metadata&quot;: &#123; &quot;LastTagTime&quot;: &quot;0001-01-01T00:00:00Z&quot; &#125; &#125;] 理解： 所有的 Docker镜像都起始于一个基础镜像层，当进行修改或培加新的内容时，就会在当前镜像层之上，创建新的镜像层。 举一个简单的例子，假如基于 Ubuntu Linux16.04创建一个新的镜像，这就是新镜像的第一层；如果在该镜像中添加 Python包，就会在基础镜像层之上创建第二个镜像层；如果继续添加一个安全补丁，就会创健第三个镜像层该像当前已经包含3个镜像层，如下图所示（这只是一个用于演示的很简单的例子）。 在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点. 在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。下图中举了一个简单的例子，每个镜像层包含3个文件，而镜像包含了来自两个镜像层的6个文件。 上图中的镜像层跟之前图中的略有区別，主要目的是便于展示文件下图中展示了一个稍微复杂的三层镜像，在外部看来整个镜像只有6个文件，这是因为最上层中的文件7是文件5的一个更新版。 文种情況下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像当中 Docker通过存储引擎（新版本采用快照机制）的方式来实现镜像层堆栈，并保证多镜像层对外展示为统一的文件系统 Linux上可用的存储引撃有AUFS、 Overlay2、 Device Mapper、Btrfs以及ZFS。顾名思义，每种存储引擎都基于 Linux中对应的件系统或者块设备技术，井且每种存储引擎都有其独有的性能特点。 Docker在 Windows上仅支持 windowsfilter 一种存储引擎，该引擎基于NTFS文件系统之上实现了分层和CoW [1]。 下图展示了与系统显示相同的三层镜像。所有镜像层堆并合井，对外提供统一的视图。 特点 Docker 镜像都是只读的，当容器启动时，一个新的可写层加载到镜像的顶部！ 这一层就是我们通常说的容器层，容器之下的都叫镜像层！ commit镜像123docker commit 提交容器成为一个新的副本# 命令和git原理类似docker commit -m=&quot;描述信息&quot; -a=&quot;作者&quot; 容器id 目标镜像名:[版本TAG] 实战测试 123456789101112131415161718192021222324252627# 1、启动一个默认的tomcat[root@iz2zeak7sgj6i7hrb2g862z ~]# docker run -d -p 8080:8080 tomcatde57d0ace5716d27d0e3a7341503d07ed4695ffc266aef78e0a855b270c4064e# 2、发现这个默认的tomcat 是没有webapps应用，官方的镜像默认webapps下面是没有文件的！#docker exec -it 容器id /bin/bash[root@iz2zeak7sgj6i7hrb2g862z ~]# docker exec -it de57d0ace571 /bin/bashroot@de57d0ace571:/usr/local/tomcat# # 3、从webapps.dist拷贝文件进去webapproot@de57d0ace571:/usr/local/tomcat# cp -r webapps.dist/* webappsroot@de57d0ace571:/usr/local/tomcat# cd webappsroot@de57d0ace571:/usr/local/tomcat/webapps# lsROOT docs examples host-manager manager# 4、将操作过的容器通过commit**为一个镜像！我们以后就使用我们修改过的镜像即可，而不需要每次都重新拷贝webapps.dist下的文件到webapps了，这就是我们自己的一个修改的镜像。docker commit -m=&quot;描述信息&quot; -a=&quot;作者&quot; 容器id 目标镜像名:[TAG]docker commit -a=&quot;kuangshen&quot; -m=&quot;add webapps app&quot; 容器id tomcat02:1.0[root@iz2zeak7sgj6i7hrb2g862z ~]# docker commit -a=&quot;csp提交的&quot; -m=&quot;add webapps app&quot; de57d0ace571 tomcat02.1.0sha256:d5f28a0bb0d0b6522fdcb56f100d11298377b2b7c51b9a9e621379b01cf1487e[root@iz2zeak7sgj6i7hrb2g862z ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtomcat02.1.0 latest d5f28a0bb0d0 14 seconds ago 652MBtomcat latest 1b6b1fe7261e 5 days ago 647MBnginx latest 9beeba249f3e 5 days ago 127MBmysql 5.7 b84d68d0a7db 5 days ago 448MBelasticsearch 7.6.2 f29a1ee41030 8 weeks ago 791MBportainer/portainer latest 2869fc110bf7 2 months ago 78.6MBcentos latest 470671670cac 4 months ago 237MBhello-world latest bf756fb1ae65 4 months ago 13.3kB 如果你想要保存当前容器的状态，就可以通过commit来提交，获得一个镜像，就好比我们我们使用虚拟机的快照。 入门成功！！！！","tags":["笔记"],"categories":["Docker"]},{"title":"资源服务器授权以及OAuth2对接微服务","path":"/2021/11/12/OAuth2-duijieweifuwu/","content":"1. 资源服务器授权配置1.1 资源服务授权配置 基本上所有微服务都是资源服务。 1. 资源服务中配置公钥： 认证服务生成令牌采用非对称加密算法，认证服务采用私钥加密生成令牌，对外向资源服务提供公钥，资源服务使用公钥来校验令牌的合法性。 将公钥拷贝到 public.key 文件中，将此文件拷贝到每一个需要的资源服务工程的classpath(resources目录)下，eg: 用户微服务: 2. 资源服务中添加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; 3. 配置每个系统的Http请求路径安全控制策略以及读取公钥信息识别令牌，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * @Auther: csp1999 * @Date: 2021/01/26/19:41 * @Description: 资源授权配置（访问该微服务时，需要校验令牌） */@Configuration@EnableResourceServer // 开启资源校验服务 ---&gt; 令牌校验// 开启全局方法安全校验（方法权限控制：不同权限的登录用户，可以访问的方法不同）@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true)// 激活方法上的PreAuthorize注解public class ResourceServerConfig extends ResourceServerConfigurerAdapter &#123; /** * 公钥 */ private static final String PUBLIC_KEY = &quot;public.key&quot;; /** * 定义JwtTokenStore * * @param jwtAccessTokenConverter * @return */ @Bean public TokenStore tokenStore(JwtAccessTokenConverter jwtAccessTokenConverter) &#123; return new JwtTokenStore(jwtAccessTokenConverter); &#125; /** * 定义JJwtAccessTokenConverter * * @return */ @Bean public JwtAccessTokenConverter jwtAccessTokenConverter() &#123; JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setVerifierKey(getPubKey()); return converter; &#125; /** * 获取非对称加密的公钥Key * * @return 公钥 Key */ private String getPubKey() &#123; Resource resource = new ClassPathResource(PUBLIC_KEY); try &#123; InputStreamReader inputStreamReader = new InputStreamReader(resource.getInputStream()); BufferedReader br = new BufferedReader(inputStreamReader); return br.lines().collect(Collectors.joining(&quot; &quot;)); &#125; catch (IOException ioe) &#123; return null; &#125; &#125; /** * Http安全配置，对每个到达系统的http请求链接进行校验 * * @param http * @throws Exception */ @Override public void configure(HttpSecurity http) throws Exception &#123; // 所有请求必须认证通过 http.authorizeRequests() // 下边的路径放行 // 放行的请求路径不用登陆也可以访问 .antMatchers( &quot;/user/add&quot;,&quot;/user/load/*&quot;). // 配置地址放行 permitAll() .anyRequest(). authenticated(); // 其他地址需要认证授权 &#125;&#125; 1.2 用户微服务资源授权1.将生成的公钥public.key拷贝到changgou-service-user微服务工程的resources目录下，如下图： 2.引入依赖: 在changgou-service-user微服务工程pom.xml中引入上面的oauth2.0依赖 3.资源授权配置: 在changgou-service-user工程中创建com.changgou.user.config.ResourceServerConfig(上边有) 1.3 授权测试 用户每次访问微服务的时候，需要先申请令牌，令牌申请后，每次将令牌放到头文件中，才能访问微服务。 头文件中每次需要添加一个Authorization头信息，头信息的内容格式为：bearer token(token为申请得到的令牌)。 1.不携带令牌测试：访问http://localhost:8089/user 不携带令牌，结果如下： 2.携带正确令牌访问先通过认证微服务执行登录，拿到令牌： 访问localhost:9001/user/login?username=szitheima&amp;password=szitheima获取token令牌，结果如下： 访问http://localhost:8089/user/szitheima（携带正确令牌）,根据username查询用户信息 执行后结果如下： 3.携带错误令牌访问http://localhost:18089/user/szitheima携带不正确的token令牌，结果如下： 2. OAuth2对接微服务 用户每次访问微服务的时候，先去oauth2.0服务登录，登录后再访问微服务网关，微服务网关将请求转发给其他微服务处理。 步骤: 1.用户登录成功后，会将令牌信息存入到cookie中(一般建议存入到头文件中) 2.用户携带Cookie中的令牌访问微服务网关 3.微服务网关先获取头文件中的令牌信息，如果Header中没有Authorization令牌信息，则去参数中找，参数中如果没有，则去Cookie中找Authorization，最后将令牌信息封装到Header中，然后再调用其他微服务 4.其他微服务会获取头文件中的Authorization令牌信息，然后匹配令牌数据是否能使用公钥解密，如果解密成功说明用户已登录，解密失败，说明用户未登录 2.1 令牌加入到Header中修改changgou-gateway-web的全局过滤器com.changgou.filter.AuthorizeFilter，实现将令牌信息添加到头文件中，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/** * @Auther: csp1999 * @Date: 2021/01/24/20:17 * @Description: 全局过滤器: 用于鉴权(获取令牌 + 解析令牌 + 判断令牌是否合法) */@Componentpublic class AuthorizeFilter implements GlobalFilter, Ordered &#123; // 令牌头 private static final String AUTHORIZE_TOKEN = &quot;Authorization&quot;; /** * 全局过滤器 * * @param exchange * @param chain * @return */ @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; // 1.获取请求对象 ServerHttpRequest request = exchange.getRequest(); // 2.获取响应对象 ServerHttpResponse response = exchange.getResponse(); // 获取请求的URI String path = request.getURI().getPath(); // 3.未登录状态下只放行登录login和搜索search if (path.startsWith(&quot;/api/user/login&quot;) || path.startsWith(&quot;/api/brand/search/&quot;)) &#123; // 直接放行 return chain.filter(exchange); &#125; // 4.判断是否为登录的URL 如果不是则权限校验 // 4.1 从头header中获取令牌数据 String token = request.getHeaders().getFirst(AUTHORIZE_TOKEN); // 如果为true：说明令牌在header中， false：令牌不在header中，将令牌封装入header，再传递给其他微服务 boolean hasToken = true; // 如果header中没有token数据 if(StringUtils.isEmpty(token))&#123; // 4.2 从cookie中中获取令牌数据 HttpCookie first = request.getCookies().getFirst(AUTHORIZE_TOKEN); if(first!=null)&#123; token=first.getValue();// 就是令牌的数据 &#125; // 令牌不在header中 hasToken = false; &#125; // 如果cookie中也没有令牌数据，则从请求参数中获取 if(StringUtils.isEmpty(token))&#123; // 4.3 从请求参数中获取令牌数据 token= request.getQueryParams().getFirst(AUTHORIZE_TOKEN); // 令牌不在header中 hasToken = false; &#125; // 如果请求参数中仍然没有token数据 if(StringUtils.isEmpty(token))&#123; // 4.4. 则，结束，响应UNAUTHORIZED状态码405. response.setStatusCode(HttpStatus.UNAUTHORIZED); return response.setComplete(); &#125; // 如果得到token数据，则： // 5.解析令牌数据(判断解析是否正确,正确就放行,否则就结束) try &#123; // 1.借助jwt工具类解析token校验令牌 // Claims claims = JwtUtil.parseJWT(token); // 2.借助oautho2校验令牌 // 如果请求头中没有token： if (!hasToken) &#123; // token令牌不为空，则判断令牌是否有bearer前缀，如果没有则添加该前缀 if (!token.startsWith(&quot;bearer&quot;) &amp;&amp; !token.startsWith(&quot;Bearer&quot;)) &#123; token = &quot;bearer&quot; + token; &#125; // 如果有前缀，放行 // 放行之前，将令牌封装到头文件中(这一步是为了方便AUTH2校验令牌) request.mutate().header(AUTHORIZE_TOKEN, token); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); // 解析失败，响应状态码401 response.setStatusCode(HttpStatus.UNAUTHORIZED); return response.setComplete(); &#125; // 放行 return chain.filter(exchange); &#125; /** * 过滤器执行顺序 * * @return */ @Override public int getOrder() &#123; // 首位 return 0; &#125;&#125; 访问测试： 访问http://localhost:8001/api/user/szitheima，将生成的新令牌放到头文件中，在令牌前面添加Bearer，这里主要由个空格，效果如下： 2.2 用户身份权限控制由于我们项目使用了微服务，任何用户都有可能使用任意微服务，此时我们需要控制相关权限，例如：普通用户角色不能使用用户的删除操作，只有管理员才可以使用,那么这个时候就需要使用到SpringSecurity的权限控制功能了。 2.2.1 角色身份定义在changgou-user-oauth2认证微服务中，com.changgou.oauth.config.UserDetailsServiceImpl该类实现了加载用户相关信息，如下代码： 上述代码给登录用户定义了2个角色，分别为user 和 admin，这一块我们目前使用的是硬编码方式将角色写死了，后面会从数据库加载。 2.2.2 角色权限控制在每个微服务中，需要获取用户的角色，然后根据角色识别是否允许操作指定的方法，Spring Security中定义了四个支持权限控制的表达式注解，分别是@PreAuthorize、@PostAuthorize、@PreFilter和@PostFilter。其中前两者可以用来在方法调用前或者调用后进行权限检查，后两者可以用来对集合类型的参数或者返回值进行过滤。在需要控制权限的方法上，我们可以添加@PreAuthorize注解，用于方法执行前进行权限检查，校验用户当前角色是否能访问该方法。 1.开启@PreAuthorize 在changgou-user-service的ResourceServerConfig类上添加@EnableGlobalMethodSecurity注解，用于开启@PreAuthorize的支持，代码如下： 2.方法权限控制 在changgoug-service-user微服务的com.changgou.user.controller.UserController类的findAll()方法(查询所有用户信息)上添加权限控制注解@PreAuthorize，代码如下： 1234567891011121314/** * 查询User全部数据 * * @return *///@PreAuthorize(&quot;hasAnyRole(&#x27;user&#x27;,&#x27;admin&#x27;)&quot;)// 添加权限：只允许管理员admin角色访问，不允许其他角色访问@PreAuthorize(&quot;hasAnyRole(&#x27;admin&#x27;)&quot;)@GetMappingpublic Result&lt;List&lt;User&gt;&gt; findAll() &#123; // 调用UserService实现查询所有User List&lt;User&gt; list = userService.findAll(); return new Result&lt;List&lt;User&gt;&gt;(true, StatusCode.OK, &quot;查询成功&quot;, list);&#125; 3.测试用户角色权限 访问localhost:8001/api/user获取所有用户信息： 发现上面请求无法访问，因为用户登录的时候，角色不包含admin角色，而findAll()方法需要admin角色，所以被拦截了。 接下来再测试其他没有加admin管理员权限的方法，其他方法（eg: findById()）没有配置拦截，所以用户登录后就会放行： 知识点说明： 如果希望一个方法能被多个角色访问，配置:@PreAuthorize(&quot;hasAnyAuthority(&#39;admin&#39;,&#39;user&#39;)&quot;) 如果希望一个类都能被多个角色访问，在类上配置:@PreAuthorize(&quot;hasAnyAuthority(&#39;admin&#39;,&#39;user&#39;)&quot;) 3. OAuth2动态加载数据(从数据库获取数据)前面OAuth2我们用的数据都是静态的，在现实工作中，数据都是从数据库加载的，所以我们需要调整一下OAuth服务，从数据库加载相关数据。 客户端数据[生成令牌相关数据] 用户登录账号密码从数据库加载 3.1 客户端信息相关数据加载3.1.1 数据介绍客户端静态数据： 在changgou-user-oauth的com.changgou.oauth.config.AuthorizationServerConfig类中配置了客户端静态数据，主要用于配置客户端数据，代码如下： 客户端表结构： 创建一个数据库changgou_oauth,并在数据库中创建一张表，表主要用于记录客户端相关信息，表结构如下： 1234567891011121314CREATE TABLE `oauth_client_details` ( `client_id` varchar(48) NOT NULL COMMENT &#x27;客户端ID，主要用于标识对应的应用&#x27;, `resource_ids` varchar(256) DEFAULT NULL, `client_secret` varchar(256) DEFAULT NULL COMMENT &#x27;客户端秘钥，BCryptPasswordEncoder加密算法加密&#x27;, `scope` varchar(256) DEFAULT NULL COMMENT &#x27;对应的范围&#x27;, `authorized_grant_types` varchar(256) DEFAULT NULL COMMENT &#x27;认证模式&#x27;, `web_server_redirect_uri` varchar(256) DEFAULT NULL COMMENT &#x27;认证后重定向地址&#x27;, `authorities` varchar(256) DEFAULT NULL, `access_token_validity` int(11) DEFAULT NULL COMMENT &#x27;令牌有效期&#x27;, `refresh_token_validity` int(11) DEFAULT NULL COMMENT &#x27;令牌刷新周期&#x27;, `additional_information` varchar(4096) DEFAULT NULL, `autoapprove` varchar(256) DEFAULT NULL, PRIMARY KEY (`client_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 字段说明： 1234567client_id：客户端id resource_ids：资源id（暂时不用） client_secret：客户端秘钥 scope：范围 access_token_validity：访问token的有效期（秒） refresh_token_validity：刷新token的有效期（秒） authorized_grant_type：授权类型:authorization_code,password,refresh_token,client_credentials 导入2条记录到表中，SQL如下：数据中密文分别为changgou、szitheima： 12INSERT INTO `oauth_client_details` VALUES (&#x27;changgou&#x27;, null, &#x27;$2a$10$wZRCFgWnwABfE60igAkBPeuGFuzk74V2jw3/trkdUZpnteCtJ9p9m&#x27;, &#x27;app&#x27;, &#x27;authorization_code,password,refresh_token,client_credentials&#x27;, &#x27;http://localhost&#x27;, null, &#x27;432000000&#x27;, &#x27;432000000&#x27;, null, null);INSERT INTO `oauth_client_details` VALUES (&#x27;szitheima&#x27;, null, &#x27;$2a$10$igxoCZxTbjWx5TrmfWEEpe/WFdwbUhbxik9BKTe9i64ZOSfnu/lqe&#x27;, &#x27;app&#x27;, &#x27;authorization_code,password,refresh_token,client_credentials&#x27;, &#x27;http://localhost&#x27;, null, &#x27;432000000&#x27;, &#x27;432000000&#x27;, null, null); 上述表结构属于SpringSecurity Oauth2.0所需的一个认证表结构，不能随意更改。相关操作在其他类中有所体现，如：org.springframework.security.oauth2.provider.client.JdbcClientDetailsService中的片段代码如下： 3.1.2 从库数据加载相关数据修改连接配置： 从数据库加载数据，我们需要先配置数据库连接，在changgou-user-oauth2的application.yml中配置连接信息，如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758server: # 认证微服务端口 port: 9001# spring 相关配置spring: application: # 微服务名称 name: user-auth # Redis配置 redis: # Redis数据库索引（默认为0） database: 0 # Redis服务器地址 host: 8.131.66.136 # Redis服务器连接端口 port: 6379 # Redis服务器连接密码（默认为空） password: csp19990129 # 数据库相关配置 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/changgou_oauth?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;allowMultiQueries=true&amp;serverTimezone=UTC username: root password: root main: allow-bean-definition-overriding: true# eureka相关配置eureka: instance: prefer-ip-address: true client: service-url: defaultZone: http://127.0.0.1:7001/eureka# auth相关配置auth: # token存储到redis的过期时间 ttl: 3600 # client唯一id clientId: changgou # client密钥 clientSecret: changgou # cookie域名 cookieDomain: localhost cookieMaxAge: -1# 本地证书、密钥以及证书密码配置encrypt: key-store: # 证书路径（resources路径下） location: classpath:/changgou.jks # 密钥 # 公钥(提供给每个微服务)，可以加密，用于校验令牌的合法性---&gt;私钥(提供给认证微服务)，可以解密，用于生成令牌---&gt;非对称加密算法RSA # 我们之前做的MD5加密算法，使用的是摘要加密算法，不可逆！ # AES/DESC 使用的是对称加密，可以加密和解密，加密解密的密钥是相同的！ secret: changgou # 证书别名 alias: changgou # 证书密码 password: changgou 修改客户端加载源： 修改changgou-user-oauth2的com.changgou.oauth.config.AuthorizationServerConfig类的configure方法，将之前静态的客户端数据变成从数据库加载，修改如下： 1234567891011121314151617181920212223242526/** * 客户端信息配置 * * @param clients * @throws Exception */@Overridepublic void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; // 静态客户端信息配置 /* clients.inMemory() .withClient(&quot;changgou&quot;) // 客户端id .secret(&quot;changgou&quot;) // 秘钥 .redirectUris(&quot;http://localhost&quot;) // 重定向地址 .accessTokenValiditySeconds(3600) // 访问令牌有效期 .refreshTokenValiditySeconds(3600) // 刷新令牌有效期 .authorizedGrantTypes( &quot;authorization_code&quot;, // 根据授权码生成令牌 &quot;client_credentials&quot;, // 客户端认证 &quot;refresh_token&quot;, // 刷新令牌 &quot;password&quot;) // 密码方式认证 .scopes(&quot;app&quot;); // 客户端范围，名称自定义，必填 */ // 从数据库中获取上面的数据： clients.jdbc(dataSource).clients(clientDetails());// 从数据库加载客户端信息&#125; UserDetailsServiceImpl修改： 将之前的加密方式去掉即可，代码如下： 1234567891011121314151617181920212223242526@Overridepublic UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; //====================================客户端信息认证 开始==================================== // 取出身份，如果身份为空说明没有认证 Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); // 没有认证统一采用httpbasic认证，httpbasic中存储了client_id和client_secret，开始认证client_id和client_secret if (authentication == null) &#123; ClientDetails clientDetails = clientDetailsService.loadClientByClientId(username); if (clientDetails != null) &#123; // 秘钥 String clientSecret = clientDetails.getClientSecret(); // 1.静态方式 //return new User( // username, // 客户端id // new BCryptPasswordEncoder().encode(clientSecret), // 客户端密钥-&gt;加密操作 // AuthorityUtils.commaSeparatedStringToAuthorityList(&quot;&quot;));// 权限 // 2.数据库查找方式 return new User( username,// 客户端id clientSecret,// 客户端密钥-&gt;不需要再加密操作，因为数据库中已经加密 AuthorityUtils.commaSeparatedStringToAuthorityList(&quot;&quot;));// 权限 &#125; &#125; //====================================客户端信息认证 结束==================================== ...&#125; 3.1.3 测试授权码模式测试： 访问：http://localhost:9001/oauth/authorize?client_id=szitheima&amp;response_type=code&amp;scop=app&amp;redirect_uri=http://localhost效果如下： 用户名对应应用id，密码对应秘钥。账号输入：szitheima 密码：szitheima，效果如下： 密码模式授权测试： 我们之前编写的账号密码登录代码如下，每次都会加载指定的客户端ID和指定的秘钥，所以此时的客户端ID和秘钥固定了，输入的账号密码不再是客户端ID和秘钥了。 123456789101112131415161718192021222324/** * 登录方法： * 1.密码模式认证-授权方式：grant_type=password * * @param username 2.账号 szitheima * @param password 3.密码 szitheima * @return */ @RequestMapping(&quot;/login&quot;) public Result&lt;Map&gt; login(String username, String password) &#123; if (StringUtils.isEmpty(username) || StringUtils.isEmpty(password)) &#123; throw new RuntimeException(&quot;用户名/密码不允许为空&quot;); &#125; // 申请令牌：调用loginService的login方法进行登录，并返回生成的令牌数据 AuthToken authToken = loginService.login(username, password, clientId, clientSecret, GRAND_TYPE); // 设置到cookie中 this.saveCookie(authToken.getAccessToken()); return new Result&lt;&gt;(true, StatusCode.OK, &quot;令牌生成成功&quot;, authToken); &#125; // 保存token到cookie中 private void saveCookie(String token) &#123; HttpServletResponse response = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getResponse(); CookieUtil.addCookie(response, cookieDomain, &quot;/&quot;, &quot;Authorization&quot;, token, cookieMaxAge, false); &#125; OAuth中的com.changgou.oauth.config.UserDetailsServiceImpl配置如下： 用户每次输入账号和密码，只要密码是szitheima，即可登录成功。 访问地址http://localhost:9001/user/login 输入账号密码均为szitheima，效果如下： 3.2 用户相关数据加载 因为我们目前整套系统是对内提供登录访问，所以每次用户登录的时候oauth需要调用用户微服务查询用户信息，如上图： 我们需要在用户微服务中提供用户信息查询的方法，并在oauth中使用feign调用即可。 在真实工作中，用户和管理员对应的oauth认证服务器会分开，网关也会分开，我们今天的课堂案例只实现用户相关的认证即可。 1.Feign创建在changgou-service-user-api中创建com.changgou.user.feign.UserFeign，代码如下： 123456789101112131415161718/** * @Auther: csp1999 * @Date: 2021/01/27/14:19 * @Description: 用户微服务feign客户端接口 */@FeignClient(value = &quot;changgou-user&quot;)@RequestMapping(value = &quot;/user&quot;)public interface UserFeign &#123; /*** * 根据ID查询User数据 * @param id * @return */ @GetMapping(&#123; &quot;/load/&#123;id&#125;&quot;&#125;) //@GetMapping(&#123;&quot;/&#123;id&#125;&quot;, &quot;/load/&#123;id&#125;&quot;&#125;)不能这样写！ public Result&lt;User&gt; findById(@PathVariable String id);&#125; 2.修改UserController修改changgou-service-user的UserController的findById方法，添加一个新的地址，用于加载用户信息，代码如下： 123456789101112/*** * 根据ID查询User数据 * @param id * @return */@GetMapping(&#123; &quot;/&#123;id&#125;&quot;,&quot;/load/&#123;id&#125;&quot;&#125;)public Result&lt;User&gt; findById(@PathVariable String id) &#123; // 调用UserService实现根据主键查询User User user = userService.findById(id); return new Result&lt;User&gt;(true, StatusCode.OK, &quot;查询成功&quot;, user);&#125; 3.放行查询用户方法因为oauth需要调用查询用户信息，需要在changgou-service-user中放行/user/load/&#123;id&#125;方法,修改ResourceServerConfig，添加对/user/load/&#123;id&#125;的放行操作，代码如下： 123456789101112131415161718/** * Http安全配置，对每个到达系统的http请求链接进行校验 * * @param http * @throws Exception */@Overridepublic void configure(HttpSecurity http) throws Exception &#123; // 所有请求必须认证通过 http.authorizeRequests() // 下边的路径放行 // 放行的请求路径不用登陆也可以访问 .antMatchers( &quot;/user/add&quot;,&quot;/user/load/*&quot;). // 配置地址放行 permitAll() .anyRequest(). authenticated(); // 其他地址需要认证授权&#125; 4.oauth调用查询用户信息oauth认证微服务引入对changgou-user-api的依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.changgou&lt;/groupId&gt; &lt;artifactId&gt;changgou-service-user-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 修改oauth的com.changgou.oauth.config.UserDetailsServiceImpl的loadUserByUsername方法，调用UserFeign查询用户信息，代码如下： 1234567891011121314151617//====================================用户信息认证 开始====================================if (StringUtils.isEmpty(username)) &#123; return null;&#125;// 从数据库加载查询用户信息Result&lt;com.changgou.user.pojo.User&gt; userResult = userFeign.findById(username);// 判空if (userResult == null || userResult.getData() == null) &#123; return null;&#125;// 根据用户名查询用户信息//String pwd = new BCryptPasswordEncoder().encode(&quot;szitheima&quot;);String pwd = userResult.getData().getPassword();// 创建User对象String permissions = &quot;user,admin&quot;;// 指定用户的角色身份，普通用户user/admin用户UserJwt userDetails = new UserJwt(username, pwd, AuthorityUtils.commaSeparatedStringToAuthorityList(permissions));//====================================用户信息认证 结束==================================== 完整的UserDetailsServiceImpl代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 自定义授权认证类 */@Servicepublic class UserDetailsServiceImpl implements UserDetailsService &#123; @Autowired ClientDetailsService clientDetailsService; @Autowired private UserFeign userFeign; /** * 自定义授权认证 * * @param username * @return * @throws UsernameNotFoundException */ @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; //====================================客户端信息认证 开始==================================== // 取出身份，如果身份为空说明没有认证 Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); // 没有认证统一采用httpbasic认证，httpbasic中存储了client_id和client_secret，开始认证client_id和client_secret if (authentication == null) &#123; ClientDetails clientDetails = clientDetailsService.loadClientByClientId(username); if (clientDetails != null) &#123; // 秘钥 String clientSecret = clientDetails.getClientSecret(); // 1.静态方式 //return new User( // username, // 客户端id // new BCryptPasswordEncoder().encode(clientSecret), // 客户端密钥-&gt;加密操作 // AuthorityUtils.commaSeparatedStringToAuthorityList(&quot;&quot;));// 权限 // 2.数据库查找方式 return new User( username,// 客户端id clientSecret,// 客户端密钥-&gt;不需要再加密操作，因为数据库中已经加密 AuthorityUtils.commaSeparatedStringToAuthorityList(&quot;&quot;));// 权限 &#125; &#125; //====================================客户端信息认证 结束==================================== //====================================用户信息认证 开始==================================== if (StringUtils.isEmpty(username)) &#123; return null; &#125; // 从数据库加载查询用户信息 Result&lt;com.changgou.user.pojo.User&gt; userResult = userFeign.findById(username); // 判空 if (userResult == null || userResult.getData() == null) &#123; return null; &#125; // 根据用户名查询用户信息 //String pwd = new BCryptPasswordEncoder().encode(&quot;szitheima&quot;); String pwd = userResult.getData().getPassword(); // 创建User对象 String permissions = &quot;user,admin&quot;;// 指定用户的角色身份，普通用户user/admin用户 UserJwt userDetails = new UserJwt(username, pwd, AuthorityUtils.commaSeparatedStringToAuthorityList(permissions)); //====================================用户信息认证 结束==================================== //userDetails.setComy(songsi); return userDetails; &#125;&#125; 5.主启动类Feign开启123456789101112131415161718/** * @Author: csp1999 * @Date: 2020/7/6 8:01 * @Description: OAUTH2 认证授权微服务启动类 */@SpringBootApplication@EnableDiscoveryClient//@MapperScan(basePackages = &quot;com.changgou.auth.dao&quot;)@EnableFeignClients(&quot;com.changgou.user.feign&quot;)public class OAuthApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OAuthApplication.class, args); &#125; @Bean(name = &quot;restTemplate&quot;) public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 6.测试我们换个数据库中的账号密码登录，分别输入zhangsan，效果如下：","tags":["笔记"],"categories":["Java"]},{"title":"springboot学习笔记","path":"/2021/11/12/SpringBoot-1/","content":"源码+笔记哔哩哔哩视频学习链接 一、Spring Boot 入门1、Spring Boot 简介 简化Spring应用开发的一个框架； 整个Spring技术栈的一个大整合； J2EE开发的一站式解决方案； 2、微服务2014，martin fowler 微服务：架构风格（服务微化） 一个应用应该是一组小型服务；可以通过HTTP的方式进行互通； 单体应用：ALL IN ONE 微服务：每一个功能元素最终都是一个可独立替换和独立升级的软件单元； 详细参照微服务文档 3、环境准备http://www.gulixueyuan.com/ 谷粒学院 环境约束 –jdk1.8：Spring Boot 推荐jdk1.7及以上；java version “1.8.0_112” –maven3.x：maven 3.3以上版本；Apache Maven 3.3.9 –IntelliJIDEA2017：IntelliJ IDEA 2017.2.2 x64、STS –SpringBoot 1.5.9.RELEASE：1.5.9； 统一环境； 1、MAVEN设置；给maven 的settings.xml配置文件的profiles标签添加 123456789101112&lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt;&lt;/profile&gt; 2、IDEA设置整合maven进来； [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-QuSgyFbV-1586693502365)(src/main/resources/notes/images/搜狗截图20180129151045.png)] [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-8w8vdsVG-1586693502367)(src/main/resources/notes/images/搜狗截图20180129151112.png)] 4、Spring Boot HelloWorld一个功能： 浏览器发送hello请求，服务器接受请求并处理，响应Hello World字符串； 1、创建一个maven工程；（jar）2、导入spring boot相关的依赖1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3、编写一个主程序；启动Spring Boot应用12345678910/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123; public static void main(String[] args) &#123; // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); &#125;&#125; 4、编写相关的Controller、Service12345678@Controllerpublic class HelloController &#123; @ResponseBody @RequestMapping(&quot;/hello&quot;) public String hello()&#123; return &quot;Hello World!&quot;; &#125;&#125; 5、运行主程序测试6、简化部署123456789&lt;!-- 这个插件，可以将应用打包成一个可执行的jar包；--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 将这个应用打成jar包，直接使用java -jar的命令进行执行； 5、Hello World探究1、POM文件1、父项目12345678910111213&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;他的父项目是&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;&lt;/parent&gt;他来真正管理Spring Boot应用里面的所有依赖版本； Spring Boot的版本仲裁中心； 以后我们导入依赖默认是不需要写版本；（没有在dependencies里面管理的依赖自然需要声明版本号） 2、启动器1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter-web： spring-boot-starter：spring-boot场景启动器；帮我们导入了web模块正常运行所依赖的组件； Spring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter相关场景的所有依赖都会导入进来。要用什么功能就导入什么场景的启动器 2、主程序类，主入口类12345678910/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123; public static void main(String[] args) &#123; // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); &#125;&#125; @SpringBootApplication: Spring Boot应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用； 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; @SpringBootConfiguration:Spring Boot的配置类； 标注在某个类上，表示这是一个Spring Boot的配置类； @Configuration:配置类上来标注这个注解； 配置类 ——- 配置文件；配置类也是容器中的一个组件；@Component @EnableAutoConfiguration：开启自动配置功能； 以前我们需要配置的东西，Spring Boot帮我们自动配置；@EnableAutoConfiguration告诉SpringBoot开启自动配置功能；这样自动配置才能生效； 123@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; @AutoConfigurationPackage：自动配置包 @Import(AutoConfigurationPackages.Registrar.class)： Spring的底层注解@Import，给容器中导入一个组件；导入的组件由AutoConfigurationPackages.Registrar.class； 将主配置类（@SpringBootApplication标注的类）的所在包及下面所有子包里面的所有组件扫描到Spring容器； @Import(EnableAutoConfigurationImportSelector.class)； 给容器中导入组件？ EnableAutoConfigurationImportSelector：导入哪些组件的选择器； 将所有需要导入的组件以全类名的方式返回；这些组件就会被添加到容器中； 会给容器中导入非常多的自动配置类（xxxAutoConfiguration）；就是给容器中导入这个场景需要的所有组件，并配置好这些组件； [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-j2WxHggQ-1586693502368)(src/main/resources/notes/images/搜狗截图20180129224104.png)] 有了自动配置类，免去了我们手动编写配置注入功能组件等的工作； SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class,classLoader)； ==Spring Boot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值，将这些值作为自动配置类导入到容器中，自动配置类就生效，帮我们进行自动配置工作；==以前我们需要自己配置的东西，自动配置类都帮我们； J2EE的整体整合解决方案和自动配置都在spring-boot-autoconfigure-1.5.9.RELEASE.jar； Spring注解版（谷粒学院） 6、使用Spring Initializer快速创建Spring Boot项目1、IDEA：使用 Spring Initializer快速创建项目IDE都支持使用Spring的项目创建向导快速创建一个Spring Boot项目； 选择我们需要的模块；向导会联网创建Spring Boot项目； 默认生成的Spring Boot项目； 主程序已经生成好了，我们只需要我们自己的逻辑 resources文件夹中目录结构 static：保存所有的静态资源； js css images； templates：保存所有的模板页面；（Spring Boot默认jar包使用嵌入式的Tomcat，默认不支持JSP页面）；可以使用模板引擎（freemarker、thymeleaf）； application.properties：Spring Boot应用的配置文件；可以修改一些默认设置； 2、STS使用 Spring Starter Project快速创建项目 二、配置文件1、配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的； •application.properties •application.yml 配置文件的作用：修改SpringBoot自动配置的默认值；SpringBoot在底层都给我们自动配置好； YAML（YAML Ain’t Markup Language） YAML A Markup Language：是一个标记语言 YAML isn’t Markup Language：不是一个标记语言； 标记语言： 以前的配置文件；大多都使用的是 xxxx.xml文件； YAML：以数据为中心，比json、xml等更适合做配置文件； YAML：配置例子 12server: port: 8081 XML： 123&lt;server&gt; &lt;port&gt;8081&lt;/port&gt;&lt;/server&gt; 2、YAML语法：1、基本语法k:(空格)v：表示一对键值对（空格必须有）； 以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的 123server: port: 8081 path: /hello 属性和值也是大小写敏感； 2、值的写法字面量：普通的值（数字，字符串，布尔）k: v：字面直接来写； 字符串默认不用加上单引号或者双引号； “”：双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思 name: “zhangsan lisi”：输出；zhangsan 换行 lisi ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据 name: ‘zhangsan lisi’：输出；zhangsan lisi 对象、Map（属性和值）（键值对）：k: v：在下一行来写对象的属性和值的关系；注意缩进 对象还是k: v的方式 123friends: lastName: zhangsan age: 20 行内写法： 12friends: &#123; lastName: zhangsan,age: 18&#125; 数组（List、Set）：用- 值表示数组中的一个元素 1234pets: - cat - dog - pig 行内写法 1pets: [cat,dog,pig] 3、配置文件值注入配置文件 12345678910111213person: lastName: hello age: 18 boss: false birth: 2017/12/12 maps: &#123; k1: v1,k2: 12&#125; lists: - lisi - zhaoliu dog: name: 小狗 age: 12 javaBean： 123456789101112131415161718/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = &quot;person&quot;：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * */@Component@ConfigurationProperties(prefix = &quot;person&quot;)public class Person &#123; private String lastName; private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 我们可以导入配置文件处理器，以后编写配置就有提示了 123456&lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 1、properties配置文件在idea中默认utf-8可能会乱码调整 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-frb2uIOo-1586693502369)(src/main/resources/notes/images/搜狗截图20180130161620.png)] 2、@Value获取值和@ConfigurationProperties获取值比较 @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 配置文件yml还是properties他们都能获取到值； 如果说，我们只是在某个业务逻辑中需要获取一下配置文件中的某项值，使用@Value； 如果说，我们专门编写了一个javaBean来和配置文件进行映射，我们就直接使用@ConfigurationProperties； 3、配置文件注入值数据校验123456789101112131415161718192021@Component@ConfigurationProperties(prefix = &quot;person&quot;)@Validatedpublic class Person &#123; /** * &lt;bean class=&quot;Person&quot;&gt; * &lt;property name=&quot;lastName&quot; value=&quot;字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;&quot;&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 @Email //@Value(&quot;$&#123;person.last-name&#125;&quot;) private String lastName; //@Value(&quot;#&#123;11*2&#125;&quot;) private Integer age; //@Value(&quot;true&quot;) private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 4、@PropertySource&amp;@ImportResource&amp;@Bean@PropertySource：加载指定的配置文件； 12345678910111213141516171819202122232425262728/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = &quot;person&quot;：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * @ConfigurationProperties(prefix = &quot;person&quot;)默认从全局配置文件中获取值； * */@PropertySource(value = &#123; &quot;classpath:person.properties&quot;&#125;)@Component@ConfigurationProperties(prefix = &quot;person&quot;)//@Validatedpublic class Person &#123; /** * &lt;bean class=&quot;Person&quot;&gt; * &lt;property name=&quot;lastName&quot; value=&quot;字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;&quot;&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 // @Email //@Value(&quot;$&#123;person.last-name&#125;&quot;) private String lastName; //@Value(&quot;#&#123;11*2&#125;&quot;) private Integer age; //@Value(&quot;true&quot;) private Boolean boss; @ImportResource：导入Spring的配置文件，让配置文件里面的内容生效； Spring Boot里面没有Spring的配置文件，我们自己编写的配置文件，也不能自动识别； 想让Spring的配置文件生效，加载进来；@ImportResource标注在一个配置类上 123@ImportResource(locations = &#123; &quot;classpath:beans.xml&quot;&#125;)导入Spring的配置文件让其生效 不来编写Spring的配置文件 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;helloService&quot; class=&quot;com.atguigu.springboot.service.HelloService&quot;&gt;&lt;/bean&gt;&lt;/beans&gt; SpringBoot推荐给容器中添加组件的方式；推荐使用全注解的方式 1、配置类**@Configuration**———&gt;Spring配置文件 2、使用**@Bean**给容器中添加组件 123456789101112131415/** * @Configuration：指明当前类是一个配置类；就是来替代之前的Spring配置文件 * * 在配置文件中用&lt;bean&gt;&lt;bean/&gt;标签添加组件 * */@Configurationpublic class MyAppConfig &#123; //将方法的返回值添加到容器中；容器中这个组件默认的id就是方法名 @Bean public HelloService helloService02()&#123; System.out.println(&quot;配置类@Bean给容器中添加组件了...&quot;); return new HelloService(); &#125;&#125; ##4、配置文件占位符 1、随机数1234567$&#123; random.value&#125;、$&#123; random.int&#125;、$&#123; random.long&#125;$&#123; random.int(10)&#125;、$&#123; random.int[1024,65536]&#125; 2、占位符获取之前配置的值，如果没有可以是用:指定默认值123456789person.last-name=张三$&#123;random.uuid&#125;person.age=$&#123;random.int&#125;person.birth=2017/12/15person.boss=falseperson.maps.k1=v1person.maps.k2=14person.lists=a,b,cperson.dog.name=$&#123;person.hello:hello&#125;_dogperson.dog.age=15 5、Profile1、多Profile文件我们在主配置文件编写的时候，文件名可以是 application-{profile}.properties/yml 默认使用application.properties的配置； 2、yml支持多文档块方式123456789101112131415server: port: 8081spring: profiles: active: prod---server: port: 8083spring: profiles: dev---server: port: 8084spring: profiles: prod #指定属于哪个环境 3、激活指定profile1、在配置文件中指定 spring.profiles.active=dev 2、命令行： java -jar spring-boot-02-config-0.0.1-SNAPSHOT.jar —spring.profiles.active=dev； 可以直接在测试的时候，配置传入命令行参数 3、虚拟机参数； -Dspring.profiles.active=dev 6、配置文件加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件 –file:./config/ –file:./ –classpath:/config/ –classpath:/ 优先级由高到底，高优先级的配置会覆盖低优先级的配置； SpringBoot会从这四个位置全部加载主配置文件；互补配置； 我们还可以通过spring.config.location来改变默认的配置文件位置 项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置； java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar —spring.config.location=G:/application.properties 7、外部配置加载顺序SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置 1.命令行参数 所有的配置都可以在命令行上进行指定 java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar —server.port=8087 —server.context-path=/abc 多个配置用空格分开； —配置项=值 2.来自java:comp/env的JNDI属性 3.Java系统属性（System.getProperties()） 4.操作系统环境变量 5.RandomValuePropertySource配置的random.*属性值 由jar包外向jar包内进行寻找； 优先加载带profile 6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 再来加载不带profile 8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件 9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件 10.@Configuration注解类上的@PropertySource 11.通过SpringApplication.setDefaultProperties指定的默认属性 所有支持的配置加载来源； 参考官方文档 8、自动配置原理配置文件到底能写什么？怎么写？自动配置原理； 配置文件能配置的属性参照 1、自动配置原理：1）、SpringBoot启动的时候加载主配置类，开启了自动配置功能 @EnableAutoConfiguration 2）、@EnableAutoConfiguration 作用： 利用EnableAutoConfigurationImportSelector给容器中导入一些组件？ 可以查看selectImports()方法的内容； List configurations = getCandidateConfigurations(annotationMetadata, attributes);获取候选的配置 ```SpringFactoriesLoader.loadFactoryNames()扫描所有jar包类路径下 META-INF/spring.factories把扫描到的这些文件的内容包装成properties对象从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102**将 类路径下 META-INF/spring.factories 里面配置的所有EnableAutoConfiguration的值加入到了容器中；**```yaml# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\\org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\\org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\\org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\\org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置； 3）、每一个自动配置类进行自动配置功能； 4）、以HttpEncodingAutoConfiguration（Http编码自动配置）为例解释自动配置原理； 12345678910111213141516171819202122@Configuration //表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@EnableConfigurationProperties(HttpEncodingProperties.class) //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中@ConditionalOnWebApplication //Spring底层@Conditional注解（Spring注解版），根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效； 判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnClass(CharacterEncodingFilter.class) //判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤器；@ConditionalOnProperty(prefix = &quot;spring.http.encoding&quot;, value = &quot;enabled&quot;, matchIfMissing = true) //判断配置文件中是否存在某个配置 spring.http.encoding.enabled；如果不存在，判断也是成立的//即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；public class HttpEncodingAutoConfiguration &#123; //他已经和SpringBoot的配置文件映射了 private final HttpEncodingProperties properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123; this.properties = properties; &#125; @Bean //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？ public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; 根据当前不同的条件判断，决定这个配置类是否生效？ 一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的； 5）、所有在配置文件中能配置的属性都是在xxxxProperties类中封装者‘；配置文件能配置什么就可以参照某个功能对应的这个属性类 123@ConfigurationProperties(prefix = &quot;spring.http.encoding&quot;) //从配置文件中获取指定的值和bean的属性进行绑定public class HttpEncodingProperties &#123; public static final Charset DEFAULT_CHARSET = Charset.forName(&quot;UTF-8&quot;); 精髓： 1）、SpringBoot启动会加载大量的自动配置类 2）、我们看我们需要的功能有没有SpringBoot默认写好的自动配置类； 3）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了） 4）、给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值； xxxxAutoConfigurartion：自动配置类； 给容器中添加组件 xxxxProperties:封装配置文件中相关属性； 2、细节1、@Conditional派生注解（Spring注解版原生的@Conditional作用）作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 自动配置类必须在一定的条件下才能生效； 我们怎么知道哪些自动配置类生效； 我们可以通过启用 debug=true属性；来让控制台打印自动配置报告，这样我们就可以很方便的知道哪些自动配置类生效； 12345678910111213141516=========================AUTO-CONFIGURATION REPORT=========================Positive matches:（自动配置类启用的）----------------- DispatcherServletAutoConfiguration matched: - @ConditionalOnClass found required class &#x27;org.springframework.web.servlet.DispatcherServlet&#x27;; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) - @ConditionalOnWebApplication (required) found StandardServletEnvironment (OnWebApplicationCondition)Negative matches:（没有启动，没有匹配成功的自动配置类）----------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes &#x27;javax.jms.ConnectionFactory&#x27;, &#x27;org.apache.activemq.ActiveMQConnectionFactory&#x27; (OnClassCondition) AopAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes &#x27;org.aspectj.lang.annotation.Aspect&#x27;, &#x27;org.aspectj.lang.reflect.Advice&#x27; (OnClassCondition) 三、日志1、日志框架小张；开发一个大型系统； 1、System.out.println(“”)；将关键数据打印在控制台；去掉？写在一个文件？ 2、框架来记录系统的一些运行时信息；日志框架 ； zhanglogging.jar； 3、高大上的几个功能？异步模式？自动归档？xxxx？ zhanglogging-good.jar？ 4、将以前框架卸下来？换上新的框架，重新修改之前相关的API；zhanglogging-prefect.jar； 5、JDBC—数据库驱动； 写了一个统一的接口层；日志门面（日志的一个抽象层）；logging-abstract.jar； 给项目中导入具体的日志实现就行了；我们之前的日志框架都是实现的抽象层； 市面上的日志框架； JUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j… 日志门面 （日志的抽象层） 日志实现 JCL（Jakarta Commons Logging） SLF4j（Simple Logging Facade for Java） jboss-logging Log4j JUL（java.util.logging） Log4j2 Logback 左边选一个门面（抽象层）、右边来选一个实现； 日志门面： SLF4J； 日志实现：Logback； SpringBoot：底层是Spring框架，Spring框架默认是用JCL；‘ SpringBoot选用 SLF4j和logback； 2、SLF4j使用1、如何在系统中使用SLF4j https://www.slf4j.org以后开发的时候，日志记录方法的调用，不应该来直接调用日志的实现类，而是调用日志抽象层里面的方法； 给系统里面导入slf4j的jar和 logback的实现jar 12345678import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld &#123; public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(&quot;Hello World&quot;); &#125;&#125; 图示； [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-GcWTAW29-1586693502369)(src/main/resources/notes/images/concrete-bindings.png)] 每一个日志的实现框架都有自己的配置文件。使用slf4j以后，配置文件还是做成日志实现框架自己本身的配置文件； 2、遗留问题a（slf4j+logback）: Spring（commons-logging）、Hibernate（jboss-logging）、MyBatis、xxxx 统一日志记录，即使是别的框架和我一起统一使用slf4j进行输出？ [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-WJg5NKSY-1586693502370)(images/legacy.png)] 如何让系统中所有的日志都统一到slf4j； 1、将系统中其他日志框架先排除出去； 2、用中间包来替换原有的日志框架； 3、我们导入slf4j其他的实现 3、SpringBoot日志关系1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; SpringBoot使用它来做日志功能； 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; 底层依赖关系 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-qKWPqvD2-1586693502370)(images/搜狗截图20180131220946.png)] 总结： 1）、SpringBoot底层也是使用slf4j+logback的方式进行日志记录 2）、SpringBoot也把其他的日志都替换成了slf4j； 3）、中间替换包？ 1234@SuppressWarnings(&quot;rawtypes&quot;)public abstract class LogFactory &#123; static String UNSUPPORTED_OPERATION_IN_JCL_OVER_SLF4J = &quot;http://www.slf4j.org/codes.html#unsupported_operation_in_jcl_over_slf4j&quot;; static LogFactory logFactory = new SLF4JLogFactory(); [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-oSNieyV7-1586693502371)(src/main/resources/notes/images/搜狗截图20180131221411.png)] 4）、如果我们要引入其他框架？一定要把这个框架的默认日志依赖移除掉？ Spring框架用的是commons-logging； 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; SpringBoot能自动适配所有的日志，而且底层使用slf4j+logback的方式记录日志，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉即可； 4、日志使用；1、默认配置SpringBoot默认帮我们配置好了日志； 123456789101112131415//记录器 Logger logger = LoggerFactory.getLogger(getClass()); @Test public void contextLoads() &#123; //System.out.println(); //日志的级别； //由低到高 trace&lt;debug&lt;info&lt;warn&lt;error //可以调整输出的日志级别；日志就只会在这个级别以以后的高级别生效 logger.trace(&quot;这是trace日志...&quot;); logger.debug(&quot;这是debug日志...&quot;); //SpringBoot默认给我们使用的是info级别的，没有指定级别的就用SpringBoot默认规定的级别；root级别 logger.info(&quot;这是info日志...&quot;); logger.warn(&quot;这是warn日志...&quot;); logger.error(&quot;这是error日志...&quot;); &#125; 123456789日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; %d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n SpringBoot修改日志的默认配置 1234567891011logging.level.com.atguigu=trace#logging.path=# 不指定路径在当前项目下生成springboot.log日志# 可以指定完整的路径；#logging.file=G:/springboot.log# 在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件logging.path=/spring/log# 在控制台输出的日志的格式logging.pattern.console=%d&#123;yyyy-MM-dd&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n# 指定文件中日志输出的格式logging.pattern.file=%d&#123;yyyy-MM-dd&#125; === [%thread] === %-5level === %logger&#123;50&#125; ==== %msg%n logging.file logging.path Example Description (none) (none) 只在控制台输出 指定文件名 (none) my.log 输出日志到my.log文件 (none) 指定目录 /var/log 输出到指定目录的 spring.log 文件中 2、指定配置给类路径下放上每个日志框架自己的配置文件即可；SpringBoot就不使用他默认配置的了 Logging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties logback.xml：直接就被日志框架识别了； logback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，可以使用SpringBoot的高级Profile功能 1234&lt;springProfile name=&quot;staging&quot;&gt; &lt;!-- configuration to be enabled when the &quot;staging&quot; profile is active --&gt; 可以指定某段配置只在某个环境下生效&lt;/springProfile&gt; 如： 12345678910111213141516171819&lt;appender name=&quot;stdout&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;springProfile name=&quot;dev&quot;&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ----&gt; [%thread] ---&gt; %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name=&quot;!dev&quot;&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ==== [%thread] ==== %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt; &lt;/appender&gt; 如果使用logback.xml作为日志配置文件，还要使用profile功能，会有以下错误 1no applicable action for [springProfile] 5、切换日志框架可以按照slf4j的日志适配图，进行相关的切换； slf4j+log4j的方式； 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;/dependency&gt; 切换为log4j2 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt; 四、Web开发1、简介使用SpringBoot； 1）、创建SpringBoot应用，选中我们需要的模块； 2）、SpringBoot已经默认将这些场景配置好了，只需要在配置文件中指定少量配置就可以运行起来 3）、自己编写业务代码； 自动配置原理？ 这个场景SpringBoot帮我们配置了什么？能不能修改？能修改哪些配置？能不能扩展？xxx 12xxxxAutoConfiguration：帮我们给容器中自动配置组件；xxxxProperties:配置类来封装配置文件的内容； 2、SpringBoot对静态资源的映射规则；123@ConfigurationProperties(prefix = &quot;spring.resources&quot;, ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware &#123; //可以设置和静态资源有关的参数，缓存时间等 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657WebMvcAuotConfiguration： @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if (!this.resourceProperties.isAddMappings()) &#123; logger.debug(&quot;Default resource handling disabled&quot;); return; &#125; Integer cachePeriod = this.resourceProperties.getCachePeriod(); if (!registry.hasMappingForPattern(&quot;/webjars/**&quot;)) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(&quot;/webjars/**&quot;) .addResourceLocations( &quot;classpath:/META-INF/resources/webjars/&quot;) .setCachePeriod(cachePeriod)); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); //静态资源文件夹映射 if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations( this.resourceProperties.getStaticLocations()) .setCachePeriod(cachePeriod)); &#125; &#125; //配置欢迎页映射 @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping( ResourceProperties resourceProperties) &#123; return new WelcomePageHandlerMapping(resourceProperties.getWelcomePage(), this.mvcProperties.getStaticPathPattern()); &#125; //配置喜欢的图标 @Configuration @ConditionalOnProperty(value = &quot;spring.mvc.favicon.enabled&quot;, matchIfMissing = true) public static class FaviconConfiguration &#123; private final ResourceProperties resourceProperties; public FaviconConfiguration(ResourceProperties resourceProperties) &#123; this.resourceProperties = resourceProperties; &#125; @Bean public SimpleUrlHandlerMapping faviconHandlerMapping() &#123; SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE + 1); //所有 **/favicon.ico mapping.setUrlMap(Collections.singletonMap(&quot;**/favicon.ico&quot;, faviconRequestHandler())); return mapping; &#125; @Bean public ResourceHttpRequestHandler faviconRequestHandler() &#123; ResourceHttpRequestHandler requestHandler = new ResourceHttpRequestHandler(); requestHandler .setLocations(this.resourceProperties.getFaviconLocations()); return requestHandler; &#125; &#125; 1）、所有 /webjars/** ，都去 classpath:/META-INF/resources/webjars/ 找资源； webjars：以jar包的方式引入静态资源； http://www.webjars.org/ [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-7xGUUphO-1586693502372)(src/main/resources/notes/images/搜狗截图20180203181751.png)] localhost:8080/webjars/jquery/3.3.1/jquery.js 123456&lt;!--引入jquery-webjar--&gt;在访问的时候只需要写webjars下面资源的名称即可 &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; 2）、”/**“ 访问当前项目的任何资源，都去（静态资源的文件夹）找映射 12345&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,&quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &quot;/&quot;：当前项目的根路径 localhost:8080/abc === 去静态资源文件夹里面找abc 3）、欢迎页； 静态资源文件夹下的所有index.html页面；被”/**“映射； localhost:8080/ 找index页面 4）、所有的 **/favicon.ico 都是在静态资源文件下找； 3、模板引擎JSP、Velocity、Freemarker、Thymeleaf [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-1DmRA9y0-1586693502372)(src/main/resources/notes/images/template-engine.png)] SpringBoot推荐的Thymeleaf； 语法更简单，功能更强大； 1、引入thymeleaf；123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; 2.1.6 &lt;/dependency&gt;切换thymeleaf版本&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt; &lt;!-- 布局功能的支持程序 thymeleaf3主程序 layout2以上版本 --&gt; &lt;!-- thymeleaf2 layout1--&gt; &lt;thymeleaf-layout-dialect.version&gt;2.2.2&lt;/thymeleaf-layout-dialect.version&gt; &lt;/properties&gt; 2、Thymeleaf使用1234567@ConfigurationProperties(prefix = &quot;spring.thymeleaf&quot;)public class ThymeleafProperties &#123; private static final Charset DEFAULT_ENCODING = Charset.forName(&quot;UTF-8&quot;); private static final MimeType DEFAULT_CONTENT_TYPE = MimeType.valueOf(&quot;text/html&quot;); public static final String DEFAULT_PREFIX = &quot;classpath:/templates/&quot;; public static final String DEFAULT_SUFFIX = &quot;.html&quot;; // 只要我们把HTML页面放在classpath:/templates/，thymeleaf就能自动渲染； 使用： 1、导入thymeleaf的名称空间 1&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; 2、使用thymeleaf语法； 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;成功！&lt;/h1&gt; &lt;!--th:text 将div里面的文本内容设置为 --&gt; &lt;div th:text=&quot;$&#123;hello&#125;&quot;&gt;这是显示欢迎信息&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3、语法规则1）、th:text；改变当前元素里面的文本内容； th：任意html属性；来替换原生属性的值 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-7zVqpbhD-1586693502373)(src/main/resources/notes/images/2018-02-04_123955.png)] 2）、表达式？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465Simple expressions:（表达式语法） Variable Expressions: $&#123;...&#125;：获取变量值；OGNL； 1）、获取对象的属性、调用方法 2）、使用内置的基本对象： #ctx : the context object. #vars: the context variables. #locale : the context locale. #request : (only in Web Contexts) the HttpServletRequest object. #response : (only in Web Contexts) the HttpServletResponse object. #session : (only in Web Contexts) the HttpSession object. #servletContext : (only in Web Contexts) the ServletContext object. $&#123;session.foo&#125; 3）、内置的一些工具对象：#execInfo : information about the template being processed.#messages : methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #&#123;…&#125; syntax.#uris : methods for escaping parts of URLs/URIs#conversions : methods for executing the configured conversion service (if any).#dates : methods for java.util.Date objects: formatting, component extraction, etc.#calendars : analogous to #dates , but for java.util.Calendar objects.#numbers : methods for formatting numeric objects.#strings : methods for String objects: contains, startsWith, prepending/appending, etc.#objects : methods for objects in general.#bools : methods for boolean evaluation.#arrays : methods for arrays.#lists : methods for lists.#sets : methods for sets.#maps : methods for maps.#aggregates : methods for creating aggregates on arrays or collections.#ids : methods for dealing with id attributes that might be repeated (for example, as a result of an iteration). Selection Variable Expressions: *&#123;...&#125;：选择表达式：和$&#123;&#125;在功能上是一样； 补充：配合 th:object=&quot;$&#123;session.user&#125;： &lt;div th:object=&quot;$&#123;session.user&#125;&quot;&gt; &lt;p&gt;Name: &lt;span th:text=&quot;*&#123;firstName&#125;&quot;&gt;Sebastian&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Surname: &lt;span th:text=&quot;*&#123;lastName&#125;&quot;&gt;Pepper&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Nationality: &lt;span th:text=&quot;*&#123;nationality&#125;&quot;&gt;Saturn&lt;/span&gt;.&lt;/p&gt; &lt;/div&gt; Message Expressions: #&#123;...&#125;：获取国际化内容 Link URL Expressions: @&#123;...&#125;：定义URL； @&#123;/order/process(execId=$&#123;execId&#125;,execType=&#x27;FAST&#x27;)&#125; Fragment Expressions: ~&#123;...&#125;：片段引用表达式 &lt;div th:insert=&quot;~&#123;commons :: main&#125;&quot;&gt;...&lt;/div&gt;Literals（字面量） Text literals: &#x27;one text&#x27; , &#x27;Another one!&#x27; ,… Number literals: 0 , 34 , 3.0 , 12.3 ,… Boolean literals: true , false Null literal: null Literal tokens: one , sometext , main ,…Text operations:（文本操作） String concatenation: + Literal substitutions: |The name is $&#123;name&#125;|Arithmetic operations:（数学运算） Binary operators: + , - , * , / , % Minus sign (unary operator): -Boolean operations:（布尔运算） Binary operators: and , or Boolean negation (unary operator): ! , notComparisons and equality:（比较运算） Comparators: &gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le ) Equality operators: == , != ( eq , ne )Conditional operators:条件运算（三元运算符） If-then: (if) ? (then) If-then-else: (if) ? (then) : (else) Default: (value) ?: (defaultvalue)Special tokens: No-Operation: _ 4、SpringMVC自动配置https://docs.spring.io/spring-boot/docs/1.5.10.RELEASE/reference/htmlsingle/#boot-features-developing-web-applications 1. Spring MVC auto-configurationSpring Boot 自动配置好了SpringMVC 以下是SpringBoot对SpringMVC的默认配置:（WebMvcAutoConfiguration） Inclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans. 自动配置了ViewResolver（视图解析器：根据方法的返回值得到视图对象（View），视图对象决定如何渲染（转发？重定向？）） ContentNegotiatingViewResolver：组合所有的视图解析器的； 如何定制：我们可以自己给容器中添加一个视图解析器；自动的将其组合进来； Support for serving static resources, including support for WebJars (see below).静态资源文件夹路径,webjars Static index.html support. 静态首页访问 Custom Favicon support (see below). favicon.ico 自动注册了 of Converter, GenericConverter, Formatter beans. Converter：转换器； public String hello(User user)：类型转换使用Converter Formatter 格式化器； 2017.12.17===Date； 12345@Bean @ConditionalOnProperty(prefix = &quot;spring.mvc&quot;, name = &quot;date-format&quot;)//在文件中配置日期格式化的规则 public Formatter&lt;Date&gt; dateFormatter() &#123; return new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件 &#125; 自己添加的格式化器转换器，我们只需要放在容器中即可 Support for HttpMessageConverters (see below). HttpMessageConverter：SpringMVC用来转换Http请求和响应的；User—Json； HttpMessageConverters 是从容器中确定；获取所有的HttpMessageConverter； 自己给容器中添加HttpMessageConverter，只需要将自己的组件注册容器中（@Bean,@Component） Automatic registration of MessageCodesResolver (see below).定义错误代码生成规则 Automatic use of a ConfigurableWebBindingInitializer bean (see below). 我们可以配置一个ConfigurableWebBindingInitializer来替换默认的；（添加到容器） 12初始化WebDataBinder；请求数据=====JavaBean； org.springframework.boot.autoconfigure.web：web的所有自动场景； If you want to keep Spring Boot MVC features, and you just want to add additional MVC configuration (interceptors, formatters, view controllers etc.) you can add your own @Configuration class of type WebMvcConfigurerAdapter, but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter or ExceptionHandlerExceptionResolver you can declare a WebMvcRegistrationsAdapter instance providing such components. If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc. 2、扩展SpringMVC1234567&lt;mvc:view-controller path=&quot;/hello&quot; view-name=&quot;success&quot;/&gt; &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/hello&quot;/&gt; &lt;bean&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 编写一个配置类（@Configuration），是WebMvcConfigurerAdapter类型；不能标注@EnableWebMvc; 既保留了所有的自动配置，也能用我们扩展的配置； 12345678910//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(&quot;/atguigu&quot;).setViewName(&quot;success&quot;); &#125;&#125; 原理： 1）、WebMvcAutoConfiguration是SpringMVC的自动配置类 2）、在做其他自动配置时会导入；@Import(EnableWebMvcConfiguration.class) 1234567891011121314151617@Configuration public static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration &#123; private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); //从容器中获取所有的WebMvcConfigurer @Autowired(required = false) public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123; if (!CollectionUtils.isEmpty(configurers)) &#123; this.configurers.addWebMvcConfigurers(configurers); //一个参考实现；将所有的WebMvcConfigurer相关配置都来一起调用； @Override // public void addViewControllers(ViewControllerRegistry registry) &#123; // for (WebMvcConfigurer delegate : this.delegates) &#123; // delegate.addViewControllers(registry); // &#125; &#125; &#125; &#125; 3）、容器中所有的WebMvcConfigurer都会一起起作用； 4）、我们的配置类也会被调用； 效果：SpringMVC的自动配置和我们的扩展配置都会起作用； 3、全面接管SpringMVC；SpringBoot对SpringMVC的自动配置不需要了，所有都是我们自己配置；所有的SpringMVC的自动配置都失效了 我们需要在配置类中添加@EnableWebMvc即可； 1234567891011//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@EnableWebMvc@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(&quot;/atguigu&quot;).setViewName(&quot;success&quot;); &#125;&#125; 原理： 为什么@EnableWebMvc自动配置就失效了； 1）@EnableWebMvc的核心 12@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123; 2）、 12@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; 3）、 123456789101112@Configuration@ConditionalOnWebApplication@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class &#125;)//容器中没有这个组件的时候，这个自动配置类才生效@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123; 4）、@EnableWebMvc将WebMvcConfigurationSupport组件导入进来； 5）、导入的WebMvcConfigurationSupport只是SpringMVC最基本的功能； 5、如何修改SpringBoot的默认配置模式： 1）、SpringBoot在自动配置很多组件的时候，先看容器中有没有用户自己配置的（@Bean、@Component）如果有就用用户配置的，如果没有，才自动配置；如果有些组件可以有多个（ViewResolver）将用户配置的和自己默认的组合起来； 2）、在SpringBoot中会有非常多的xxxConfigurer帮助我们进行扩展配置 3）、在SpringBoot中会有很多的xxxCustomizer帮助我们进行定制配置 6、RestfulCRUD1）、默认访问首页1234567891011121314151617181920212223//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能//@EnableWebMvc 不要接管SpringMVC@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(&quot;/atguigu&quot;).setViewName(&quot;success&quot;); &#125; //所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(&quot;/&quot;).setViewName(&quot;login&quot;); registry.addViewController(&quot;/index.html&quot;).setViewName(&quot;login&quot;); &#125; &#125;; return adapter; &#125;&#125; 2）、国际化1）、编写国际化配置文件； 2）、使用ResourceBundleMessageSource管理国际化资源文件 3）、在页面使用fmt:message取出国际化内容 步骤： 1）、编写国际化配置文件，抽取页面需要显示的国际化消息 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-3BINqTLD-1586693502373)(src/main/resources/notes/images/搜狗截图20180211130721.png)] 2）、SpringBoot自动配置好了管理国际化资源文件的组件； 1234567891011121314151617181920212223242526@ConfigurationProperties(prefix = &quot;spring.messages&quot;)public class MessageSourceAutoConfiguration &#123; /** * Comma-separated list of basenames (essentially a fully-qualified classpath * location), each following the ResourceBundle convention with relaxed support for * slash based locations. If it doesn&#x27;t contain a package qualifier (such as * &quot;org.mypackage&quot;), it will be resolved from the classpath root. */ private String basename = &quot;messages&quot;; //我们的配置文件可以直接放在类路径下叫messages.properties； @Bean public MessageSource messageSource() &#123; ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); if (StringUtils.hasText(this.basename)) &#123; //设置国际化资源文件的基础名（去掉语言国家代码的） messageSource.setBasenames(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(this.basename))); &#125; if (this.encoding != null) &#123; messageSource.setDefaultEncoding(this.encoding.name()); &#125; messageSource.setFallbackToSystemLocale(this.fallbackToSystemLocale); messageSource.setCacheSeconds(this.cacheSeconds); messageSource.setAlwaysUseMessageFormat(this.alwaysUseMessageFormat); return messageSource; &#125; 3）、去页面获取国际化的值； [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-0pjrmxWE-1586693502374)(src/main/resources/notes/images/搜狗截图20180211134506.png)] 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; &lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;&gt; &lt;meta name=&quot;description&quot; content=&quot;&quot;&gt; &lt;meta name=&quot;author&quot; content=&quot;&quot;&gt; &lt;title&gt;Signin Template for Bootstrap&lt;/title&gt; &lt;!-- Bootstrap core CSS --&gt; &lt;link href=&quot;asserts/css/bootstrap.min.css&quot; th:href=&quot;@&#123;/webjars/bootstrap/4.0.0/css/bootstrap.css&#125;&quot; rel=&quot;stylesheet&quot;&gt; &lt;!-- Custom styles for this template --&gt; &lt;link href=&quot;asserts/css/signin.css&quot; th:href=&quot;@&#123;/asserts/css/signin.css&#125;&quot; rel=&quot;stylesheet&quot;&gt; &lt;/head&gt; &lt;body class=&quot;text-center&quot;&gt; &lt;form class=&quot;form-signin&quot; action=&quot;dashboard.html&quot;&gt; &lt;img class=&quot;mb-4&quot; th:src=&quot;@&#123;/asserts/img/bootstrap-solid.svg&#125;&quot; src=&quot;asserts/img/bootstrap-solid.svg&quot; alt=&quot;&quot; width=&quot;72&quot; height=&quot;72&quot;&gt; &lt;h1 class=&quot;h3 mb-3 font-weight-normal&quot; th:text=&quot;#&#123;login.tip&#125;&quot;&gt;Please sign in&lt;/h1&gt; &lt;label class=&quot;sr-only&quot; th:text=&quot;#&#123;login.username&#125;&quot;&gt;Username&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;Username&quot; th:placeholder=&quot;#&#123;login.username&#125;&quot; required=&quot;&quot; autofocus=&quot;&quot;&gt; &lt;label class=&quot;sr-only&quot; th:text=&quot;#&#123;login.password&#125;&quot;&gt;Password&lt;/label&gt; &lt;input type=&quot;password&quot; class=&quot;form-control&quot; placeholder=&quot;Password&quot; th:placeholder=&quot;#&#123;login.password&#125;&quot; required=&quot;&quot;&gt; &lt;div class=&quot;checkbox mb-3&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot; value=&quot;remember-me&quot;/&gt; [[#&#123;login.remember&#125;]] &lt;/label&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-lg btn-primary btn-block&quot; type=&quot;submit&quot; th:text=&quot;#&#123;login.btn&#125;&quot;&gt;Sign in&lt;/button&gt; &lt;p class=&quot;mt-5 mb-3 text-muted&quot;&gt;© 2017-2018&lt;/p&gt; &lt;a class=&quot;btn btn-sm&quot;&gt;中文&lt;/a&gt; &lt;a class=&quot;btn btn-sm&quot;&gt;English&lt;/a&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 效果：根据浏览器语言设置的信息切换了国际化； 原理： 国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）； 12345678910111213@Bean @ConditionalOnMissingBean @ConditionalOnProperty(prefix = &quot;spring.mvc&quot;, name = &quot;locale&quot;) public LocaleResolver localeResolver() &#123; if (this.mvcProperties .getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) &#123; return new FixedLocaleResolver(this.mvcProperties.getLocale()); &#125; AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver(); localeResolver.setDefaultLocale(this.mvcProperties.getLocale()); return localeResolver; &#125;默认的就是根据请求头带来的区域信息获取Locale进行国际化 4）、点击链接切换国际化 1234567891011121314151617181920212223/** * 可以在连接上携带区域信息 */public class MyLocaleResolver implements LocaleResolver &#123; @Override public Locale resolveLocale(HttpServletRequest request) &#123; String l = request.getParameter(&quot;l&quot;); Locale locale = Locale.getDefault(); if(!StringUtils.isEmpty(l))&#123; String[] split = l.split(&quot;_&quot;); locale = new Locale(split[0],split[1]); &#125; return locale; &#125; @Override public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123; &#125;&#125; @Bean public LocaleResolver localeResolver()&#123; return new MyLocaleResolver(); &#125;&#125; 3）、登陆开发期间模板引擎页面修改以后，要实时生效 1）、禁用模板引擎的缓存 12# 禁用缓存spring.thymeleaf.cache=false 2）、页面修改完成以后ctrl+f9：重新编译； 登陆错误消息的显示 1&lt;p style=&quot;color: red&quot; th:text=&quot;$&#123;msg&#125;&quot; th:if=&quot;$&#123;not #strings.isEmpty(msg)&#125;&quot;&gt;&lt;/p&gt; 4）、拦截器进行登陆检查拦截器 12345678910111213141516171819202122232425/** * 登陆检查， */public class LoginHandlerInterceptor implements HandlerInterceptor &#123; //目标方法执行之前 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; Object user = request.getSession().getAttribute(&quot;loginUser&quot;); if(user == null)&#123; //未登陆，返回登陆页面 request.setAttribute(&quot;msg&quot;,&quot;没有权限请先登陆&quot;); request.getRequestDispatcher(&quot;/index.html&quot;).forward(request,response); return false; &#125;else&#123; //已登陆，放行请求 return true; &#125; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 注册拦截器 12345678910111213141516171819202122//所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(&quot;/&quot;).setViewName(&quot;login&quot;); registry.addViewController(&quot;/index.html&quot;).setViewName(&quot;login&quot;); registry.addViewController(&quot;/main.html&quot;).setViewName(&quot;dashboard&quot;); &#125; //注册拦截器 @Override public void addInterceptors(InterceptorRegistry registry) &#123; //super.addInterceptors(registry); //静态资源； *.css , *.js //SpringBoot已经做好了静态资源映射 registry.addInterceptor(new LoginHandlerInterceptor()).addPathPatterns(&quot;/**&quot;) .excludePathPatterns(&quot;/index.html&quot;,&quot;/&quot;,&quot;/user/login&quot;); &#125; &#125;; return adapter; &#125; 5）、CRUD-员工列表实验要求： 1）、RestfulCRUD：CRUD满足Rest风格； URI： /资源名称/资源标识 HTTP请求方式区分对资源CRUD操作 普通CRUD（uri来区分操作） RestfulCRUD 查询 getEmp emp—GET 添加 addEmp?xxx emp—POST 修改 updateEmp?id=xxx&amp;xxx=xx emp/{id}—PUT 删除 deleteEmp?id=1 emp/{id}—DELETE 2）、实验的请求架构; 实验功能 请求URI 请求方式 查询所有员工 emps GET 查询某个员工(来到修改页面) emp/1 GET 来到添加页面 emp GET 添加员工 emp POST 来到修改页面（查出员工进行信息回显） emp/1 GET 修改员工 emp PUT 删除员工 emp/1 DELETE 3）、员工列表： thymeleaf公共页面元素抽取1234567891011121、抽取公共片段&lt;div th:fragment=&quot;copy&quot;&gt;© 2011 The Good Thymes Virtual Grocery&lt;/div&gt;2、引入公共片段&lt;div th:insert=&quot;~&#123;footer :: copy&#125;&quot;&gt;&lt;/div&gt;~&#123;templatename::selector&#125;：模板名::选择器~&#123;templatename::fragmentname&#125;:模板名::片段名3、默认效果：insert的公共片段在div标签中如果使用th:insert等属性进行引入，可以不用写~&#123;&#125;：行内写法可以加上：[[~&#123;&#125;]];[(~&#123;&#125;)]； 三种引入公共片段的th属性： th:insert：将公共片段整个插入到声明引入的元素中 th:replace：将声明引入的元素替换为公共片段 th:include：将被引入的片段的内容包含进这个标签中 12345678910111213141516171819&lt;footer th:fragment=&quot;copy&quot;&gt;© 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;引入方式&lt;div th:insert=&quot;footer :: copy&quot;&gt;&lt;/div&gt;&lt;div th:replace=&quot;footer :: copy&quot;&gt;&lt;/div&gt;&lt;div th:include=&quot;footer :: copy&quot;&gt;&lt;/div&gt;效果&lt;div&gt; &lt;footer&gt; © 2011 The Good Thymes Virtual Grocery &lt;/footer&gt;&lt;/div&gt;&lt;footer&gt;© 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;&lt;div&gt;© 2011 The Good Thymes Virtual Grocery&lt;/div&gt; 引入片段的时候传入参数： 12345678910111213141516&lt;nav class=&quot;col-md-2 d-none d-md-block bg-light sidebar&quot; id=&quot;sidebar&quot;&gt; &lt;div class=&quot;sidebar-sticky&quot;&gt; &lt;ul class=&quot;nav flex-column&quot;&gt; &lt;li class=&quot;nav-item&quot;&gt; &lt;a class=&quot;nav-link active&quot; th:class=&quot;$&#123;activeUri==&#x27;main.html&#x27;?&#x27;nav-link active&#x27;:&#x27;nav-link&#x27;&#125;&quot; href=&quot;#&quot; th:href=&quot;@&#123;/main.html&#125;&quot;&gt; &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24&quot; height=&quot;24&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;none&quot; stroke=&quot;currentColor&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot; class=&quot;feather feather-home&quot;&gt; &lt;path d=&quot;M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z&quot;&gt;&lt;/path&gt; &lt;polyline points=&quot;9 22 9 12 15 12 15 22&quot;&gt;&lt;/polyline&gt; &lt;/svg&gt; Dashboard &lt;span class=&quot;sr-only&quot;&gt;(current)&lt;/span&gt; &lt;/a&gt; &lt;/li&gt;&lt;!--引入侧边栏;传入参数--&gt;&lt;div th:replace=&quot;commons/bar::#sidebar(activeUri=&#x27;emps&#x27;)&quot;&gt;&lt;/div&gt; 6）、CRUD-员工添加添加页面 123456789101112131415161718192021222324252627282930313233343536&lt;form&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input type=&quot;email&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan@atguigu.com&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class=&quot;form-check form-check-inline&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;1&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;form-check form-check-inline&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;0&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;department&lt;/label&gt; &lt;select class=&quot;form-control&quot;&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot;&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;添加&lt;/button&gt;&lt;/form&gt; 提交的数据格式不对：生日：日期； 2017-12-12；2017/12/12；2017.12.12； 日期的格式化；SpringMVC将页面提交的值需要转换为指定的类型; 2017-12-12—Date； 类型转换，格式化; 默认日期是按照/的方式； 7）、CRUD-员工修改修改添加二合一表单 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!--需要区分是员工修改还是添加；--&gt;&lt;form th:action=&quot;@&#123;/emp&#125;&quot; method=&quot;post&quot;&gt; &lt;!--发送put请求修改员工数据--&gt; &lt;!--1、SpringMVC中配置HiddenHttpMethodFilter;（SpringBoot自动配置好的）2、页面创建一个post表单3、创建一个input项，name=&quot;_method&quot;;值就是我们指定的请求方式--&gt; &lt;input type=&quot;hidden&quot; name=&quot;_method&quot; value=&quot;put&quot; th:if=&quot;$&#123;emp!=null&#125;&quot;/&gt; &lt;input type=&quot;hidden&quot; name=&quot;id&quot; th:if=&quot;$&#123;emp!=null&#125;&quot; th:value=&quot;$&#123;emp.id&#125;&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input name=&quot;lastName&quot; type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot; th:value=&quot;$&#123;emp!=null&#125;?$&#123;emp.lastName&#125;&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input name=&quot;email&quot; type=&quot;email&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan@atguigu.com&quot; th:value=&quot;$&#123;emp!=null&#125;?$&#123;emp.email&#125;&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class=&quot;form-check form-check-inline&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;1&quot; th:checked=&quot;$&#123;emp!=null&#125;?$&#123;emp.gender==1&#125;&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class=&quot;form-check form-check-inline&quot;&gt; &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gender&quot; value=&quot;0&quot; th:checked=&quot;$&#123;emp!=null&#125;?$&#123;emp.gender==0&#125;&quot;&gt; &lt;label class=&quot;form-check-label&quot;&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;department&lt;/label&gt; &lt;!--提交的是部门的id--&gt; &lt;select class=&quot;form-control&quot; name=&quot;department.id&quot;&gt; &lt;option th:selected=&quot;$&#123;emp!=null&#125;?$&#123;dept.id == emp.department.id&#125;&quot; th:value=&quot;$&#123;dept.id&#125;&quot; th:each=&quot;dept:$&#123;depts&#125;&quot; th:text=&quot;$&#123;dept.departmentName&#125;&quot;&gt;1&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input name=&quot;birth&quot; type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;zhangsan&quot; th:value=&quot;$&#123;emp!=null&#125;?$&#123;#dates.format(emp.birth, &#x27;yyyy-MM-dd HH:mm&#x27;)&#125;&quot;&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot; th:text=&quot;$&#123;emp!=null&#125;?&#x27;修改&#x27;:&#x27;添加&#x27;&quot;&gt;添加&lt;/button&gt;&lt;/form&gt; 8）、CRUD-员工删除12345678910111213141516171819&lt;tr th:each=&quot;emp:$&#123;emps&#125;&quot;&gt; &lt;td th:text=&quot;$&#123;emp.id&#125;&quot;&gt;&lt;/td&gt; &lt;td&gt;[[$&#123;emp.lastName&#125;]]&lt;/td&gt; &lt;td th:text=&quot;$&#123;emp.email&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;emp.gender&#125;==0?&#x27;女&#x27;:&#x27;男&#x27;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;emp.department.departmentName&#125;&quot;&gt;&lt;/td&gt; &lt;td th:text=&quot;$&#123;#dates.format(emp.birth, &#x27;yyyy-MM-dd HH:mm&#x27;)&#125;&quot;&gt;&lt;/td&gt; &lt;td&gt; &lt;a class=&quot;btn btn-sm btn-primary&quot; th:href=&quot;@&#123;/emp/&#125;+$&#123;emp.id&#125;&quot;&gt;编辑&lt;/a&gt; &lt;button th:attr=&quot;del_uri=@&#123;/emp/&#125;+$&#123;emp.id&#125;&quot; class=&quot;btn btn-sm btn-danger deleteBtn&quot;&gt;删除&lt;/button&gt; &lt;/td&gt;&lt;/tr&gt;&lt;script&gt; $(&quot;.deleteBtn&quot;).click(function()&#123; //删除当前员工的 $(&quot;#deleteEmpForm&quot;).attr(&quot;action&quot;,$(this).attr(&quot;del_uri&quot;)).submit(); return false; &#125;);&lt;/script&gt; 7、错误处理机制1）、SpringBoot默认的错误处理机制默认效果： 1）、浏览器，返回一个默认的错误页面 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-TGmI6y0o-1586693502375)(src/main/resources/notes/images/搜狗截图20180226173408.png)] 浏览器发送请求的请求头： [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-64pHWCar-1586693502375)(src/main/resources/notes/images/搜狗截图20180226180347.png)] 2）、如果是其他客户端，默认响应一个json数据 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-Ha3vUoHR-1586693502375)(src/main/resources/notes/images/搜狗截图20180226173527.png)] [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-UCm6ihJ9-1586693502376)(src/main/resources/notes/images/搜狗截图20180226180504.png)] 原理： 可以参照ErrorMvcAutoConfiguration；错误处理的自动配置； 1给容器中添加了以下组件 1、DefaultErrorAttributes： 1234567891011帮我们在页面共享信息；@Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;(); errorAttributes.put(&quot;timestamp&quot;, new Date()); addStatus(errorAttributes, requestAttributes); addErrorDetails(errorAttributes, requestAttributes, includeStackTrace); addPath(errorAttributes, requestAttributes); return errorAttributes; &#125; 2、BasicErrorController：处理默认/error请求 12345678910111213141516171819202122@Controller@RequestMapping(&quot;$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;&quot;)public class BasicErrorController extends AbstractErrorController &#123; @RequestMapping(produces = &quot;text/html&quot;)//产生html类型的数据；浏览器发送的请求来到这个方法处理 public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) &#123; HttpStatus status = getStatus(request); Map&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); //去哪个页面作为错误页面；包含页面地址和页面内容 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView == null ? new ModelAndView(&quot;error&quot;, model) : modelAndView); &#125; @RequestMapping @ResponseBody //产生json数据，其他客户端来到这个方法处理； public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) &#123; Map&lt;String, Object&gt; body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); return new ResponseEntity&lt;Map&lt;String, Object&gt;&gt;(body, status); &#125; 3、ErrorPageCustomizer： 12@Value(&quot;$&#123;error.path:/error&#125;&quot;) private String path = &quot;/error&quot;; 系统出现错误以后来到error请求进行处理；（web.xml注册的错误页面规则） 4、DefaultErrorViewResolver： 12345678910111213141516171819202122@Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) &#123; ModelAndView modelAndView = resolve(String.valueOf(status), model); if (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) &#123; modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); &#125; return modelAndView; &#125; private ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) &#123; //默认SpringBoot可以去找到一个页面？ error/404 String errorViewName = &quot;error/&quot; + viewName; //模板引擎可以解析这个页面地址就用模板引擎解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders .getProvider(errorViewName, this.applicationContext); if (provider != null) &#123; //模板引擎可用的情况下返回到errorViewName指定的视图地址 return new ModelAndView(errorViewName, model); &#125; //模板引擎不可用，就在静态资源文件夹下找errorViewName对应的页面 error/404.html return resolveResource(errorViewName, model); &#125; 步骤： 一但系统出现4xx或者5xx之类的错误；ErrorPageCustomizer就会生效（定制错误的响应规则）；就会来到/error请求；就会被BasicErrorController处理； 1）响应页面；去哪个页面是由DefaultErrorViewResolver解析得到的； 1234567891011protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status, Map&lt;String, Object&gt; model) &#123; //所有的ErrorViewResolver得到ModelAndView for (ErrorViewResolver resolver : this.errorViewResolvers) &#123; ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) &#123; return modelAndView; &#125; &#125; return null;&#125; 2）、如果定制错误响应：1）、如何定制错误的页面；1）、有模板引擎的情况下；error/状态码; 【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的 error文件夹下】，发生此状态码的错误就会来到 对应的页面； 我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）； 页面能获取的信息； timestamp：时间戳 status：状态码 error：错误提示 exception：异常对象 message：异常消息 errors：JSR303数据校验的错误都在这里 2）、没有模板引擎（模板引擎找不到这个错误页面），静态资源文件夹下找； 3）、以上都没有错误页面，就是默认来到SpringBoot默认的错误提示页面； 2）、如何定制错误的json数据；1）、自定义异常处理&amp;返回定制json数据； 123456789101112@ControllerAdvicepublic class MyExceptionHandler &#123; @ResponseBody @ExceptionHandler(UserNotExistException.class) public Map&lt;String,Object&gt; handleException(Exception e)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;code&quot;,&quot;user.notexist&quot;); map.put(&quot;message&quot;,e.getMessage()); return map; &#125;&#125;//没有自适应效果... 2）、转发到/error进行自适应响应效果处理 1234567891011121314@ExceptionHandler(UserNotExistException.class) public String handleException(Exception e, HttpServletRequest request)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //传入我们自己的错误状态码 4xx 5xx，否则就不会进入定制错误页面的解析流程 /** * Integer statusCode = (Integer) request .getAttribute(&quot;javax.servlet.error.status_code&quot;); */ request.setAttribute(&quot;javax.servlet.error.status_code&quot;,500); map.put(&quot;code&quot;,&quot;user.notexist&quot;); map.put(&quot;message&quot;,e.getMessage()); //转发到/error return &quot;forward:/error&quot;; &#125; 3）、将我们的定制数据携带出去；出现错误以后，会来到/error请求，会被BasicErrorController处理，响应出去可以获取的数据是由getErrorAttributes得到的（是AbstractErrorController（ErrorController）规定的方法）； 1、完全来编写一个ErrorController的实现类【或者是编写AbstractErrorController的子类】，放在容器中； 2、页面上能用的数据，或者是json返回能用的数据都是通过errorAttributes.getErrorAttributes得到； 容器中DefaultErrorAttributes.getErrorAttributes()；默认进行数据处理的； 自定义ErrorAttributes 12345678910//给容器中加入我们自己定义的ErrorAttributes@Componentpublic class MyErrorAttributes extends DefaultErrorAttributes &#123; @Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; map = super.getErrorAttributes(requestAttributes, includeStackTrace); map.put(&quot;company&quot;,&quot;atguigu&quot;); return map; &#125;&#125; 最终的效果：响应是自适应的，可以通过定制ErrorAttributes改变需要返回的内容， [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-DLQTimNB-1586693502376)(images/搜狗截图20180228135513.png)] 8、配置嵌入式Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器； [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-uN56zF4h-1586693502377)(src/main/resources/notes/images/搜狗截图20180301142915.png)] 问题？ 1）、如何定制和修改Servlet容器的相关配置；1、修改和server有关的配置（ServerProperties【也是EmbeddedServletContainerCustomizer】）； 1234567server.port=8081server.context-path=/crudserver.tomcat.uri-encoding=UTF-8//通用的Servlet容器设置server.xxx//Tomcat的设置server.tomcat.xxx 2、编写一个EmbeddedServletContainerCustomizer：嵌入式的Servlet容器的定制器；来修改Servlet容器的配置 12345678910@Bean //一定要将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer()&#123; return new EmbeddedServletContainerCustomizer() &#123; //定制嵌入式的Servlet容器相关的规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.setPort(8083); &#125; &#125;;&#125; 2）、注册Servlet三大组件【Servlet、Filter、Listener】由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动SpringBoot的web应用，没有web.xml文件。 注册三大组件用以下方式 ServletRegistrationBean 123456//注册三大组件@Beanpublic ServletRegistrationBean myServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),&quot;/myServlet&quot;); return registrationBean;&#125; FilterRegistrationBean 1234567@Beanpublic FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new MyFilter()); registrationBean.setUrlPatterns(Arrays.asList(&quot;/hello&quot;,&quot;/myServlet&quot;)); return registrationBean;&#125; ServletListenerRegistrationBean 12345@Beanpublic ServletListenerRegistrationBean myListener()&#123; ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener()); return registrationBean;&#125; SpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器；DIspatcherServlet； DispatcherServletAutoConfiguration中： 12345678910111213141516@Bean(name = DEFAULT_DISPATCHER_SERVLET_REGISTRATION_BEAN_NAME)@ConditionalOnBean(value = DispatcherServlet.class, name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)public ServletRegistrationBean dispatcherServletRegistration( DispatcherServlet dispatcherServlet) &#123; ServletRegistrationBean registration = new ServletRegistrationBean( dispatcherServlet, this.serverProperties.getServletMapping()); //默认拦截： / 所有请求；包静态资源，但是不拦截jsp请求； /*会拦截jsp //可以通过server.servletPath来修改SpringMVC前端控制器默认拦截的请求路径 registration.setName(DEFAULT_DISPATCHER_SERVLET_BEAN_NAME); registration.setLoadOnStartup( this.webMvcProperties.getServlet().getLoadOnStartup()); if (this.multipartConfig != null) &#123; registration.setMultipartConfig(this.multipartConfig); &#125; return registration;&#125; 2）、SpringBoot能不能支持其他的Servlet容器； 3）、替换为其他嵌入式Servlet容器[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-ZRkMQqoJ-1586693502377)(src/main/resources/notes/images/搜狗截图20180302114401.png)] 默认支持： Tomcat（默认使用） 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; 引入web模块默认就是使用嵌入式的Tomcat作为Servlet容器；&lt;/dependency&gt; Jetty 12345678910111213141516&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; Undertow 12345678910111213141516&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 4）、嵌入式Servlet容器自动配置原理；EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)//导入BeanPostProcessorsRegistrar：Spring注解版；给容器中导入一些组件//导入了EmbeddedServletContainerCustomizerBeanPostProcessor：//后置处理器：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作public class EmbeddedServletContainerAutoConfiguration &#123; @Configuration @ConditionalOnClass(&#123; Servlet.class, Tomcat.class &#125;)//判断当前是否引入了Tomcat依赖； @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)//判断当前容器没有用户自己定义EmbeddedServletContainerFactory：嵌入式的Servlet容器工厂；作用：创建嵌入式的Servlet容器 public static class EmbeddedTomcat &#123; @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123; return new TomcatEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class, WebAppContext.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty &#123; @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() &#123; return new JettyEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow &#123; @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() &#123; return new UndertowEmbeddedServletContainerFactory(); &#125; &#125; 1）、EmbeddedServletContainerFactory（嵌入式Servlet容器工厂） 1public interface EmbeddedServletContainerFactory &#123; [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-XAKsyaIK-1586693502377)(images/搜狗截图20180302144835.png)] 2）、EmbeddedServletContainer：（嵌入式的Servlet容器） [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-3DmPBHry-1586693502378)(images/搜狗截图20180302144910.png)] 3）、以TomcatEmbeddedServletContainerFactory为例 12345678910111213141516171819202122@Overridepublic EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; //创建一个Tomcat Tomcat tomcat = new Tomcat(); //配置Tomcat的基本环节 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir(&quot;tomcat&quot;)); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); //将配置好的Tomcat传入进去，返回一个EmbeddedServletContainer；并且启动Tomcat服务器 return getTomcatEmbeddedServletContainer(tomcat);&#125; 4）、我们对嵌入式容器的配置修改是怎么生效？ 1ServerProperties、EmbeddedServletContainerCustomizer EmbeddedServletContainerCustomizer：定制器帮我们修改了Servlet容器的配置？ 怎么修改的原理？ 5）、容器中导入了EmbeddedServletContainerCustomizerBeanPostProcessor 12345678910111213141516171819202122232425262728293031323334//初始化之前@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; //如果当前初始化的是一个ConfigurableEmbeddedServletContainer类型的组件 if (bean instanceof ConfigurableEmbeddedServletContainer) &#123; // postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean); &#125; return bean;&#125;private void postProcessBeforeInitialization( ConfigurableEmbeddedServletContainer bean) &#123; //获取所有的定制器，调用每一个定制器的customize方法来给Servlet容器进行属性赋值； for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) &#123; customizer.customize(bean); &#125;&#125;private Collection&lt;EmbeddedServletContainerCustomizer&gt; getCustomizers() &#123; if (this.customizers == null) &#123; // Look up does not include the parent context this.customizers = new ArrayList&lt;EmbeddedServletContainerCustomizer&gt;( this.beanFactory //从容器中获取所有这葛类型的组件：EmbeddedServletContainerCustomizer //定制Servlet容器，给容器中可以添加一个EmbeddedServletContainerCustomizer类型的组件 .getBeansOfType(EmbeddedServletContainerCustomizer.class, false, false) .values()); Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); &#125; return this.customizers;&#125;ServerProperties也是定制器 步骤： 1）、SpringBoot根据导入的依赖情况，给容器中添加相应的EmbeddedServletContainerFactory【TomcatEmbeddedServletContainerFactory】 2）、容器中某个组件要创建对象就会惊动后置处理器；EmbeddedServletContainerCustomizerBeanPostProcessor； 只要是嵌入式的Servlet容器工厂，后置处理器就工作； 3）、后置处理器，从容器中获取所有的EmbeddedServletContainerCustomizer，调用定制器的定制方法 ###5）、嵌入式Servlet容器启动原理； 什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat； 获取嵌入式的Servlet容器工厂： 1）、SpringBoot应用启动运行run方法 2）、refreshContext(context);SpringBoot刷新IOC容器【创建IOC容器对象，并初始化容器，创建容器中的每一个组件】；如果是web应用创建AnnotationConfigEmbeddedWebApplicationContext，否则：AnnotationConfigApplicationContext 3）、refresh(context);刷新刚才创建好的ioc容器； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &#x27;active&#x27; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&#x27;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 4）、 onRefresh(); web的ioc容器重写了onRefresh方法 5）、webioc容器会创建嵌入式的Servlet容器；createEmbeddedServletContainer(); 6）、获取嵌入式的Servlet容器工厂： EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); 从ioc容器中获取EmbeddedServletContainerFactory 组件；TomcatEmbeddedServletContainerFactory创建对象，后置处理器一看是这个对象，就获取所有的定制器来先定制Servlet容器的相关配置； 7）、使用容器工厂获取嵌入式的Servlet容器：this.embeddedServletContainer = containerFactory .getEmbeddedServletContainer(getSelfInitializer()); 8）、嵌入式的Servlet容器创建对象并启动Servlet容器； 先启动嵌入式的Servlet容器，再将ioc容器中剩下没有创建出的对象获取出来； IOC容器启动创建嵌入式的Servlet容器 9、使用外置的Servlet容器嵌入式Servlet容器：应用打成可执行的jar 优点：简单、便携； 缺点：默认不支持JSP、优化定制比较复杂（使用定制器【ServerProperties、自定义EmbeddedServletContainerCustomizer】，自己编写嵌入式Servlet容器的创建工厂【EmbeddedServletContainerFactory】）； 外置的Servlet容器：外面安装Tomcat—应用war包的方式打包； 步骤1）、必须创建一个war项目；（利用idea创建好目录结构） 2）、将嵌入式的Tomcat指定为provided； 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3）、必须编写一个SpringBootServletInitializer的子类，并调用configure方法 1234567public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; //传入SpringBoot应用的主程序 return application.sources(SpringBoot04WebJspApplication.class); &#125;&#125; 4）、启动服务器就可以使用； 原理jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器； war包：启动服务器，服务器启动SpringBoot应用【SpringBootServletInitializer】，启动ioc容器； servlet3.0（Spring注解版）： 8.2.4 Shared libraries / runtimes pluggability： 规则： 1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面ServletContainerInitializer实例： 2）、ServletContainerInitializer的实现放在jar包的META-INF/services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名 3）、还可以使用@HandlesTypes，在应用启动的时候加载我们感兴趣的类； 流程： 1）、启动Tomcat 2）、org\\springframework\\spring-web\\4.3.14.RELEASE\\spring-web-4.3.14.RELEASE.jar!\\META-INF\\services\\javax.servlet.ServletContainerInitializer： Spring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer 3）、SpringServletContainerInitializer将@HandlesTypes(WebApplicationInitializer.class)标注的所有这个类型的类都传入到onStartup方法的Set&lt;Class&lt;?&gt;&gt;；为这些WebApplicationInitializer类型的类创建实例； 4）、每一个WebApplicationInitializer都调用自己的onStartup； 5）、相当于我们的SpringBootServletInitializer的类会被创建对象，并执行onStartup方法 6）、SpringBootServletInitializer实例执行onStartup的时候会createRootApplicationContext；创建容器 123456789101112131415161718192021222324252627282930313233343536protected WebApplicationContext createRootApplicationContext( ServletContext servletContext) &#123; //1、创建SpringApplicationBuilder SpringApplicationBuilder builder = createSpringApplicationBuilder(); StandardServletEnvironment environment = new StandardServletEnvironment(); environment.initPropertySources(servletContext, null); builder.environment(environment); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; this.logger.info(&quot;Root context already created (using as parent).&quot;); servletContext.setAttribute( WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers( new ServletContextApplicationContextInitializer(servletContext)); builder.contextClass(AnnotationConfigEmbeddedWebApplicationContext.class); //调用configure方法，子类重写了这个方法，将SpringBoot的主程序类传入了进来 builder = configure(builder); //使用builder创建一个Spring应用 SpringApplication application = builder.build(); if (application.getSources().isEmpty() &amp;&amp; AnnotationUtils .findAnnotation(getClass(), Configuration.class) != null) &#123; application.getSources().add(getClass()); &#125; Assert.state(!application.getSources().isEmpty(), &quot;No SpringApplication sources have been defined. Either override the &quot; + &quot;configure method or add an @Configuration annotation&quot;); // Ensure error pages are registered if (this.registerErrorPageFilter) &#123; application.getSources().add(ErrorPageFilterConfiguration.class); &#125; //启动Spring应用 return run(application);&#125; 7）、Spring的应用就启动并且创建IOC容器 12345678910111213141516171819202122232425262728293031323334public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新IOC容器 refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 启动Servlet容器，再启动SpringBoot应用 五、Docker1、简介Docker是一个开源的应用容器引擎；是一个轻量级容器技术； Docker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像； 运行中的这个镜像称为容器，容器启动是非常快速的。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-m2tdNlNQ-1586693502379)(src/main/resources/notes/images/搜狗截图20180303145450.png)] [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-56PIirmU-1586693502380)(src/main/resources/notes/images/搜狗截图20180303145531.png)] 2、核心概念docker主机(Host)：安装了Docker程序的机器（Docker直接安装在操作系统之上）； docker客户端(Client)：连接docker主机进行操作； docker仓库(Registry)：用来保存各种打包好的软件镜像； docker镜像(Images)：软件打包好的镜像；放在docker仓库中； docker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-2bq1fVFI-1586693502380)(src/main/resources/notes/images/搜狗截图20180303165113.png)] 使用Docker的步骤： 1）、安装Docker 2）、去Docker仓库找到这个软件对应的镜像； 3）、使用Docker运行这个镜像，这个镜像就会生成一个Docker容器； 4）、对容器的启动停止就是对软件的启动停止； 3、安装Docker1）、安装linux虚拟机1）、VMWare、VirtualBox（安装）； 2）、导入虚拟机文件centos7-atguigu.ova； 3）、双击启动linux虚拟机;使用 root/ 123456登陆 4）、使用客户端连接linux服务器进行命令操作； 5）、设置虚拟机网络； 桥接网络=选好网卡==接入网线； 6）、设置好网络以后使用命令重启虚拟机的网络 1service network restart 7）、查看linux的ip地址 1ip addr 8）、使用客户端连接linux； 2）、在linux虚拟机上安装docker步骤： 12345678910111213141、检查内核版本，必须是3.10及以上uname -r2、安装dockeryum install docker3、输入y确认安装4、启动docker[root@localhost ~]# systemctl start docker[root@localhost ~]# docker -vDocker version 1.12.6, build 3e8e77d/1.12.65、开机启动docker[root@localhost ~]# systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.6、停止dockersystemctl stop docker 4、Docker常用命令&amp;操作1）、镜像操作 操作 命令 说明 检索 docker search 关键字 eg：docker search redis 我们经常去docker hub上检索镜像的详细信息，如镜像的TAG。 拉取 docker pull 镜像名:tag :tag是可选的，tag表示标签，多为软件的版本，默认是latest 列表 docker images 查看所有本地镜像 删除 docker rmi image-id 删除指定的本地镜像 https://hub.docker.com/ 2）、容器操作软件镜像（QQ安装程序）——运行镜像——产生一个容器（正在运行的软件，运行的QQ）； 步骤： 123456789101112131415161718192021222324252627281、搜索镜像[root@localhost ~]# docker search tomcat2、拉取镜像[root@localhost ~]# docker pull tomcat3、根据镜像启动容器docker run --name mytomcat -d tomcat:latest4、docker ps 查看运行中的容器5、 停止运行中的容器docker stop 容器的id6、查看所有的容器docker ps -a7、启动容器docker start 容器id8、删除一个容器 docker rm 容器id9、启动一个做了端口映射的tomcat[root@localhost ~]# docker run -d -p 8888:8080 tomcat-d：后台运行-p: 将主机的端口映射到容器的一个端口 主机端口:容器内部的端口10、为了演示简单关闭了linux的防火墙service firewalld status ；查看防火墙状态service firewalld stop：关闭防火墙11、查看容器的日志docker logs container-name/container-id更多命令参看https://docs.docker.com/engine/reference/commandline/docker/可以参考每一个镜像的文档 3）、安装MySQL示例1docker pull mysql 错误的启动 1234567891011121314[root@localhost ~]# docker run --name mysql01 -d mysql42f09819908bb72dd99ae19e792e0a5d03c48638421fa64cce5f8ba0f40f5846mysql退出了[root@localhost ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES42f09819908b mysql &quot;docker-entrypoint.sh&quot; 34 seconds ago Exited (1) 33 seconds ago mysql01538bde63e500 tomcat &quot;catalina.sh run&quot; About an hour ago Exited (143) About an hour ago compassionate_goldstinec4f1ac60b3fc tomcat &quot;catalina.sh run&quot; About an hour ago Exited (143) About an hour ago lonely_fermi81ec743a5271 tomcat &quot;catalina.sh run&quot; About an hour ago Exited (143) About an hour ago sick_ramanujan//错误日志[root@localhost ~]# docker logs 42f09819908berror: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD；这个三个参数必须指定一个 正确的启动 12345[root@localhost ~]# docker run --name mysql01 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlb874c56bec49fb43024b3805ab51e9097da779f2f572c22c695305dedd684c5f[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb874c56bec49 mysql &quot;docker-entrypoint.sh&quot; 4 seconds ago Up 3 seconds 3306/tcp mysql01 做了端口映射 12345[root@localhost ~]# docker run -p 3306:3306 --name mysql02 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlad10e4bc5c6a0f61cbad43898de71d366117d120e39db651844c0e73863b9434[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESad10e4bc5c6a mysql &quot;docker-entrypoint.sh&quot; 4 seconds ago Up 2 seconds 0.0.0.0:3306-&gt;3306/tcp mysql02 几个其他的高级操作 12345docker run --name mysql03 -v /conf/mysql:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag把主机的/conf/mysql文件夹挂载到 mysqldocker容器的/etc/mysql/conf.d文件夹里面改mysql的配置文件就只需要把mysql配置文件放在自定义的文件夹下（/conf/mysql）docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci指定mysql的一些配置参数 六、SpringBoot与数据访问1、JDBC123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; 123456spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.15.22:3306/jdbc driver-class-name: com.mysql.jdbc.Driver 效果： 默认是用org.apache.tomcat.jdbc.pool.DataSource作为数据源； 数据源的相关配置都在DataSourceProperties里面； 自动配置原理： org.springframework.boot.autoconfigure.jdbc： 1、参考DataSourceConfiguration，根据配置创建数据源，默认使用Tomcat连接池；可以使用spring.datasource.type指定自定义的数据源类型； 2、SpringBoot默认可以支持； 1org.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource、 3、自定义数据源类型 123456789101112/** * Generic DataSource configuration. */@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(name = &quot;spring.datasource.type&quot;)static class Generic &#123; @Bean public DataSource dataSource(DataSourceProperties properties) &#123; //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); &#125;&#125; 4、DataSourceInitializer：ApplicationListener； 作用： 1）、runSchemaScripts();运行建表语句； 2）、runDataScripts();运行插入数据的sql语句； 默认只需要将文件命名为： 123456schema-*.sql、data-*.sql默认规则：schema.sql，schema-all.sql；可以使用 schema: - classpath:department.sql 指定位置 5、操作数据库：自动配置了JdbcTemplate操作数据库 2、整合Druid数据源123456789101112131415161718192021222324252627282930313233导入druid数据源@Configurationpublic class DruidConfig &#123; @ConfigurationProperties(prefix = &quot;spring.datasource&quot;) @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), &quot;/druid/*&quot;); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(&quot;loginUsername&quot;,&quot;admin&quot;); initParams.put(&quot;loginPassword&quot;,&quot;123456&quot;); initParams.put(&quot;allow&quot;,&quot;&quot;);//默认就是允许所有访问 initParams.put(&quot;deny&quot;,&quot;192.168.15.21&quot;); bean.setInitParameters(initParams); return bean; &#125; //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(&quot;exclusions&quot;,&quot;*.js,*.css,/druid/*&quot;); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList(&quot;/*&quot;)); return bean; &#125;&#125; 3、整合MyBatis12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-TrwYP1He-1586693502381)(src/main/resources/notes/images/搜狗截图20180305194443.png)] 步骤： 1）、配置数据源相关属性（见上一节Druid） 2）、给数据库建表 3）、创建JavaBean 4）、注解版12345678910111213//指定这是一个操作数据库的mapper@Mapperpublic interface DepartmentMapper &#123; @Select(&quot;select * from department where id=#&#123;id&#125;&quot;) public Department getDeptById(Integer id); @Delete(&quot;delete from department where id=#&#123;id&#125;&quot;) public int deleteDeptById(Integer id); @Options(useGeneratedKeys = true,keyProperty = &quot;id&quot;) @Insert(&quot;insert into department(departmentName) values(#&#123;departmentName&#125;)&quot;) public int insertDept(Department department); @Update(&quot;update department set departmentName=#&#123;departmentName&#125; where id=#&#123;id&#125;&quot;) public int updateDept(Department department);&#125; 问题： 自定义MyBatis的配置规则；给容器中添加一个ConfigurationCustomizer； 123456789101112@org.springframework.context.annotation.Configurationpublic class MyBatisConfig &#123; @Bean public ConfigurationCustomizer configurationCustomizer()&#123; return new ConfigurationCustomizer()&#123; @Override public void customize(Configuration configuration) &#123; configuration.setMapUnderscoreToCamelCase(true); &#125; &#125;; &#125;&#125; 12345678使用MapperScan批量扫描所有的Mapper接口；@MapperScan(value = &quot;com.atguigu.springboot.mapper&quot;)@SpringBootApplicationpublic class SpringBoot06DataMybatisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBoot06DataMybatisApplication.class, args); &#125;&#125; 5）、配置文件版123mybatis: config-location: classpath:mybatis/mybatis-config.xml 指定全局配置文件的位置 mapper-locations: classpath:mybatis/mapper/*.xml 指定sql映射文件的位置 更多使用参照 http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/ 4、整合SpringData JPA1）、SpringData简介[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-lAI6Cgj7-1586693502381)(src/main/resources/notes/images/搜狗截图20180306105412.png)] 2）、整合SpringData JPAJPA:ORM（Object Relational Mapping）； 1）、编写一个实体类（bean）和数据表进行映射，并且配置好映射关系； 1234567891011//使用JPA注解配置映射关系@Entity //告诉JPA这是一个实体类（和数据表映射的类）@Table(name = &quot;tbl_user&quot;) //@Table来指定和哪个数据表对应;如果省略默认表名就是user；public class User &#123; @Id //这是一个主键 @GeneratedValue(strategy = GenerationType.IDENTITY)//自增主键 private Integer id; @Column(name = &quot;last_name&quot;,length = 50) //这是和数据表对应的一个列 private String lastName; @Column //省略默认列名就是属性名 private String email; 2）、编写一个Dao接口来操作实体类对应的数据表（Repository） 123//继承JpaRepository来完成对数据库的操作public interface UserRepository extends JpaRepository&lt;User,Integer&gt; &#123;&#125; 3）、基本的配置JpaProperties 1234567spring: jpa: hibernate:# 更新或者创建数据表结构 ddl-auto: update# 控制台显示SQL show-sql: true 七、启动配置原理几个重要的事件回调机制 配置在META-INF/spring.factories ApplicationContextInitializer SpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner CommandLineRunner 启动流程： 1、创建SpringApplication对象12345678910111213141516initialize(sources);private void initialize(Object[] sources) &#123; //保存主配置类 if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判断当前是否一个web应用 this.webEnvironment = deduceWebEnvironment(); //从类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //从类路径下找到ETA-INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 2、运行run方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //获取SpringApplicationRunListeners；从类路径下META-INF/spring.factories SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的获取SpringApplicationRunListener.starting()方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成 Banner printedBanner = printBanner(environment); //创建ApplicationContext；决定创建web的ioc还是普通的ioc context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //准备上下文环境;将environment保存到ioc中；而且applyInitializers()； //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 //回调所有的SpringApplicationRunListener的contextPrepared()； // prepareContext(context, environment, listeners, applicationArguments, printedBanner); //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； //s刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat）；Spring注解版 //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置） refreshContext(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调 //ApplicationRunner先回调，CommandLineRunner再回调 afterRefresh(context, applicationArguments); //所有的SpringApplicationRunListener回调finished方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; //整个SpringBoot应用启动完成以后返回启动的ioc容器； return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 3、事件监听机制配置在META-INF/spring.factories ApplicationContextInitializer 123456public class HelloApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println(&quot;ApplicationContextInitializer...initialize...&quot;+applicationContext); &#125;&#125; SpringApplicationRunListener 1234567891011121314151617181920212223242526public class HelloSpringApplicationRunListener implements SpringApplicationRunListener &#123; //必须有的构造器 public HelloSpringApplicationRunListener(SpringApplication application, String[] args)&#123; &#125; @Override public void starting() &#123; System.out.println(&quot;SpringApplicationRunListener...starting...&quot;); &#125; @Override public void environmentPrepared(ConfigurableEnvironment environment) &#123; Object o = environment.getSystemProperties().get(&quot;os.name&quot;); System.out.println(&quot;SpringApplicationRunListener...environmentPrepared..&quot;+o); &#125; @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; System.out.println(&quot;SpringApplicationRunListener...contextPrepared...&quot;); &#125; @Override public void contextLoaded(ConfigurableApplicationContext context) &#123; System.out.println(&quot;SpringApplicationRunListener...contextLoaded...&quot;); &#125; @Override public void finished(ConfigurableApplicationContext context, Throwable exception) &#123; System.out.println(&quot;SpringApplicationRunListener...finished...&quot;); &#125;&#125; 配置（META-INF/spring.factories） 1234org.springframework.context.ApplicationContextInitializer=\\com.atguigu.springboot.listener.HelloApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=\\com.atguigu.springboot.listener.HelloSpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner 1234567@Componentpublic class HelloApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println(&quot;ApplicationRunner...run....&quot;); &#125;&#125; CommandLineRunner 1234567@Componentpublic class HelloCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println(&quot;CommandLineRunner...run...&quot;+ Arrays.asList(args)); &#125;&#125; 八、自定义starterstarter： 1、这个场景需要使用到的依赖是什么？ 2、如何编写自动配置 1234567891011@Configuration //指定这个类是一个配置类@ConditionalOnXXX //在指定条件成立的情况下自动配置类生效@AutoConfigureAfter //指定自动配置类的顺序@Bean //给容器中添加组件@ConfigurationPropertie结合相关xxxProperties类来绑定相关的配置@EnableConfigurationProperties //让xxxProperties生效加入到容器中自动配置类要能加载将需要启动就加载的自动配置类，配置在META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ 3、模式： 启动器只用来做依赖导入； 专门来写一个自动配置模块； 启动器依赖自动配置；别人只需要引入启动器（starter） mybatis-spring-boot-starter；自定义启动器名-spring-boot-starter 步骤： 1）、启动器模块 123456789101112131415161718&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--启动器--&gt; &lt;dependencies&gt; &lt;!--引入自动配置模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2）、自动配置模块 1234567891011121314151617181920212223242526272829&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.10.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--引入spring-boot-starter；所有starter的基本配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 12345678910111213141516171819package com.atguigu.starter;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = &quot;atguigu.hello&quot;)public class HelloProperties &#123; private String prefix; private String suffix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public String getSuffix() &#123; return suffix; &#125; public void setSuffix(String suffix) &#123; this.suffix = suffix; &#125;&#125; 12345678910111213package com.atguigu.starter;public class HelloService &#123; HelloProperties helloProperties; public HelloProperties getHelloProperties() &#123; return helloProperties; &#125; public void setHelloProperties(HelloProperties helloProperties) &#123; this.helloProperties = helloProperties; &#125; public String sayHellAtguigu(String name)&#123; return helloProperties.getPrefix()+&quot;-&quot; +name + helloProperties.getSuffix(); &#125;&#125; 12345678910111213141516171819package com.atguigu.starter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration@ConditionalOnWebApplication //web应用才生效@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration &#123; @Autowired HelloProperties helloProperties; @Bean public HelloService helloService()&#123; HelloService service = new HelloService(); service.setHelloProperties(helloProperties); return service; &#125;&#125;","tags":["笔记"],"categories":["Java"]},{"title":"SpringBoot整合Thymleaf实现页面静态化","path":"/2021/11/12/SpringBoot-Thymleaf/","content":"1. 问题需求分析 在做乐优商城时，页面是通过Thymeleaf模板引擎渲染后返回到客户端。当商品详情页数据渲染时，在后台需要大量的数据查询，而后渲染得到HTML页面。在用户访问量大的情况下会对数据库造成压力，并且请求的响应时间过长，并发能力不高。 如何解决？ 一般我们优先会考虑使用缓存技术，比如 Redis 分布式缓存，Guava 本地缓存等。然而 Redis 只适合数据规模比较小的情况，假如数据量比较大，例如商品详情页，每个页面如果10kb，100万商品，就是10GB空间，对内存占用比较大。此时就给缓存系统带来极大压力，如果缓存崩溃，接下来倒霉的就是数据库了。 所以缓存并不是万能的，某些场景需要其它技术来解决，比如静态化技术。 2. 什么是静态化？ 静态化是指把动态生成的HTML页面变为静态内容保存，以后用户的请求到来，直接访问静态页面，不再经过服务的渲染。 而静态的HTML页面可以部署在nginx中，从而大大提高并发能力，减小tomcat压力。 3. 如何实现静态化？目前，静态化页面都是通过模板引擎来生成，而后保存到nginx服务器来部署。常用的模板引擎比如： Freemarker Velocity Thymeleaf 乐优项目中使用的是Thymeleaf 模板引擎! 4. Thymeleaf实现静态化4.1 概念介绍Thymeleaf 模板引擎实现页面静态化的几个概念介绍： Context：运行上下文 TemplateResolver：模板解析器 TemplateEngine：模板引擎 Context： Thymeleaf 模板中的上下文： 用来保存模型数据，当模板引擎渲染时，可以从Context上下文中获取数据用于渲染。 当与Spring Boot结合使用时，我们放入Model的数据就会被处理到Context，作为模板渲染的数据使用。 TemplateResolver： Thymeleaf 模板中的模板解析器：用来读取模板相关的配置，例如：模板存放的位置信息，模板文件名称，模板文件的类型等等。 当与SpringBoot结合时，TemplateResolver已经由其创建完成，并且各种配置也都有默认值，比如模板存放位置，其默认值就是：templates。比如模板文件类型，其默认值就是html。 TemplateEngine： Thymeleaf 模板中的模板引擎：用来解析模板的引擎，需要使用到上下文、模板解析器。分别从两者中获取模板中需要的数据，模板文件。然后利用内置的语法规则解析，从而输出解析后的文件。来看下模板引擎进行处理的函数： 1templateEngine.process(&quot;模板名&quot;, context, writer); 三个参数： 模板名称 上下文：里面包含模型数据 writer：输出目的地的流 在输出时，我们可以指定输出的目的地，如果目的地是Response的流，那就是网络响应。如果目的地是本地文件，那就实现静态化了。 而在SpringBoot中已经自动配置了模板引擎，因此不需要关心这个。我们做静态化，就是把输出的目的地改成本地文件即可！ 4.2 具体实现GoodsHtmlService 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * @Auther: csp1999 * @Date: 2020/12/16/19:43 * @Description: 生成HTML页面的Service */@Servicepublic class GoodsHtmlService &#123; // themleaf 模板引擎 @Autowired private TemplateEngine templateEngine; @Autowired private GoodsService goodsService; /** * 根据spuId 将对应的商品详情页面生成HTML静态页面 * * @param spuId */ public void createHTML(Long spuId) &#123; // 初始化运行上下文: org.thymeleaf.context 包下 Context context = new Context(); // 设置数据模板 // 从goodsService.loadData(spuId) 方法中获取模板页面中需要渲染的数据 context.setVariables(goodsService.loadData(spuId)); // 获取输出流 // 将需要输出的html 文件地址设置为服务器中的nginx 目录下的html 目录中的item文件夹下（我这里nginx 部署的是win10本地！） File file = new File( &quot;M:\\ ote\\\\MyProjects\\\\leyou\\\\tools\\ ginx-1.14.0\\\\html\\\\item\\\\&quot; + spuId + &quot;.html&quot;); PrintWriter writer = null; try &#123; writer = new PrintWriter(file); // 模板引擎生成静态html 页面 templateEngine.process(&quot;item&quot;, context, writer); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; finally &#123; // 判断并关闭流 if (writer != null) &#123; writer.close(); &#125; &#125; &#125; /** * 新建线程处理页面静态化 * * @param spuId */ public void asyncExcute(Long spuId) &#123; ThreadUtils.execute(() -&gt; createHTML(spuId)); /*ThreadUtils.execute(new Runnable() &#123; @Override public void run() &#123; createHtml(spuId); &#125; &#125;);*/ &#125;&#125; 多线程工具类ThreadUtils 1234567891011/** * @Auther: csp1999 * @Date: 2020/12/16/20:18 * @Description: 多线程工具类 */public class ThreadUtils &#123; private static final ExecutorService es = Executors.newFixedThreadPool(10); public static void execute(Runnable runnable) &#123; es.submit(runnable); &#125;&#125; GoodsController 在调用GoodsController访问商品页面的同时生成缓存的页面： 1234567891011121314151617181920212223242526272829/** * @Auther: csp1999 * @Date: 2020/12/16/10:00 * @Description: */@Controllerpublic class GoodsController &#123; @Autowired private GoodsService goodsService; @Autowired private GoodsHtmlService goodsHtmlService; /** * 商品详情也页面 * * @param id * @param model * @return */ @GetMapping(&quot;/item/&#123;id&#125;.html&quot;) public String toItemPage(@PathVariable(&quot;id&quot;) Long id, Model model) &#123; Map&lt;String, Object&gt; map = goodsService.loadData(id); model.addAllAttributes(map); // 页面静态化：调用createHTML(id) 方法生成静态页面并保存到服务器的nginx 对应目录下缓存 // 通过多线程方式： goodsHtmlService.asyncExcute(id);// goodsHtmlService.createHTML(id); return &quot;/item&quot;; &#125;&#125; 注意：生成html 的代码不能对用户请求产生影响，所以这里我们使用额外的线程进行异步创建。 5. nginx 中进行访问配置12345678910111213141516171819202122232425# 前端前台相关配置server &#123; listen 80; server_name www.leyou.com; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 如果是以item 开头的路径，代理到前台8084端口 # eg: www.leyou.com/item/4586.html location /item &#123; # 先到本地nginx 路径下的html文件夹 中找页面，如果有则走该页面(相当于缓存效果) root html; if (!-f $request_filename) &#123; # 如果请求的文件不存在，就反向代理，通过请求去访问该页面 proxy_pass http://127.0.0.1:8084; break; &#125; &#125; # 代理到前台9002端口 location / &#123; proxy_pass http://127.0.0.1:9002; proxy_connect_timeout 600; proxy_read_timeout 600; &#125;&#125; nginx 代理的流程图： 6. 访问页面测试第一次访问页面： nginx路径下的html/item/下生成了该页面的静态资源： 第二次访问该页面：","tags":["笔记"],"categories":["Java"]},{"title":"springboot整合富文本编辑器editor.md","path":"/2021/11/12/SpringBoot-editor/","content":"狂神哔哩哔哩视频地址Editor.md——功能非常丰富的编辑器，左端编辑，右端预览，非常方便，完全免费 官网：https://pandao.github.io/editor.md/ 官网下载：https://pandao.github.io/editor.md/ 基础工程搭建 数据库设计 article：文章表 字段 备注 id int 文章的唯一ID author varchar 作者 title varchar 标题 content longtext 文章的内容 建表SQL： 1234567CREATE TABLE `article` (`id` int(10) NOT NULL AUTO_INCREMENT COMMENT &#x27;int文章的唯一ID&#x27;,`author` varchar(50) NOT NULL COMMENT &#x27;作者&#x27;,`title` varchar(100) NOT NULL COMMENT &#x27;标题&#x27;,`content` longtext NOT NULL COMMENT &#x27;文章的内容&#x27;,PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 基础项目搭建 1、建一个SpringBoot项目配置 1234567spring:datasource: username: root password: 123456 #?serverTimezone=UTC解决时区的报错 url: jdbc:mysql://localhost:3306/springboot?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8 driver-class-name: com.mysql.cj.jdbc.Driver 2、实体类： 12345678910//文章类@Data@NoArgsConstructor@AllArgsConstructorpublic class Article implements Serializable &#123; private int id; //文章的唯一ID private String author; //作者名 private String title; //标题 private String content; //文章的内容&#125; 3、mapper接口： 123456789101112@Mapper@Repositorypublic interface ArticleMapper &#123; //查询所有的文章 List&lt;Article&gt; queryArticles(); //新增一个文章 int addArticle(Article article); //根据文章id查询文章 Article getArticleById(int id); //根据文章id删除文章 int deleteArticleById(int id);&#125; 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.kuang.mapper.ArticleMapper&quot;&gt; &lt;select id=&quot;queryArticles&quot; resultType=&quot;Article&quot;&gt; select * from article &lt;/select&gt; &lt;select id=&quot;getArticleById&quot; resultType=&quot;Article&quot;&gt; select * from article where id = #&#123;id&#125; &lt;/select&gt; &lt;insert id=&quot;addArticle&quot; parameterType=&quot;Article&quot;&gt; insert into article (author,title,content) values (#&#123;author&#125;,#&#123;title&#125;,#&#123;content&#125;); &lt;/insert&gt; &lt;delete id=&quot;deleteArticleById&quot; parameterType=&quot;int&quot;&gt; delete from article where id = #&#123;id&#125; &lt;/delete&gt;&lt;/mapper&gt; 既然已经提供了 myBatis 的映射配置文件，自然要告诉 spring boot 这些文件的位置 123mybatis:mapper-locations: classpath:com/kuang/mapper/*.xmltype-aliases-package: com.kuang.pojo 编写一个Controller测试下，是否ok； 文章编辑整合（重点）1、导入 editor.md 资源 ，删除多余文件 2、编辑文章页面 editor.html、需要引入 jQuery； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;!DOCTYPE html&gt;&lt;html class=&quot;x-admin-sm&quot; lang=&quot;zh&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;秦疆&#x27;Blog&lt;/title&gt; &lt;meta name=&quot;renderer&quot; content=&quot;webkit&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,user-scalable=yes, minimum-scale=0.4, initial-scale=0.8,target-densitydpi=low-dpi&quot; /&gt; &lt;!--Editor.md--&gt; &lt;link rel=&quot;stylesheet&quot; th:href=&quot;@&#123;/editormd/css/editormd.css&#125;&quot;/&gt; &lt;link rel=&quot;shortcut icon&quot; href=&quot;https://pandao.github.io/editor.md/favicon.ico&quot; type=&quot;image/x-icon&quot; /&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;layui-fluid&quot;&gt; &lt;div class=&quot;layui-row layui-col-space15&quot;&gt; &lt;div class=&quot;layui-col-md12&quot;&gt; &lt;!--博客表单--&gt; &lt;form name=&quot;mdEditorForm&quot;&gt; &lt;div&gt; 标题：&lt;input type=&quot;text&quot; name=&quot;title&quot;&gt; &lt;/div&gt; &lt;div&gt; 作者：&lt;input type=&quot;text&quot; name=&quot;author&quot;&gt; &lt;/div&gt; &lt;div id=&quot;article-content&quot;&gt; &lt;textarea name=&quot;content&quot; id=&quot;content&quot; style=&quot;display:none;&quot;&gt; &lt;/textarea&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;!--editormd--&gt;&lt;script th:src=&quot;@&#123;/editormd/lib/jquery.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;/editormd/editormd.js&#125;&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; var testEditor; //window.onload = function()&#123; &#125; $(function() &#123; testEditor = editormd(&quot;article-content&quot;, &#123; width : &quot;95%&quot;, //宽 height : 600, //高 syncScrolling : &quot;single&quot;, path : &quot;../editormd/lib/&quot;, //加载编辑器lib路径 saveHTMLToTextarea : true, // 保存 HTML 到 Textarea emoji: true, //功能开启表情 theme: &quot;dark&quot;,//工具栏主题 previewTheme: &quot;dark&quot;,//预览主题 editorTheme: &quot;pastel-on-dark&quot;,//编辑主题 tex : true, // 开启科学公式TeX语言支持，默认关闭 flowChart : true, // 开启流程图支持，默认关闭 sequenceDiagram : true, // 开启时序/序列图支持，默认关闭, //图片上传 imageUpload : true, imageFormats : [&quot;jpg&quot;, &quot;jpeg&quot;, &quot;gif&quot;, &quot;png&quot;, &quot;bmp&quot;, &quot;webp&quot;], imageUploadURL : &quot;/article/file/upload&quot;, onload : function() &#123; console.log(&#x27;onload&#x27;, this); &#125;, /*指定需要显示的功能按钮*/ toolbarIcons : function() &#123; return [&quot;undo&quot;,&quot;redo&quot;,&quot;|&quot;, &quot;bold&quot;,&quot;del&quot;,&quot;italic&quot;,&quot;quote&quot;,&quot;ucwords&quot;,&quot;uppercase&quot;,&quot;lowercase&quot;,&quot;|&quot;, &quot;h1&quot;,&quot;h2&quot;,&quot;h3&quot;,&quot;h4&quot;,&quot;h5&quot;,&quot;h6&quot;,&quot;|&quot;, &quot;list-ul&quot;,&quot;list-ol&quot;,&quot;hr&quot;,&quot;|&quot;, &quot;link&quot;,&quot;reference-link&quot;,&quot;image&quot;,&quot;code&quot;,&quot;preformatted-text&quot;, &quot;code-block&quot;,&quot;table&quot;,&quot;datetime&quot;,&quot;emoji&quot;,&quot;html-entities&quot;,&quot;pagebreak&quot;,&quot;|&quot;, &quot;goto-line&quot;,&quot;watch&quot;,&quot;preview&quot;,&quot;fullscreen&quot;,&quot;clear&quot;,&quot;search&quot;,&quot;|&quot;, &quot;help&quot;,&quot;info&quot;,&quot;releaseIcon&quot;, &quot;index&quot;] &#125;, /*自定义功能按钮，下面我自定义了2个，一个是发布，一个是返回首页*/ toolbarIconTexts : &#123; releaseIcon : &quot;&lt;span bgcolor=\\&quot;gray\\&quot;&gt;发布&lt;/span&gt;&quot;, index : &quot;&lt;span bgcolor=\\&quot;red\\&quot;&gt;返回首页&lt;/span&gt;&quot;, &#125;, /*给自定义按钮指定回调函数*/ toolbarHandlers:&#123; releaseIcon : function(cm, icon, cursor, selection) &#123; //表单提交 mdEditorForm.method = &quot;post&quot;; mdEditorForm.action = &quot;/article/addArticle&quot;;//提交至服务器的路径 mdEditorForm.submit(); &#125;, index : function()&#123; window.location.href = &#x27;/&#x27;; &#125;, &#125; &#125;); &#125;);&lt;/script&gt;&lt;/html&gt; 3、编写Controller，进行跳转，以及保存文章 12345678910111213@Controller@RequestMapping(&quot;/article&quot;)public class ArticleController &#123; @GetMapping(&quot;/toEditor&quot;) public String toEditor()&#123; return &quot;editor&quot;; &#125; @PostMapping(&quot;/addArticle&quot;) public String addArticle(Article article)&#123; articleMapper.addArticle(article); return &quot;editor&quot;; &#125;&#125; 图片上传问题 1、前端js中添加配置 1234//图片上传imageUpload : true,imageFormats : [&quot;jpg&quot;, &quot;jpeg&quot;, &quot;gif&quot;, &quot;png&quot;, &quot;bmp&quot;, &quot;webp&quot;],imageUploadURL : &quot;/article/file/upload&quot;, // //这个是上传图片时的访问地址 2、后端请求，接收保存这个图片, 需要导入 FastJson 的依赖 12345678910111213141516171819202122232425262728//博客图片上传问题@RequestMapping(&quot;/file/upload&quot;)@ResponseBodypublic JSONObject fileUpload(@RequestParam(value = &quot;editormd-image-file&quot;, required = true) MultipartFile file, HttpServletRequest request) throws IOException &#123; //上传路径保存设置 //获得SpringBoot当前项目的路径：System.getProperty(&quot;user.dir&quot;) String path = System.getProperty(&quot;user.dir&quot;)+&quot;/upload/&quot;; //按照月份进行分类： Calendar instance = Calendar.getInstance(); String month = (instance.get(Calendar.MONTH) + 1)+&quot;月&quot;; path = path+month; File realPath = new File(path); if (!realPath.exists())&#123; realPath.mkdir(); &#125; //上传文件地址 System.out.println(&quot;上传文件保存地址：&quot;+realPath); //解决文件名字问题：我们使用uuid; String filename = &quot;ks-&quot;+UUID.randomUUID().toString().replaceAll(&quot;-&quot;, &quot;&quot;); //通过CommonsMultipartFile的方法直接写文件（注意这个时候） file.transferTo(new File(realPath +&quot;/&quot;+ filename)); //给editormd进行回调 JSONObject res = new JSONObject(); res.put(&quot;url&quot;,&quot;/upload/&quot;+month+&quot;/&quot;+ filename); res.put(&quot;success&quot;, 1); res.put(&quot;message&quot;, &quot;upload success!&quot;); return res;&#125; 3、解决文件回显显示的问题，设置虚拟目录映射！在我们自己拓展的MvcConfig中进行配置即可！ 12345678910@Configurationpublic class MyMvcConfig implements WebMvcConfigurer &#123; // 文件保存在真实目录/upload/下， // 访问的时候使用虚路径/upload，比如文件名为1.png，就直接/upload/1.png就ok了。 @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;/upload/**&quot;) .addResourceLocations(&quot;file:&quot;+System.getProperty(&quot;user.dir&quot;)+&quot;/upload/&quot;); &#125;&#125; 表情包问题 自己手动下载，emoji 表情包，放到图片路径下： 修改editormd.js文件 12345// Emoji graphics files url patheditormd.emoji = &#123; path : &quot;../editormd/plugins/emoji-dialog/emoji/&quot;, ext : &quot;.png&quot;&#125;; 文章展示1、Controller 中增加方法 123456@GetMapping(&quot;/&#123;id&#125;&quot;)public String show(@PathVariable(&quot;id&quot;) int id,Model model)&#123; Article article = articleMapper.getArticleById(id); model.addAttribute(&quot;article&quot;,article); return &quot;article&quot;;&#125; 2、编写页面 article.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, maximum-scale=1&quot;&gt; &lt;title th:text=&quot;$&#123;article.title&#125;&quot;&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt; &lt;!--文章头部信息：标题，作者，最后更新日期，导航--&gt; &lt;h2 style=&quot;margin: auto 0&quot; th:text=&quot;$&#123;article.title&#125;&quot;&gt;&lt;/h2&gt; 作者：&lt;span style=&quot;float: left&quot; th:text=&quot;$&#123;article.author&#125;&quot;&gt;&lt;/span&gt; &lt;!--文章主体内容--&gt; &lt;div id=&quot;doc-content&quot;&gt; &lt;textarea style=&quot;display:none;&quot; placeholder=&quot;markdown&quot; th:text=&quot;$&#123;article.content&#125;&quot;&gt;&lt;/textarea&gt; &lt;/div&gt;&lt;/div&gt;&lt;link rel=&quot;stylesheet&quot; th:href=&quot;@&#123;/editormd/css/editormd.preview.css&#125;&quot; /&gt;&lt;script th:src=&quot;@&#123;/editormd/lib/jquery.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;/editormd/lib/marked.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;/editormd/lib/prettify.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;/editormd/lib/raphael.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;/editormd/lib/underscore.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;/editormd/lib/sequence-diagram.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;/editormd/lib/flowchart.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;/editormd/lib/jquery.flowchart.min.js&#125;&quot;&gt;&lt;/script&gt;&lt;script th:src=&quot;@&#123;/editormd/editormd.js&#125;&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; var testEditor; $(function () &#123; testEditor = editormd.markdownToHTML(&quot;doc-content&quot;, &#123; //注意：这里是上面DIV的id htmlDecode: &quot;style,script,iframe&quot;, emoji: true, taskList: true, tocm: true, tex: true, // 默认不解析 flowChart: true, // 默认不解析 sequenceDiagram: true, // 默认不解析 codeFold: true &#125;);&#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 重启项目，访问进行测试！大功告成！","tags":["笔记"],"categories":["Java"]},{"title":"Git常用命令总结","path":"/2021/11/12/git-richang/","content":"把码云官方给的git常用命令总结放在文章最前面，为的是先方便上手使用！后边的文章再详细介绍！ 0. 码云git常用命令总结仓库123456# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 配置1234567# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot; 增加/删除文件123456789101112131415# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 代码提交12345678910111213# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 分支1234567891011121314151617181920212223242526272829# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 标签123456789101112131415161718# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 查看信息1234567891011121314151617181920212223242526272829303132333435363738394041# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 远程同步12345678910111213141516# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all 撤销12345678910111213141516171819202122# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 其他12# 生成一个可供发布的压缩包$ git archive 1. Git环境配置软件下载打开 GIT官网，下载GIT对应操作系统的版本。 所有东西下载慢的话就可以去找镜像！ 官网下载太慢，我们可以使用淘宝镜像下载：GIT淘宝镜像下载 下载对应的版本即可安装！ 安装：无脑下一步即可！安装完毕就可以使用了！ 启动Git安装成功后在开始菜单中会有Git项，菜单下有3个程序：任意文件夹下右键也可以看到对应的程序！ Git Bash：Unix与Linux风格的命令行，使用最多，推荐最多 Git CMD：Windows风格的命令行 Git GUI：图形界面的Git，不建议初学者使用，尽量先熟悉常用命令 常用的Linux命令平时一定要多使用这些基础的命令！ 1）cd : 改变目录。 2）cd ..: 回退到上一个目录，直接cd进入默认目录 3）pwd : 显示当前所在的目录路径。 4）ls(ll): 都是列出当前目录中的所有文件，只不过ll(两个ll)列出的内容更为详细。 5）touch : 新建一个文件 如 touch index.js 就会在当前目录下新建一个index.js文件。 6）rm: 删除一个文件, rm index.js 就会把index.js文件删除。 7）mkdir: 新建一个目录,就是新建一个文件夹。 8）rm -r : 删除一个文件夹, rm -r src 删除src目录 1rm -rf / 切勿在Linux中尝试！删除电脑中全部文件！ 9）mv 移动文件,mv index.html src index.html 是我们要移动的文件, src 是目标文件夹,当然, 这样写,必须保证文件和目标文件夹在同一目录下 10）reset 重新初始化终端/清屏 11）clear 清屏 12）history 查看命令历史 13）help 帮助 14）exit 退出 15）#表示注释 Git配置所有的配置文件，其实都保存在本地！ 查看配置 git config -l 查看不同级别的配置文件： 12345#查看系统configgit config --system --list #查看当前用户（global）配置git config --global --list Git相关的配置文件： 1）Git\\etc\\gitconfig ：Git 安装目录下的gitconfig --system 系统级 2）C:\\Users\\Administrator\\ .gitconfig 只适用于当前登录用户的配置 --global全局 这里可以直接编辑配置文件，通过命令设置后会响应到这里。 设置用户名与邮箱（用户标识，必要) 当你安装Git后首先要做的事情是设置你的用户名称和e-mail地址。这是非常重要的，因为每次Git提交都会使用该信息。它被永远的嵌入到了你的提交中： 1git config --global user.name &quot;xxxxx&quot; # 名称git config --global user.email 123456@qq.com #邮箱 只需要做一次这个设置，如果你传递了--global选项，因为Git将总是会使用该信息来处理你在系统中所做的一切操作。如果你希望在一个特定的项目中使用不同的名称或e-mail地址，你可以在该项目中运行该命令而不要--global选项。总之--global为全局配置，不加为某个项目的特定配置。 2. Git基本理论Git的三个区域Git本地有三个工作区域：工作目录（Working Directory）、暂存区(Stage/Index)、资源库(Repository或Git Directory)。如果在加上远程的git仓库(Remote Directory)就可以分为四个工作区域。文件在这四个区域之间的转换关系如下： Workspace：工作区，就是你平时存放项目代码的地方 Index / Stage：暂存区，用于临时存放你的改动，事实上它只是一个文件，保存即将提交到文件列表信息 Repository：仓库区（或本地仓库），就是安全存放数据的位置，这里面有你提交到所有版本的数据。其中HEAD指向最新放入仓库的版本 Remote：远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换 本地的三个区域确切的说应该是git仓库中HEAD指向的版本： Directory：使用Git管理的一个目录，也就是一个仓库，包含我们的工作空间和Git的管理空间。 WorkSpace：需要通过Git进行版本控制的目录和文件，这些目录和文件组成了工作空间。 .git：存放Git管理信息的目录，初始化仓库的时候自动创建。 Index/Stage：暂存区，或者叫待提交更新区，在提交进入repo之前，我们可以把所有的更新放在暂存区。 Local Repo：本地仓库，一个存放在本地的版本库；HEAD会只是当前的开发分支（branch）。 Stash：隐藏，是一个工作状态保存栈，用于保存/恢复WorkSpace中的临时状态。 3. Git项目搭建本地仓库搭建创建本地仓库的方法有两种：一种是创建全新的仓库，另一种是克隆远程仓库。 1、创建全新的仓库，需要用GIT管理的项目的根目录执行： 12# 在当前目录新建一个Git代码库$ git init 2、执行后可以看到，仅仅在项目目录多出了一个.git目录，关于版本等的所有信息都在这个目录里面。 克隆远程仓库1、另一种方式是克隆远程目录，由于是将远程服务器上的仓库完全镜像一份至本地！ 12# 克隆一个项目和它的整个代码历史(版本信息)$ git clone [url] # https://gitee.com/xxxxx/openclass.git 2、去 gitee 或者 github 上克隆一个测试！ 4. Git文件操作文件的四种状态 Untracked: 未跟踪, 此文件在文件夹中, 但并没有加入到git库, 不参与版本控制. 通过git add 状态变为Staged. Unmodify: 文件已经入库, 未修改, 即版本库中的文件快照内容与文件夹中完全一致. 这种类型的文件有两种去处, 如果它被修改, 而变为Modified. 如果使用git rm移出版本库, 则成为Untracked文件 Modified: 文件已修改, 仅仅是修改, 并没有进行其他的操作. 这个文件也有两个去处, 通过git add可进入暂存staged状态, 使用git checkout 则丢弃修改过, 返回到unmodify状态, 这个git checkout即从库中取出文件, 覆盖当前修改 ! Staged: 暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodify状态. 执行git reset HEAD filename取消暂存, 文件状态为Modified 查看文件状态上面说文件有4种状态，通过如下命令可以查看到文件的状态： 123456#查看指定文件状态git status [filename]#查看所有文件状态git status# git add . 添加所有文件到暂存区# git commit -m &quot;消息内容&quot; 提交暂存区中的内容到本地仓库 -m 提交信息 git分支中常用指令123456789101112131415# 列出所有本地分支git branch# 列出所有远程分支git branch -r# 新建一个分支，但依然停留在当前分支git branch [branch-name]# 新建一个分支，并切换到该分支git checkout -b [branch]# 合并指定分支到当前分支$ git merge [branch]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 如果同一个文件在合并分支时都被修改了则会引起冲突：解决的办法是我们可以修改冲突文件后重新提交！选择要保留他的代码还是你的代码！ master主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作，工作一般情况下在新建的dev分支上工作，工作完后，比如上要发布，或者说dev分支代码稳定后可以合并到主分支master上来。","tags":["笔记"],"categories":["git"]},{"title":"Java设计模式之——适配器模式","path":"/2021/11/12/java-shejimoshi/","content":"5.1 适配器模式简介 适配器模式（Adapter Pattern ⻅名知意，是作为两个不兼容的接⼝之间的桥梁，属于结构型模式 适配器模式使得原本由于接⼝不兼容⽽不能⼀起⼯作的那些类可以⼀起⼯作 常⻅的⼏类适配器 类的适配器模式 想将⼀个类转换成满⾜另⼀个新接⼝的类时，可以使⽤类的适配器模式，创建⼀个新类，继承原 有的类，实现新的接⼝即可 对象的适配器模式 想将⼀个对象转换成满⾜另⼀个新接⼝的对象时，可以创建⼀个适配器类，持有原类的⼀个实例，在适配器类的⽅法中，调⽤实例的⽅法就⾏ 接⼝的适配器模式 不想实现⼀个接⼝中所有的⽅法时，可以创建⼀ 个Adapter，实现所有⽅法，在写别的类的时 候，继承Adapter类即可 应⽤场景 电脑需要读取内存卡的数据，读卡器就是适配器 ⽇常使⽤的转换头，如电源转换头，电压转换头 系统需要使⽤现有的类，⽽这些类的接⼝不符合系统的 需要 JDK中InputStreamReader就是适配器 JDBC就是我们⽤的最多的适配器模式 123JDBC给出⼀个客户端通⽤的抽象接⼝，每⼀个具体数据库⼚商 如 SQL Server、Oracle、MySQL等，就会开发JDBC驱动，就是⼀个介于JDBC接⼝和数据库引擎接⼝之间的适配器软件 5.2 接⼝的适配器案例 设计模式的疑惑 会感觉到好像是理解了模式的功能，但是⼀到真实的系统开发中，就不知道如何使⽤这个模式了 前⾯每个案例都有讲实际的编码操作，⼤家⼀定要充分领悟 接⼝适配器 12有些接⼝中有多个抽象⽅法，当我们写该接⼝的实现类时，必须实现该接⼝的所有⽅法，这明显有时⽐较浪费，因为并不是所有的⽅法都是我们需要的，有时只需要实现部分接⼝就可以了 编码实战： 首先我们来定义一个支付网关接口PayGateWay(仅仅是模拟) 1234567891011121314151617181920212223/** * @Auther: csp1999 * @Date: 2020/11/09/18:40 * @Description: 支付网关接口 */public interface PayGateWay &#123; /** * 下单 */ void unifiedOrder(); /** * 退款 */ void refund(); /** * 查询支付状态 */ void query(); /** * 发红包 */ void sendRedPack();&#125; 再来一个视频产品订单类ProductVideoOrder 去实现 PayGateWay 接口： 1234567/** * @Auther: csp1999 * @Date: 2020/11/09/18:44 * @Description: 视频产品订单 */public class ProductVideoOrder implements PayGateWay&#123;&#125; 当我们实现该接口的时候，默认就需要实现接口中的所有抽象方法。而实际上如果我们只需要在ProductVideoOrder 实现下单unifiedOrder() 和refund() 退款功能，而并不需要多余的查询支付状态 query(); 和 发红包sendRedPack();功能，那么如何解决呢？ 这就需要用到一个适配器，适配器去实现PayGateWay 接口的所有方法，ProductVideoOrder 只需要继承 该适配器，就可以按需重写相关方法即可： 12345678910111213141516171819/** * @Auther: csp1999 * @Date: 2020/11/09/18:45 * @Description: 支付网关接口的适配器 */public class PayGateWayAdapter implements PayGateWay&#123; @Override public void unifiedOrder() &#123; &#125; @Override public void refund() &#123; &#125; @Override public void query() &#123; &#125; @Override public void sendRedPack() &#123; &#125;&#125; 然后在ProductVideoOrder 和ProductVipOrder 按需重写响应的方法： 12345678910111213141516171819/** * @Auther: csp1999 * @Date: 2020/11/09/18:48 * @Description: 超级会员用户产品订单 */public class ProductVipOrder extends PayGateWayAdapter&#123; @Override public void unifiedOrder() &#123; super.unifiedOrder(); &#125; @Override public void refund() &#123; super.refund(); &#125; @Override public void sendRedPack() &#123; super.sendRedPack(); &#125;&#125; 123456789101112131415/** * @Auther: csp1999 * @Date: 2020/11/09/18:44 * @Description: 视频产品订单 */public class ProductVideoOrder extends PayGateWayAdapter&#123; @Override public void unifiedOrder() &#123; System.out.println(&quot;产品下单...&quot;); &#125; @Override public void refund() &#123; System.out.println(&quot;产品退款...&quot;); &#125;&#125; 5.3 类的适配器实战 类的适配器模式 想将⼀个类转换成满⾜另⼀个新接⼝的类时，可以使⽤ 类的适配器模式，创建⼀个新类，继承原有的类，实现 新的接⼝即可 首先，假设我们在升级或者优化一个项目时，需要将老的模块中的相关功能进行升级扩展，这个功能目前是由模块中的某个类OldModule进行实现。 12345678910/** * @Auther: csp1999 * @Date: 2020/11/09/19:35 * @Description: */public class OldModule &#123; public void methodA()&#123; System.out.println(&quot;OldModule 中的 methodA...&quot;); &#125;&#125; 那么我们如何在不改动老模块中OldModule类的前提下，对其所负责的业务功能进行扩展升级呢？ 接下来，我们先将要扩展升级的相关功能方法，包括现有功能的方法在目标接口TargetModule中进行定义 12345678910111213141516/** * @Auther: csp1999 * @Date: 2020/11/09/19:36 * @Description: */public interface TargetModule &#123; /** * 和需要适配的类的方法名一样 */ public void methodA(); /** * 新的方法，如果有多个新的方法直接编写即可 */ public void methodB(); public void methodC();&#125; 然后通过类的适配器，进行适配OldModule和TargetModule，这样就可以做到将⼀个类转换成满⾜另⼀个新接⼝的类，且不改动原有类~ 123456789101112131415161718192021222324/** * @Auther: csp1999 * @Date: 2020/11/09/19:37 * @Description: 类的适配器 */public class Adapter extends OldModule implements TargetModule&#123; /** * 注意： 已经在OldModule中实现的 methodA()是不用再实现的 */ /** * 新的方法B */ @Override public void methodB() &#123; System.out.println(&quot;Adapter 中的 methodB...&quot;); &#125; /** * 新的方法C */ @Override public void methodC() &#123; System.out.println(&quot;Adapter 中的 methodC...&quot;); &#125;&#125; 测试一下效果： 1234567@Testpublic void testClassAdapater()&#123; TargetModule targetModule = new Adapter(); targetModule.methodA(); targetModule.methodB(); targetModule.methodC();&#125; 输出结果为： 123OldModule 中的 methodA...Adapter 中的 methodB...Adapter 中的 methodC... 这样就做到了 在不改动原来OldModule 类以及其中相关功能方法的前提下，对其进行扩展实现TargetModule 接口中新增加的业务功能！ 原文：https://www.kuangstudy.com/bbs/1374938278314143745","tags":["设计模式"],"categories":["Java"]},{"title":"JDK集合源码之HashSet解析","path":"/2021/11/12/jdk-HashSet/","content":"HashSet简介 HashSet的特点 无序性（存储元素无序） 唯一性（允许使用null） 本质上，HashSet底层是通过HashMap来保证唯一性 HashSet没有提供get()方法，同HashMap一样，因为Set内部是无序的，所以只能通过迭代的方式获得 HashSet的继承体系 HashSet源码分析1. 属性(成员变量)1234// HashSet内部使用HashMap来存储元素，因此本质上是HashMapprivate transient HashMap&lt;E,Object&gt; map;// 虚拟对象，用来作为value放到map中(在HashSet底层的HashMap中，key为要存储的元素，value统一为PRESENT)private static final Object PRESENT = new Object(); 2. 构造方法1234567891011121314151617public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125;// 注意：这里未用public修饰，主要是给LinkedHashSet使用的HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 构造方法都是调用HashMap对应的构造方法。最后一个构造方法有点特殊，它不是public的，意味着它只能被同一个包或者子类调用，这是LinkedHashSet专属的方法。 3. 成员方法3.1 添加元素add(E e)12345// HashSet添加元素的时候，直接调用的是HashMap中的put()方法，// 把元素本身作为key，把PRESENT作为value，也就是这个map中所有的value都是一样的。public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 3.2 删除元素remove(Object o)123456// HashSet删除元素，直接调用HashMap的remove方法public boolean remove(Object o) &#123; // 注意：map的remove返回是删除元素的value，而Set的remov返回的是boolean类型 // 如果是null的话说明没有该元素，如果不是null肯定等于PRESENT return map.remove(o)==PRESENT;&#125; 3.3 查找元素contains(Object o)1234// Set中没有get()方法，不像List那样可以按index获取元素public boolean contains(Object o) &#123; return map.containsKey(o);&#125; 4. 完整代码HashSet是基于HashMap的，所以其源码较少： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package java.util;import java.io.InvalidObjectException;import sun.misc.SharedSecrets;public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable&#123; static final long serialVersionUID = -5024744406713321676L; // 内部元素存储在HashMap中 private transient HashMap&lt;E,Object&gt; map; // 虚拟元素，用来存到map元素的value中的，没有实际意义 private static final Object PRESENT = new Object(); // 空构造方法 public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; // 把另一个集合的元素全都添加到当前Set中 // 注意，这里初始化map的时候是计算了它的初始容量的 public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); &#125; // 指定初始容量和装载因子 public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor); &#125; // 只指定初始容量 public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity); &#125; // LinkedHashSet专用的方法 // dummy是没有实际意义的, 只是为了跟上上面那个操持方法签名不同而已 HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125; // 迭代器 public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator(); &#125; // 元素个数 public int size() &#123; return map.size(); &#125; // 检查是否为空 public boolean isEmpty() &#123; return map.isEmpty(); &#125; // 检查是否包含某个元素 public boolean contains(Object o) &#123; return map.containsKey(o); &#125; // 添加元素 public boolean add(E e) &#123; return map.put(e, PRESENT)==null; &#125; // 删除元素 public boolean remove(Object o) &#123; return map.remove(o)==PRESENT; &#125; // 清空所有元素 public void clear() &#123; map.clear(); &#125; // 克隆方法 @SuppressWarnings(&quot;unchecked&quot;) public Object clone() &#123; try &#123; HashSet&lt;E&gt; newSet = (HashSet&lt;E&gt;) super.clone(); newSet.map = (HashMap&lt;E, Object&gt;) map.clone(); return newSet; &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(e); &#125; &#125; // 序列化写出方法 private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; // 写出非static非transient属性 s.defaultWriteObject(); // 写出map的容量和装载因子 s.writeInt(map.capacity()); s.writeFloat(map.loadFactor()); // 写出元素个数 s.writeInt(map.size()); // 遍历写出所有元素 for (E e : map.keySet()) s.writeObject(e); &#125; // 序列化读入方法 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // 读入非static非transient属性 s.defaultReadObject(); // 读入容量, 并检查不能小于0 int capacity = s.readInt(); if (capacity &lt; 0) &#123; throw new InvalidObjectException(&quot;Illegal capacity: &quot; + capacity); &#125; // 读入装载因子, 并检查不能小于等于0或者是NaN(Not a Number) // java.lang.Float.NaN = 0.0f / 0.0f; float loadFactor = s.readFloat(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) &#123; throw new InvalidObjectException(&quot;Illegal load factor: &quot; + loadFactor); &#125; // 读入元素个数并检查不能小于0 int size = s.readInt(); if (size &lt; 0) &#123; throw new InvalidObjectException(&quot;Illegal size: &quot; + size); &#125; // 根据元素个数重新设置容量 // 这是为了保证map有足够的容量容纳所有元素, 防止无意义的扩容 capacity = (int) Math.min(size * Math.min(1 / loadFactor, 4.0f), HashMap.MAXIMUM_CAPACITY); // 再次检查某些东西, 不重要的代码忽视掉 SharedSecrets.getJavaOISAccess() .checkArray(s, Map.Entry[].class, HashMap.tableSizeFor(capacity)); // 创建map, 检查是不是LinkedHashSet类型 map = (((HashSet&lt;?&gt;)this) instanceof LinkedHashSet ? new LinkedHashMap&lt;E,Object&gt;(capacity, loadFactor) : new HashMap&lt;E,Object&gt;(capacity, loadFactor)); // 读入所有元素, 并放入map中 for (int i=0; i&lt;size; i++) &#123; @SuppressWarnings(&quot;unchecked&quot;) E e = (E) s.readObject(); map.put(e, PRESENT); &#125; &#125; // 可分割的迭代器, 主要用于多线程并行迭代处理时使用 public Spliterator&lt;E&gt; spliterator() &#123; return new HashMap.KeySpliterator&lt;E,Object&gt;(map, 0, -1, 0, 0); &#125;&#125; 总结 HashSet内部使用HashMap的key存储元素，以此来保证元素不重复； HashSet是无序的，因为HashMap的key是无序的； HashSet中允许有一个null元素，因为HashMap允许key为null； HashSet是非线程安全的； HashSet是没有get()方法的； 扩展： 当向HashMap中存储n个元素时，它的初始化容量应指定为：((n/0.75f) + 1)，如果这个值小于16，就直接使用16为容量。初始化时指定容量是为了减少扩容的次数，提高效率。 LinkedHashSet分析1234567891011121314151617181920212223242526272829303132package java.util;// LinkedHashSet继承自HashSetpublic class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = -2851667679971038690L; // 传入容量和装载因子 public LinkedHashSet(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor, true); &#125; // 只传入容量, 装载因子默认为0.75 public LinkedHashSet(int initialCapacity) &#123; super(initialCapacity, .75f, true); &#125; // 使用默认容量16, 默认装载因子0.75 public LinkedHashSet() &#123; super(16, .75f, true); &#125; // 将集合c中的所有元素添加到LinkedHashSet中 // 好奇怪, 这里计算容量的方式又变了 // HashSet中使用的是Math.max((int) (c.size()/.75f) + 1, 16) // 这一点有点不得其解, 是作者偷懒？ public LinkedHashSet(Collection&lt;? extends E&gt; c) &#123; super(Math.max(2*c.size(), 11), .75f, true); addAll(c); &#125; // 可分割的迭代器, 主要用于多线程并行迭代处理时使用 @Override public Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, Spliterator.DISTINCT | Spliterator.ORDERED); &#125;&#125; LinkedHashSet继承自HashSet，它的添加、删除、查询等方法都是直接用的HashSet的，唯一的不同就是它使用LinkedHashMap存储元素。 LinkedHashSet是有序的，它是按照插入的顺序排序的。 LinkedHashSet是不支持按访问顺序对元素排序的，只能按插入顺序排序。 因为，LinkedHashSet所有的构造方法都是调用HashSet的同一个构造方法，如下： 1234// HashSet的构造方法 HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125; 通过调用LinkedHashMap的构造方法初始化map，如下所示： 1234public LinkedHashMap(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); accessOrder = false; &#125; 可以看到，这里把accessOrder写死为false了。 所以，LinkedHashSet是不支持按访问顺序对元素排序的，只能按插入顺序排序","tags":["笔记"],"categories":["Java"]},{"title":"nginx限流案例","path":"/2021/11/12/nginx-xianliu/","content":"生活中限流对比 水坝泄洪，通过闸口限制洪水流量（控制流量速度）。 办理银行业务：所有人先领号，各窗口叫号处理。每个窗口处理速度根据客户具体业务而定，所有人排队等待叫号即可。若快下班时，告知客户明日再来(拒绝流量) 火车站排队买票安检，通过排队 的方式依次放入。（缓存带处理任务） nginx的限流nginx提供两种限流的方式： 一是控制速率 二是控制并发连接数 控制速率控制速率的方式之一就是采用漏桶算法。 (1)漏桶算法实现控制速率限流漏桶(Leaky Bucket)算法思路很简单,水(请求)先进入到漏桶里,漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出(访问频率超过接口响应速率),然后就拒绝请求,可以看出漏桶算法能强行限制数据的传输速率.示意图如下: (2)nginx的配置配置示意图如下： 修改/usr/local/openresty/nginx/conf/nginx.conf: 12345678910111213141516171819202122232425262728293031user root root;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #cache lua_shared_dict dis_cache 128m; # 限流设置 ，binary_remote_addr：根据请求IP进行限流，contentRateLimit：缓存空间名称 # 10m:缓存空间，rate=2r/s:每秒允许有2个请求被处理 limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; location /update_content &#123; content_by_lua_file /root/lua/update_content.lua; &#125; location /read_content &#123; # 使用限流配置 limit_req zone=contentRateLimit; content_by_lua_file /root/lua/read_content.lua; &#125; &#125;&#125; 配置说明： 123binary_remote_addr 是一种key，表示基于 remote_addr(客户端IP) 来做限流，binary_ 的目的是压缩内存占用量。zone：定义共享内存区来存储访问信息， contentRateLimit:10m 表示一个大小为10M，名字为contentRateLimit的内存区域。1M能存储16000 IP地址的访问信息，10M可以存储16W IP地址访问信息。rate 用于设置最大访问速率，rate=10r/s 表示每秒最多处理10个请求。Nginx 实际上以毫秒为粒度来跟踪请求信息，因此 10r/s 实际上是限制：每100毫秒处理一个请求。这意味着，自上一个请求处理完后，若后续100毫秒内又有请求到达，将拒绝处理该请求.我们这里设置成2 方便测试。 测试： 重新加载配置文件 12cd /usr/local/openresty/nginx/sbin./nginx -s reload 访问页面：http://ip地址/read_content?id=1 ,连续频繁刷新(1s内请求超过2次)会直接报错。 (3)处理突发流量 上面例子限制2r/s，如果有时正常流量突然增大，超出的请求将被拒绝，无法处理突发流量，可以结合 burst 参数使用来解决该问题。 例如，如下配置表示： 上图代码如下： 1234567891011server &#123; listen 80; server_name localhost; location /update_content &#123; content_by_lua_file /root/lua/update_content.lua; &#125; location /read_content &#123; limit_req zone=contentRateLimit burst=4; content_by_lua_file /root/lua/read_content.lua; &#125;&#125; burst 译为突发、爆发，表示在超过设定的处理速率后能额外处理的请求数,当 rate=10r/s 时，将1s拆成10份，即每100ms可处理1个请求。 此处，burst=4，若同时有4个请求到达，Nginx 会处理第一个请求，剩余3个请求将放入队列，然后每隔500ms从队列中获取一个请求进行处理。若请求数大于4，将拒绝处理多余的请求，直接返回503. 不过，单独使用 burst 参数并不实用。假设 burst=50 ，rate依然为10r/s，排队中的50个请求虽然每100ms会处理一个，但第50个请求却需要等待 50 * 100ms即 5s，这么长的处理时间自然难以接受。 因此，burst 往往结合 nodelay 一起使用。 例如：如下配置： 123456789101112server &#123; listen 80; server_name localhost; location /update_content &#123; content_by_lua_file /root/lua/update_content.lua; &#125; location /read_content &#123; # 使用限流配置contentRateLimit ,nodelay 不延迟 limit_req zone=contentRateLimit burst=4 nodelay; content_by_lua_file /root/lua/read_content.lua; &#125;&#125; 如上表示： 平均每秒允许不超过2个请求，突发不超过4个请求，并且处理突发4个请求的时候，没有延迟，等到完成之后，按照正常的速率处理。 如上两种配置结合就达到了速率稳定，但突然流量也能正常处理的效果。完整配置代码如下： 1234567891011121314151617181920212223242526272829user root root;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #cache lua_shared_dict dis_cache 128m; #限流设置 limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; location /update_content &#123; content_by_lua_file /root/lua/update_content.lua; &#125; location /read_content &#123; limit_req zone=contentRateLimit burst=4 nodelay; content_by_lua_file /root/lua/read_content.lua; &#125; &#125;&#125; 测试：如下图 在1秒钟之内可以刷新4次，正常处理。但是超过之后，连续刷新5次，抛出异常。 控制并发量（连接数）ngx_http_limit_conn_module 提供了限制连接数的能力。主要是利用limit_conn_zone和limit_conn两个指令。 利用连接数限制 某一个用户的ip连接的数量来控制流量。 注意：并非所有连接都被计算在内 只有当服务器正在处理请求并且已经读取了整个请求头时，才会计算有效连接。此处忽略测试。 配置语法： 123Syntax: limit_conn zone number;Default: —;Context: http, server, location; (1)配置限制固定连接数如下，配置如下： 上图配置如下： 12345678910111213141516171819202122232425262728293031http &#123; include mime.types; default_type application/octet-stream; #cache lua_shared_dict dis_cache 128m; #限流设置 limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s; #根据IP地址来限制，存储内存大小10M limit_conn_zone $binary_remote_addr zone=addr:1m; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; #所有以brand开始的请求，访问本地changgou-service-goods微服务 location /brand &#123; limit_conn addr 2; proxy_pass http://192.168.1.6:8081; &#125; location /update_content &#123; content_by_lua_file /root/lua/update_content.lua; &#125; location /read_content &#123; limit_req zone=contentRateLimit burst=4 nodelay; content_by_lua_file /root/lua/read_content.lua; &#125; &#125;&#125; 表示： 12limit_conn_zone $binary_remote_addr zone=addr:10m; 表示限制根据用户的IP地址来显示，设置存储地址为的内存大小10Mlimit_conn addr 2; 表示 同一个地址只允许连接2次。 测试： 此时开3个线程，测试的时候会发生异常，开2个就不会有异常 (2)限制每个客户端IP与服务器的连接数，同时限制与虚拟服务器的连接总数。(了解)如下配置： 1234567891011121314# 存储个人请求IP的限流容量limit_conn_zone $binary_remote_addr zone=perip:10m;limit_conn_zone $server_name zone=perserver:10m; server &#123; listen 80; server_name localhost; charset utf-8; location / &#123; limit_conn perip 10;#单个客户端ip与服务器的连接数． limit_conn perserver 100; ＃限制与服务器的总连接数 root html; index index.html index.htm; &#125;&#125;","tags":["笔记"],"categories":["Nginx"]},{"title":"Nginx快速入门","path":"/2021/11/12/nginx-rumen/","content":"Nginx 快速入门笔记(带jdk1.8、tomcat、以及相关环境配置介绍 ) 内容介绍 123456789101112131415nginx1、 nginx 简介 （1） 什么是 nginx 和可以做什么事情 （2） 正向代理 （3） 反向代理 （4） 动静分离2、 Nginx 的安装 （1） 在 linux 系统中安装 nginx3、 Nginx 的常用命令和配置文件4、 Nginx 配置实例 1 反向代理5、 Nginx 配置实例 2 负载均衡6、 Nginx 配置实例 3 动静分离7、 Nginx 的高可用集群 （1） nginx 配置主从模式 （2） nginx 配置双主模式 Nginx 的简介1. 什么是 nginxNginx 可以作为静态页面的 web 服务器，同时还支持 CGI 协议的动态语言，比如 perl、php等。但是不支持 java。Java 程序只能通过与 tomcat 配合完成。Nginx 专为性能优化而开发，性能是其最重要的考量,实现上非常注重效率 ，能经受高负载的考验,有报告表明能支持高达 50,000 个并发连接数。 https://lnmp.org/nginx.html 2. 正向代理Nginx 不仅可以做反向代理，实现负载均衡。还能用作正向代理来进行上网等功能。 正向代理：如果把局域网外的 Internet 想象成一个巨大的资源库，则局域网中的客户端要访问 Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。 （1）需要在客户端配置代理服务器进行指定网站访问 : 3. 反向代理反向代理 : 其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器 IP 地址。 4. 负载均衡客户端发送多个请求到服务器，服务器处理请求，有一些可能要与数据库进行交互，服务器处理完毕后，再将结果返回给客户端。 12这种架构模式对于早期的系统相对单一，并发请求相对较少的情况下是比较适合的，成本也低。但是随着信息数量的不断增长，访问量和数据量的飞速增长，以及系统业务的复杂度增加，这种架构会造成服务器相应客户端的请求日益缓慢，并发量特别大的时候，还容易造成服务器直接崩溃。很明显这是由于服务器性能的瓶颈造成的问题，那么如何解决这种情况呢？ 我们首先想到的可能是升级服务器的配置，比如提高 CPU 执行频率，加大内存等提高机器的物理性能来解决此问题，但是我们知道摩尔定律的日益失效，硬件的性能提升已经不能满足日益提升的需求了。最明显的一个例子，天猫双十一当天，某个热销商品的瞬时访问量是极其庞大的，那么类似上面的系统架构，将机器都增加到现有的顶级物理配置，都是不能够满足需求的。那么怎么办呢？ 上面的分析我们去掉了增加服务器物理配置来解决问题的办法，也就是说纵向解决问题的办法行不通了，那么横向增加服务器的数量呢？这时候集群的概念产生了，单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡。 5. 动静分离为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。 Nginx 的安装1. 进入 nginx 官网，下载http://nginx.org/ 2. 安装nginx第一步，安装 pcrewget http://downloads.sourceforge.net/project/pcre/pcre/8.37/pcre-8.37.tar.gz 解压文件：tar -xvf pcre-8.37.tar.gz 进入解压缩的 pcre-8.37 执行 ./configure ./configure 执行完成后，回到 pcre 目录下执行 make &amp;&amp; make install 查看版本号 判断是否成功 pcre-config —version 第二步，安装 openssl第三步，安装 zlibyum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 第四步，安装nginx 压缩包放入usr/src下，并解压 tar -xvf nginx-1.18.0.tar.gz 进入nginx目录下执行 ./configure 执行完后 再执行 make &amp;&amp; make install 安装成功后 usr/local 下会增一个 nginx 文件夹 测试启动 nginx 并在进程中查看 在nginx 目录的 conf 目录下的nginx.conf 可以查看端口号，默认是80 命令：vi nginx.conf 浏览器直接通过ip地址访问，测试能否成功！(这里如果访问不成，进不去，要考虑是否将防火墙关闭！) 防火墙配置(开放端口号)查看防火墙开放的端口号 firewall-cmd —list-all 设置开放的端口号 firewall-cmd —add-service=http –permanent sudo firewall-cmd —add-port=80/tcp —permanent 重启防火墙 firewall-cmd –reload nginx 常用操作命令和配置文件启动命令在/usr/local/nginx/sbin 目录下执行 ./nginx 关闭命令在/usr/local/nginx/sbin 目录下执行 ./nginx -s stop 重新加载命令在/usr/local/nginx/sbin 目录下执行 ./nginx -s reload nginx.conf 配置文件nginx 安装目录下，其默认的配置文件都放在这个目录的 conf 目录下，而主配置文件nginx.conf 也在其中，后续对 nginx 的使用基本上都是对此配置文件进行相应的修改。 配置文件中有很多#， 开头的表示注释内容，我们去掉所有以 # 开头的段落，精简之后的内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 根据上述文件，我们可以很明显的将 nginx.conf 配置文件分为三部分： 第一部分：全局块从配置文件开始到 events 块之间的内容，主要会设置一些影响 nginx 服务器整体运行的配置指令，主要包括：配置运行 Nginx 服务器的用户（组）、允许生成的 worker process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。 比如上面第一行配置的： 123456#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid; 这是 Nginx 服务器并发处理服务的关键配置，worker_processes 值越大，可以支持的并发处理量也越多，但是会受到硬件、软件等设备的制约。 第二部分：events 块比如上面的配置： 123events &#123; worker_connections 1024;&#125; events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 work process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 word process 可以同时支持的最大连接数等。 上述例子就表示每个 work process 支持的最大连接数为 1024。 1这部分的配置对 Nginx 的性能影响较大，在实际中应该灵活配置。 第三部分：http 块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677http &#123; include mime.types; default_type application/octet-stream; #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 这算是 Nginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。 需要注意的是：http 块也可以包括 http 全局块、server 块。 http 全局块http 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。 server 块这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。 每个 http 块可以包括多个 server 块，而每个 server 块就相当于一个虚拟主机。 而每个 server 块也分为全局 server 块，以及可以同时包含多个 locaton 块。 1**1、全局 server 块** 最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。 2、location 块 一个 server 块可以配置多个 location 块。 这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是 IP 别名）之外的字符串（例如 前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。 nginx 配置实例-反向代理反向代理实例一实现效果：使用 nginx 反向代理，访问 www.123.com 直接跳转到 127.0.0.1:8080 具体步骤： 1. 安装tomcat 解压缩命令：tar -xvf apache-tomcat-7.0.70.tar.gz 2. 安装jdk(并配置环境变量)首先查看linux 是否自带jdk java -version : 如果显示jdk版本号，则说明自带有jdk，无需要额外安装 如果不显示，就需要安装jdk1.8 并配置环境变量： 2.1 下载jdk1.8下载地址 http://www.oracle.com/technetwork/java/javase/downloads/index.html 往下来拉找到jdk1.8版本的下载地址，点击下载对应的tar.gz文件: 将下载的jdk 压缩包放入 usr/src 下 2.2 解压jdk压缩包命令：tar -zxvf jdk-8u251-linux-x64.tar.gz 2.3 配置jdk环境变量键入命令 vim /etc/profile 修改配置文件，记得要在root权限下修改 输入i进入编辑状态，然后将光标移到最后一行(GG最后一行 gg第一行)，粘贴如下内容： 1JAVA_HOME=/usr/src/jdk1.8.0_251 ##要根据自己的解压目录设置 具体内容如下： 1234#java environmentexport JAVA_HOME=/usr/src/jdk1.8.0_251export CLASSPATH=.:$&#123;JAVA_HOME&#125;/jre/lib/rt.jar:$&#123;JAVA_HOME&#125;/lib/dt.jar:$&#123;JAVA_HOME&#125;/lib/tools.jarexport PATH=$PATH:$&#123;JAVA_HOME&#125;/bin 然后键入命令source /etc/profile 使配置文件生效 2.4 测试安装效果java -version 显示上图则jdk 配置完成! 3. 启动 tomcat 启动步骤如上图所示，测试访问(这里需要注意，如果访问不成功，就有可能是你的linux 防火墙没有开8080端口，需要修改下防火墙端口配置)： 开放端口80801sudo firewall-cmd --add-port=8080/tcp --permanent 重启防火墙1firewall-cmd –reload 查看已经开放的端口1firewall-cmd --list-all 测试 访问成功！ 4. 反向代理访问过程分析 5. 配置反向代理步骤5.1 本机 host 文件配置在本机windows 系统的 host 文件进行域名和ip 对应关系的配置。 在hosts文件最后添加如下配置 1192.168.88.132 www.123.com #Linux 主机ip 本机配置的域名 浏览器地址栏输入 www.123.com:8080，出现如下界面: 配置完成之后，我们便可以通过 www.123.com:8080 访问到第一步出现的 Tomcat 初始界面。那么如何只需要输入 www.123.com 便可以跳转到 Tomcat 初始界面呢？便用到 nginx的反向代理。 5.2 在 nginx 中进行请求转发配置(反向代理配置)找到nginx 的配置文件 nginx.conf 1234567[root@bogon bin]# cd /usr/local/nginx/[root@bogon nginx]# lsclient_body_temp conf fastcgi_temp html logs proxy_temp sbin scgi_temp uwsgi_temp[root@bogon nginx]# cd conf/[root@bogon conf]# lsfastcgi.conf fastcgi_params koi-utf mime.types nginx.conf scgi_params uwsgi_params win-utf fastcgi.conf.default fastcgi_params.default koi-win mime.types.default nginx.conf.default scgi_params.default uwsgi_params.default[root@bogon conf]# vi nginx.conf 在 nginx.conf 配置文件中增加如下配置: 1234567891011121314151617server &#123; listen 80; server_name 192.168.88.132; #nginx访问地址 #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; proxy_pass http://192.168.88.132:8080; #转发到目标地址 index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; 如上配置，我们监听 80 端口，访问域名为 www.123.com，不加端口号时默认为 80 端口，故访问该域名时会跳转到 192.168.88.132:8080 路径上。 5.3 启动nginx测试在浏览器端输入 www.123.com 结果如下： 注意：修改完nginx.conf 配置文件后，启动nginx 重新加载一下配置文件 ./nginx -s reload 反向代理成功！ 反向代理实例二实现效果：使用 nginx 反向代理，根据访问的路径跳转到不同端口的服务中 nginx 监听端口为 9001， 访问 http://127.0.0.1:9001/edu/ 直接跳转到 127.0.0.1:8081 访问 http://127.0.0.1:9001/vod/ 直接跳转到 127.0.0.1:8082 反向代理配置步骤1. 准备两个 tomcat在usr/src 下建立两个文件夹 tomcat8081 tomcat8082，并在这两个文件夹下放入两个tomcat ，并解压。 创建文件夹命令：mkdir tomcat8081，mkdir tomcat8082 解压命令：tar -xvf apache-tomcat-7.0.70.tar.gz 先查看本机的tomcat是否正在运行：ps -ef|grep tomcat，如果正在运行根据运行的进程id号杀死正在运行的tomcat进程 kill 进程id号： 修改两个tomcat的端口号：一个 8081 端口，一个 8082 端口。 进入tomcat 的conf文件夹下，并vi server.xml，修改内容为如下面标记位置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130&lt;?xml version=&#x27;1.0&#x27; encoding=&#x27;utf-8&#x27;?&gt;&lt;!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.--&gt;&lt;!-- Note: A &quot;Server&quot; is not itself a &quot;Container&quot;, so you may not define subcomponents such as &quot;Valves&quot; at this level. Documentation at /docs/config/server.html --&gt;&lt;!-- 为避免冲突从8005改为8025 --&gt;&lt;Server port=&quot;8025&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt; &lt;!-- Security listener. Documentation at /docs/config/listeners.html &lt;Listener className=&quot;org.apache.catalina.security.SecurityListener&quot; /&gt; --&gt; &lt;!--APR library loader. Documentation at /docs/apr.html --&gt; &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; &lt;!--Initialize Jasper prior to webapps are loaded. Documentation at /docs/jasper-howto.html --&gt; &lt;Listener className=&quot;org.apache.catalina.core.JasperListener&quot; /&gt; &lt;!-- Prevent memory leaks due to use of particular java/javax APIs--&gt; &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; &lt;!-- Global JNDI resources Documentation at /docs/jndi-resources-howto.html --&gt; &lt;GlobalNamingResources&gt; &lt;!-- Editable user database that can also be used by UserDatabaseRealm to authenticate users --&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt; &lt;/GlobalNamingResources&gt; &lt;!-- A &quot;Service&quot; is a collection of one or more &quot;Connectors&quot; that share a single &quot;Container&quot; Note: A &quot;Service&quot; is not itself a &quot;Container&quot;, so you may not define subcomponents such as &quot;Valves&quot; at this level. Documentation at /docs/config/service.html --&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;!--The connectors can use a shared executor, you can define one or more named thread pools--&gt; &lt;!-- &lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot;/&gt; --&gt; &lt;!-- A &quot;Connector&quot; represents an endpoint by which requests are received and responses are returned. Documentation at : Java HTTP Connector: /docs/config/http.html (blocking &amp; non-blocking) Java AJP Connector: /docs/config/ajp.html APR (HTTP/AJP) Connector: /docs/apr.html Define a non-SSL HTTP/1.1 Connector on port 8080 --&gt; &lt;!-- 为避免冲突从8080改为8081 --&gt; &lt;Connector port=&quot;8081&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;!-- A &quot;Connector&quot; using the shared thread pool--&gt; &lt;!-- &lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; --&gt; &lt;!-- Define a SSL HTTP/1.1 Connector on port 8443 This connector uses the BIO implementation that requires the JSSE style configuration. When using the APR/native implementation, the OpenSSL style configuration is required as described in the APR/native documentation --&gt; &lt;!-- &lt;Connector port=&quot;8443&quot; protocol=&quot;org.apache.coyote.http11.Http11Protocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; /&gt; --&gt; &lt;!-- Define an AJP 1.3 Connector on port 8009 --&gt; &lt;!-- 为避免冲突从8009改为8029 --&gt; &lt;Connector port=&quot;8029&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;!-- An Engine represents the entry point (within Catalina) that processes every request. The Engine implementation for Tomcat stand alone analyzes the HTTP headers included with the request, and passes them on to the appropriate Host (virtual host). Documentation at /docs/config/engine.html --&gt; &lt;!-- You should set jvmRoute to support load-balancing via AJP ie : &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot; jvmRoute=&quot;jvm1&quot;&gt; --&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; &lt;!--For clustering, please take a look at documentation at: /docs/cluster-howto.html (simple how to) /docs/config/cluster.html (reference documentation) --&gt; &lt;!-- &lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot;/&gt; --&gt; &lt;!-- Use the LockOutRealm to prevent attempts to guess user passwords via a brute-force attack --&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;!-- This Realm uses the UserDatabase configured in the global JNDI resources under the key &quot;UserDatabase&quot;. Any edits that are performed against this UserDatabase are immediately available for use by the Realm. --&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;!-- SingleSignOn valve, share authentication between web applications Documentation at: /docs/config/valve.html --&gt; &lt;!-- &lt;Valve className=&quot;org.apache.catalina.authenticator.SingleSignOn&quot; /&gt; --&gt; &lt;!-- Access log processes all example. Documentation at: /docs/config/valve.html Note: The pattern used is equivalent to using pattern=&quot;common&quot; --&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &quot;%r&quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 修改完成后，到bin目录下 ./startup.sh 运行8082端口的tomcat 同理8082端口的tomcat 同样如上配置并运行启动！ 2.为两个tomcat 添加页面向两个tomcat服务器的webapps下分别创建edu 和 文件夹，并将a.html 和 b.html 分别放入这两个文件夹。(注：a.html 和 b.html 自己随便建立一个，里面输入自己想展示的信息，能够区分是来自不同tomcat 服务器即可) 测试访问： 3. nginx.conf配置反向代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name 192.168.88.132; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; proxy_pass http://127.0.0.1:8080; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # 在这里把注释去掉，添加一个server 端口监听9001 server &#123; listen 9001; server_name 192.168.88.132; # 在下面 配置转发到不同的tomcat 中的内容 格式：~ /项目名/ location ~ /edu/ &#123; proxy_pass http://127.0.0.1:8001; &#125; location ~ /vod/ &#123; proxy_pass http://127.0.0.1:8002; &#125; &#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 配置完成后，开放对外访问的端口号，如果防火墙已经关闭就不用了。 在/nginx/sbin/中执行 ./nginx -s reload 重新加载配置文件。 4. 测试 5. location 指令说明该指令用于匹配 URL。语法如下： = ：用于不含正则表达式的 uri 前，要求请求字符串与 uri 严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求。 ~：用于表示 uri 包含正则表达式，并且区分大小写。 ~*：用于表示 uri 包含正则表达式，并且不区分大小写。 ^~：用于不含正则表达式的 uri 前，要求 Nginx 服务器找到标识 uri 和请求字符串匹配度最高的 location 后，立即使用此 location 处理请求，而不再使用 location 块中的正则 uri 和请求字符串做匹配。 注意：如果 uri 包含正则表达式，则必须要有 ~ 或者 ~* 标识。 nginx 配置实例-负载均衡1、实现效果浏览器地址栏输入地址http://192.168.17.129/edu/a.html，负载均衡效果，平均到8082和 8081 端口中。 2、准备工作准备两 tomcat 服务器，一台 8082，一台 8081 在两台 tomcat 里面 webapps 目录中，创建名称是 edu 文件夹，在edu 文件夹中创建页面 a.html，用于测试。 3. 在 nginx 的配置文件中进行负载均衡的配置nginx.conf配置如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; # 加上upstream upstream myserver &#123; server 192.168.88.132:8080; #参与负载均衡的服务器地址1 server 192.168.88.132:8081; #参与负载均衡的服务器地址2 &#125; server &#123; listen 80; server_name 192.168.88.132; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; # 加上代理规则 proxy_pass http://myserver; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 4.访问测试访问http://192.168.88.132/edu/a.html：第一次访问显示如下： 刷新页面，效果如下： 可以看出，访问该页面的时候，nginx会把请求平均分担到8080和8081两个服务器。 5.nginx分配服务器策略第一种 轮询策略（默认）： 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。 第二种 权重策略 weight： weight 代表权重默认为 1,权重越高被分配的客户端越多。 123456#例如： upstream myserver &#123; server 192.168.88.132:8080 weight=5; #参与负载均衡的服务器地址1 server 192.168.88.132:8081 weight=10; #参与负载均衡的服务器地址2 &#125;# 如上，8080的权重为5 8081权重为10，则nginx 负载均衡分配时，分配的8081比例更大 第三种 ip哈希策略 ip_hash： 每个请求按访问 ip 的hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决session问题。 1234567#例如： upstream myserver &#123; ip_hash server 192.168.88.132:8080; #参与负载均衡的服务器地址1 server 192.168.88.132:8081; #参与负载均衡的服务器地址2 &#125;# 如上，每个请求按访问 ip 的hash 结果分配，即：某一个用户访问该服务器，根据该用户的ip地址分配一个ip_hash，并随机分配到端口为8080或者8081的服务器，该用户这个ip下次再访问服务器时，仍然默认访问上次分配的服务器，而不会再次随机分配。 第四种 fair（第三方）： 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 1234567#例如： upstream myserver &#123; server 192.168.88.132:8080; #参与负载均衡的服务器地址1 server 192.168.88.132:8081; #参与负载均衡的服务器地址2 fair &#125;# 如上，访问该服务器时，通过判断 8080 或者 8081 服务器响应的时间，来进行分配访问，谁的响应时间短，优先访问谁。 Nginx配置实例-动静分离1. 动静分离简述Nginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx 处理静态页面，Tomcat 处理动态页面。动静分离从目前实现角度来讲大致分为两种，一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案；另外一种方法就是动态跟静态文件混合在一起发布，通过 nginx 来分开。 通过location 指定不同的后缀名实现不同的请求转发。通过 expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（如果经常更新的文件，不建议使用 Expires 来缓存），我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码304，如果有修改，则直接从服务器重新下载，返回状态码 200。 执行流程图 2. 准备工作在 liunx 系统中准备静态资源，用于进行访问： 首先在根路径下创建 staticresource 文件夹，并在其中建立 www 和 image文件夹用于存放静态资源： 在www 文件夹中放置一个a.html 在 image 放置lf.jpg 3. 具体配置在nginx 配置文件中配置静态资源访问 配置内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name 192.168.88.132; #charset koi8-r; #access_log logs/host.access.log main; #配置静态资源访问 location /www/ &#123; root /staticresource/; index index.html index.htm; &#125; location /image/&#123; root /staticresource/; autoindex on; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 4. 测试查看效果浏览器中输入地址 http://192.168.88.132/image/lf.jpg http://192.168.88.132/www/a.html Nginx配置高可用的集群(了解) 什么是高可用 1、需要的环境 （1）需要两台 nginx 服务器（2）需要 keepalived（3）需要虚拟 ip 2、配置高可用的准备工作（1）需要两台服务器 192.168.17.129 和 192.168.17.131（2）在两台服务器安装 nginx（3）在两台服务器安装 keepalived 3、在两台服务器安装 keepalived（1）使用 yum 命令进行安装yum install keepalived –y （2）安装之后，在 etc 里面生成目录 keepalived，有文件 keepalived.conf 4、完成高可用配置（主从配置）（1）修改/etc/keepalived/keepalivec.conf 配置文件 123456789101112131415161718192021222324252627282930global_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.17.129 smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_script chk_http_port &#123; script &quot;/usr/local/src/nginx_check.sh&quot; interval 2 #（检测脚本执行的间隔） weight 2&#125;vrrp_instance VI_1 &#123; state BACKUP # 备份服务器上将 MASTER 改为 BACKUP interface ens33 //网卡 virtual_router_id 51 # 主、备机的 virtual_router_id 必须相同 priority 90 # 主、备机取不同的优先级，主机值较大，备份机值较小 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.17.50 // VRRP H 虚拟地址 &#125; &#125; （2）在/usr/local/src 添加检测脚本 123456789#!/bin/bashA=`ps -C nginx –no-header |wc -l`if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx sleep 2 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then killall keepalived fifi （3）把两台服务器上 nginx 和 keepalived 启动启动 nginx：./nginx 启动 keepalived：systemctl start keepalived.service 5、最终测试（1）在浏览器地址栏输入 虚拟 ip 地址 192.168.17.50 （2）把主服务器（192.168.17.129）nginx 和 keepalived 停止，再输入 192.168.17.50 Nginx的原理1、mater 和 worker 2、worker如何进行工作的 3、一个 master 和多个 woker 有好处（1）可以使用 nginx –s reload 热部署，利用 nginx 进行热部署操作（2）每个 woker 是独立的进程，如果有其中的一个 woker 出现问题，其他 woker 独立的，继续进行争抢，实现请求过程，不会造成服务中断 4、设置多少个 woker 合适worker 数和服务器的 cpu 数相等是最为适宜的。 5、连接数 worker_connection第一个：发送请求，占用了 woker 的几个连接数？答案：2 或者 4 个第二个：nginx 有一个 master，有四个 woker，每个 woker 支持最大的连接数 1024，支持的最大并发数是多少？ 普通的静态访问最大并发数是： worker_connections * worker_processes /2。 而如果是 HTTP 作 为反向代理来说，最大并发数量应该是 worker_connections *worker_processes/4。","tags":["笔记"],"categories":["Nginx"]},{"title":"springboot整合swagger入门","path":"/2021/11/12/swagger1/","content":"Swagger 简介学习目标： 了解Swagger的概念及作用 掌握在项目中集成Swagger自动生成API文档 Swagger协调前后端分离 前后端分离 前端 -&gt; 前端控制层、视图层 后端 -&gt; 后端控制层、服务层、数据访问层 前后端通过API进行交互 前后端相对独立且松耦合 产生的问题 前后端集成，前端或者后端无法做到“及时协商，尽早解决”，最终导致问题集中爆发 解决方案 首先定义schema [ 计划的提纲 ]，并实时跟踪最新的API，降低集成风险 Swagger 号称世界上最流行的API框架 Restful Api 文档在线自动生成器 =&gt; API 文档 与API 定义同步更新 直接运行，在线测试API 支持多种语言 （如：Java，PHP等） 官网：https://swagger.io/ SpringBoot集成SwaggerSpringBoot集成Swagger =&gt; springfox，两个jar包 Springfox-swagger2 swagger-springmvc 使用Swagger 要求：jdk 1.8 + 否则swagger2无法运行 步骤： 1、新建一个SpringBoot-web项目 2、添加Maven依赖 123456789101112&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger2 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger-ui --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 3、编写HelloController，测试确保运行成功！ 4、要使用Swagger，我们需要编写一个配置类-SwaggerConfig来配置 Swagger 1234@Configuration //配置类@EnableSwagger2// 开启Swagger2的自动配置public class SwaggerConfig &#123;&#125; 5、启动springboot访问测试 ：http://localhost:8080/swagger-ui.html ，可以看到swagger的界面: 配置Swagger1、Swagger实例Bean是Docket，所以通过配置Docket实例来配置Swaggger。 1234@Bean //配置docket以配置Swagger具体参数public Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2);&#125; 2、可以通过apiInfo()属性配置文档信息 1234567891011121314//配置文档信息private ApiInfo apiInfo() &#123; Contact contact = new Contact(&quot;联系人名字&quot;, &quot;http://xxx.xxx.com/联系人访问链接&quot;, &quot;联系人邮箱&quot;); return new ApiInfo( &quot;Swagger学习&quot;, // 标题 &quot;学习演示如何配置Swagger&quot;, // 描述 &quot;v1.0&quot;, // 版本 &quot;http://terms.service.url/组织链接&quot;, // 组织链接 contact, // 联系人信息 &quot;Apach 2.0 许可&quot;, // 许可 &quot;许可链接&quot;, // 许可连接 new ArrayList&lt;&gt;()// 扩展 );&#125; 3、Docket 实例关联上 apiInfo() 1234@Beanpublic Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo());&#125; 4、重启项目，访问测试 http://localhost:8080/swagger-ui.html 看下效果； 配置扫描接口swagger文档默认访问该页面： 1、构建Docket时通过select()方法配置怎么扫描接口。 123456789@Beanpublic Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select()// 通过.select()方法，去配置扫描接口,RequestHandlerSelectors配置如何扫描接口 .apis(RequestHandlerSelectors.basePackage( &quot;com.kuang.swagger.controller&quot;)) .build();&#125; 2、重启项目测试，由于我们配置根据包的路径扫描接口，所以我们只能看到一个类 3、除了通过包路径配置扫描接口外，还可以通过配置其他方式扫描接口，这里注释一下所有的配置方式： 1234567any() // 扫描所有，项目中的所有接口都会被扫描到none() // 不扫描接口// 通过方法上的注解扫描，如withMethodAnnotation(GetMapping.class)只扫描get请求withMethodAnnotation(final Class&lt;? extends Annotation&gt; annotation)// 通过类上的注解扫描，如.withClassAnnotation(Controller.class)只扫描有controller注解的类中的接口withClassAnnotation(final Class&lt;? extends Annotation&gt; annotation)basePackage(final String basePackage) // 根据包路径扫描接口 4、除此之外，我们还可以配置接口扫描过滤： 1234567891011@Beanpublic Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select()// 通过.select()方法，去配置扫描接口,RequestHandlerSelectors配置如何扫描接口 .apis(RequestHandlerSelectors.basePackage( &quot;com.kuang.swagger.controller&quot;)) // 配置如何通过path过滤,即这里只扫描请求以/kuang开头的接口 .paths(PathSelectors.ant(&quot;/kuang/**&quot;)) .build();&#125; 5、这里的可选值还有 1234any() // 任何请求都扫描none() // 任何请求都不扫描regex(final String pathRegex) // 通过正则表达式控制ant(final String antPattern) // 通过ant()控制 配置Swagger开关1、通过enable()方法配置是否启用swagger，如果是false，swagger将不能在浏览器中访问了 1234567891011@Beanpublic Docket docket() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .enable(false) //配置是否启用Swagger，如果是false，在浏览器将无法访问 .select()// 通过.select()方法，去配置扫描接口,RequestHandlerSelectors配置如何扫描接口 .apis(RequestHandlerSelectors.basePackage(&quot;com.kuang.swagger.controller&quot;)) // 配置如何通过path过滤,即这里只扫描请求以/kuang开头的接口 .paths(PathSelectors.ant(&quot;/kuang/**&quot;)) .build();&#125; 2、如何动态配置当项目处于test、dev环境时显示swagger，处于prod时不显示？ 12345678910111213141516@Beanpublic Docket docket(Environment environment) &#123; // 设置要显示swagger的环境 Profiles of = Profiles.of(&quot;dev&quot;, &quot;test&quot;); // 判断当前是否处于该环境 // 通过 enable() 接收此参数判断是否要显示 boolean b = environment.acceptsProfiles(of); return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .enable(b) //配置是否启用Swagger，如果是false，在浏览器将无法访问 .select()// 通过.select()方法，去配置扫描接口,RequestHandlerSelectors配置如何扫描接口 .apis(RequestHandlerSelectors.basePackage(&quot;com.kuang.swagger.controller&quot;)) // 配置如何通过path过滤,即这里只扫描请求以/kuang开头的接口 .paths(PathSelectors.ant(&quot;/kuang/**&quot;)) .build();&#125; 3、可以在项目中增加一个dev的配置文件查看效果！ [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-WV2rQd54-1600066716545)(D:\\Note\\笔记\\中间件\\swagger\\swagger.assets\\640)] 配置API分组[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-XfqELryh-1600066716547)(D:\\Note\\笔记\\中间件\\swagger\\swagger.assets\\640)]1、如果没有配置分组，默认是default。通过groupName()方法即可配置分组： 123456@Beanpublic Docket docket(Environment environment) &#123; return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()) .groupName(&quot;海贼王&quot;) // 配置分组名称 // 省略配置....&#125; 2、重启项目查看分组 3、如何配置多个分组？配置多个分组只需要配置多个docket即可： 123456789101112@Bean public Docket docket1()&#123; return new Docket(DocumentationType.SWAGGER_2).groupName(&quot;路飞&quot;); &#125; @Bean public Docket docket2()&#123; return new Docket(DocumentationType.SWAGGER_2).groupName(&quot;山治&quot;); &#125; @Bean public Docket docket3()&#123; return new Docket(DocumentationType.SWAGGER_2).groupName(&quot;索隆&quot;); &#125; 4、重启项目查看即可，如图： 在这里插入图片描述 实体配置1、新建一个实体类 1234567@ApiModel(&quot;用户实体&quot;)public class User &#123; @ApiModelProperty(&quot;用户名&quot;) public String username; @ApiModelProperty(&quot;密码&quot;) public String password;&#125; 2、只要这个实体在请求接口的返回值上（即使是泛型），都能映射到实体项中： 12345// 只要这个实体在请求接口的返回值上（即使是泛型），都能映射到实体项中@PostMapping(&quot;/user&quot;)public User user()&#123; return new User();&#125; 3、重启查看测试 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-DRRkItto-1600066716549)(D:\\Note\\笔记\\中间件\\swagger\\swagger.assets\\640)] 注：并不是因为@ApiModel这个注解让实体显示在这里了，而是只要出现在接口方法的返回值上的实体都会显示在这里，而@ApiModel和@ApiModelProperty这两个注解只是为实体添加注释的。 @ApiModel为类添加注释 @ApiModelProperty为类属性添加注释 常用注解Swagger的所有注解定义在io.swagger.annotations包下 下面列一些经常用到的，未列举出来的可以另行查阅说明： Swagger注解 简单说明 @Api(tags = “xxx模块说明”) 作用在模块类上 @ApiOperation(“xxx接口说明”) 作用在接口方法上 @ApiModel(“xxxPOJO说明”) 作用在模型类上：如VO、pojo、entity @ApiModelProperty(value = “xxx属性说明”,hidden = true) 作用在类方法和属性上，hidden设置为true可以隐藏该属性 @ApiParam(“xxx参数说明”) 作用在参数、方法和字段上，类似@ApiModelProperty 我们也可以给请求的接口配置一些注释 12345678910111213141516171819/** * @Auther: csp1999 * @Date: 2020/09/06/11:11 * @Description: */@Api(tags = &quot;Hello控制类&quot;)@RestControllerpublic class HelloController &#123; @GetMapping(&quot;/hello&quot;) public String helloController()&#123; return &quot;hello&quot;; &#125; // 只要这个实体在请求接口的返回值上（即使是泛型），都能映射到实体项中 @ApiOperation(&quot;hello控制类user方法&quot;) @PostMapping(&quot;/user&quot;) public User user(@ApiParam(&quot;用户名&quot;) String username)&#123; return new User(); &#125;&#125; 这样的话，可以给一些比较难理解的属性或者接口，增加一些配置信息，让人更容易阅读！ 如图： 相较于传统的Postman或Curl方式测试接口，使用swagger简直就是傻瓜式操作，不需要额外说明文档(写得好本身就是文档)而且更不容易出错，只需要录入数据然后点击Execute，如果再配合自动化框架，可以说基本就不需要人为操作了。 Swagger是个优秀的工具，现在国内已经有很多的中小型互联网公司都在使用它，相较于传统的要先出Word接口文档再测试的方式，显然这样也更符合现在的快速迭代开发行情。当然了，提醒下大家在正式环境要记得关闭Swagger，一来出于安全考虑二来也可以节省运行时内存。 测试获取数据 发送请求数据，点击execute： 响应回来的结果： 拓展：其他皮肤我们可以导入不同的包实现不同的皮肤定义： 1、默认的 访问 http://localhost:8080/swagger-ui.html 12345&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-OYVeu8Ld-1600066716554)(D:\\Note\\笔记\\中间件\\swagger\\swagger.assets\\640)] 2、bootstrap-ui 访问 http://localhost:8080/doc.html 123456&lt;!-- 引入swagger-bootstrap-ui包 /doc.html--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt; [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-RcfHXKfa-1600066716555)(D:\\Note\\笔记\\中间件\\swagger\\swagger.assets\\640)] 3、Layui-ui 访问 http://localhost:8080/docs.html 123456&lt;!-- 引入swagger-ui-layer包 /docs.html--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.caspar-chen&lt;/groupId&gt; &lt;artifactId&gt;swagger-ui-layer&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt;&lt;/dependency&gt; [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-YdlgxhxZ-1600066716556)(D:\\Note\\笔记\\中间件\\swagger\\swagger.assets\\640)] 4、mg-ui 访问 http://localhost:8080/document.html 123456&lt;!-- 引入swagger-ui-layer包 /document.html--&gt;&lt;dependency&gt; &lt;groupId&gt;com.zyplayer&lt;/groupId&gt; &lt;artifactId&gt;swagger-mg-ui&lt;/artifactId&gt; &lt;version&gt;1.0.6&lt;/version&gt;&lt;/dependency&gt;","tags":["笔记"],"categories":["Java"]},{"title":"零基础spring学习笔记","path":"/2021/11/12/spring-1/","content":"Spring概述 官网地址 官网 : http://spring.io/ 官方下载地址 : https://repo.spring.io/libs-release-local/org/springframework/spring/ GitHub : https://github.com/spring-projects 优点 1、Spring是一个开源免费的框架 , 容器 . 2、Spring是一个轻量级的框架 , 非侵入式的 . 3、控制反转 IoC , 面向切面 Aop(核心) 4、对事物的支持 , 对框架的支持 Spring是一个轻量级的控制反转(IoC)和面向切面(AOP)的容器（框架）。 Spring 组成 Spring 框架是一个分层架构，由 7 个定义良好的模块组成。Spring 模块构建在核心容器之上，核心容器定义了创建、配置和管理 bean 的方式 . 组成 Spring 框架的每个模块（或组件）都可以单独存在，或者与其他一个或多个模块联合实现。每个模块的功能如下： 核心容器：核心容器提供 Spring 框架的基本功能。核心容器的主要组件是BeanFactory，它是工厂模式的实现。BeanFactory 使用控制反转（IOC） 模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。 Spring 上下文：Spring 上下文是一个配置文件，向 Spring 框架提供上下文信息。Spring 上下文包括企业服务，例如 JNDI、EJB、电子邮件、国际化、校验和调度功能。 Spring AOP：通过配置管理特性，Spring AOP 模块直接将面向切面的编程功能 , 集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理任何支持 AOP的对象。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖组件，就可以将声明性事务管理集成到应用程序中。 Spring DAO：JDBC DAO 抽象层提供了有意义的异常层次结构，可用该结构来管理异常处理和不同数据库供应商抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写的异常代码数量（例如打开和关闭连接）。Spring DAO 的面向 JDBC 的异常遵从通用的 DAO 异常层次结构。 Spring ORM：Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。 Spring Web 模块：Web 上下文模块建立在应用程序上下文模块之上，为基于 Web 的应用程序提供了上下文。所以，Spring 框架支持与 Jakarta Struts 的集成。Web 模块还简化了处理多部分请求以及将请求参数绑定到域对象的工作。 Spring MVC 框架：MVC 框架是一个全功能的构建 Web 应用程序的 MVC 实现。通过策略接口，MVC 框架变成为高度可配置的，MVC 容纳了大量视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。 拓展 Spring Boot与Spring Cloud Spring Boot 是 Spring 的一套快速配置脚手架，可以基于Spring Boot 快速开发单个微服务; Spring Cloud是基于Spring Boot实现的； Spring Boot专注于快速、方便集成的单个微服务个体，Spring Cloud关注全局的服务治理框架； Spring Boot使用了约束优于配置的理念，很多集成方案已经帮你选择好了，能不配置就不配置 , Spring Cloud很大的一部分是基于Spring Boot来实现，Spring Boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring Boot，属于依赖的关系。 SpringBoot在SpringClound中起到了承上启下的作用，如果你要学习SpringCloud必须要学习SpringBoot。 IOC本质 控制反转IoC(Inversion of Control)，是一种设计思想，DI(依赖注入)是实现IoC的一种方法，也有人认为DI只是IoC的另一种说法。没有IoC的程序中 , 我们使用面向对象编程 , 对象的创建与对象间的依赖关系完全硬编码在程序中，对象的创建由程序自己控制，控制反转后将对象的创建转移给第三方，个人认为所谓控制反转就是：获得依赖对象的方式反转了。 IoC是Spring框架的核心内容，使用多种方式完美的实现了IoC，可以使用XML配置，也可以使用注解，新版本的Spring也可以零配置实现IoC。 Spring容器在初始化时先读取配置文件，根据配置文件或元数据创建与组织对象存入容器中，程序使用时再从Ioc容器中取出需要的对象。 采用XML方式配置Bean的时候，Bean的定义信息是和实现分离的，而采用注解的方式可以把两者合为一体，Bean的定义信息直接以注解的形式定义在实现类中，从而达到了零配置的目的。 控制反转是一种通过描述（XML或注解）并通过第三方去生产或获取特定对象的方式。在Spring中实现控制反转的是IoC容器，其实现方法是依赖注入（Dependency Injection,DI）。 快速上手Spring入门案例一 导入Jar包 注 : spring 需要导入commons-logging进行日志记录 . 我们利用maven , 他会自动下载对应的依赖项 . 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.1.10.RELEASE&lt;/version&gt;&lt;/dependency&gt; 编写代码 1、编写一个Hello实体类 123456789101112public class Hello &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public void show()&#123; System.out.println(&quot;Hello,&quot;+ name ); &#125;&#125; 2、编写我们的spring文件 , 这里我们命名为beans.xml 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!--bean就是java对象 , 由Spring创建和管理--&gt; &lt;bean id=&quot;hello&quot; class=&quot;com.kuang.pojo.Hello&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;Spring&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 3、我们可以去进行测试了 . 12345678@Testpublic void test()&#123; //解析beans.xml文件 , 生成管理相应的Bean对象 ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); //getBean : 参数即为spring配置文件中bean的id . Hello hello = (Hello) context.getBean(&quot;hello&quot;); hello.show();&#125; 思考 Hello 对象是谁创建的 ? 【hello 对象是由Spring创建的 Hello 对象的属性是怎么设置的 ? hello 对象的属性是由Spring容器设置的这个过程就叫控制反转 : 控制 : 谁来控制对象的创建 , 传统应用程序的对象是由程序本身控制创建的 , 使用Spring后 , 对象是由Spring来创建的 反转 : 程序本身不创建对象 , 而变成被动的接收对象 . 依赖注入 : 就是利用set方法来进行注入的. IOC是一种编程思想，由主动的编程变成被动的接收 可以通过newClassPathXmlApplicationContext去浏览一下底层源码 . 修改案例一 我们在案例一中， 新增一个Spring配置文件beans.xml 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;MysqlImpl&quot; class=&quot;com.kuang.dao.impl.UserDaoMySqlImpl&quot;/&gt; &lt;bean id=&quot;OracleImpl&quot; class=&quot;com.kuang.dao.impl.UserDaoOracleImpl&quot;/&gt; &lt;bean id=&quot;ServiceImpl&quot; class=&quot;com.kuang.service.impl.UserServiceImpl&quot;&gt; &lt;!--注意: 这里的name并不是属性 , 而是set方法后面的那部分 , 首字母小写--&gt; &lt;!--引用另外一个bean , 不是用value 而是用 ref--&gt; &lt;property name=&quot;userDao&quot; ref=&quot;OracleImpl&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 测试！ 123456@Testpublic void test2()&#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserServiceImpl serviceImpl = (UserServiceImpl) context.getBean(&quot;ServiceImpl&quot;); serviceImpl.getUser();&#125; OK , 到了现在 , 我们彻底不用再程序中去改动了 , 要实现不同的操作 , 只需要在xml配置文件中进行修改 , 所谓的IoC,一句话搞定 : 对象由Spring 来创建 , 管理 , 装配 ! IOC创建对象方式1. 通过无参构造方法来创建1、User.java 123456789101112public class User &#123; private String name; public User() &#123; System.out.println(&quot;user无参构造方法&quot;); &#125; public void setName(String name) &#123; this.name = name; &#125; public void show()&#123; System.out.println(&quot;name=&quot;+ name ); &#125;&#125; 2、beans.xml 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;user&quot; class=&quot;com.kuang.pojo.User&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;kuangshen&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 3、测试类 12345678@Testpublic void test()&#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); //在执行getBean的时候, user已经创建好了 , 通过无参构造 User user = (User) context.getBean(&quot;user&quot;); //调用对象的方法 . user.show();&#125; 结果可以发现，在调用show方法之前，User对象已经通过无参构造初始化了！ 2. 通过有参构造方法来创建1、UserT . java 123456789101112public class UserT &#123; private String name; public UserT(String name) &#123; this.name = name; &#125; public void setName(String name) &#123; this.name = name; &#125; public void show()&#123; System.out.println(&quot;name=&quot;+ name ); &#125;&#125; 2、beans.xml 有三种方式编写 1234567891011121314&lt;!-- 第一种根据index参数下标设置 --&gt;&lt;bean id=&quot;userT&quot; class=&quot;com.kuang.pojo.UserT&quot;&gt; &lt;!-- index指构造方法 , 下标从0开始 --&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;kuangshen2&quot;/&gt;&lt;/bean&gt;&lt;!-- 第二种根据参数名字设置 --&gt;&lt;bean id=&quot;userT&quot; class=&quot;com.kuang.pojo.UserT&quot;&gt; &lt;!-- name指参数名 --&gt; &lt;constructor-arg name=&quot;name&quot; value=&quot;kuangshen2&quot;/&gt;&lt;/bean&gt;&lt;!-- 第三种根据参数类型设置 --&gt;&lt;bean id=&quot;userT&quot; class=&quot;com.kuang.pojo.UserT&quot;&gt; &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;kuangshen2&quot;/&gt;&lt;/bean&gt; 3、测试 123456@Testpublic void testT()&#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserT user = (UserT) context.getBean(&quot;userT&quot;); user.show();&#125; 结论：在配置文件加载的时候。其中管理的对象都已经初始化了！ Spring配置 别名 alias 设置别名 , 为bean设置别名 , 可以设置多个别名 12&lt;!--设置别名：在获取Bean的时候可以使用别名获取--&gt;&lt;alias name=&quot;userT&quot; alias=&quot;userNew&quot;/&gt; Bean的配置 1234567891011&lt;!--bean就是java对象,由Spring创建和管理--&gt;&lt;!-- id 是bean的标识符,要唯一,如果没有配置id,name就是默认标识符 如果配置id,又配置了name,那么name是别名 name可以设置多个别名,可以用逗号,分号,空格隔开 如果不配置id和name,可以根据applicationContext.getBean(.class)获取对象;class是bean的全限定名=包名+类名--&gt;&lt;bean id=&quot;hello&quot; name=&quot;hello2&quot; class=&quot;com.haust.pojo.Hello&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;Spring&quot;/&gt;&lt;/bean&gt; import 团队的合作通过import来实现 . 1&lt;import resource=&quot;&#123;path&#125;/beans.xml&quot;/&gt; 依赖注入（DI）概念 依赖注入（Dependency Injection,DI）。 依赖 : 指Bean对象的创建依赖于容器 . Bean对象的依赖资源 . 注入 : 指Bean对象所依赖的资源 , 由容器来设置和装配 . 构造器注入在之前的案例已经讲过了 Set 注入 （重点）要求被注入的属性 , 必须有set方法 , set方法的方法名由set + 属性首字母大写 , 如果属性是boolean类型 , 没有set方法 , 是 is . 测试pojo类 : Address.java 123456789public class Address &#123; private String address; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; &#125; Student.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.kuang.pojo; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.Set; public class Student &#123; private String name; private Address address; private String[] books; private List&lt;String&gt; hobbys; private Map&lt;String,String&gt; card; private Set&lt;String&gt; games; private String wife; private Properties info; public void setName(String name) &#123; this.name = name; &#125; public void setAddress(Address address) &#123; this.address = address; &#125; public void setBooks(String[] books) &#123; this.books = books; &#125; public void setHobbys(List&lt;String&gt; hobbys) &#123; this.hobbys = hobbys; &#125; public void setCard(Map&lt;String, String&gt; card) &#123; this.card = card; &#125; public void setGames(Set&lt;String&gt; games) &#123; this.games = games; &#125; public void setWife(String wife) &#123; this.wife = wife; &#125; public void setInfo(Properties info) &#123; this.info = info; &#125; public void show()&#123; System.out.println(&quot;name=&quot;+ name + &quot;,address=&quot;+ address.getAddress() + &quot;,books=&quot; ); for (String book:books)&#123; System.out.print(&quot;&lt;&lt;&quot;+book+&quot;&gt;&gt;\\t&quot;); &#125; System.out.println(&quot; 爱好:&quot;+hobbys); System.out.println(&quot;card:&quot;+card); System.out.println(&quot;games:&quot;+games); System.out.println(&quot;wife:&quot;+wife); System.out.println(&quot;info:&quot;+info); &#125; &#125; 1、常量注入123&lt;bean id=&quot;student&quot; class=&quot;com.kuang.pojo.Student&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;小明&quot;/&gt; &lt;/bean&gt; 测试： 123456@Test public void test01()&#123; ApplicationContext context = newClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); Student student = (Student) context.getBean(&quot;student&quot;); System.out.println(student.getName()); &#125; 2、Bean注入注意点：这里的值是一个引用，ref 1234567&lt;bean id=&quot;addr&quot; class=&quot;com.kuang.pojo.Address&quot;&gt; &lt;property name=&quot;address&quot; value=&quot;重庆&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;student&quot; class=&quot;com.kuang.pojo.Student&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;小明&quot;/&gt; &lt;property name=&quot;address&quot; ref=&quot;addr&quot;/&gt; &lt;/bean&gt; 3、数组注入1234567891011&lt;bean id=&quot;student&quot; class=&quot;com.kuang.pojo.Student&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;小明&quot;/&gt; &lt;property name=&quot;address&quot; ref=&quot;addr&quot;/&gt; &lt;property name=&quot;books&quot;&gt; &lt;array&gt; &lt;value&gt;西游记&lt;/value&gt; &lt;value&gt;红楼梦&lt;/value&gt; &lt;value&gt;水浒传&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; 4、List注入1234567&lt;property name=&quot;hobbys&quot;&gt; &lt;list&gt; &lt;value&gt;听歌&lt;/value&gt; &lt;value&gt;看电影&lt;/value&gt; &lt;value&gt;爬山&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; 5、Map注入123456&lt;property name=&quot;card&quot;&gt; &lt;map&gt; &lt;entry key=&quot;中国邮政&quot; value=&quot;456456456465456&quot;/&gt; &lt;entry key=&quot;建设&quot; value=&quot;1456682255511&quot;/&gt; &lt;/map&gt; &lt;/property&gt; 6、set注入1234567&lt;property name=&quot;games&quot;&gt; &lt;set&gt; &lt;value&gt;LOL&lt;/value&gt; &lt;value&gt;BOB&lt;/value&gt; &lt;value&gt;COC&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; 7、Null注入1&lt;property name=&quot;wife&quot;&gt;&lt;null/&gt;&lt;/property&gt; 8、Properties注入1234567&lt;property name=&quot;info&quot;&gt; &lt;props&gt; &lt;prop key=&quot;学号&quot;&gt;20190604&lt;/prop&gt; &lt;prop key=&quot;性别&quot;&gt;男&lt;/prop&gt; &lt;prop key=&quot;姓名&quot;&gt;小明&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; 测试结果： p命名和c命名注入User.java ：【注意：这里没有有参构造器！】 1234567891011121314151617public class User &#123; private String name; private int age; public void setName(String name) &#123; this.name = name; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, age=&quot; + age + &#x27;&#125;&#x27;; &#125; &#125; 1、P命名空间注入 : 需要在头文件中加入约束文件 123导入约束 : xmlns:p=&quot;http://www.springframework.org/schema/p&quot; &lt;!--P(属性: properties)命名空间 , 属性依然要设置set方法--&gt; &lt;bean id=&quot;user&quot; class=&quot;com.kuang.pojo.User&quot; p:name=&quot;狂神&quot; p:age=&quot;18&quot;/&gt; 2、c 命名空间注入 : 需要在头文件中加入约束文件 123导入约束 : xmlns:c=&quot;http://www.springframework.org/schema/c&quot; &lt;!--C(构造: Constructor)命名空间 , 属性依然要设置set方法--&gt; &lt;bean id=&quot;user&quot; class=&quot;com.kuang.pojo.User&quot; c:name=&quot;狂神&quot; c:age=&quot;18&quot;/&gt; 发现问题：爆红了，刚才我们没有写有参构造！ 解决：把有参构造器加上，这里也能知道，c 就是所谓的构造器注入！ 测试代码： 123456@Test public void test02()&#123; ApplicationContext context = newClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); User user = (User) context.getBean(&quot;user&quot;); System.out.println(user); &#125; Bean的作用域在Spring中，那些组成应用程序的主体及由Spring IoC容器所管理的对象，被称之为bean。简单地讲，bean就是由IoC容器初始化、装配及管理的对象 . 几种作用域中，request、session作用域仅在基于web的应用中使用（不必关心你所采用的是什么web应用框架），只能用在基于web的Spring ApplicationContext环境。 Singleton当一个bean的作用域为Singleton，那么Spring IoC容器中只会存在一个共享的bean实例，并且所有对bean的请求，只要id与该bean定义相匹配，则只会返回bean的同一实例。Singleton是单例类型，就是在创建起容器时就同时自动创建了一个bean的对象，不管你是否使用，他都存在了，每次获取到的对象都是同一个对象。注意，Singleton作用域是Spring中的缺省作用域。要在XML中将bean定义成singleton，可以这样配置： 1&lt;bean id=&quot;ServiceImpl&quot; class=&quot;cn.csdn.service.ServiceImpl&quot; scope=&quot;singleton&quot;&gt; 测试： 1234567@Test public void test03()&#123; ApplicationContext context = newClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); User user = (User) context.getBean(&quot;user&quot;); User user2 = (User) context.getBean(&quot;user&quot;); System.out.println(user==user2); &#125; Prototype当一个bean的作用域为Prototype，表示一个bean定义对应多个对象实例。Prototype作用域的bean会导致在每次对该bean请求（将其注入到另一个bean中，或者以程序的方式调用容器的getBean()方法）时都会创建一个新的bean实例。Prototype是原型类型，它在我们创建容器的时候并没有实例化，而是当我们获取bean的时候才会去创建一个对象，而且我们每次获取到的对象都不是同一个对象。根据经验，对有状态的bean应该使用prototype作用域，而对无状态的bean则应该使用singleton作用域。在XML中将bean定义成prototype，可以这样配置： 123&lt;bean id=&quot;account&quot; class=&quot;com.foo.DefaultAccount&quot; scope=&quot;prototype&quot;/&gt; 或者 &lt;bean id=&quot;account&quot; class=&quot;com.foo.DefaultAccount&quot; singleton=&quot;false&quot;/&gt; Request当一个bean的作用域为Request，表示在一次HTTP请求中，一个bean定义对应一个实例；即每个HTTP请求都会有各自的bean实例，它们依据某个bean定义创建而成。该作用域仅在基于web的Spring ApplicationContext情形下有效。考虑下面bean定义： 1&lt;bean id=&quot;loginAction&quot; class=cn.csdn.LoginAction&quot; scope=&quot;request&quot;/&gt; 针对每次HTTP请求，Spring容器会根据loginAction bean的定义创建一个全新的LoginAction bean实例，且该loginAction bean实例仅在当前HTTP request内有效，因此可以根据需要放心的更改所建实例的内部状态，而其他请求中根据loginAction bean定义创建的实例，将不会看到这些特定于某个请求的状态变化。当处理请求结束，request作用域的bean实例将被销毁。 Session当一个bean的作用域为Session，表示在一个HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。考虑下面bean定义： 1&lt;bean id=&quot;userPreferences&quot; class=&quot;com.foo.UserPreferences&quot; scope=&quot;session&quot;/&gt; 针对某个HTTP Session，Spring容器会根据userPreferences bean定义创建一个全新的userPreferences bean实例，且该userPreferences bean仅在当前HTTP Session内有效。与request作用域一样，可以根据需要放心的更改所创建实例的内部状态，而别的HTTP Session中根据userPreferences创建的实例，将不会看到这些特定于某个HTTP Session的状态变化。当HTTP Session最终被废弃的时候，在该HTTP Session作用域内的bean也会被废弃掉。 自动装配Bean的自动装配 自动装配说明 自动装配是使用spring满足bean依赖的一种方法 spring会在应用上下文中为某个bean寻找其依赖的bean。 Spring中bean有三种装配机制，分别是： 在xml中显式配置； 在java中显式配置； 隐式的bean发现机制和自动装配。 这里我们主要讲第三种：自动化的装配bean。 Spring的自动装配需要从两个角度来实现，或者说是两个操作： 组件扫描(component scanning)：spring会自动发现应用上下文中所创建的bean； 自动装配(autowiring)：spring自动满足bean之间的依赖，也就是我们说的IoC/DI； 组件扫描和自动装配组合发挥巨大威力，使得显示的配置降低到最少。 推荐不使用自动装配xml配置 , 而使用注解 . 测试环境搭建 1、新建一个项目 2、新建两个实体类，Cat Dog 都有一个叫的方法 12345678910public class Cat &#123; public void shout() &#123; System.out.println(&quot;miao~&quot;); &#125;&#125;public class Dog &#123; public void shout() &#123; System.out.println(&quot;wang~&quot;); &#125;&#125; 3、新建一个用户类 User 12345public class User &#123; private Cat cat; private Dog dog; private String str;&#125; 4、编写Spring配置文件 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;dog&quot; class=&quot;com.kuang.pojo.Dog&quot;/&gt; &lt;bean id=&quot;cat&quot; class=&quot;com.kuang.pojo.Cat&quot;/&gt; &lt;bean id=&quot;user&quot; class=&quot;com.kuang.pojo.User&quot;&gt; &lt;property name=&quot;cat&quot; ref=&quot;cat&quot;/&gt; &lt;property name=&quot;dog&quot; ref=&quot;dog&quot;/&gt; &lt;property name=&quot;str&quot; value=&quot;qinjiang&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 5、测试 123456789public class MyTest &#123; @Test public void testMethodAutowire() &#123; ApplicationContext context = newClassPathXmlApplicationContext(&quot;beans.xml&quot;); User user = (User) context.getBean(&quot;user&quot;); user.getCat().shout(); user.getDog().shout(); &#125;&#125; 结果正常输出，环境OK byName autowire byName (按名称自动装配) 由于在手动配置xml过程中，常常发生字母缺漏和大小写等错误，而无法对其进行检查，使得开发效率降低。 采用自动装配将避免这些错误，并且使配置简单化。 测试： 1、修改bean配置，增加一个属性 autowire=“byName” 123&lt;bean id=&quot;user&quot; class=&quot;com.kuang.pojo.User&quot; autowire=&quot;byName&quot;&gt; &lt;property name=&quot;str&quot; value=&quot;qinjiang&quot;/&gt;&lt;/bean&gt; 2、再次测试，结果依旧成功输出！ 3、我们将 cat 的bean id修改为 catXXX 4、再次测试， 执行时报空指针java.lang.NullPointerException。因为按byName规则找不对应set方法，真正的setCat就没执行，对象就没有初始化，所以调用时就会报空指针错误。 小结： 当一个bean节点带有 autowire byName的属性时。 将查找其类中所有的set方法名，例如setCat，获得将set去掉并且首字母小写的字符串，即cat。 去spring容器中寻找是否有此字符串名称id的对象。 如果有，就取出注入；如果没有，就报空指针异常。 byType autowire byType (按类型自动装配) 使用autowire byType首先需要保证：同一类型的对象，在spring容器中唯一。如果不唯一，会报不唯一的异常。 1NoUniqueBeanDefinitionException 测试： 1、将user的bean配置修改一下 ： autowire=“byType” 2、测试，正常输出 3、在注册一个cat 的bean对象！ 123456&lt;bean id=&quot;dog&quot; class=&quot;com.kuang.pojo.Dog&quot;/&gt;&lt;bean id=&quot;cat&quot; class=&quot;com.kuang.pojo.Cat&quot;/&gt;&lt;bean id=&quot;cat2&quot; class=&quot;com.kuang.pojo.Cat&quot;/&gt;&lt;bean id=&quot;user&quot; class=&quot;com.kuang.pojo.User&quot; autowire=&quot;byType&quot;&gt; &lt;property name=&quot;str&quot; value=&quot;qinjiang&quot;/&gt;&lt;/bean&gt; 4、测试，报错：NoUniqueBeanDefinitionException 5、删掉cat2，将cat的bean名称改掉！测试！因为是按类型装配，所以并不会报异常，也不影响最后的结果。甚至将id属性去掉，也不影响结果。 这就是按照类型自动装配！ 使用注解开启注解jdk1.5开始支持注解，spring2.5开始全面支持注解。 准备工作：利用注解的方式注入属性。 1、在spring配置文件中引入context文件头 123xmlns:context=&quot;http://www.springframework.org/schema/context&quot;http://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsd 2、开启属性注解支持！ 1&lt;context:annotation-config/&gt; @Autowired @Autowired是按类型自动转配的，不支持id匹配。 需要导入 spring-aop的包！ 测试： 1、将User类中的set方法去掉，使用@Autowired注解 12345678910111213141516public class User &#123; @Autowired private Cat cat; @Autowired private Dog dog; private String str; public Cat getCat() &#123; return cat; &#125; public Dog getDog() &#123; return dog; &#125; public String getStr() &#123; return str; &#125;&#125; 2、此时配置文件内容 1234&lt;context:annotation-config/&gt;&lt;bean id=&quot;dog&quot; class=&quot;com.kuang.pojo.Dog&quot;/&gt;&lt;bean id=&quot;cat&quot; class=&quot;com.kuang.pojo.Cat&quot;/&gt;&lt;bean id=&quot;user&quot; class=&quot;com.kuang.pojo.User&quot;/&gt; 3、测试，成功输出结果！ 【小狂神科普时间】 @Autowired(required=false) 说明：false，对象可以为null；true，对象必须存对象，不能为null。 123//如果允许对象为null，设置required = false,默认为true@Autowired(required = false)private Cat cat; @Qualifier @Autowired是根据类型自动装配的，加上@Qualifier则可以根据byName的方式自动装配 @Qualifier不能单独使用。 测试实验步骤： 1、配置文件修改内容，保证类型存在对象。且名字不为类的默认名字！ 1234&lt;bean id=&quot;dog1&quot; class=&quot;com.kuang.pojo.Dog&quot;/&gt;&lt;bean id=&quot;dog2&quot; class=&quot;com.kuang.pojo.Dog&quot;/&gt;&lt;bean id=&quot;cat1&quot; class=&quot;com.kuang.pojo.Cat&quot;/&gt;&lt;bean id=&quot;cat2&quot; class=&quot;com.kuang.pojo.Cat&quot;/&gt; 2、没有加Qualifier测试，直接报错 3、在属性上添加Qualifier注解 123456@Autowired@Qualifier(value = &quot;cat2&quot;)private Cat cat;@Autowired@Qualifier(value = &quot;dog2&quot;)private Dog dog; 测试，成功输出！ @Resource @Resource如有指定的name属性，先按该属性进行byName方式查找装配； 其次再进行默认的byName方式进行装配； 如果以上都不成功，则按byType的方式自动装配。 都不成功，则报异常。 实体类： 12345678public class User &#123; //如果允许对象为null，设置required = false,默认为true @Resource(name = &quot;cat2&quot;) private Cat cat; @Resource private Dog dog; private String str;&#125; beans.xml 1234&lt;bean id=&quot;dog&quot; class=&quot;com.kuang.pojo.Dog&quot;/&gt;&lt;bean id=&quot;cat1&quot; class=&quot;com.kuang.pojo.Cat&quot;/&gt;&lt;bean id=&quot;cat2&quot; class=&quot;com.kuang.pojo.Cat&quot;/&gt;&lt;bean id=&quot;user&quot; class=&quot;com.kuang.pojo.User&quot;/&gt; 测试：结果OK 配置文件2：beans.xml ， 删掉cat2 12&lt;bean id=&quot;dog&quot; class=&quot;com.kuang.pojo.Dog&quot;/&gt;&lt;bean id=&quot;cat1&quot; class=&quot;com.kuang.pojo.Cat&quot;/&gt; 实体类上只保留注解 1234@Resourceprivate Cat cat;@Resourceprivate Dog dog; 结果：OK 结论：先进行byName查找，失败；再进行byType查找，成功。 小结@Autowired与@Resource异同：1、@Autowired与@Resource都可以用来装配bean。都可以写在字段上，或写在setter方法上。 2、@Autowired默认按类型装配（属于spring规范），默认情况下必须要求依赖对象必须存在，如果要允许null 值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用 3、@Resource（属于J2EE复返），默认按照名称进行装配，名称可以通过name属性进行指定。如果没有指定name属性，当注解写在字段上时，默认取字段名进行按照名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。 它们的作用相同都是用注解方式注入对象，但执行顺序不同。@Autowired先byType，@Resource先byName。 使用注解开发说明在spring4之后，想要使用注解形式，必须得要引入aop的包 在配置文件当中，还得要引入一个context约束 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;&lt;/beans&gt; Bean的实现我们之前都是使用 bean 的标签进行bean注入，但是实际开发中，我们一般都会使用注解！ 1、配置扫描哪些包下的注解 12&lt;!--指定注解扫描包--&gt;&lt;context:component-scan base-package=&quot;com.kuang.pojo&quot;/&gt; 2、在指定包下编写类，增加注解 12345@Component(&quot;user&quot;)// 相当于配置文件中 &lt;bean id=&quot;user&quot; class=&quot;当前注解的类&quot;/&gt;public class User &#123; public String name = &quot;秦疆&quot;;&#125; 3、测试 1234567@Testpublic void test()&#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); User user = (User) applicationContext.getBean(&quot;user&quot;); System.out.println(user.name);&#125; 属性注入使用注解注入属性 @Component1、可以不用提供set方法，直接在直接名上添加@value(“值”) 1234567@Component(&quot;user&quot;)// 相当于配置文件中 &lt;bean id=&quot;user&quot; class=&quot;当前注解的类&quot;/&gt;public class User &#123; @Value(&quot;秦疆&quot;) // 相当于配置文件中 &lt;property name=&quot;name&quot; value=&quot;秦疆&quot;/&gt; public String name;&#125; 2、如果提供了set方法，在set方法上添加@value(“值”); 12345678@Component(&quot;user&quot;)public class User &#123; public String name; @Value(&quot;秦疆&quot;) public void setName(String name) &#123; this.name = name; &#125;&#125; 衍生注解我们这些注解，就是替代了在配置文件当中配置步骤而已！更加的方便快捷！ @Component三个衍生注解为了更好的进行分层，Spring可以使用其它三个注解，功能一样，目前使用哪一个功能都一样。 @Controller：web层 @Service：service层 @Repository：dao层 写上这些注解，就相当于将这个类交给Spring管理装配了！ 自动装配注解 在Bean的自动装配已经讲过了，可以回顾！ 作用域 @scope singleton：默认的，Spring会采用单例模式创建这个对象。关闭工厂 ，所有的对象都会销毁。 prototype：多例模式。关闭工厂 ，所有的对象不会销毁。内部的垃圾回收机制会回收 123456@Controller(&quot;user&quot;)@Scope(&quot;prototype&quot;)public class User &#123; @Value(&quot;秦疆&quot;) public String name;&#125; 配置类注解@ConfigurationJavaConfig 原来是 Spring 的一个子项目，它通过 Java 类的方式提供 Bean 的定义信息，在 Spring4 的版本， JavaConfig 已正式成为 Spring4 的核心功能 。 测试： 1、编写一个实体类，Dog 1234@Component //将这个类标注为Spring的一个组件，放到容器中！public class Dog &#123; public String name = &quot;dog&quot;;&#125; 2、新建一个config配置包，编写一个MyConfig配置类 1234567@Configuration //代表这是一个配置类public class MyConfig &#123; @Bean //通过方法注册一个bean，这里的返回值就Bean的类型，方法名就是bean的id！ public Dog dog()&#123; return new Dog(); &#125;&#125; 3、测试 1234567@Testpublic void test2()&#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MyConfig.class); Dog dog = (Dog) applicationContext.getBean(&quot;dog&quot;); System.out.println(dog.name);&#125; 4、成功输出结果！ 导入其他配置如何做呢？ 1、我们再编写一个配置类！ 123@Configuration //代表这是一个配置类public class MyConfig2 &#123;&#125; 2、在之前的配置类中我们来选择导入这个配置类 12345678@Configuration@Import(MyConfig2.class) //导入合并其他配置类，类似于配置文件中的 inculde 标签public class MyConfig &#123; @Bean public Dog dog()&#123; return new Dog(); &#125;&#125; 关于这种Java类的配置方式，我们在之后的SpringBoot 和 SpringCloud中还会大量看到，我们需要知道这些注解的作用即可！ 小结XML与注解比较 XML可以适用任何场景 ，结构清晰，维护方便 注解不是自己提供的类使用不了，开发简单方便 xml与注解整合开发 ：推荐最佳实践 xml管理Bean 注解完成属性注入 使用过程中， 可以不用扫描，扫描是为了类上的注解 1&lt;context:annotation-config/&gt; 作用： 进行注解驱动注册，从而使注解生效 用于激活那些已经在spring容器里注册过的bean上面的注解，也就是显示的向Spring注册 如果不扫描包，就需要手动配置bean 如果不加注解驱动，则注入的值为null！ 静态/动态代理模式代理模式简介为什么要学习代理模式，因为AOP的底层机制就是动态代理！ 代理模式： 静态代理 动态代理 学习aop之前 , 我们要先了解一下代理模式！ 静态代理静态代理角色分析 抽象角色 : 一般使用接口或者抽象类来实现 真实角色 : 被代理的角色 代理角色 : 代理真实角色 ; 代理真实角色后 , 一般会做一些附属的操作 . 客户 : 使用代理角色来进行一些操作 . 代码实现 Rent . java 即抽象角色 1234//抽象角色：租房public interface Rent &#123; public void rent();&#125; Host . java 即真实角色 123456//真实角色: 房东，房东要出租房子public class Host implements Rent&#123; public void rent() &#123; System.out.println(&quot;房屋出租&quot;); &#125;&#125; Proxy . java 即代理角色 1234567891011121314151617181920212223//代理角色：中介public class Proxy implements Rent &#123; private Host host; public Proxy() &#123; &#125; public Proxy(Host host) &#123; this.host = host; &#125; //租房 public void rent()&#123; seeHouse(); host.rent(); fare(); &#125; //看房 public void seeHouse()&#123; System.out.println(&quot;带房客看房&quot;); &#125; //收中介费 public void fare()&#123; System.out.println(&quot;收中介费&quot;); &#125;&#125; Client . java 即客户 1234567891011//客户类，一般客户都会去找代理！public class Client &#123; public static void main(String[] args) &#123; //房东要租房 Host host = new Host(); //中介帮助房东 Proxy proxy = new Proxy(host); //你去找中介！ proxy.rent(); &#125;&#125; 分析：在这个过程中，你直接接触的就是中介，就如同现实生活中的样子，你看不到房东，但是你依旧租到了房东的房子通过代理，这就是所谓的代理模式，程序源自于生活，所以学编程的人，一般能够更加抽象的看待生活中发生的事情。 静态代理的好处: 可以使得我们的真实角色更加纯粹 . 不再去关注一些公共的事情 . 公共的业务由代理来完成 . 实现了业务的分工 , 公共业务发生扩展时变得更加集中和方便 . 缺点 : 类多了 , 多了代理类 , 工作量变大了 . 开发效率降低 . 我们想要静态代理的好处，又不想要静态代理的缺点，所以 , 就有了动态代理 ! 静态代理再理解同学们练习完毕后，我们再来举一个例子，巩固大家的学习！ 练习步骤： 1、创建一个抽象角色，比如咋们平时做的用户业务，抽象起来就是增删改查！ 1234567//抽象角色：增删改查业务public interface UserService &#123; void add(); void delete(); void update(); void query();&#125; 2、我们需要一个真实对象来完成这些增删改查操作 123456789101112131415//真实对象，完成增删改查操作的人public class UserServiceImpl implements UserService &#123; public void add() &#123; System.out.println(&quot;增加了一个用户&quot;); &#125; public void delete() &#123; System.out.println(&quot;删除了一个用户&quot;); &#125; public void update() &#123; System.out.println(&quot;更新了一个用户&quot;); &#125; public void query() &#123; System.out.println(&quot;查询了一个用户&quot;); &#125;&#125; 3、需求来了，现在我们需要增加一个日志功能，怎么实现！ 思路1 ：在实现类上增加代码 【麻烦！】 思路2：使用代理来做，能够不改变原来的业务情况下，实现此功能就是最好的了！ 4、设置一个代理类来处理日志！代理角色 1234567891011121314151617181920212223242526//代理角色，在这里面增加日志的实现public class UserServiceProxy implements UserService &#123; private UserServiceImpl userService; public void setUserService(UserServiceImpl userService) &#123; this.userService = userService; &#125; public void add() &#123; log(&quot;add&quot;); userService.add(); &#125; public void delete() &#123; log(&quot;delete&quot;); userService.delete(); &#125; public void update() &#123; log(&quot;update&quot;); userService.update(); &#125; public void query() &#123; log(&quot;query&quot;); userService.query(); &#125; public void log(String msg)&#123; System.out.println(&quot;执行了&quot;+msg+&quot;方法&quot;); &#125;&#125; 5、测试访问类： 1234567891011public class Client &#123; public static void main(String[] args) &#123; //真实业务 UserServiceImpl userService = new UserServiceImpl(); //代理类 UserServiceProxy proxy = new UserServiceProxy(); //使用代理类实现日志功能！ proxy.setUserService(userService); proxy.add(); &#125;&#125; OK，到了现在代理模式大家应该都没有什么问题了，重点大家需要理解其中的思想； 我们在不改变原来的代码的情况下，实现了对原有功能的增强，这是AOP中最核心的思想 聊聊AOP：纵向开发，横向开发。 动态代理 动态代理的角色和静态代理的一样 . 动态代理的代理类是动态生成的 . 静态代理的代理类是我们提前写好的 动态代理分为两类 : 一类是基于接口动态代理 , 一类是基于类的动态代理 基于接口的动态代理——JDK动态代理 基于类的动态代理–cglib 现在用的比较多的是 javasist 来生成动态代理 . 百度一下javasist 我们这里使用JDK的原生代码来实现，其余的道理都是一样的！、 JDK的动态代理需要了解两个类 核心 : InvocationHandler 和 Proxy ， 打开JDK帮助文档看看 【InvocationHandler：调用处理程序】 12345Object invoke(Object proxy, 方法 method, Object[] args)；//参数//proxy - 调用该方法的代理实例//method -所述方法对应于调用代理实例上的接口方法的实例。方法对象的声明类将是该方法声明的接口，它可以是代理类继承该方法的代理接口的超级接口。//args -包含的方法调用传递代理实例的参数值的对象的阵列，或null如果接口方法没有参数。原始类型的参数包含在适当的原始包装器类的实例中，例如java.lang.Integer或java.lang.Boolean 。 【Proxy : 代理】 12345//生成代理类public Object getProxy()&#123; return Proxy.newProxyInstance(this.getClass().getClassLoader(), rent.getClass().getInterfaces(),this);&#125; 代码实现 抽象角色和真实角色和之前的一样！ Rent . java 即抽象角色 1234//抽象角色：租房public interface Rent &#123; public void rent();&#125; Host . java 即真实角色 123456//真实角色: 房东，房东要出租房子public class Host implements Rent&#123; public void rent() &#123; System.out.println(&quot;房屋出租&quot;); &#125;&#125; ProxyInvocationHandler. java 即代理角色 1234567891011121314151617181920212223242526272829public class ProxyInvocationHandler implements InvocationHandler &#123; private Rent rent; public void setRent(Rent rent) &#123; this.rent = rent; &#125; //生成代理类，重点是第二个参数，获取要代理的抽象角色！之前都是一个角色，现在可以代理一类角色 public Object getProxy()&#123; return Proxy.newProxyInstance(this.getClass().getClassLoader(), rent.getClass().getInterfaces(),this); &#125; // proxy : 代理类 method : 代理类的调用处理程序的方法对象. // 处理代理实例上的方法调用并返回结果 @Override public Object invoke(Object proxy, Method method, Object[] args) throwsThrowable &#123; seeHouse(); //核心：本质利用反射实现！ Object result = method.invoke(rent, args); fare(); return result; &#125; //看房 public void seeHouse()&#123; System.out.println(&quot;带房客看房&quot;); &#125; //收中介费 public void fare()&#123; System.out.println(&quot;收中介费&quot;); &#125;&#125; Client . java 123456789101112//租客public class Client &#123; public static void main(String[] args) &#123; //真实角色 Host host = new Host(); //代理实例的调用处理程序 ProxyInvocationHandler pih = new ProxyInvocationHandler(); pih.setRent(host); //将真实角色放置进去！ Rent proxy = (Rent)pih.getProxy(); //动态生成对应的代理类！ proxy.rent(); &#125;&#125; 核心：一个动态代理 , 一般代理某一类业务 , 一个动态代理可以代理多个类，代理的是接口！ 动态代理再理解我们来使用动态代理实现代理我们后面写的UserService！ 我们也可以编写一个通用的动态代理实现的类！所有的代理对象设置为Object即可！ 123456789101112131415161718192021public class ProxyInvocationHandler implements InvocationHandler &#123; private Object target; public void setTarget(Object target) &#123; this.target = target; &#125; //生成代理类 public Object getProxy()&#123; return Proxy.newProxyInstance(this.getClass().getClassLoader(), target.getClass().getInterfaces(),this); &#125; // proxy : 代理类 // method : 代理类的调用处理程序的方法对象. public Object invoke(Object proxy, Method method, Object[] args) throwsThrowable &#123; log(method.getName()); Object result = method.invoke(target, args); return result; &#125; public void log(String methodName)&#123; System.out.println(&quot;执行了&quot;+methodName+&quot;方法&quot;); &#125;&#125; 测试！ 1234567891011public class Test &#123; public static void main(String[] args) &#123; //真实对象 UserServiceImpl userService = new UserServiceImpl(); //代理对象的调用处理程序 ProxyInvocationHandler pih = new ProxyInvocationHandler(); pih.setTarget(userService); //设置要代理的对象 UserService proxy = (UserService)pih.getProxy(); //动态生成代理类！ proxy.delete(); &#125;&#125; 测试，增删改查，查看结果！ 动态代理的好处 静态代理有的它都有，静态代理没有的，它也有！ 可以使得我们的真实角色更加纯粹 . 不再去关注一些公共的事情 . 公共的业务由代理来完成 . 实现了业务的分工 , 公共业务发生扩展时变得更加集中和方便 . 一个动态代理 , 一般代理某一类业务 一个动态代理可以代理多个类，代理的是接口！ AOP 面向切面编程 什么是AOP AOP（Aspect Oriented Programming）意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 Aop在Spring中的作用 提供声明式事务；允许用户自定义切面 以下名词需要了解下： 横切关注点：跨越应用程序多个模块的方法或功能。即是，与我们业务逻辑无关的，但是我们需要关注的部分，就是横切关注点。如日志 , 安全 , 缓存 , 事务等等 … 切面（ASPECT）：横切关注点 被模块化 的特殊对象。即，它是一个类。 通知（Advice）：切面必须要完成的工作。即，它是类中的一个方法。 目标（Target）：被通知对象。 代理（Proxy）：向目标对象应用通知之后创建的对象。 切入点（PointCut）：切面通知 执行的 “地点”的定义。 连接点（JointPoint）：与切入点匹配的执行点。 SpringAOP中，通过Advice定义横切逻辑，Spring中支持5种类型的Advice: 即 Aop 在 不改变原有代码的情况下 , 去增加新的功能 . 使用Spring实现Aop【重点】使用AOP织入，需要导入一个依赖包！ 123456&lt;!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver --&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.4&lt;/version&gt;&lt;/dependency&gt; 第一种方式通过 Spring API 实现首先编写我们的业务接口和实现类 123456789101112131415161718192021222324public interface UserService &#123; public void add(); public void delete(); public void update(); public void search();&#125;public class UserServiceImpl implements UserService&#123; @Override public void add() &#123; System.out.println(&quot;增加用户&quot;); &#125; @Override public void delete() &#123; System.out.println(&quot;删除用户&quot;); &#125; @Override public void update() &#123; System.out.println(&quot;更新用户&quot;); &#125; @Override public void search() &#123; System.out.println(&quot;查询用户&quot;); &#125;&#125; 然后去写我们的增强类 , 我们编写两个 , 一个前置增强 一个后置增强 123456789101112131415161718192021public class Log implements MethodBeforeAdvice &#123; //method : 要执行的目标对象的方法 //objects : 被调用的方法的参数 //Object : 目标对象 @Override public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println( o.getClass().getName() + &quot;的&quot; + method.getName() + &quot;方法被执行了&quot;); &#125;&#125;public class AfterLog implements AfterReturningAdvice &#123; //returnValue 返回值 //method被调用的方法 //args 被调用的方法的对象的参数 //target 被调用的目标对象 @Override public void afterReturning(Object returnValue, Method method, Object[] args,Object target) throws Throwable &#123; System.out.println(&quot;执行了&quot; + target.getClass().getName() +&quot;的&quot;+method.getName()+&quot;方法,&quot; +&quot;返回值：&quot;+returnValue); &#125;&#125; 最后去spring的文件中注册 , 并实现aop切入实现 , 注意导入约束 . 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;!--注册bean--&gt; &lt;bean id=&quot;userService&quot; class=&quot;com.kuang.service.UserServiceImpl&quot;/&gt; &lt;bean id=&quot;log&quot; class=&quot;com.kuang.log.Log&quot;/&gt; &lt;bean id=&quot;afterLog&quot; class=&quot;com.kuang.log.AfterLog&quot;/&gt; &lt;!--aop的配置--&gt; &lt;aop:config&gt; &lt;!--切入点 expression:表达式匹配要执行的方法--&gt; &lt;aop:pointcut id=&quot;pointcut&quot; expression=&quot;execution(* com.kuang.service.UserServiceImpl.*(..))&quot;/&gt; &lt;!--执行环绕; advice-ref执行方法 . pointcut-ref切入点--&gt; &lt;aop:advisor advice-ref=&quot;log&quot; pointcut-ref=&quot;pointcut&quot;/&gt; &lt;aop:advisor advice-ref=&quot;afterLog&quot; pointcut-ref=&quot;pointcut&quot;/&gt; &lt;/aop:config&gt;&lt;/beans&gt; 测试 12345678public class MyTest &#123; @Test public void test()&#123; ApplicationContext context = newClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserService userService = (UserService) context.getBean(&quot;userService&quot;); userService.search(); &#125;&#125; Aop的重要性 : 很重要 . 一定要理解其中的思路 , 主要是思想的理解这一块 . Spring的Aop就是将公共的业务 (日志 , 安全等) 和领域业务结合起来 , 当执行领域业务时 , 将会把公共业务加进来 . 实现公共业务的重复利用 . 领域业务更纯粹 , 程序猿专注领域业务 , 其本质还是动态代理 . 第二种方式 自定义类来实现目标业务类不变依旧是userServiceImpl 第一步 : 写我们自己的一个切入类 12345678public class DiyPointcut &#123; public void before()&#123; System.out.println(&quot;---------方法执行前---------&quot;); &#125; public void after()&#123; System.out.println(&quot;---------方法执行后---------&quot;); &#125;&#125; 去spring中配置 123456789101112&lt;!--第二种方式自定义实现--&gt;&lt;!--注册bean--&gt;&lt;bean id=&quot;diy&quot; class=&quot;com.kuang.config.DiyPointcut&quot;/&gt;&lt;!--aop的配置--&gt;&lt;aop:config&gt; &lt;!--第二种方式：使用AOP的标签实现--&gt; &lt;aop:aspect ref=&quot;diy&quot;&gt; &lt;aop:pointcut id=&quot;diyPonitcut&quot; expression=&quot;execution(* com.kuang.service.UserServiceImpl.*(..))&quot;/&gt; &lt;aop:before pointcut-ref=&quot;diyPonitcut&quot; method=&quot;before&quot;/&gt; &lt;aop:after pointcut-ref=&quot;diyPonitcut&quot; method=&quot;after&quot;/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 测试： 12345678public class MyTest &#123; @Test public void test()&#123; ApplicationContext context = newClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserService userService = (UserService) context.getBean(&quot;userService&quot;); userService.add(); &#125;&#125; 第三种方式 使用注解实现第一步：编写一个注解实现的增强类 1234567891011121314151617181920212223242526package com.kuang.config;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;@Aspectpublic class AnnotationPointcut &#123; @Before(&quot;execution(* com.kuang.service.UserServiceImpl.*(..))&quot;) public void before()&#123; System.out.println(&quot;---------方法执行前---------&quot;); &#125; @After(&quot;execution(* com.kuang.service.UserServiceImpl.*(..))&quot;) public void after()&#123; System.out.println(&quot;---------方法执行后---------&quot;); &#125; @Around(&quot;execution(* com.kuang.service.UserServiceImpl.*(..))&quot;) public void around(ProceedingJoinPoint jp) throws Throwable &#123; System.out.println(&quot;环绕前&quot;); System.out.println(&quot;签名:&quot;+jp.getSignature()); //执行目标方法proceed Object proceed = jp.proceed(); System.out.println(&quot;环绕后&quot;); System.out.println(proceed); &#125;&#125; 第二步：在Spring配置文件中，注册bean，并增加支持注解的配置 123&lt;!--第三种方式:注解实现--&gt;&lt;bean id=&quot;annotationPointcut&quot; class=&quot;com.kuang.config.AnnotationPointcut&quot;/&gt;&lt;aop:aspectj-autoproxy/&gt; aop:aspectj-autoproxy：说明 12通过aop命名空间的&lt;aop:aspectj-autoproxy /&gt;声明自动为spring容器中那些配置@aspectJ切面的bean创建代理，织入切面。当然，spring 在内部依旧采用AnnotationAwareAspectJAutoProxyCreator进行自动代理的创建工作，但具体实现的细节已经被&lt;aop:aspectj-autoproxy /&gt;隐藏起来了&lt;aop:aspectj-autoproxy /&gt;有一个proxy-target-class属性，默认为false，表示使用jdk动态代理织入增强，当配为&lt;aop:aspectj-autoproxy poxy-target-class=&quot;true&quot;/&gt;时，表示使用CGLib动态代理技术织入增强。不过即使proxy-target-class设置为false，如果目标类没有声明接口，则spring将自动使用CGLib动态代理。 Spring整合MyBatis 步骤 1、导入相关jar包 junit 12345&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt;&lt;/dependency&gt; mybatis 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt;&lt;/dependency&gt; mysql-connector-java 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt;&lt;/dependency&gt; spring相关 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.1.10.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.1.10.RELEASE&lt;/version&gt;&lt;/dependency&gt; aspectJ AOP 织入器 123456&lt;!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver --&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.4&lt;/version&gt;&lt;/dependency&gt; mybatis-spring整合包 【重点】 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt; 配置Maven静态资源过滤问题！ 123456789101112&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 2、编写配置文件 3、代码实现 回忆MyBatis 编写pojo实体类 123456package com.kuang.pojo;public class User &#123; private int id; //id private String name; //姓名 private String pwd; //密码&#125; 实现mybatis的配置文件 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;typeAliases&gt; &lt;package name=&quot;com.kuang.pojo&quot;/&gt; &lt;/typeAliases&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?useSSL=true&amp;useUnicode=true&amp;characterEncoding=utf8&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;package name=&quot;com.kuang.dao&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; UserDao接口编写 123public interface UserMapper &#123; public List&lt;User&gt; selectUser();&#125; 接口对应的Mapper映射文件 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.kuang.dao.UserMapper&quot;&gt; &lt;select id=&quot;selectUser&quot; resultType=&quot;User&quot;&gt; select * from user &lt;/select&gt;&lt;/mapper&gt; 测试类 12345678910111213@Testpublic void selectUser() throws IOException &#123; String resource = &quot;mybatis-config.xml&quot;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = newSqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession = sqlSessionFactory.openSession(); UserMapper mapper = sqlSession.getMapper(UserMapper.class); List&lt;User&gt; userList = mapper.selectUser(); for (User user: userList)&#123; System.out.println(user); &#125; sqlSession.close();&#125; MyBatis-Spring学习 引入Spring之前需要了解mybatis-spring包中的一些重要类； http://www.mybatis.org/spring/zh/index.html 什么是 MyBatis-Spring？ MyBatis-Spring 会帮助你将 MyBatis 代码无缝地整合到 Spring 中。 知识基础 在开始使用 MyBatis-Spring 之前，你需要先熟悉 Spring 和 MyBatis 这两个框架和有关它们的术语。这很重要 MyBatis-Spring 需要以下版本： MyBatis-Spring MyBatis Spring 框架 Spring Batch Java 2.0 3.5+ 5.0+ 4.0+ Java 8+ 1.3 3.4+ 3.2.2+ 2.1+ Java 6+ 如果使用 Maven 作为构建工具，仅需要在 pom.xml 中加入以下代码即可： 123&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt; 要和 Spring 一起使用 MyBatis，需要在 Spring 应用上下文中定义至少两样东西：一个 SqlSessionFactory 和至少一个数据映射器类。 在 MyBatis-Spring 中，可使用SqlSessionFactoryBean来创建 SqlSessionFactory。要配置这个工厂 bean，只需要把下面代码放在 Spring 的 XML 配置文件中： 123&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt; 注意：SqlSessionFactory需要一个 DataSource（数据源）。这可以是任意的 DataSource，只需要和配置其它 Spring 数据库连接一样配置它就可以了。 在基础的 MyBatis 用法中，是通过 SqlSessionFactoryBuilder 来创建 SqlSessionFactory 的。而在 MyBatis-Spring 中，则使用 SqlSessionFactoryBean 来创建。 在 MyBatis 中，你可以使用 SqlSessionFactory 来创建 SqlSession。一旦你获得一个 session 之后，你可以使用它来执行映射了的语句，提交或回滚连接，最后，当不再需要它的时候，你可以关闭 session。 SqlSessionFactory有一个唯一的必要属性：用于 JDBC 的 DataSource。这可以是任意的 DataSource 对象，它的配置方法和其它 Spring 数据库连接是一样的。 一个常用的属性是 configLocation，它用来指定 MyBatis 的 XML 配置文件路径。它在需要修改 MyBatis 的基础配置非常有用。通常，基础配置指的是 &lt; settings&gt; 或 &lt; typeAliases&gt;元素。 需要注意的是，这个配置文件并不需要是一个完整的 MyBatis 配置。确切地说，任何环境配置（），数据源（）和 MyBatis 的事务管理器（）都会被忽略。SqlSessionFactoryBean 会创建它自有的 MyBatis 环境配置（Environment），并按要求设置自定义环境的值。 SqlSessionTemplate 是 MyBatis-Spring 的核心。作为 SqlSession 的一个实现，这意味着可以使用它无缝代替你代码中已经在使用的 SqlSession。 模板可以参与到 Spring 的事务管理中，并且由于其是线程安全的，可以供多个映射器类使用，你应该总是用 SqlSessionTemplate 来替换 MyBatis 默认的 DefaultSqlSession 实现。在同一应用程序中的不同类之间混杂使用可能会引起数据一致性的问题。 可以使用 SqlSessionFactory 作为构造方法的参数来创建 SqlSessionTemplate 对象。 123&lt;bean id=&quot;sqlSession&quot; class=&quot;org.mybatis.spring.SqlSessionTemplate&quot;&gt; &lt;constructor-arg index=&quot;0&quot; ref=&quot;sqlSessionFactory&quot; /&gt;&lt;/bean&gt; 现在，这个 bean 就可以直接注入到你的 DAO bean 中了。你需要在你的 bean 中添加一个 SqlSession 属性，就像下面这样： 123456789public class UserDaoImpl implements UserDao &#123; private SqlSession sqlSession; public void setSqlSession(SqlSession sqlSession) &#123; this.sqlSession = sqlSession;&#125; public User getUser(String userId) &#123; return sqlSession.getMapper...; &#125;&#125; 按下面这样，注入 SqlSessionTemplate： 123&lt;bean id=&quot;userDao&quot; class=&quot;org.mybatis.spring.sample.dao.UserDaoImpl&quot;&gt; &lt;property name=&quot;sqlSession&quot; ref=&quot;sqlSession&quot; /&gt;&lt;/bean&gt; 整合实现一 1、引入Spring配置文件beans.xml 12345&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; 2、配置数据源替换mybaits的数据源 1234567&lt;!--配置数据源：数据源有非常多，可以使用第三方的，也可使使用Spring的--&gt;&lt;bean id=&quot;dataSource&quot;class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?useSSL=true&amp;useUnicode=true&amp;characterEncoding=utf8&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt;&lt;/bean&gt; 3、配置SqlSessionFactory，关联MyBatis 1234567&lt;!--配置SqlSessionFactory--&gt;&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!--关联Mybatis--&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:com/kuang/dao/*.xml&quot;/&gt;&lt;/bean&gt; 4、注册sqlSessionTemplate，关联sqlSessionFactory； 12345&lt;!--注册sqlSessionTemplate , 关联sqlSessionFactory--&gt;&lt;bean id=&quot;sqlSession&quot; class=&quot;org.mybatis.spring.SqlSessionTemplate&quot;&gt; &lt;!--利用构造器注入--&gt; &lt;constructor-arg index=&quot;0&quot; ref=&quot;sqlSessionFactory&quot;/&gt;&lt;/bean&gt; 5、增加Dao接口的实现类；私有化sqlSessionTemplate 1234567891011public class UserDaoImpl implements UserMapper &#123; //sqlSession不用我们自己创建了，Spring来管理 private SqlSessionTemplate sqlSession; public void setSqlSession(SqlSessionTemplate sqlSession) &#123; this.sqlSession = sqlSession; &#125; public List&lt;User&gt; selectUser() &#123; UserMapper mapper = sqlSession.getMapper(UserMapper.class); return mapper.selectUser(); &#125;&#125; 6、注册bean实现 123&lt;bean id=&quot;userDao&quot; class=&quot;com.kuang.dao.UserDaoImpl&quot;&gt; &lt;property name=&quot;sqlSession&quot; ref=&quot;sqlSession&quot;/&gt;&lt;/bean&gt; 7、测试 1234567@Test public void test2()&#123; ApplicationContext context = newClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserMapper mapper = (UserMapper) context.getBean(&quot;userDao&quot;); List&lt;User&gt; user = mapper.selectUser(); System.out.println(user); &#125; 结果成功输出！现在我们的Mybatis配置文件的状态！发现都可以被Spring整合！ 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;typeAliases&gt; &lt;package name=&quot;com.kuang.pojo&quot;/&gt; &lt;/typeAliases&gt;&lt;/configuration&gt; 整合实现二 mybatis-spring1.2.3版以上的才有这个 . 官方文档截图 : dao继承Support类 , 直接利用 getSqlSession() 获得 , 然后直接注入SqlSessionFactory . 比起方式1 , 不需要管理SqlSessionTemplate , 而且对事务的支持更加友好 . 可跟踪源码查看 测试： 1、将我们上面写的UserDaoImpl修改一下 123456public class UserDaoImpl extends SqlSessionDaoSupport implements UserMapper &#123; public List&lt;User&gt; selectUser() &#123; UserMapper mapper = getSqlSession().getMapper(UserMapper.class); return mapper.selectUser(); &#125;&#125; 2、修改bean的配置 123&lt;bean id=&quot;userDao&quot; class=&quot;com.kuang.dao.UserDaoImpl&quot;&gt; &lt;property name=&quot;sqlSessionFactory&quot; ref=&quot;sqlSessionFactory&quot; /&gt;&lt;/bean&gt; 3、测试 1234567@Testpublic void test2()&#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserMapper mapper = (UserMapper) context.getBean(&quot;userDao&quot;); List&lt;User&gt; user = mapper.selectUser(); System.out.println(user);&#125; 总结 : 整合到spring以后可以完全不要mybatis的配置文件，除了这些方式可以实现整合之外，我们还可以使用注解来实现，这个等我们后面学习SpringBoot的时候还会测试整合！ Spring 声明式事务 回顾事务 事务在项目开发过程非常重要，涉及到数据的一致性的问题，不容马虎！ 事务管理是企业级应用程序开发中必备技术，用来确保数据的完整性和一致性。 事务就是把一系列的动作当成一个独立的工作单元，这些动作要么全部完成，要么全部不起作用。 事务四个属性ACID 原子性（atomicity） 事务是原子性操作，由一系列动作组成，事务的原子性确保动作要么全部完成，要么完全不起作用 一致性（consistency） 一旦所有事务动作完成，事务就要被提交。数据和资源处于一种满足业务规则的一致性状态中 隔离性（isolation） 可能多个事务会同时处理相同的数据，因此每个事务都应该与其他事务隔离开来，防止数据损坏 持久性（durability） 事务一旦完成，无论系统发生什么错误，结果都不会受到影响。通常情况下，事务的结果被写到持久化存储器中 测试 将上面的代码拷贝到一个新项目中 在之前的案例中，我们给userDao接口新增两个方法，删除和增加用户； 1234//添加一个用户int addUser(User user);//根据id删除用户int deleteUser(int id); mapper文件，我们故意把 deletes 写错，测试！ 123456&lt;insert id=&quot;addUser&quot; parameterType=&quot;com.kuang.pojo.User&quot;&gt;insert into user (id,name,pwd) values (#&#123;id&#125;,#&#123;name&#125;,#&#123;pwd&#125;)&lt;/insert&gt;&lt;delete id=&quot;deleteUser&quot; parameterType=&quot;int&quot;&gt;deletes from user where id = #&#123;id&#125;&lt;/delete&gt; 编写接口的实现类，在实现类中，我们去操作一波 1234567891011121314151617181920public class UserDaoImpl extends SqlSessionDaoSupport implements UserMapper &#123; //增加一些操作 public List&lt;User&gt; selectUser() &#123; User user = new User(4,&quot;小明&quot;,&quot;123456&quot;); UserMapper mapper = getSqlSession().getMapper(UserMapper.class); mapper.addUser(user); mapper.deleteUser(4); return mapper.selectUser(); &#125; //新增 public int addUser(User user) &#123; UserMapper mapper = getSqlSession().getMapper(UserMapper.class); return mapper.addUser(user); &#125; //删除 public int deleteUser(int id) &#123; UserMapper mapper = getSqlSession().getMapper(UserMapper.class); return mapper.deleteUser(id); &#125;&#125; 测试 1234567@Testpublic void test2()&#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserMapper mapper = (UserMapper) context.getBean(&quot;userDao&quot;); List&lt;User&gt; user = mapper.selectUser(); System.out.println(user);&#125; 报错：sql异常，delete写错了 结果 ：插入成功！ 没有进行事务的管理；我们想让他们都成功才成功，有一个失败，就都失败，我们就应该需要事务！ 以前我们都需要自己手动管理事务，十分麻烦！ 但是Spring给我们提供了事务管理，我们只需要配置即可； Spring中的事务管理 Spring在不同的事务管理API之上定义了一个抽象层，使得开发人员不必了解底层的事务管理API就可以使用Spring的事务管理机制。Spring支持编程式事务管理和声明式的事务管理。 编程式事务管理 将事务管理代码嵌到业务方法中来控制事务的提交和回滚 缺点：必须在每个事务操作业务逻辑中包含额外的事务管理代码 声明式事务管理 一般情况下比编程式事务好用。 将事务管理代码从业务方法中分离出来，以声明的方式来实现事务管理。 将事务管理作为横切关注点，通过aop方法模块化。Spring中通过Spring AOP框架支持声明式事务管理。 使用Spring管理事务，注意头文件的约束导入 : tx 123xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;http://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; 事务管理器 无论使用Spring的哪种事务管理策略（编程式或者声明式）事务管理器都是必须的。 就是 Spring的核心事务管理抽象，管理封装了一组独立于技术的方法。 JDBC事务 123&lt;bean id=&quot;transactionManager&quot;class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt; 配置好事务管理器后我们需要去配置事务的通知 123456789101112&lt;!--配置事务通知--&gt;&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;!--配置哪些方法使用什么样的事务,配置事务的传播特性--&gt; &lt;tx:method name=&quot;add&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;delete&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;update&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;search*&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;get&quot; read-only=&quot;true&quot;/&gt; &lt;tx:method name=&quot;*&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; spring事务传播特性： 事务传播行为就是多个事务方法相互调用时，事务如何在这些方法间传播。spring支持7种事务传播行为： propagation_requierd：如果当前没有事务，就新建一个事务，如果已存在一个事务中，加入到这个事务中，这是最常见的选择。 propagation_supports：支持当前事务，如果没有当前事务，就以非事务方法执行。 propagation_mandatory：使用当前事务，如果没有当前事务，就抛出异常。 propagation_required_new：新建事务，如果当前存在事务，把当前事务挂起。 propagation_not_supported：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 propagation_never：以非事务方式执行操作，如果当前事务存在则抛出异常。 propagation_nested：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作 Spring 默认的事务传播行为是 PROPAGATION_REQUIRED，它适合于绝大多数的情况。 假设 ServiveX#methodX() 都工作在事务环境下（即都被 Spring 事务增强了），假设程序中存在如下的调用链：Service1#method1()-&gt;Service2#method2()-&gt;Service3#method3()，那么这 3 个服务类的 3 个方法通过 Spring 的事务传播机制都工作在同一个事务中。 就好比，我们刚才的几个方法存在调用，所以会被放在一组事务当中！ 配置AOP 导入aop的头文件！ 12345&lt;!--配置aop织入事务--&gt;&lt;aop:config&gt; &lt;aop:pointcut id=&quot;txPointcut&quot; expression=&quot;execution(* com.kuang.dao.*.*(..))&quot;/&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;txPointcut&quot;/&gt;&lt;/aop:config&gt; 进行测试 删掉刚才插入的数据，再次测试！ 1234567@Testpublic void test2()&#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); UserMapper mapper = (UserMapper) context.getBean(&quot;userDao&quot;); List&lt;User&gt; user = mapper.selectUser(); System.out.println(user);&#125; 思考问题？ 为什么需要配置事务？ 如果不配置，就需要我们手动提交控制事务； 事务在项目开发过程非常重要，涉及到数据的一致性的问题，不容马虎！","tags":["笔记"],"categories":["Java"]},{"title":"SpringCloud笔记","path":"/2021/11/12/springcloudnote/","content":"学习前言1.1 学习前提 熟练使用SpringBoot 微服务快速开发框架 了解过Dubbo + Zookeeper 分布式基础 电脑配置内存不低于8G(我自己的是16G) 给大家看下多个服务跑起来后的内存开销图： 1.2 文章大纲 Spring Cloud 五大组件 服务注册与发现——Netflix Eureka 负载均衡： 客户端负载均衡——Netflix Ribbon 服务端负载均衡：——Feign(其也是依赖于Ribbon，只是将调用方式RestTemplete 更改成Service 接口) 断路器——Netflix Hystrix 服务网关——Netflix Zuul 分布式配置——Spring Cloud Config 1.3 常见面试题1.1 什么是微服务？ 1.2 微服务之间是如何独立通讯的？ 1.3 SpringCloud 和 Dubbo有那些区别？ 1.4 SpringBoot 和 SpringCloud，请谈谈你对他们的理解 1.5 什么是服务熔断？什么是服务降级？ 1.6 微服务的优缺点分别是什么？说下你在项目开发中遇到的坑 1.7 你所知道的微服务技术栈有哪些？列举一二 1.8 Eureka和Zookeeper都可以提供服务注册与发现的功能，请说说两者的区别 … 2. 微服务概述2.1 什么是微服务？ 什么是微服务？ 微服务(Microservice Architecture) 是近几年流行的一种架构思想，关于它的概念很难一言以蔽之。 究竟什么是微服务呢？我们在此引用ThoughtWorks 公司的首席科学家 Martin Fowler 于2014年提出的一段话： 原文：https://martinfowler.com/articles/microservices.html 汉化：https://www.cnblogs.com/liuning8023/p/4493156.html 就目前而言，对于微服务，业界并没有一个统一的，标准的定义。 但通常而言，微服务架构是一种架构模式，或者说是一种架构风格，它体长将单一的应用程序划分成一组小的服务，每个服务运行在其独立的自己的进程内，服务之间互相协调，互相配置，为用户提供最终价值，服务之间采用轻量级的通信机制(HTTP)互相沟通，每个服务都围绕着具体的业务进行构建，并且能狗被独立的部署到生产环境中，另外，应尽量避免统一的，集中式的服务管理机制，对具体的一个服务而言，应该根据业务上下文，选择合适的语言，工具(Maven)对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。 再来从技术维度角度理解下： 微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底地去耦合，每一个微服务提供单个业务功能的服务，一个服务做一件事情，从技术角度看就是一种小而独立的处理过程，类似进程的概念，能够自行单独启动或销毁，拥有自己独立的数据库。 2.2 微服务与微服务架构 微服务 强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题/提供落地对应服务的一个服务应用，狭义的看，可以看作是IDEA中的一个个微服务工程，或者Moudel。IDEA 工具里面使用Maven开发的一个个独立的小Moudel，它具体是使用SpringBoot开发的一个小模块，专业的事情交给专业的模块来做，一个模块就做着一件事情。强调的是一个个的个体，每个个体完成一个具体的任务或者功能。 微服务架构 一种新的架构形式，Martin Fowler 于2014年提出。 微服务架构是一种架构模式，它体长将单一应用程序划分成一组小的服务，服务之间相互协调，互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务之间采用轻量级的通信机制**(如HTTP)互相协作，每个服务都围绕着具体的业务进行构建，并且能够被独立的部署到生产环境中，另外，应尽量避免统一的，集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具(如Maven)**对其进行构建。 2.3 微服务优缺点 优点 单一职责原则； 每个服务足够内聚，足够小，代码容易理解，这样能聚焦一个指定的业务功能或业务需求； 开发简单，开发效率高，一个服务可能就是专一的只干一件事； 微服务能够被小团队单独开发，这个团队只需2-5个开发人员组成； 微服务是松耦合的，是有功能意义的服务，无论是在开发阶段或部署阶段都是独立的； 微服务能使用不同的语言开发； 易于和第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成工具，如jenkins，Hudson，bamboo； 微服务易于被一个开发人员理解，修改和维护，这样小团队能够更关注自己的工作成果，无需通过合作才能体现价值； 微服务允许利用和融合最新技术； 微服务只是业务逻辑的代码，不会和HTML，CSS，或其他的界面混合; 每个微服务都有自己的存储能力，可以有自己的数据库，也可以有统一的数据库； 缺点 开发人员要处理分布式系统的复杂性； 多服务运维难度，随着服务的增加，运维的压力也在增大； 系统部署依赖问题； 服务间通信成本问题； 数据一致性问题； 系统集成测试问题； 性能和监控问题； 2.4 微服务技术栈有那些？ 微服务技术条目 落地技术 服务开发 SpringBoot、Spring、SpringMVC等 服务配置与管理 Netfix公司的Archaius、阿里的Diamond等 服务注册与发现 Eureka、Consul、Zookeeper等 服务调用 Rest、PRC、gRPC 服务熔断器 Hystrix、Envoy等 负载均衡 Ribbon、Nginx等 服务接口调用(客户端调用服务的简化工具) Fegin等 消息队列 Kafka、RabbitMQ、ActiveMQ等 服务配置中心管理 SpringCloudConfig、Chef等 服务路由(API网关) Zuul等 服务监控 Zabbix、Nagios、Metrics、Specatator等 全链路追踪 Zipkin、Brave、Dapper等 数据流操作开发包 SpringCloud Stream(封装与Redis，Rabbit，Kafka等发送接收消息) 时间消息总栈 SpringCloud Bus 服务部署 Docker、OpenStack、Kubernetes等 2.5 为什么选择SpringCloud作为微服务架构 选型依据 整体解决方案和框架成熟度 社区热度 可维护性 学习曲线 当前各大IT公司用的微服务架构有那些？ 阿里：dubbo+HFS 京东：JFS 新浪：Motan 当当网：DubboX … 各微服务框架对比 功能点/服务框架 Netflix/SpringCloud Motan gRPC Thri t Dubbo/DubboX 功能定位 完整的微服务框架 RPC框架，但整合了ZK或Consul，实现集群环境的基本服务注册发现 RPC框架 RPC框架 服务框架 支持Rest 是，Ribbon支持多种可拔插的序列号选择 否 否 否 否 支持RPC 否 是(Hession2) 是 是 是 支持多语言 是(Rest形式) 否 是 是 否 负载均衡 是(服务端zuul+客户端Ribbon)，zuul-服务，动态路由，云端负载均衡Eureka（针对中间层服务器） 是(客户端) 否 否 是(客户端) 配置服务 Netfix Archaius，Spring Cloud Config Server 集中配置 是(Zookeeper提供) 否 否 否 服务调用链监控 是(zuul)，zuul提供边缘服务，API网关 否 否 否 否 高可用/容错 是(服务端Hystrix+客户端Ribbon) 是(客户端) 否 否 是(客户端) 典型应用案例 Netflix Sina Google Facebook 社区活跃程度 高 一般 高 一般 2017年后重新开始维护，之前中断了5年 学习难度 中等 低 高 高 低 文档丰富程度 高 一般 一般 一般 高 其他 Spring Cloud Bus为我们的应用程序带来了更多管理端点 支持降级 Netflix内部在开发集成gRPC IDL定义 实践的公司比较多 3. SpringCloud入门概述3.1 SpringCloud是什么？Spring官网：https://spring.io/ 3.2 SpringCloud和SpringBoot的关系 SpringBoot专注于开苏方便的开发单个个体微服务； SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务，整合并管理起来，为各个微服务之间提供：配置管理、服务发现、断路器、路由、为代理、事件总栈、全局锁、决策竞选、分布式会话等等集成服务； SpringBoot可以离开SpringCloud独立使用，开发项目，但SpringCloud离不开SpringBoot，属于依赖关系； SpringBoot专注于快速、方便的开发单个个体微服务，SpringCloud关注全局的服务治理框架； 3.3 Dubbo 和 SpringCloud技术选型1. 分布式+服务治理Dubbo目前成熟的互联网架构，应用服务化拆分 + 消息中间件 2. Dubbo 和 SpringCloud对比可以看一下社区活跃度： https://github.com/dubbo https://github.com/spring-cloud 对比结果： Dubbo SpringCloud 服务注册中心 Zookeeper Spring Cloud Netfilx Eureka 服务调用方式 RPC REST API 服务监控 Dubbo-monitor Spring Boot Admin 断路器 不完善 Spring Cloud Netfilx Hystrix 服务网关 无 Spring Cloud Netfilx Zuul 分布式配置 无 Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 消息总栈 无 Spring Cloud Bus 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task 最大区别：Spring Cloud 抛弃了Dubbo的RPC通信，采用的是基于HTTP的REST方式 严格来说，这两种方式各有优劣。虽然从一定程度上来说，后者牺牲了服务调用的性能，但也避免了上面提到的原生RPC带来的问题。而且REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这个优点在当下强调快速演化的微服务环境下，显得更加合适。 品牌机和组装机的区别 社区支持与更新力度的区别 总结：二者解决的问题域不一样：Dubbo的定位是一款RPC框架，而SpringCloud的目标是微服务架构下的一站式解决方案。 3.4 SpringCloud能干嘛？ Distributed/versioned configuration 分布式/版本控制配置 Service registration and discovery 服务注册与发现 Routing 路由 Service-to-service calls 服务到服务的调用 Load balancing 负载均衡配置 Circuit Breakers 断路器 Distributed messaging 分布式消息管理 … 3.5 SpringCloud下载官网：http://projects.spring.io/spring-cloud/ 版本号有点特别： SpringCloud没有采用数字编号的方式命名版本号，而是采用了伦敦地铁站的名称，同时根据字母表的顺序来对应版本时间顺序，比如最早的Realse版本：Angel，第二个Realse版本：Brixton，然后是Camden、Dalston、Edgware，目前最新的是Hoxton SR4 CURRENT GA通用稳定版。 自学参考书： SpringCloud Netflix 中文文档：https://springcloud.cc/spring-cloud-netflix.html SpringCloud 中文API文档(官方文档翻译版)：https://springcloud.cc/spring-cloud-dalston.html SpringCloud中国社区：http://springcloud.cn/ SpringCloud中文网：https://springcloud.cc 4. SpringCloud Rest学习环境搭建：服务提供者4.1 介绍 我们会使用一个Dept部门模块做一个微服务通用案例Consumer消费者(Client)通过REST调用Provider提供者(Server)提供的服务。 回顾Spring，SpringMVC，Mybatis等以往学习的知识。 Maven的分包分模块架构复习。 12345678910一个简单的Maven模块结构是这样的：-- app-parent: 一个父项目(app-parent)聚合了很多子项目(app-util\\app-dao\\app-web...) |-- pom.xml | |-- app-core ||---- pom.xml | |-- app-web ||---- pom.xml ...... 一个父工程带着多个Moudule子模块 MicroServiceCloud父工程(Project)下初次带着3个子模块(Module) microservicecloud-api 【封装的整体entity/接口/公共配置等】 microservicecloud-consumer-dept-80 【服务提供者】 microservicecloud-provider-dept-8001 【服务消费者】 4.2 SpringCloud版本选择大版本说明 SpringBoot SpringCloud 关系 1.2.x Angel版本(天使) 兼容SpringBoot1.2x 1.3.x Brixton版本(布里克斯顿) 兼容SpringBoot1.3x，也兼容SpringBoot1.4x 1.4.x Camden版本(卡姆登) 兼容SpringBoot1.4x，也兼容SpringBoot1.5x 1.5.x Dalston版本(多尔斯顿) 兼容SpringBoot1.5x，不兼容SpringBoot2.0x 1.5.x Edgware版本(埃奇韦尔) 兼容SpringBoot1.5x，不兼容SpringBoot2.0x 2.0.x Finchley版本(芬奇利) 兼容SpringBoot2.0x，不兼容SpringBoot1.5x 2.1.x Greenwich版本(格林威治) 实际开发版本关系 spring-boot-starter-parent spring-cloud-dependencles 版本号 发布日期 版本号 发布日期 1.5.2.RELEASE 2017-03 Dalston.RC1 2017-x 1.5.9.RELEASE 2017-11 Edgware.RELEASE 2017-11 1.5.16.RELEASE 2018-04 Edgware.SR5 2018-10 1.5.20.RELEASE 2018-09 Edgware.SR5 2018-10 2.0.2.RELEASE 2018-05 Fomchiey.BULD-SNAPSHOT 2018-x 2.0.6.RELEASE 2018-10 Fomchiey-SR2 2018-10 2.1.4.RELEASE 2019-04 Greenwich.SR1 2019-03 使用后两个 4.3 创建父工程 新建父工程项目springcloud，切记Packageing是pom模式 主要是定义POM文件，将后续各个子模块公用的jar包等统一提取出来，类似一个抽象父类 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.haust&lt;/groupId&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;springcloud-api&lt;/module&gt; &lt;module&gt;springcloud-provider-dept-8001&lt;/module&gt; &lt;module&gt;springcloud-consumer-dept-80&lt;/module&gt; &lt;module&gt;springcloud-eureka-7001&lt;/module&gt; &lt;module&gt;springcloud-eureka-7002&lt;/module&gt; &lt;module&gt;springcloud-eureka-7003&lt;/module&gt; &lt;module&gt;springcloud-provider-dept-8002&lt;/module&gt; &lt;module&gt;springcloud-provider-dept-8003&lt;/module&gt; &lt;module&gt;springcloud-consumer-dept-feign&lt;/module&gt; &lt;module&gt;springcloud-provider-dept-hystrix-8001&lt;/module&gt; &lt;module&gt;springcloud-consumer-hystrix-dashboard&lt;/module&gt; &lt;module&gt;springcloud-zuul-9527&lt;/module&gt; &lt;module&gt;springcloud-config-server-3344&lt;/module&gt; &lt;module&gt;springcloud-config-client-3355&lt;/module&gt; &lt;module&gt;springcloud-config-eureka-7001&lt;/module&gt; &lt;module&gt;springcloud-config-dept-8001&lt;/module&gt; &lt;/modules&gt; &lt;!--打包方式 pom--&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;0.2.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--springCloud的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Greenwich.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--SpringBoot--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--数据库--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringBoot 启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--日志测试~--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 父工程为springcloud，其下有多个子mudule，详情参考完整代码了解 springcloud-consumer-dept-80访问springcloud-provider-dept-8001下的controller使用REST方式 如DeptConsumerController.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * @Auther: csp1999 * @Date: 2020/05/17/22:44 * @Description: */@RestControllerpublic class DeptConsumerController &#123; /** * 理解：消费者，不应该有service层~ * RestTemplate .... 供我们直接调用就可以了！ 注册到Spring中 * (地址：url, 实体：Map ,Class&lt;T&gt; responseType) * &lt;p&gt; * 提供多种便捷访问远程http服务的方法，简单的Restful服务模板~ */ @Autowired private RestTemplate restTemplate; /** * 服务提供方地址前缀 * &lt;p&gt; * Ribbon:我们这里的地址，应该是一个变量，通过服务名来访问 */ private static final String REST_URL_PREFIX = &quot;http://localhost:8001&quot;; //private static final String REST_URL_PREFIX = &quot;http://SPRINGCLOUD-PROVIDER-DEPT&quot;; /** * 消费方添加部门信息 * @param dept * @return */ @RequestMapping(&quot;/consumer/dept/add&quot;) public boolean add(Dept dept) &#123; // postForObject(服务提供方地址(接口),参数实体,返回类型.class) return restTemplate.postForObject(REST_URL_PREFIX + &quot;/dept/add&quot;, dept, Boolean.class); &#125; /** * 消费方根据id查询部门信息 * @param id * @return */ @RequestMapping(&quot;/consumer/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; // getForObject(服务提供方地址(接口),返回类型.class) return restTemplate.getForObject(REST_URL_PREFIX + &quot;/dept/get/&quot; + id, Dept.class); &#125; /** * 消费方查询部门信息列表 * @return */ @RequestMapping(&quot;/consumer/dept/list&quot;) public List&lt;Dept&gt; list() &#123; return restTemplate.getForObject(REST_URL_PREFIX + &quot;/dept/list&quot;, List.class); &#125;&#125; 使用RestTemplete先需要放入Spring容器中 ConfigBean.java 1234567891011121314@Configurationpublic class ConfigBean &#123; //@Configuration -- spring applicationContext.xml //配置负载均衡实现RestTemplate // IRule // RoundRobinRule 轮询 // RandomRule 随机 // AvailabilityFilteringRule ： 会先过滤掉，跳闸，访问故障的服务~，对剩下的进行轮询~ // RetryRule ： 会先按照轮询获取服务~，如果服务获取失败，则会在指定的时间内进行，重试 @Bean public RestTemplate getRestTemplate()&#123; return new RestTemplate(); &#125;&#125; springcloud-provider-dept-8001的dao接口调用springcloud-api模块下的pojo，可使用在springcloud-provider-dept-8001的pom文件导入springcloud-api模块依赖的方式： 123456&lt;!--我们需要拿到实体类，所以要配置api module--&gt; &lt;dependency&gt; &lt;groupId&gt;com.haust&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; springcloud-consumer-dept-80和springcloud-provider-dept-8001的pom.xml和父工程下的依赖基本一样，直接看完整代码即可，不再添加重复笔记。 5. Eureka服务注册中心5.1 什么是Eureka Netflix在涉及Eureka时，遵循的就是API原则. Eureka是Netflix的有个子模块，也是核心模块之一。Eureka是基于REST的服务，用于定位服务，以实现云端中间件层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务注册与发现，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了，功能类似于Dubbo的注册中心，比如Zookeeper. 5.2 原理理解 Eureka基本的架构 Springcloud 封装了Netflix公司开发的Eureka模块来实现服务注册与发现 (对比Zookeeper). Eureka采用了C-S的架构设计，EurekaServer作为服务注册功能的服务器，他是服务注册中心. 而系统中的其他微服务，使用Eureka的客户端连接到EurekaServer并维持心跳连接。这样系统的维护人员就可以通过EurekaServer来监控系统中各个微服务是否正常运行，Springcloud 的一些其他模块 (比如Zuul) 就可以通过EurekaServer来发现系统中的其他微服务，并执行相关的逻辑. 和Dubbo架构对比. Eureka 包含两个组件：Eureka Server 和 Eureka Client. Eureka Server 提供服务注册，各个节点启动后，回在EurekaServer中进行注册，这样Eureka Server中的服务注册表中将会储存所有课用服务节点的信息，服务节点的信息可以在界面中直观的看到. Eureka Client 是一个Java客户端，用于简化EurekaServer的交互，客户端同时也具备一个内置的，使用轮询负载算法的负载均衡器。在应用启动后，将会向EurekaServer发送心跳 (默认周期为30秒) 。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除掉 (默认周期为90s). 三大角色 Eureka Server：提供服务的注册与发现 Service Provider：服务生产方，将自身服务注册到Eureka中，从而使服务消费方能狗找到 Service Consumer：服务消费方，从Eureka中获取注册服务列表，从而找到消费服务 目前工程状况 5.3 构建步骤1. eureka-server springcloud-eureka-7001 模块建立 pom.xml 配置 123456789101112131415&lt;!--导包~--&gt;&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;!--导入Eureka Server依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--热部署工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml 1234567891011121314151617server: port: 7001# Eureka配置eureka: instance: # Eureka服务端的实例名字 hostname: 127.0.0.1 client: # 表示是否向 Eureka 注册中心注册自己(这个模块本身是服务器,所以不需要) register-with-eureka: false # fetch-registry如果为false,则表示自己为注册中心,客户端的化为 ture fetch-registry: false # Eureka监控页面~ service-url: defaultZone: http://$&#123; eureka.instance.hostname&#125;:$&#123; server.port&#125;/eureka/ 源码中Eureka的默认端口以及访问路径: 主启动类 12345678910111213/** * @Auther: csp1999 * @Date: 2020/05/18/10:26 * @Description: 启动之后，访问 http://127.0.0.1:7001/ */@SpringBootApplication// @EnableEurekaServer 服务端的启动类，可以接受别人注册进来~@EnableEurekaServerpublic class EurekaServer_7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer_7001.class,args); &#125;&#125; 启动成功后访问 http://localhost:7001/ 得到以下页面 2. eureka-client调整之前创建的springlouc-provider-dept-8001 导入Eureca依赖 1234567&lt;!--Eureka依赖--&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; application中新增Eureca配置 12345# Eureka配置：配置服务注册中心地址eureka: client: service-url: defaultZone: http://localhost:7001/eureka/ 为主启动类添加@EnableEurekaClient注解 12345678910111213/** * @Auther: csp1999 * @Date: 2020/05/17/22:09 * @Description: 启动类 */@SpringBootApplication// @EnableEurekaClient 开启Eureka客户端注解，在服务启动后自动向注册中心注册服务@EnableEurekaClientpublic class DeptProvider_8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider_8001.class,args); &#125;&#125; 先启动7001服务端后启动8001客户端进行测试，然后访问监控页http://localhost:7001/ 产看结果如图，成功 修改Eureka上的默认描述信息 1234567# Eureka配置：配置服务注册中心地址eureka: client: service-url: defaultZone: http://localhost:7001/eureka/ instance: instance-id: springcloud-provider-dept-8001 #修改Eureka上的默认描述信息 结果如图： 如果此时停掉springcloud-provider-dept-8001 等30s后 监控会开启保护机制： 配置关于服务加载的监控信息 pom.xml中添加依赖 12345&lt;!--actuator完善监控信息--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; application.yml中添加配置 123456# info配置info:# 项目的名称app.name: haust-springcloud# 公司的名称company.name: 河南科技大学西苑校区软件学院 此时刷新监控页，点击进入跳转新页面显示如下内容： 3. EureKa自我保护机制：好死不如赖活着一句话总结就是：某时刻某一个微服务不可用，eureka不会立即清理，依旧会对该微服务的信息进行保存！ 默认情况下，当eureka server在一定时间内没有收到实例的心跳，便会把该实例从注册表中删除（默认是90秒），但是，如果短时间内丢失大量的实例心跳，便会触发eureka server的自我保护机制，比如在开发测试时，需要频繁地重启微服务实例，但是我们很少会把eureka server一起重启（因为在开发过程中不会修改eureka注册中心），当一分钟内收到的心跳数大量减少时，会触发该保护机制。可以在eureka管理界面看到Renews threshold和Renews(last min)，当后者（最后一分钟收到的心跳数）小于前者（心跳阈值）的时候，触发保护机制，会出现红色的警告：EMERGENCY!EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY&#39;RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEGING EXPIRED JUST TO BE SAFE.从警告中可以看到，eureka认为虽然收不到实例的心跳，但它认为实例还是健康的，eureka会保护这些实例，不会把它们从注册表中删掉。 该保护机制的目的是避免网络连接故障，在发生网络故障时，微服务和注册中心之间无法正常通信，但服务本身是健康的，不应该注销该服务，如果eureka因网络故障而把微服务误删了，那即使网络恢复了，该微服务也不会重新注册到eureka server了，因为只有在微服务启动的时候才会发起注册请求，后面只会发送心跳和服务列表请求，这样的话，该实例虽然是运行着，但永远不会被其它服务所感知。所以，eureka server在短时间内丢失过多的客户端心跳时，会进入自我保护模式，该模式下，eureka会保护注册表中的信息，不在注销任何微服务，当网络故障恢复后，eureka会自动退出保护模式。自我保护模式可以让集群更加健壮。 但是我们在开发测试阶段，需要频繁地重启发布，如果触发了保护机制，则旧的服务实例没有被删除，这时请求有可能跑到旧的实例中，而该实例已经关闭了，这就导致请求错误，影响开发测试。所以，在开发测试阶段，我们可以把自我保护模式关闭，只需在eureka server配置文件中加上如下配置即可：eureka.server.enable-self-preservation=false【不推荐关闭自我保护机制】 详细内容可以参考下这篇博客内容：https://blog.csdn.net/wudiyong22/article/details/80827594 4. 注册进来的微服务，获取一些消息（团队开发会用到）DeptController.java新增方法 123456789101112131415161718192021222324252627/** * DiscoveryClient 可以用来获取一些配置的信息，得到具体的微服务！ */@Autowiredprivate DiscoveryClient client;/** * 获取一些注册进来的微服务的信息~， * * @return */@GetMapping(&quot;/dept/discovery&quot;)public Object discovery() &#123; // 获取微服务列表的清单 List&lt;String&gt; services = client.getServices(); System.out.println(&quot;discovery=&gt;services:&quot; + services); // 得到一个具体的微服务信息,通过具体的微服务id，applicaioinName； List&lt;ServiceInstance&gt; instances = client.getInstances(&quot;SPRINGCLOUD-PROVIDER-DEPT&quot;); for (ServiceInstance instance : instances) &#123; System.out.println( instance.getHost() + &quot;\\t&quot; + // 主机名称 instance.getPort() + &quot;\\t&quot; + // 端口号 instance.getUri() + &quot;\\t&quot; + // uri instance.getServiceId() // 服务id ); &#125; return this.client;&#125; 主启动类中加入@EnableDiscoveryClient 注解 12345678@SpringBootApplication// @EnableEurekaClient 开启Eureka客户端注解，在服务启动后自动向注册中心注册服务@EnableEurekaClient// @EnableEurekaClient 开启服务发现客户端的注解，可以用来获取一些配置的信息，得到具体的微服务@EnableDiscoveryClientpublic class DeptProvider_8001 &#123; ...&#125; 结果如图： 5.4 Eureka：集群环境配置 1.初始化新建springcloud-eureka-7002、springcloud-eureka-7003 模块 1.为pom.xml添加依赖 (与springcloud-eureka-7001相同) 123456789101112131415&lt;!--导包~--&gt;&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;!--导入Eureka Server依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--热部署工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.application.yml配置(与springcloud-eureka-7001相同) 1234567891011121314server: port: 7003# Eureka配置eureka: instance: hostname: localhost # Eureka服务端的实例名字 client: register-with-eureka: false # 表示是否向 Eureka 注册中心注册自己(这个模块本身是服务器,所以不需要) fetch-registry: false # fetch-registry如果为false,则表示自己为注册中心 service-url: # 监控页面~ # 重写Eureka的默认端口以及访问路径 ---&gt;http://localhost:7001/eureka/ defaultZone: http://$&#123; eureka.instance.hostname&#125;:$&#123; server.port&#125;/eureka/ 3.主启动类(与springcloud-eureka-7001相同) 123456789101112/** * @Auther: csp1999 * @Date: 2020/05/18/10:26 * @Description: 启动之后，访问 http://127.0.0.1:7003/ */@SpringBootApplication// @EnableEurekaServer 服务端的启动类，可以接受别人注册进来~public class EurekaServer_7003 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer_7003.class,args); &#125;&#125; 2.集群成员相互关联配置一些自定义本机名字，找到本机hosts文件并打开 在hosts文件最后加上，要访问的本机名称，默认是localhost 修改application.yml的配置，如图为springcloud-eureka-7001配置，springcloud-eureka-7002/springcloud-eureka-7003同样分别修改为其对应的名称即可 在集群中使springcloud-eureka-7001关联springcloud-eureka-7002、springcloud-eureka-7003 完整的springcloud-eureka-7001下的application.yml如下 123456789101112/** * @Auther: csp1999 * @Date: 2020/05/18/10:26 * @Description: 启动之后，访问 http://127.0.0.1:7003/ */@SpringBootApplication// @EnableEurekaServer 服务端的启动类，可以接受别人注册进来~public class EurekaServer_7003 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer_7003.class,args); &#125;&#125; 同时在集群中使springcloud-eureka-7002关联springcloud-eureka-7001、springcloud-eureka-7003 完整的springcloud-eureka-7002下的application.yml如下 1234567891011121314server: port: 7002#Eureka配置eureka: instance: hostname: eureka7002.com #Eureka服务端的实例名字 client: register-with-eureka: false #表示是否向 Eureka 注册中心注册自己(这个模块本身是服务器,所以不需要) fetch-registry: false #fetch-registry如果为false,则表示自己为注册中心 service-url: #监控页面~ #重写Eureka的默认端口以及访问路径 ---&gt;http://localhost:7001/eureka/ # 单机： defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # 集群（关联）：7002关联7001、7003 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7003.com:7003/eureka/ springcloud-eureka-7003配置方式同理可得. 通过springcloud-provider-dept-8001下的yml配置文件，修改Eureka配置：配置服务注册中心地址 12345678# Eureka配置：配置服务注册中心地址eureka: client: service-url: # 注册中心地址7001-7003 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-8001 #修改Eureka上的默认描述信息 这样模拟集群就搭建号了，就可以把一个项目挂载到三个服务器上了 5.5 对比和Zookeeper区别1. 回顾CAP原则RDBMS (MySQL\\Oracle\\sqlServer) ===&gt; ACID NoSQL (Redis\\MongoDB) ===&gt; CAP 2. ACID是什么？ A (Atomicity) 原子性 C (Consistency) 一致性 I (Isolation) 隔离性 D (Durability) 持久性 3. CAP是什么? C (Consistency) 强一致性 A (Availability) 可用性 P (Partition tolerance) 分区容错性 CAP的三进二：CA、AP、CP 4. CAP理论的核心 一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求 根据CAP原理，将NoSQL数据库分成了满足CA原则，满足CP原则和满足AP原则三大类 CA：单点集群，满足一致性，可用性的系统，通常可扩展性较差 CP：满足一致性，分区容错的系统，通常性能不是特别高 AP：满足可用性，分区容错的系统，通常可能对一致性要求低一些 5. 作为分布式服务注册中心，Eureka比Zookeeper好在哪里？著名的CAP理论指出，一个分布式系统不可能同时满足C (一致性) 、A (可用性) 、P (容错性)，由于分区容错性P再分布式系统中是必须要保证的，因此我们只能再A和C之间进行权衡。 Zookeeper 保证的是 CP —&gt; 满足一致性，分区容错的系统，通常性能不是特别高 Eureka 保证的是 AP —&gt; 满足可用性，分区容错的系统，通常可能对一致性要求低一些 Zookeeper保证的是CP 当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接收服务直接down掉不可用。也就是说，服务注册功能对可用性的要求要高于一致性。但zookeeper会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30-120s，且选举期间整个zookeeper集群是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因为网络问题使得zookeeper集群失去master节点是较大概率发生的事件，虽然服务最终能够恢复，但是，漫长的选举时间导致注册长期不可用，是不可容忍的。 Eureka保证的是AP Eureka看明白了这一点，因此在设计时就优先保证可用性。Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册时，如果发现连接失败，则会自动切换至其他节点，只要有一台Eureka还在，就能保住注册服务的可用性，只不过查到的信息可能不是最新的，除此之外，Eureka还有之中自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况： Eureka不在从注册列表中移除因为长时间没收到心跳而应该过期的服务 Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上 (即保证当前节点依然可用) 当网络稳定时，当前实例新的注册信息会被同步到其他节点中 因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪 6. Ribbon：负载均衡(基于客户端)6.1 负载均衡以及Ribbon Ribbon是什么？ Spring Cloud Ribbon 是基于Netflix Ribbon 实现的一套客户端负载均衡的工具。 简单的说，Ribbon 是 Netflix 发布的开源项目，主要功能是提供客户端的软件负载均衡算法，将 Netflix 的中间层服务连接在一起。Ribbon 的客户端组件提供一系列完整的配置项，如：连接超时、重试等。简单的说，就是在配置文件中列出 LoadBalancer (简称LB：负载均衡) 后面所有的及其，Ribbon 会自动的帮助你基于某种规则 (如简单轮询，随机连接等等) 去连接这些机器。我们也容易使用 Ribbon 实现自定义的负载均衡算法！ Ribbon能干嘛？ LB，即负载均衡 (LoadBalancer) ，在微服务或分布式集群中经常用的一种应用。 负载均衡简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA (高用)。 常见的负载均衡软件有 Nginx、Lvs 等等。 Dubbo、SpringCloud 中均给我们提供了负载均衡，SpringCloud 的负载均衡算法可以自定义。 负载均衡简单分类： 集中式LB 即在服务的提供方和消费方之间使用独立的LB设施，如**Nginx(反向代理服务器)**，由该设施负责把访问请求通过某种策略转发至服务的提供方！ 进程式 LB 将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选出一个合适的服务器。 Ribbon 就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址！ 6.2 集成Ribbonspringcloud-consumer-dept-80向pom.xml中添加Ribbon和Eureka依赖 123456789101112&lt;!--Ribbon--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--Eureka: Ribbon需要从Eureka服务中心获取要拿什么--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在application.yml文件中配置Eureka 123456# Eureka配置eureka: client: register-with-eureka: false # 不向 Eureka注册自己 service-url: # 从三个注册中心中随机取一个去访问 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 主启动类加上@EnableEurekaClient注解，开启Eureka 12345678//Ribbon 和 Eureka 整合以后，客户端可以直接调用，不用关心IP地址和端口号@SpringBootApplication@EnableEurekaClient //开启Eureka 客户端public class DeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer_80.class, args); &#125;&#125; 自定义Spring配置类：ConfigBean.java 配置负载均衡实现RestTemplate 123456789@Configurationpublic class ConfigBean &#123; //@Configuration -- spring applicationContext.xml @LoadBalanced //配置负载均衡实现RestTemplate @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; 修改conroller：DeptConsumerController.java 123//Ribbon:我们这里的地址，应该是一个变量，通过服务名来访问//private static final String REST_URL_PREFIX = &quot;http://localhost:8001&quot;;private static final String REST_URL_PREFIX = &quot;http://SPRINGCLOUD-PROVIDER-DEPT&quot;; 6.3 使用Ribbon实现负载均衡流程图： 1.新建两个服务提供者Moudle：springcloud-provider-dept-8003、springcloud-provider-dept-8002 2.参照springcloud-provider-dept-8001 依次为另外两个Moudle添加pom.xml依赖 、resourece下的mybatis和application.yml配置，Java代码 3.启动所有服务测试(根据自身电脑配置决定启动服务的个数)，访问http://eureka7001.com:7002/查看结果 测试访问http://localhost/consumer/dept/list 这时候随机访问的是服务提供者8003 再次访问http://localhost/consumer/dept/list这时候随机的是服务提供者8001 以上这种每次访问http://localhost/consumer/dept/list随机访问集群中某个服务提供者，这种情况叫做轮询，轮询算法在SpringCloud中可以自定义。 如何切换或者自定义规则呢？ 在springcloud-provider-dept-80模块下的ConfigBean中进行配置，切换使用不同的规则 123456789101112131415161718@Configurationpublic class ConfigBean &#123; //@Configuration -- spring applicationContext.xml /** * IRule: * RoundRobinRule 轮询策略 * RandomRule 随机策略 * AvailabilityFilteringRule ： 会先过滤掉，跳闸，访问故障的服务~，对剩下的进行轮询~ * RetryRule ： 会先按照轮询获取服务~，如果服务获取失败，则会在指定的时间内进行，重试 */ @Bean public IRule myRule() &#123; return new RandomRule();//使用随机策略 //return new RoundRobinRule();//使用轮询策略 //return new AvailabilityFilteringRule();//使用轮询策略 //return new RetryRule();//使用轮询策略 &#125;&#125; 也可以自定义规则，在myRule包下自定义一个配置类MyRule.java，注意：该包不要和主启动类所在的包同级，要跟启动类所在包同级： MyRule.java 123456789101112/** * @Auther: csp1999 * @Date: 2020/05/19/11:58 * @Description: 自定义规则 */@Configurationpublic class MyRule &#123; @Bean public IRule myRule()&#123; return new MyRandomRule();//默认是轮询RandomRule,现在自定义为自己的 &#125;&#125; 主启动类开启负载均衡并指定自定义的MyRule配置类 12345678910//Ribbon 和 Eureka 整合以后，客户端可以直接调用，不用关心IP地址和端口号@SpringBootApplication@EnableEurekaClient//在微服务启动的时候就能加载自定义的Ribbon类(自定义的规则会覆盖原有默认的规则)@RibbonClient(name = &quot;SPRINGCLOUD-PROVIDER-DEPT&quot;,configuration = MyRule.class)//开启负载均衡,并指定自定义的规则public class DeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer_80.class, args); &#125;&#125; 自定义的规则(这里我们参考Ribbon中默认的规则代码自己稍微改动)：MyRandomRule.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class MyRandomRule extends AbstractLoadBalancerRule &#123; /** * 每个服务访问5次则换下一个服务(总共3个服务) * &lt;p&gt; * total=0,默认=0,如果=5,指向下一个服务节点 * index=0,默认=0,如果total=5,index+1 */ private int total = 0;//被调用的次数 private int currentIndex = 0;//当前是谁在提供服务 //@edu.umd.cs.findbugs.annotations.SuppressWarnings(value = &quot;RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE&quot;) public Server choose(ILoadBalancer lb, Object key) &#123; if (lb == null) &#123; return null; &#125; Server server = null; while (server == null) &#123; if (Thread.interrupted()) &#123; return null; &#125; List&lt;Server&gt; upList = lb.getReachableServers();//获得当前活着的服务 List&lt;Server&gt; allList = lb.getAllServers();//获取所有的服务 int serverCount = allList.size(); if (serverCount == 0) &#123; /* * No servers. End regardless of pass, because subsequent passes * only get more restrictive. */ return null; &#125; //int index = chooseRandomInt(serverCount);//生成区间随机数 //server = upList.get(index);//从或活着的服务中,随机获取一个 //=====================自定义代码========================= if (total &lt; 5) &#123; server = upList.get(currentIndex); total++; &#125; else &#123; total = 0; currentIndex++; if (currentIndex &gt; upList.size()) &#123; currentIndex = 0; &#125; server = upList.get(currentIndex);//从活着的服务中,获取指定的服务来进行操作 &#125; //====================================================== if (server == null) &#123; /* * The only time this should happen is if the server list were * somehow trimmed. This is a transient condition. Retry after * yielding. */ Thread.yield(); continue; &#125; if (server.isAlive()) &#123; return (server); &#125; // Shouldn&#x27;t actually happen.. but must be transient or a bug. server = null; Thread.yield(); &#125; return server; &#125; protected int chooseRandomInt(int serverCount) &#123; return ThreadLocalRandom.current().nextInt(serverCount); &#125; @Override public Server choose(Object key) &#123; return choose(getLoadBalancer(), key); &#125; @Override public void initWithNiwsConfig(IClientConfig clientConfig) &#123; // TODO Auto-generated method stub &#125;&#125; 7.Feign：负载均衡(基于服务端)7.1 Feign简介Feign是声明式Web Service客户端，它让微服务之间的调用变得更简单，类似controller调用service。SpringCloud集成了Ribbon和Eureka，可以使用Feigin提供负载均衡的http客户端 只需要创建一个接口，然后添加注解即可~ Feign，主要是社区版，大家都习惯面向接口编程。这个是很多开发人员的规范。调用微服务访问两种方法 微服务名字 【ribbon】 接口和注解 【feign】 Feign能干什么？ Feign旨在使编写Java Http客户端变得更容易 前面在使用Ribbon + RestTemplate时，利用RestTemplate对Http请求的封装处理，形成了一套模板化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一个客户端类来包装这些依赖服务的调用。所以，Feign在此基础上做了进一步的封装，由他来帮助我们定义和实现依赖服务接口的定义，在Feign的实现下，我们只需要创建一个接口并使用注解的方式来配置它 (类似以前Dao接口上标注Mapper注解，现在是一个微服务接口上面标注一个Feign注解)，即可完成对服务提供方的接口绑定，简化了使用Spring Cloud Ribbon 时，自动封装服务调用客户端的开发量。 Feign默认集成了Ribbon 利用Ribbon维护了MicroServiceCloud-Dept的服务列表信息，并且通过轮询实现了客户端的负载均衡，而与Ribbon不同的是，通过Feign只需要定义服务绑定接口且以声明式的方法，优雅而简单的实现了服务调用。 7.2 Feign的使用步骤 创建springcloud-consumer-fdept-feign模块 拷贝springcloud-consumer-dept-80模块下的pom.xml，resource，以及java代码到springcloud-consumer-feign模块，并添加feign依赖。 123456&lt;!--Feign的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 通过Ribbon实现：—原来的controller：DeptConsumerController.java ``````````/** @Auther: csp1999 @Date: 2020/05/17/22:44 @Description:*/@RestControllerpublic class DeptConsumerController { 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106 /** * 理解：消费者，不应该有service层~ * RestTemplate .... 供我们直接调用就可以了！ 注册到Spring中 * (地址：url, 实体：Map ,Class&lt;T&gt; responseType) * &lt;p&gt; * 提供多种便捷访问远程http服务的方法，简单的Restful服务模板~ */ @Autowired private RestTemplate restTemplate; /** * 服务提供方地址前缀 * &lt;p&gt; * Ribbon:我们这里的地址，应该是一个变量，通过服务名来访问 */// private static final String REST_URL_PREFIX = &quot;http://localhost:8001&quot;; private static final String REST_URL_PREFIX = &quot;http://SPRINGCLOUD-PROVIDER-DEPT&quot;; /** * 消费方添加部门信息 * @param dept * @return */ @RequestMapping(&quot;/consumer/dept/add&quot;) public boolean add(Dept dept) &#123; // postForObject(服务提供方地址(接口),参数实体,返回类型.class) return restTemplate.postForObject(REST_URL_PREFIX + &quot;/dept/add&quot;, dept, Boolean.class); &#125; /** * 消费方根据id查询部门信息 * @param id * @return */ @RequestMapping(&quot;/consumer/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; // getForObject(服务提供方地址(接口),返回类型.class) return restTemplate.getForObject(REST_URL_PREFIX + &quot;/dept/get/&quot; + id, Dept.class); &#125; /** * 消费方查询部门信息列表 * @return */ @RequestMapping(&quot;/consumer/dept/list&quot;) public List&lt;Dept&gt; list() &#123; return restTemplate.getForObject(REST_URL_PREFIX + &quot;/dept/list&quot;, List.class); &#125;&#125;``````````通过**Feign**实现：—改造后controller：**DeptConsumerController.java**``````````/** * @Auther: csp1999 * @Date: 2020/05/17/22:44 * @Description: */@RestControllerpublic class DeptConsumerController &#123; @Autowired private DeptClientService deptClientService; /** * 消费方添加部门信息 * @param dept * @return */ @RequestMapping(&quot;/consumer/dept/add&quot;) public boolean add(Dept dept) &#123; return deptClientService.addDept(dept); &#125; /** * 消费方根据id查询部门信息 * @param id * @return */ @RequestMapping(&quot;/consumer/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; return deptClientService.queryById(id); &#125; /** * 消费方查询部门信息列表 * @return */ @RequestMapping(&quot;/consumer/dept/list&quot;) public List&lt;Dept&gt; list() &#123; return deptClientService.queryAll(); &#125;&#125;``````````Feign和Ribbon二者对比，前者显现出面向接口编程特点，代码看起来更清爽，而且Feign调用方式更符合我们之前在做SSM或者SprngBoot项目时，Controller层调用Service层的编程习惯！**主配置类**：``````````/** * @Auther: csp1999 * @Date: 2020/05/17/22:47 * @Description: */@SpringBootApplication@EnableEurekaClient// feign客户端注解,并指定要扫描的包以及配置接口DeptClientService@EnableFeignClients(basePackages = &#123; &quot;com.haust.springcloud&quot;&#125;)// 切记不要加这个注解，不然会出现404访问不到//@ComponentScan(&quot;com.haust.springcloud&quot;)public class FeignDeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignDeptConsumer_80.class, args); &#125;&#125;`````````` 改造springcloud-api模块 pom.xml添加feign依赖 123456&lt;!--Feign的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 新建service包，并新建DeptClientService.java接口， ``````````// @FeignClient:微服务客户端注解,value:指定微服务的名字,这样就可以使Feign客户端直接找到对应的微服务@FeignClient(value = “SPRINGCLOUD-PROVIDER-DEPT”)public interface DeptClientService { 12345678 @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) public Dept queryById(@PathVariable(&quot;id&quot;) Long id); @GetMapping(&quot;/dept/list&quot;) public Dept queryAll(); @GetMapping(&quot;/dept/add&quot;) public Dept addDept(Dept dept);&#125;`````````` 7.3 Feign和Ribbon如何选择？根据个人习惯而定，如果喜欢REST风格使用Ribbon；如果喜欢社区版的面向接口风格使用Feign. Feign 本质上也是实现了 Ribbon，只不过后者是在调用方式上，为了满足一些开发者习惯的接口调用习惯！ 下面我们关闭springcloud-consumer-dept-80 这个服务消费方，换用springcloud-consumer-dept-feign(端口还是80) 来代替：(依然可以正常访问，就是调用方式相比于Ribbon变化了) 8. Hystrix：服务熔断 分布式系统面临的问题 复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免失败！ 8.1 服务雪崩多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其他的微服务，这就是所谓的“扇出”，如果扇出的链路上某个微服务的调用响应时间过长，或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”。 对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几十秒内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障，这些都表示需要对故障和延迟进行隔离和管理，以达到单个依赖关系的失败而不影响整个应用程序或系统运行。 我们需要，弃车保帅！ 8.2 什么是Hystrix？Hystrix是一个应用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时，异常等，Hystrix 能够保证在一个依赖出问题的情况下，不会导致整个体系服务失败，避免级联故障，以提高分布式系统的弹性。 “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控 (类似熔断保险丝) ，向调用方返回一个服务预期的，可处理的备选响应 (FallBack) ，而不是长时间的等待或者抛出调用方法无法处理的异常，这样就可以保证了服务调用方的线程不会被长时间，不必要的占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 8.3 Hystrix能干嘛？ 服务降级 服务熔断 服务限流 接近实时的监控 … 当一切正常时，请求流可以如下所示： 当许多后端系统中有一个潜在阻塞服务时，它可以阻止整个用户请求： 随着大容量通信量的增加，单个后端依赖项的潜在性会导致所有服务器上的所有资源在几秒钟内饱和。 应用程序中通过网络或客户端库可能导致网络请求的每个点都是潜在故障的来源。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，从而备份队列、线程和其他系统资源，从而导致更多跨系统的级联故障。 当使用Hystrix包装每个基础依赖项时，上面的图表中所示的体系结构会发生类似于以下关系图的变化。每个依赖项是相互隔离的，限制在延迟发生时它可以填充的资源中，并包含在回退逻辑中，该逻辑决定在依赖项中发生任何类型的故障时要做出什么样的响应： 官网资料：https://github.com/Netflix/Hystrix/wiki 8.4 服务熔断什么是服务熔断?熔断机制是赌赢雪崩效应的一种微服务链路保护机制。 当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阀值缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是：@HystrixCommand。 服务熔断解决如下问题： 当所依赖的对象不稳定时，能够起到快速失败的目的； 快速失败后，能够根据一定的算法动态试探所依赖对象是否恢复。 入门案例新建springcloud-provider-dept-hystrix-8001模块并拷贝springcloud-provider-dept–8001内的pom.xml、resource和Java代码进行初始化并调整。 导入hystrix依赖 123456&lt;!--导入Hystrix依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 调整yml配置文件 1234567891011121314151617181920212223242526272829303132333435server: port: 8001# mybatis配置mybatis: # springcloud-api 模块下的pojo包 type-aliases-package: com.haust.springcloud.pojo # 本模块下的mybatis-config.xml核心配置文件类路径 config-location: classpath:mybatis/mybatis-config.xml # 本模块下的mapper配置文件类路径 mapper-locations: classpath:mybatis/mapper/*.xml# spring配置spring: application: #项目名 name: springcloud-provider-dept datasource: # 德鲁伊数据源 type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/db01?useUnicode=true&amp;characterEncoding=utf-8 username: root password: root# Eureka配置：配置服务注册中心地址eureka: client: service-url: # 注册中心地址7001-7003 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-hystrix-8001 #修改Eureka上的默认描述信息 prefer-ip-address: true #改为true后默认显示的是ip地址而不再是localhost#info配置info: app.name: haust-springcloud #项目的名称 company.name: com.haust #公司的名称 prefer-ip-address: false: prefer-ip-address: true： 修改controller 1234567891011121314151617181920212223242526272829303132333435/** * @Auther: csp1999 * @Date: 2020/05/17/22:06 * @Description: 提供Restful服务 */@RestControllerpublic class DeptController &#123; @Autowired private DeptService deptService; /** * 根据id查询部门信息 * 如果根据id查询出现异常,则走hystrixGet这段备选代码 * @param id * @return */ @HystrixCommand(fallbackMethod = &quot;hystrixGet&quot;) @RequestMapping(&quot;/dept/get/&#123;id&#125;&quot;)//根据id查询 public Dept get(@PathVariable(&quot;id&quot;) Long id)&#123; Dept dept = deptService.queryById(id); if (dept==null)&#123; throw new RuntimeException(&quot;这个id=&gt;&quot;+id+&quot;,不存在该用户，或信息无法找到~&quot;); &#125; return dept; &#125; /** * 根据id查询备选方案(熔断) * @param id * @return */ public Dept hystrixGet(@PathVariable(&quot;id&quot;) Long id)&#123; return new Dept().setDeptno(id) .setDname(&quot;这个id=&gt;&quot;+id+&quot;,没有对应的信息,null---@Hystrix~&quot;) .setDb_source(&quot;在MySQL中没有这个数据库&quot;); &#125;&#125; 为主启动类添加对熔断的支持注解@EnableCircuitBreaker 1234567891011121314/** * @Auther: csp1999 * @Date: 2020/05/17/22:09 * @Description: 启动类 */@SpringBootApplication@EnableEurekaClient // EnableEurekaClient 客户端的启动类，在服务启动后自动向注册中心注册服务@EnableDiscoveryClient // 服务发现~@EnableCircuitBreaker // 添加对熔断的支持注解public class HystrixDeptProvider_8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(HystrixDeptProvider_8001.class,args); &#125;&#125; 测试： 使用熔断后，当访问一个不存在的id时，前台页展示数据如下: 而不适用熔断的springcloud-provider-dept–8001模块访问相同地址会出现下面状况: 因此，为了避免因某个微服务后台出现异常或错误而导致整个应用或网页报错，使用熔断是必要的 8.5 服务降级什么是服务降级?服务降级是指 当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理，或换种简单的方式处理，从而释放服务器资源以保证核心业务正常运作或高效运作。说白了，就是尽可能的把系统资源让给优先级高的服务。 资源有限，而请求是无限的。如果在并发高峰期，不做服务降级处理，一方面肯定会影响整体服务的性能，严重的话可能会导致宕机某些重要的服务不可用。所以，一般在高峰期，为了保证核心功能服务的可用性，都要对某些服务降级处理。比如当双11活动时，把交易无关的服务统统降级，如查看蚂蚁深林，查看历史订单等等。 服务降级主要用于什么场景呢？当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，可以将一些 不重要 或 不紧急 的服务或任务进行服务的 延迟使用 或 暂停使用。 降级的方式可以根据业务来，可以延迟服务，比如延迟给用户增加积分，只是放到一个缓存中，等服务平稳之后再执行 ；或者在粒度范围内关闭服务，比如关闭相关文章的推荐。 由上图可得，当某一时间内服务A的访问量暴增，而B和C的访问量较少，为了缓解A服务的压力，这时候需要B和C暂时关闭一些服务功能，去承担A的部分服务，从而为A分担压力，叫做服务降级。 服务降级需要考虑的问题 1）那些服务是核心服务，哪些服务是非核心服务 2）那些服务可以支持降级，那些服务不能支持降级，降级策略是什么 3）除服务降级之外是否存在更复杂的业务放通场景，策略是什么？ 自动降级分类1）超时降级：主要配置好超时时间和超时重试次数和机制，并使用异步机制探测回复情况 2）失败次数降级：主要是一些不稳定的api，当失败调用次数达到一定阀值自动降级，同样要使用异步机制探测回复情况 3）故障降级：比如要调用的远程服务挂掉了（网络故障、DNS故障、http服务返回错误的状态码、rpc服务抛出异常），则可以直接降级。降级后的处理方案有：默认值（比如库存服务挂了，返回默认现货）、兜底数据（比如广告挂了，返回提前准备好的一些静态页面）、缓存（之前暂存的一些缓存数据） 4）限流降级：秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级；降级后的处理方案可以是：排队页面（将用户导流到排队页面等一会重试）、无货（直接告知用户没货了）、错误页（如活动太火爆了，稍后重试）。 入门案例在springcloud-api模块下的service包中新建降级配置类DeptClientServiceFallBackFactory.java 12345678910111213141516171819202122232425262728/** * @Auther: csp1999 * @Date: 2020/05/20/9:18 * @Description: Hystrix服务降级 ~ */@Componentpublic class DeptClientServiceFallBackFactory implements FallbackFactory &#123; @Override public DeptClientService create(Throwable cause) &#123; return new DeptClientService() &#123; @Override public Dept queryById(Long id) &#123; return new Dept() .setDeptno(id) .setDname(&quot;id=&gt;&quot; + id + &quot;没有对应的信息，客户端提供了降级的信息，这个服务现在已经被关闭&quot;) .setDb_source(&quot;没有数据~&quot;); &#125; @Override public List&lt;Dept&gt; queryAll() &#123; return null; &#125; @Override public Boolean addDept(Dept dept) &#123; return false; &#125; &#125;; &#125;&#125; 在DeptClientService中指定降级配置类DeptClientServiceFallBackFactory 1234567891011@Component //注册到spring容器中//@FeignClient:微服务客户端注解,value:指定微服务的名字,这样就可以使Feign客户端直接找到对应的微服务@FeignClient(value = &quot;SPRINGCLOUD-PROVIDER-DEPT&quot;,fallbackFactory = DeptClientServiceFallBackFactory.class)//fallbackFactory指定降级配置类public interface DeptClientService &#123; @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) public Dept queryById(@PathVariable(&quot;id&quot;) Long id); @GetMapping(&quot;/dept/list&quot;) public List&lt;Dept&gt; queryAll(); @GetMapping(&quot;/dept/add&quot;) public Boolean addDept(Dept dept);&#125; 在springcloud-consumer-dept-feign模块中开启降级： 123456789101112server: port: 80# Eureka配置eureka: client: register-with-eureka: false # 不向 Eureka注册自己 service-url: # 从三个注册中心中随机取一个去访问 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/# 开启降级feign.hystrixfeign: hystrix: enabled: true 8.6 服务熔断和降级的区别 服务熔断—&gt;服务端：某个服务超时或异常，引起熔断~，类似于保险丝(自我熔断) 服务降级—&gt;客户端：从整体网站请求负载考虑，当某个服务熔断或者关闭之后，服务将不再被调用，此时在客户端，我们可以准备一个 FallBackFactory ，返回一个默认的值(缺省值)。会导致整体的服务下降，但是好歹能用，比直接挂掉强。 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 实现方式不太一样，服务降级具有代码侵入性(由控制器完成/或自动降级)，熔断一般称为自我熔断。 熔断，降级，限流： 限流：限制并发的请求访问量，超过阈值则拒绝； 降级：服务分优先级，牺牲非核心服务（不可用），保证核心服务稳定；从整体负荷考虑； 熔断：依赖的下游服务故障触发熔断，避免引发本系统崩溃；系统自动执行和恢复 8.7 Dashboard 流监控新建springcloud-consumer-hystrix-dashboard模块 添加依赖 123456789101112131415161718192021222324252627282930313233343536373839&lt;!--Hystrix依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--dashboard依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--Ribbon--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--Eureka--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--实体类+web--&gt;&lt;dependency&gt; &lt;groupId&gt;com.haust&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--热部署--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;&lt;/dependency&gt; 主启动类 12345678@SpringBootApplication// 开启Dashboard@EnableHystrixDashboardpublic class DeptConsumerDashboard_9001 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumerDashboard_9001.class,args); &#125;&#125; 给springcloud-provider-dept-hystrix-8001模块下的主启动类添加如下代码,添加监控 123456789101112131415@SpringBootApplication@EnableEurekaClient //EnableEurekaClient 客户端的启动类，在服务启动后自动向注册中心注册服务public class DeptProvider_8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider_8001.class,args); &#125; //增加一个 Servlet @Bean public ServletRegistrationBean hystrixMetricsStreamServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new HystrixMetricsStreamServlet()); //访问该页面就是监控页面 registrationBean.addUrlMappings(&quot;/actuator/hystrix.stream&quot;); return registrationBean; &#125;&#125; 访问：http://localhost:9001/hystrix 进入监控页面： 效果如下图： 9. Zull路由网关概述 什么是zuul? Zull包含了对请求的路由(用来跳转的)和过滤两个最主要功能： 其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础，而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验，服务聚合等功能的基础。Zuul和Eureka进行整合，将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获得其他服务的消息，也即以后的访问微服务都是通过Zuul跳转后获得。 注意：Zuul 服务最终还是会注册进 Eureka 提供：代理 + 路由 + 过滤 三大功能！ Zuul 能干嘛？ 路由 过滤 官方文档：https://github.com/Netflix/zuul/ 入门案例新建springcloud-zuul模块，并导入依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;dependencies&gt; &lt;!--导入zuul依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Hystrix依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--dashboard依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboar&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Ribbon--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--实体类+web--&gt; &lt;dependency&gt; &lt;groupId&gt;com.haust&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml 12345678910111213141516171819202122232425262728server: port: 9527spring: application: name: springcloud-zuul #微服务名称# eureka 注册中心配置eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: #实例的id instance-id: zuul9527.com prefer-ip-address: true # 显示ipinfo: app.name: haust.springcloud # 项目名称 company.name: 河南科技大学西苑校区 # 公司名称# zull 路由网关配置zuul: # 路由相关配置 # 原来访问路由 eg:http://www.cspStudy.com:9527/springcloud-provider-dept/dept/get/1 # zull路由配置后访问路由 eg:http://www.cspstudy.com:9527/haust/mydept/dept/get/1 routes: mydept.serviceId: springcloud-provider-dept # eureka注册中心的服务提供方路由名称 mydept.path: /mydept/** # 将eureka注册中心的服务提供方路由名称 改为自定义路由名称 # 不能再使用这个路径访问了，*： 忽略,隐藏全部的服务名称~ ignored-services: &quot;*&quot; # 设置公共的前缀 prefix: /haust 主启动类 123456789101112/** * @Auther: csp1999 * @Date: 2020/05/20/20:53 * @Description: Zull路由网关主启动类 */@SpringBootApplication@EnableZuulProxy // 开启Zuulpublic class ZuulApplication_9527 &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication_9527.class,args); &#125;&#125; 测试： 可以看出Zull路由网关被注册到Eureka注册中心中了！ 上图是没有经过Zull路由网关配置时，服务接口访问的路由，可以看出直接用微服务(服务提供方)名称去访问，这样不安全，不能将微服务名称暴露！ 所以经过Zull路由网关配置后，访问的路由为： 我们看到，微服务名称被替换并隐藏，换成了我们自定义的微服务名称mydept，同时加上了前缀haust，这样就做到了对路由fan访问的加密处理！ 详情参考springcloud中文社区zuul组件 :https://www.springcloud.cc/spring-cloud-greenwich.html#_router_and_filter_zuul 10. Spring Cloud Config 分布式配置Dalston.RELEASE Spring Cloud Config为分布式系统中的外部配置提供服务器和客户端支持。使用Config Server，您可以在所有环境中管理应用程序的外部属性。客户端和服务器上的概念映射与Spring Environment和PropertySource抽象相同，因此它们与Spring应用程序非常契合，但可以与任何以任何语言运行的应用程序一起使用。随着应用程序通过从开发人员到测试和生产的部署流程，您可以管理这些环境之间的配置，并确定应用程序具有迁移时需要运行的一切。服务器存储后端的默认实现使用git，因此它轻松支持标签版本的配置环境，以及可以访问用于管理内容的各种工具。很容易添加替代实现，并使用Spring配置将其插入。 概述分布式系统面临的–配置文件问题 微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务，由于每个服务都需要必要的配置信息才能运行，所以一套集中式的，动态的配置管理设施是必不可少的。spring cloud提供了configServer来解决这个问题，我们每一个微服务自己带着一个application.yml，那上百个的配置文件修改起来，令人头疼！ 什么是SpringCloud config分布式配置中心？ spring cloud config 为微服务架构中的微服务提供集中化的外部支持，配置服务器为各个不同微服务应用的所有环节提供了一个中心化的外部配置。 spring cloud config 分为服务端和客户端两部分。 服务端也称为 分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密，解密信息等访问接口。 客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息。配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理。并且可用通过git客户端工具来方便的管理和访问配置内容。 spring cloud config 分布式配置中心能干嘛？ 集中式管理配置文件 不同环境，不同配置，动态化的配置更新，分环境部署，比如 /dev /test /prod /beta /release 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息 当配置发生变动时，服务不需要重启，即可感知到配置的变化，并应用新的配置 将配置信息以REST接口的形式暴露 spring cloud config 分布式配置中心与GitHub整合 由于spring cloud config 默认使用git来存储配置文件 (也有其他方式，比如自持SVN 和本地文件)，但是最推荐的还是git ，而且使用的是 http / https 访问的形式。 入门案例服务端新建springcloud-config-server-3344模块导入pom.xml依赖 12345678910111213141516171819&lt;dependencies&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; resource下创建application.yml配置文件，Spring Cloud Config服务器从git存储库（必须提供）为远程客户端提供配置： 12345678910111213141516171819server: port: 3344spring: application: name: springcloud-config-server # 连接码云远程仓库 cloud: config: server: git: # 注意是https的而不是ssh uri: https://gitee.com/cao_shi_peng/springcloud-config.git # 通过 config-server可以连接到git，访问其中的资源以及配置~# 不加这个配置会报Cannot execute request on any known server 这个错：连接Eureka服务端地址不对# 或者直接注释掉eureka依赖 这里暂时用不到eurekaeureka: client: register-with-eureka: false fetch-registry: false 主启动类 1234567@EnableConfigServer // 开启spring cloud config server服务@SpringBootApplicationpublic class Config_server_3344 &#123; public static void main(String[] args) &#123; SpringApplication.run(Config_server_3344.class,args); &#125;&#125; 将本地git仓库springcloud-config文件夹下新建的application.yml提交到码云仓库： 定位资源的默认策略是克隆一个git仓库（在spring.cloud.config.server.git.uri），并使用它来初始化一个迷你SpringApplication。小应用程序的Environment用于枚举属性源并通过JSON端点发布。 HTTP服务具有以下格式的资源： 123456789101112131415161718/&#123; application&#125;/&#123; profile&#125;[/&#123; label&#125;]/&#123; application&#125;-&#123; profile&#125;.yml/&#123; label&#125;/&#123; application&#125;-&#123; profile&#125;.yml/&#123; application&#125;-&#123; profile&#125;.properties/&#123; label&#125;/&#123; application&#125;-&#123; profile&#125;.properties 其中“应用程序”作为SpringApplication中的spring.config.name注入（即常规的Spring Boot应用程序中通常是“应用程序”），“配置文件”是活动配置文件（或逗号分隔列表的属性），“label”是可选的git标签（默认为“master”）。 测试访问http://localhost:3344/application-dev.yml 测试访问 http://localhost:3344/application/test/master 测试访问 http://localhost:3344/master/application-dev.yml 如果测试访问不存在的配置则不显示 如：http://localhost:3344/master/application-aaa.yml 客户端将本地git仓库springcloud-config文件夹下新建的config-client.yml提交到码云仓库： 新建一个springcloud-config-client-3355模块，并导入依赖 123456789101112131415&lt;!--config--&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-start --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; resources下创建application.yml和bootstrap.yml配置文件 bootstrap.yml 是系统级别的配置 12345678# 系统级别的配置spring: cloud: config: name: config-client # 需要从git上读取的资源名称，不要后缀 profile: dev label: master uri: http://localhost:3344 application.yml 是用户级别的配置 1234# 用户级别的配置spring: application: name: springcloud-config-client 创建controller包下的ConfigClientController.java 用于测试 123456789101112131415@RestControllerpublic class ConfigClientController &#123; @Value(&quot;$&#123;spring.application.name&#125;&quot;) private String applicationName; //获取微服务名称 @Value(&quot;$&#123;eureka.client.service-url.defaultZone&#125;&quot;) private String eurekaServer; //获取Eureka服务 @Value(&quot;$&#123;server.port&#125;&quot;) private String port; //获取服务端的端口号 @RequestMapping(&quot;/config&quot;) public String getConfig()&#123; return &quot;applicationName:&quot;+applicationName + &quot;eurekaServer:&quot;+eurekaServer + &quot;port:&quot;+port; &#125;&#125; 主启动类 123456@SpringBootApplicationpublic class ConfigClient &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigClient.class,args); &#125;&#125; 测试： 启动服务端Config_server_3344 再启动客户端ConfigClient 访问：http://localhost:8201/config/ 小案例 本地新建config-dept.yml和config-eureka.yml并提交到码云仓库 这里配置文件内容不再列举直接到代码中看把。 新建springcloud-config-eureka-7001模块，并将原来的springcloud-eureka-7001模块下的内容拷贝的该模块。 1.清空该模块的application.yml配置，并新建bootstrap.yml连接远程配置 1234567spring: cloud: config: name: config-eureka # 仓库中的配置文件名称 label: master profile: dev uri: http://localhost:3344 2.在pom.xml中添加spring cloud config依赖 1234567&lt;!--config--&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-config --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 3.主启动类 1234567@SpringBootApplication@EnableEurekaServer //EnableEurekaServer 服务端的启动类，可以接受别人注册进来~public class ConfigEurekaServer_7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigEurekaServer_7001.class,args); &#125;&#125; 4.测试 第一步：启动 Config_Server_3344，并访问 http://localhost:3344/master/config-eureka-dev.yml 测试 第二部：启动ConfigEurekaServer_7001，访问 http://localhost:7001/ 测试 显示上图则成功 新建springcloud-config-dept-8001模块并拷贝springcloud-provider-dept-8001的内容 同理导入spring cloud config依赖、清空application.yml 、新建bootstrap.yml配置文件并配置 1234567spring: cloud: config: name: config-dept label: master profile: dev uri: http://localhost:3344 主启动类 12345678910111213141516@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中！@EnableDiscoveryClient //服务发现~@EnableCircuitBreaker //public class ConfigDeptProvider_8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigDeptProvider_8001.class,args); &#125; //增加一个 Servlet @Bean public ServletRegistrationBean hystrixMetricsStreamServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new HystrixMetricsStreamServlet()); registrationBean.addUrlMappings(&quot;/actuator/hystrix.stream&quot;); return registrationBean; &#125;&#125; 测试 (略)","tags":["笔记"],"categories":["Java"]},{"title":"navicat连接mysql出现2059错误","path":"/2021/11/11/mysql2059/","content":"这个错误出现的原因是在mysql8之前的版本中加密规则为mysql_native_password，而在mysql8以后的加密规则为caching_sha2_password 解决此问题有两种方法，一种是更新navicat驱动来解决此问题，一种是将mysql用户登录的加密规则修改为mysql_native_password。；根据网上大部分建议采取了第二种方式： 1.用管理员权限打开cmd，输入mysql -u root -p进入输入密码后进入mysql数据库 1mysql -u root -p #进入数据库 2.修改加密规则及密码，刷新即可； 123ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;你的mysql密码&#x27; PASSWORD EXPIRE NEVER; #修改加密规则ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;你的mysql密码&#x27;; #修改密码FLUSH PRIVILEGES; #刷新数据 注意，语句后面的分号不能去掉","tags":["报错"],"categories":["mysql"]},{"title":"应用程序无法正常启动(0xc000007b)","path":"/2021/11/11/0xc000007b/","content":"安装mysql的时候，到最后一步系统提示错误，应用程序无法正常启动(0xc000007b) 方案一：打开电脑搜索输入cmd.exe，选择以管理员身份运行，跳出提示框时选择继续 键入sfc /scannow ，然后按 Enter。系统开始扫描，请您耐心等待几分钟 修复完成后，重新打开软件就不会再出现警告了 第二种方案：使用DirectX修复工具","tags":["报错"],"categories":["windows"]},{"title":"css设置高度占满","path":"/2021/11/10/cssheightmax/","content":"想让下面的header元素高度为100%，奈何设置了height： 100%；之后没作用,高度自适应问题 123&lt;body&gt; &lt;div class=&quot;wrap&quot;&gt;&lt;/div&gt;&lt;/body&gt; 我想让这个div铺满整个页面 方法一：先让根元素和body铺满，再然div铺满，这样div就会继承body的高度了 123456789:root,body &#123; height: 100%;&#125;.wrap &#123; width: 100%; height: 100%; background-color: skyblue;&#125; 方法二：让div脱离文档流，再铺满 123456.wrap &#123; width: 100%; height: 100%; background-color: skyblue; position: fixed;&#125; 方法三：让div脱离文档流，再吸收剩余空间 12345678.wrap &#123; background-color: skyblue; position: absolute; left: 0; top: 0; right: 0; bottom: 0;&#125;","tags":["随笔"],"categories":["css"]},{"title":"Vue-websocket,vue全局通讯","path":"/2021/11/09/websocket/","content":"websocket123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176import moment from &#x27;moment&#x27;import Vue from &#x27;vue&#x27;Vue.prototype.$moment = momentvar websock = nullvar ws = nullvar globalCallback = function () &#123;&#125;;let rec; //断线重连后，延迟5秒重新创建WebSocket连接 rec用来存储延迟请求的代码let isConnect = false; //连接标识 避免重复连接let checkMsg = &quot;ping&quot;; //心跳发送/返回的信息 服务器和客户端收到的信息内容如果如下 就识别为心跳信息 不要做业务处理var data = &#123; to:-1, text:&#x27;/&#x27;&#125;;let createWebSocket = () =&gt; &#123; try &#123; var ishttps = &#x27;https:&#x27; == document.location.protocol ? true : false; var ws if(ishttps) &#123; ws = &#x27;wss://wdev.xxx.com/api/screen/webSocket/&#x27;+moment().valueOf() &#125; else &#123; ws = &#x27;ws://wdev.xxx.com/api/screen/webSocket/&#x27;+moment().valueOf(); &#125; initWebSocket(); //初始化websocket连接 &#125; catch (e) &#123; console.log(&quot;尝试创建连接失败&quot;); reConnect(); //如果无法连接上webSocket 那么重新连接！可能会因为服务器重新部署，或者短暂断网等导致无法创建连接 &#125;&#125;;//定义重连函数let reConnect = () =&gt; &#123; console.log(&quot;尝试重新连接&quot;); if (isConnect) return; //如果已经连上就不在重连了 rec &amp;&amp; clearTimeout(rec); rec = setTimeout(function () &#123; // 延迟5秒重连 避免过多次过频繁请求重连 createWebSocket(); &#125;, 5000);&#125;; //心跳设置var heartCheck = &#123; timeout: 20000, //每段时间发送一次心跳包 这里设置为20s timeoutObj: null, //延时发送消息对象（启动心跳新建这个对象，收到消息后重置对象） start: function () &#123; this.timeoutObj = setTimeout(function () &#123; // if (isConnect) websock.send(checkMsg); // console.log(&#x27;0&#x27;,websock) // websock.send(checkMsg); websock.send(JSON.stringify(data)); &#125;, this.timeout); &#125;, reset: function () &#123; clearTimeout(this.timeoutObj); this.start(); &#125;&#125;;// 数据接收function websocketonmessage (e) &#123; // console.log(JSON.parse(e.data)) globalCallback(JSON.parse(e.data))&#125; // 数据发送function websocketsend (agentData) &#123;// websock.send(JSON.stringify(agentData)) setTimeout(() =&gt; &#123; // 添加状态判断，当为OPEN时，发送消息 if (websock.readyState === websock.OPEN) &#123; // futwebsock.OPEN = 1 // 发给后端的数据需要字符串化 websock.send(agentData) &#125; if (websock.readyState === websock.CLOSED) &#123; // futwebsock.CLOSED = 3 // document.write(&quot;重连中，请稍候&quot; + &quot;&lt;/br&gt;&quot;); console.log(&quot;重连中，请稍候&quot;) isConnect = false; //连接断开修改标识 reConnect(); //连接错误 需要重连 &#125; &#125;, 500)&#125; // 关闭function websocketclose (e) &#123; // e.code === 1000 表示正常关闭。 无论为何目的而创建, 该链接都已成功完成任务。 // e.code !== 1000 表示非正常关闭。 // document.write(&#x27;websocket 连接关闭 connection closed (&#x27; + e.code + &#x27;)&#x27; + &quot;&lt;/br&gt;&quot;) isConnect = false ; //断开后修改标识 console.log(&#x27;connection closed (&#x27; + e.code + &#x27;)&#x27;) console.log(&#x27;websocket 连接关闭&#x27;)&#125; // 创建 websocket 连接function websocketOpen (e) &#123; console.log(&#x27;连接成功&#x27;)&#125; // 初始化websocketfunction initWebSocket (path) &#123; if (typeof(WebSocket) === &quot;undefined&quot;) &#123; alert(&quot;您的浏览器不支持socket&quot;) &#125; else &#123; // ws = path // ws地址 --&gt;这里是你的请求路径 var ishttps = &#x27;https:&#x27; == document.location.protocol ? true : false; var ws if(ishttps) &#123; // ws = `wss://` + &#x27;v3.zt.uhappy.net.cn/ws/msg?token=&#x27;+token+&#x27;&amp;uid=&#x27;+uid; ws = &#x27;wss://wdev.xxx.com/api/screen/webSocket/&#x27;+moment().valueOf() &#125; else &#123; ws = &#x27;ws://wdev.xxx.com/api/screen/webSocket/&#x27;+moment().valueOf() &#125; websock = new WebSocket(ws) websock.onmessage = function (e) &#123; websocketonmessage(e) heartCheck.reset(); &#125; websock.onclose = function (e) &#123; websocketclose(e) reConnect(); //连接错误 需要重连 &#125; websock.onopen = function () &#123; websocketOpen() heartCheck.start(); &#125; // 连接发生错误的回调方法 websock.onerror = function () &#123; // document.write(&#x27;WebSocket连接发生错误&#x27; + &quot;&lt;/br&gt;&quot;) console.log(&#x27;WebSocket连接发生错误&#x27;) isConnect = false; //连接断开修改标识 reConnect(); //连接错误 需要重连 &#125; &#125;&#125; // 实际调用的方法function sendSock (agentData, callback) &#123; globalCallback = callback if (websock.readyState === websock.OPEN) &#123; // 若是ws开启状态 websocketsend(agentData) &#125; else if (websock.readyState === websock.CONNECTING) &#123; // 若是 正在开启状态，则等待1s后重新调用 setTimeout(function () &#123; sendSock(agentData, callback) &#125;, 1000) &#125; else &#123; // 若未开启 ，则等待1s后重新调用 setTimeout(function () &#123; sendSock(agentData, callback) &#125;, 1000) &#125;&#125;function getSock(callback) &#123; globalCallback = callback&#125; /** * 关闭websocket函数 */function closeSock () &#123; if (websock) &#123; websock.close() // 关闭websocket &#125; &#125;initWebSocket()// 将方法暴露出去export &#123; initWebSocket, sendSock, getSock, closeSock&#125; 设置全局在main.js中 12345678910111213141516171819import * as socketApi from &#x27;@/api/websocket&#x27;Vue.prototype.socketApi = socketApiwebsocket.js //路径在api里initWebSocket() //连接websocket (已自动连接)vue页面中调用方法：发送消息： var data = &#123;&#125;; data[&quot;to&quot;] = -1; data[&quot;text&quot;] = &#x27;456&#x27;; //text 发送值//发送的参数：JSON.stringify(data) 回调方法：this.getConfigResultthis.socketApi.sendSock(JSON.stringify(data), this.getConfigResult);获取消息：this.socketApi.getSock(this.getConfigResult);关闭连接：this.socketApi.closeSock 演示页面1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;template&gt; &lt;div class=&quot;msgContent&quot;&gt; &lt;p&gt;【发送消息】：&lt;input type=&quot;text&quot; value=&quot;hello websocket&quot; v-model=&quot;value&quot;&gt; &lt;!-- &lt;p&gt;【操作开启socket】：&lt;div&gt;&lt;button onclick=&quot;openSocket()&quot;&gt;开启socket&lt;/button&gt;&lt;/div&gt; --&gt; &lt;div class=&quot;sendBtn&quot; @click=&quot;sendMessage()&quot;&gt;发送消息&lt;/div&gt; &lt;div&gt; 【收到消息】： &lt;p v-for=&quot;(item,index) in message&quot; :key=&quot;index&quot;&gt;&#123;&#123;item&#125;&#125;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt; &lt;script&gt; export default &#123; name: &#x27;mymarquee&#x27;, data() &#123; return &#123; path: &#x27;ws://wdev.xxx.com/api/screen/webSocket/&#x27;, message:[], msgShow:false, value:&#x27;&#x27; &#125; &#125;, created()&#123; // this.path += this.$moment().valueOf() // this.socketApi.initWebSocket(this.path); this.socketApi.getSock(this.getConfigResult); &#125;, methods: &#123; stop()&#123; this.msgShow = false; &#125;, getConfigResult (res) &#123; this.message.push(res.date+&#x27; 消息：&#x27;+ res.text) // // 接收回调函数返回数据的方法 console.log(this.message) &#125;, sendMessage() &#123; if(typeof(WebSocket) == &quot;undefined&quot;) &#123; console.log(&quot;您的浏览器不支持WebSocket&quot;); &#125;else &#123; var data = &#123;&#125;; data[&quot;to&quot;] = -1; data[&quot;text&quot;] = this.value; console.log(JSON.stringify(data)) this.socketApi.sendSock(JSON.stringify(data), this.getConfigResult); &#125; &#125;, &#125;, destroyed () &#123; this.socketApi.closeSock() &#125;, &#125; &lt;/script&gt; &lt;style lang=&quot;less&quot;&gt;.msgContent &#123; width: 100%; font-size: 32px; margin-top: 200px; .sendBtn &#123; width: 300px; padding: 10px; border: 1px solid #333; margin: 50px auto; cursor: pointer; &#125;&#125;&lt;/style&gt;","tags":["随笔"],"categories":["Vue"]},{"title":"python新的环境下安装所有项目依赖+报错处理","path":"/2021/11/08/pythonyilai/","content":"一 pip install pipreqs 在项目目录 shift+右键—-》打开命令行或者powershell 输入pipreqs ./ 可能报错 1.gbk问题 pipreqs ./ –encoding=utf8 2.SyntaxError: (unicode error) ‘unicodeescape’ codec can’t decode bytes in position 480-481: truncated \\UXXXXXXXX escape 将报错的文件中路径改成\\ 应该是有 \\u开头的字符串包括注释里面的 3.You are using pip version 21.2.4; however, version 21.3.1 is available. You should consider upgrading via the ‘C:\\Users\\xl\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install –upgrade pip’ command 1python -m pip install -U pip 进行更新 二 pip install -r requriements.txt 然后就可以批量安装依赖了，安排~","tags":["随笔","bug"],"categories":["python"]},{"title":"uniapp退出APP","path":"/2021/11/06/exitapp/","content":"123456789// #ifdef APP-PLUS if (plus.os.name.toLowerCase() === &#x27;android&#x27;) &#123; plus.runtime.quit(); &#125; else &#123; const threadClass = plus.ios.importClass(&quot;NSThread&quot;); const mainThread = plus.ios.invoke(threadClass, &quot;mainThread&quot;); plus.ios.invoke(mainThread, &quot;exit&quot;); &#125; // #endif","tags":["随笔"],"categories":["uniapp"]},{"title":"uniapp,保存视频到相册","path":"/2021/11/03/downvideo/","content":"uniapp,保存视频到相册，安卓端是正常的，ios端下载成功，在把文件塞进相册的时候却一直失败。 找了好几个解决方案最后才定位问题，下载下来的视频是flv格式的，把视频变成mp4格式的就成功了，估计是ios不认为flv是一个视频文件，所以不让进相册 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970uni.showModal(&#123; title: &quot;提示&quot;, content: &quot;是否下载该视频&quot;, showCancel: true, cancelText: &#x27;取消&#x27;, confirmText: &#x27;下载&#x27;, success: res =&gt; &#123; if (res.confirm) &#123; // 用户点击确定 that.downvideo = true const downloadTask = uni.downloadFile(&#123; url: encodeURI(`$&#123;apiUrl&#125;` + &#x27;/api/downvideo-web/downVideo/likeVideo?dangerId=&#x27; + that.id + &#x27;&amp;&amp;groupId=&#x27; + header().groupId), header: header(), success: (data) =&gt; &#123; if (data.statusCode === 200) &#123; if (uni.getSystemInfoSync().platform == &#x27;ios&#x27;) data.tempFilePath = escape(data.tempFilePath) filePath: data.tempFilePath, // 视频的本地临时地址 success: function(res) &#123; uni.showToast(&#123; title: &#x27;下载完成,请到相册查看&#x27;, position: &#x27;center&#x27;, icon: &#x27;none&#x27;, duration: 2000 &#125;); &#125;, fail: (err) =&gt; &#123; uni.showToast(&#123; title: err, position: &#x27;center&#x27;, icon: &#x27;none&#x27;, duration: 2000 &#125;); &#125;, complete: () =&gt; &#123; that.downvideo = false that.videoprogress = 0 &#125; &#125;); &#125; &#125;, fail: (err) =&gt; &#123; uni.hideLoading() uni.showToast(&#123; title: err || &#x27;未开通或没有权限&#x27;, position: &#x27;center&#x27;, icon: &#x27;none&#x27;, duration: 2000 &#125;); &#125;, complete: () =&gt; &#123; that.downvideo = false that.videoprogress = 0 &#125; &#125;); downloadTask.onProgressUpdate((res) =&gt; &#123; // 下载进度 // console.log(&#x27;进度=&#x27; + res.progress) if (this.videoprogress &lt; 100) &#123; this.videoprogress = res.progress &#125; &#125;); &#125; &#125; &#125;)","tags":["随笔"],"categories":["uniapp"]},{"title":"创建全局变量","path":"/2021/11/03/creadstaticvar/","content":"使用App.vue在export default的下面新建一个对象globalDat，对象名不支持自定义 例如: 1234globalData: &#123; debug: true, //是否对前台开启调试模式选择 state: false //调试功能开关 &#125; 调用1getApp().globalData.debug 修改1getApp().globalData.debug=false","tags":["随笔"],"categories":["uniapp"]},{"title":"调用/修改上个页面数据","path":"/2021/11/03/backpage/","content":"内页123456let pages = getCurrentPages();let prevPage = pages[pages.length - 2]; //上一个页面//直接调用上一个页面的setImage()方法，把数据存到上一个页面中去prevPage.$vm.setImage(&#123; path: _this.snapshotsrc &#125;); 上页1234567891011121314151617//设置图片 setImage(e) &#123; //显示在页面 //this.imagesrc = e.path; //保存到相册 uni.saveImageToPhotosAlbum(&#123; filePath: e.path, success: () =&gt; &#123; uni.showToast(&#123; title: &#x27;已保存至相册&#x27;, duration: 2000 &#125;); &#125; &#125;); &#125;","tags":["随笔"],"categories":["uniapp"]},{"title":"ios获取idfa","path":"/2021/11/03/iosgetidfa/","content":"123456789101112131415161718if (uni.getSystemInfoSync().platform == &#x27;ios&#x27;) &#123; var NSUUID = plus.ios.importClass(&#x27;NSUUID&#x27;); var UIDevice = plus.ios.importClass(&quot;UIDevice&quot;); var currentDevice = UIDevice.currentDevice() var identifierForVendor = currentDevice.identifierForVendor().UUIDString(); var ASIdentifierManager = plus.ios.importClass(&quot;ASIdentifierManager&quot;); var sharedManager = ASIdentifierManager.sharedManager(); if (sharedManager.isAdvertisingTrackingEnabled()) &#123; var advertisingIdentifier = sharedManager.advertisingIdentifier(); var idfa2 = plus.ios.invoke(advertisingIdentifier, &quot;UUIDString&quot;); &#125; // var result = &#123;&#x27;idfa&#x27;:idfa,&#x27;idfv&#x27;:identifierForVendor&#125; // uni.showToast(&#123; // title: &quot;2-idfa:&quot; + idfa2, // position: &#x27;center&#x27;, // duration: 2500 // &#125;); &#125;","tags":["随笔"],"categories":["uniapp"]},{"title":"页面回弹bounce失效问题","path":"/2021/11/02/pagesbounce/","content":"有时候在page里面设置了禁止页面回弹会无效 1&quot;app-plus&quot;:&#123;&quot;bounce&quot;:&quot;none&quot;&#125; 可以尝试如下方式解决： 1234567&quot;style&quot;: &#123;&quot;disableScroll&quot;:true,&quot;app-plus&quot;:&#123;&quot;bounce&quot;:&quot;none&quot;&#125;,&#125;","tags":["随笔","bug"],"categories":["uniapp"]},{"path":"/about/index.html","content":"扫码可加微信,请备注来意留言友链 博客历程 2021 年 11 月 01 日突然想写点笔记？那搞个博客吧?2022 年 10 月 11 日我好像有个博客来着？"},{"path":"/comments/index.html","content":""},{"path":"/friends/index.html","content":"我可以交换友链吗？满足以下一点的都欧克： 合法的、非营利性、无商业广告 如何添加友链？第一步：添加本站的友链123title: 苏三博客avatar: https://su3.cn/pic.jpgurl: https://su3.cn第二步：下方留言告知我一下留言内容包含贵方的链接情况以及友链页面123title: 小明avatar: x.pngurl:xx.xx 苏三博客苏三博客2"},{"path":"/music/index.html","content":"苏三博客 歌曲 舞曲 轻音乐 周杰伦 许嵩"},{"path":"/notes/index.html","content":"集成工具 在线psjsonmarkdown编辑器思维导图H5在线运行JS/Html在线格式化CSS在线格式化正则测试工具HTML和JS互转html标签闭合查询字符串去重复md截图图片快速处理md网络图片快速处理urlencode编码解码驼峰和下划线互转字母大小写在线转换音乐 常用工具 JSON在线流程图 开发工具 mavenJava工具类库特殊符号 资料相关 Linux命令大全kuangstudystellar 资料整理 SpringCloud脑图若依文档 其他工具 poeascii字符画1ascii字符画2"},{"path":"/talk/index.html","content":"2021年11月 搞开发这么多年来没怎么写过博客，主要吧是因为懒，现在开始慢慢养成写博客的习惯，加油吧，看看能坚持多久~ 2021年11月5日 第一条动态~ 2021年11月5日 (function () { var oldClass = \"\"; var Obj = \"\"; $(\".cbp_tmtimeline li\").hover(function () { Obj = $(this).children(\".shuoshuo_author_img\"); Obj = Obj.children(\"img\"); oldClass = Obj.attr(\"class\"); var newClass = oldClass + \" zhuan\"; Obj.attr(\"class\", newClass); }, function () { Obj.attr(\"class\", oldClass); }) })"},{"path":"/utils/index.html","content":"/* 全局样式 */ body { margin: 0; font-family: Arial, sans-serif; } /* 导航栏样式 */ .nav { background-color: #fff; display: flex; justify-content: space-between; align-items: center; padding: 10px 20px; box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1); position: fixed; top: 0; left: 0; right: 0; z-index: 100; } .logo { font-size: 24px; font-weight: bold; color: #333; } .menu { display: flex; list-style-type: none; margin: 0; padding: 0; } .menu li { margin-left: 20px; } .menu li a { text-decoration: none; color: #333; transition: color 0.3s; } .menu li a:hover { color: #007bff; } /* 主体内容样式 */ .container23 { max-width: 90%; margin: 80px auto 0; padding: 20px; } .category23 { border: 1px solid #ccc; border-radius: 5px; margin-bottom: 10px; } .category23-header { background-color: #f1f1f1; padding: 10px; /* cursor: pointer; */ } .category23-header h3 { margin: 0; } .category23-content { padding: 10px; display: flex; flex-wrap: wrap; gap: 10px; } .link-container23 { display: inline-block; padding: 5px 10px; border: 1px solid #ccc; border-radius: 5px; transition: background-color 0.3s, color 0.3s; } .link-container23:hover { background-color: #007bff; color: #fff; } .link { text-decoration: none; color: inherit; } @media (max-width: 767px) { .container23 { margin-top: 60px; padding: 10px; } } // 网址信息数组 const categories = [ { name: \"集成工具\", links: [ { name: \"json\", url: \"https://xen.cc/json/\" }, { name: \"API在线调试\", url: \"https://xen.cc/tools/api-debugger/\" }, { name: \"Sitemap/robots生成器\", url: \"https://xen.cc/tools/SiteMap/\" }, { name: \"模板表格快速填充工具\", url: \"https://xen.cc/tools/excel/\" }, { name: \"tk定价计算器\", url: \"https://xen.cc/tools/calculator2.html\" }, { name: \"多步骤计算器\", url: \"https://xen.cc/tools/calculator.html\" }, { name: \"二维码生成\", url: \"https://xen.cc/tools/qrcode/\" }, { name: \"正则测试工具\", url: \"https://xen.cc/tools/regex/regex.html\" }, { name: \"urlencode编码解码\", url: \"https://xen.cc/tools/Encode.html\" }, { name: \"在线ps\", url: \"https://xen.cc/tools/ps.html\" }, { name: \"QuartzCron生成和解析\", url: \"https://xen.cc/tools/QuartzCron/\" }, { name: \"时区时间\", url: \"https://xen.cc/tools/timeZone.html\" }, { name: \"md5在线加密\", url: \"https://xen.cc/tools/md5/\" }, { name: \"驼峰和下划线互转\", url: \"https://xen.cc/tools/convertFormat.html\" }, { name: \"字母大小写互换\", url: \"https://xen.cc/tools/LetterCaseConversion.html\" }, { name: \"字母转大转小\", url: \"https://xen.cc/tools/LetterSize.html\" }, { name: \"颜色代码对照表\", url: \"https://xen.cc/tools/ColorCodeReference.html\" }, { name: \"markdown编辑器\", url: \"https://xen.cc/md\" }, { name: \"字符串去重复\", url: \"https://xen.cc/tools/qc/qc.html\" }, { name: \"思维导图\", url: \"https://xen.cc/tools/mindtools/mindtools.html\" }, { name: \"html标签闭合查询\", url: \"https://xen.cc/tools/bh/bh.html\" }, { name: \"JS/Html在线格式化\", url: \"https://xen.cc/tools/jshtmlformat/jshtmlformat.html\" }, { name: \"CSS在线格式化\", url: \"https://xen.cc/tools/csslformat/csslformat.html\" }, { name: \"HTML和JS互转\", url: \"https://xen.cc/tools/htmljs/htmljs.html\" }, { name: \"H5在线运行\", url: \"https://xen.cc/tools/h5.html\" }, { name: \"md截图图片快速处理\", url: \"https://xen.cc/tools/mdimgstool/mdimgtool.html\" }, { name: \"md网络图片快速处理\", url: \"https://xen.cc/tools/mdimgstool/mdimgstool.html\" }, { name: \"MusicArrayCreat\", url: \"https://xen.cc/tools/MusicArrayCreat.html\" }, { name: \"MusicFolderTool\", url: \"https://xen.cc/tools/MusicFolderTool.html\" }, { name: \"AI对话\", url: \"https://ai.su3.cn\" }, { name: \"活动价格计算\", url: \"https://xen.cc/tools/ActivityDiscount.html\" }, { name: \"日期间隔计算\", url: \"https://xen.cc/tools/DateDiffer.html\" }, { name: \"系统更新\", url: \"https://xen.cc/tools/systemUpdate/\" }, { name: \"wifi卡片\", url: \"https://xen.cc/tools/wifiCard/\" }, { name: \"音乐\", url: \"https://xen.cc/tools/music.html\" } ] }, { name: \"资料相关\", links: [ { name: \"Linux命令大全\", url: \"https://www.linuxcool.com/\" }, { name: \"stellar\", url: \"https://xaoxuu.com/wiki/stellar/\" } ] }, { name: \"资料整理\", links: [ { name: \"SpringCloud脑图\", url: \"https://xen.cc/ns/SpringCloud2020.html\" }, { name: \"若依文档\", url: \"http://doc.ruoyi.vip/\" }, { name: \"blog\", url: \"https://github.com/dunwu/blog/\" } ] }, { name: \"开发工具\", links: [ { name: \"maven\", url: \"https://mvnrepository.com/\" }, { name: \"Java工具类库\", url: \"https://hutool.cn/docs/\" }, { name: \"特殊符号\", url: \"http://www.fhdq.net/\" } ] }, { name: \"其他工具\", links: [ { name: \"java在线生成代码\", url: \"https://java.bejson.com/generator\" }, { name: \"deepseek\", url: \"https://www.deepseek.com/\" }, { name: \"moonshot\", url: \"https://kimi.moonshot.cn/\" }, { name: \"cursor\", url: \"https://www.cursor.com/\" }, { name: \"TraeCN\", url: \"https://www.trae.cn/\" }, { name: \"claude\", url: \"http://claude.ai\" }, { name: \"chatgpt\", url: \"https://chatgpt.com/\" }, { name: \"vercel\", url: \"https://vercel.com/\" }, { name: \"zeabur\", url: \"https://zeabur.com/\" }, { name: \"poe\", url: \"https://poe.com/\" }, { name: \"pdf编辑\", url: \"https://www.sejda.com\" }, { name: \"音乐魔石\", url: \"https://yym4.com\" }, { name: \"yymp3\", url: \"https://www.yymp3.com\" }, { name: \"极光无损\", url: \"https://www.jgwav.com/\" }, { name: \"歌曲宝\", url: \"https://www.gequbao.com\" }, { name: \"ascii字符画1\", url: \"http://patorjk.com/software/taag\" }, { name: \"ascii字符画2\", url: \"http://www.network-science.de/ascii/\" }, { name: \"draw\", url: \"https://draw.io/\" }, { name: \"代码画流程图\", url: \"https://mermaid.live\" }, { name: \"ip\", url: \"https://whatismyipaddress.com/\" }, { name: \"阿里云域名市场\", url: \"https://mi.aliyun.com/\" }, { name: \"超级设计\", url: \"https://www.superdesign.dev\" } ] }, ]; // 渲染函数 function renderCategories() { const categoriesContainer = document.getElementById(\"categories\"); categories.forEach(category => { const categoryElement = document.createElement(\"div\"); categoryElement.classList.add(\"category23\"); const categoryHeader = document.createElement(\"div\"); categoryHeader.classList.add(\"category23-header\"); const categoryTitle = document.createElement(\"label\"); categoryTitle.textContent = category.name; categoryHeader.appendChild(categoryTitle); categoryElement.appendChild(categoryHeader); const categoryContent = document.createElement(\"div\"); categoryContent.classList.add(\"category23-content\"); category.links.forEach(link => { const linkContainer = document.createElement(\"div\"); linkContainer.classList.add(\"link-container23\"); const linkElement = document.createElement(\"a\"); linkElement.classList.add(\"link\"); linkElement.href = link.url; linkElement.textContent = link.name; linkElement.target = \"_blank\"; // 在新窗口打开链接 linkContainer.appendChild(linkElement); categoryContent.appendChild(linkContainer); }); categoryElement.appendChild(categoryContent); categoriesContainer.appendChild(categoryElement); }); } // 渲染网址导航 renderCategories();"},{"title":"Flutter 相关问题","path":"/notes/flutter/index.html","content":"运行时弹出「无法打开“iproxy”，因为无法验证开发者。」弹窗，手动添加信任： 1sudo xattr -r -d com.apple.quarantine futter的SDK目录/bin/cache/artifacts/usbmuxd/iproxy 清除缓存，重新 build： 123rm -rf buildflutter cleanflutter build ios --debug"},{"path":"/notes/gitnote/index.html","content":"Git 安装配置Git 各平台安装包下载地址http://git-scm.com/downloads Linux 平台上安装Git 的工作需要调用 curl，zlib，openssl，expat，libiconv 等库的代码，所以需要先安装这些依赖工具。 在有 yum 的系统上（比如 Fedora）或者有 apt-get 的系统上（比如 Debian 体系），可以用下面的命令安装： 各 Linux 系统可以使用其安装包管理工具（apt-get、yum 等）进行安装： Debian/UbuntuDebian/Ubuntu Git 安装命令为： 1234567$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev$ apt-get install git$ git --versiongit version 1.8.1.2 Centos/RedHat 安装1234567$ yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel$ yum -y install git-core$ git --versiongit version 1.7.1 源码安装Git 最新源码包下载地址https://git-scm.com/download 安装指定系统的依赖包： 1234567########## Centos/RedHat ##########$ yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel########## Debian/Ubuntu ##########$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev 解压安装下载的源码包： 1234$ tar -zxf git-1.7.2.2.tar.gz$ cd git-1.7.2.2$ make prefix=/usr/local all$ sudo make prefix=/usr/local install Git 常用命令git branch 查看本地所有分支git status 查看当前状态git commit 提交git branch -a 查看所有的分支git branch -r 查看本地所有分支git commit -am “init” 提交并且加注释git remote add origin &#x67;&#x69;&#116;&#x40;&#49;&#x39;&#x32;&#x2e;&#49;&#54;&#x38;&#x2e;&#x31;&#46;&#x31;&#49;&#57;:ndshowgit push origin master 将文件给推到服务器上git remote show origin 显示远程库origin里的资源git push origin master:developgit push origin master:hb-dev 将本地库与服务器上的库进行关联git checkout –track origin/dev 切换到远程dev分支git branch -D master develop 删除本地库developgit checkout -b dev 建立一个新的本地分支devgit merge origin/dev 将分支dev与当前分支进行合并git checkout dev 切换到本地dev分支git remote show 查看远程库git add .git rm 文件名(包括路径) 从git中删除指定文件git clone git://github.com/schacon/grit.git 从服务器上将代码给拉下来git config –list 看所有用户git ls-files 看已经被提交的git rm [file name] 删除一个文件git commit -a 提交当前repos的所有的改变git add [file name] 添加一个文件到git indexgit commit -v 当你用－v参数的时候可以看commit的差异git commit -m “This is the message describing the commit” 添加commit信息git commit -a -a是代表add，把所有的change加到git index里然后再commitgit commit -a -v 一般提交命令git log 看你commit的日志git diff 查看尚未暂存的更新git rm a.a 移除文件(从暂存区和工作区中删除)git rm –cached a.a 移除文件(只从暂存区中删除)git commit -m “remove” 移除文件(从Git中删除)git rm -f a.a 强行移除修改后文件(从暂存区和工作区中删除)git diff –cached 或 $ git diff –staged 查看尚未提交的更新git stash push 将文件给push到一个临时空间中git stash pop 将文件从临时空间pop下来 git remote add origin &#103;&#x69;&#x74;&#64;&#103;&#x69;&#116;&#104;&#117;&#98;&#x2e;&#99;&#111;&#x6d;:username/Hello-World.gitgit push origin master 将本地项目给提交到服务器中 git pull 本地与服务器端同步git push (远程仓库名) (分支名) 将本地分支推送到服务器上去。git push origin serverfix:awesomebranch git fetch 相当于是从远程获取最新版本到本地，不会自动mergegit commit -a -m “log_message” (-a是提交所有改动，-m是加入log信息) 本地修改同步至服务器端 ：git branch branch_0.1 master 从主分支master创建branch_0.1分支git branch -m branch_0.1 branch_1.0 将branch_0.1重命名为branch_1.0git checkout branch_1.0/master 切换到branch_1.0/master分支du -hs mkdir WebAppcd WebAppgit inittouch READMEgit add READMEgit commit -m ‘first commit’git remote add origin &#103;&#105;&#116;&#x40;&#x67;&#x69;&#x74;&#104;&#117;&#x62;&#46;&#99;&#x6f;&#109;:daixu/WebApp.gitgit push -u origin master 图例git图例。"},{"path":"/notes/ios/index.html","content":"最新版 CocoaPods 的安装流程 （首次安装）移除现有Ruby默认源 （首次安装）使用新的源 （首次安装）验证新源是否替换成功 （可选）更新 gem 安装 CocoaPods Podfile 文件中的一些写法CocoaPods&nbsp;Guides&nbsp;-&nbsp;The&nbsp;Podfilehttps://guides.cocoapods.org/using/the-podfile.html 1234# 设置镜像源source &#x27;https://cdn.cocoapods.org/&#x27;# 忽略警告inhibit_all_warnings! 如何发布开源库到 CocoaPods说实在话，类似的教程网上很多，基本可以满足大多数人零基础发布 CocoaPods，但是其中可能会遇到一些问题，只有亲自尝试过才知道。 准备工作1. clone 远程仓库到本地1git clone 你的仓库链接 2. 注册 trunk注册的命令 1pod trunk register 你的邮箱 你的用户名 记得去邮箱里验证，然后可以输入以下命令查看个人信息 1pod trunk me 步骤1. 创建 .podspec1pod spec create AXKit 2. 修改 .podspec 并验证有很多类似的教程，可以参考。 一个小技巧：你可以去GItHub搜索一些热门的第三方库，然后点击查看这些大牛的 .podspec 是怎么写的。传送门：YYKit的podspec、ReactiveObjC的podspec、BlocksKit的podspec 最容易出错的地方就是资源路径 1s.source_files = &quot;AXKit/**/*.&#123;h,m&#125;&quot; 常见写法 123&quot;Directory1/*&quot; 表示匹配所有文件&quot;Directory1/Directory2/*.&#123;h,m&#125;&quot; 表示匹配所有以.h和.m结尾的文件&quot;Directory1/**/*.h&quot; 表示匹配所有子目录 s.source 常见写法 1234# 推荐写法：与版本号绑定s.source = &#123; :git =&gt; &quot;https://github.com/TeaseTian/HTQRCode.git&quot;, :tag =&gt; &quot;#&#123;s.version&#125;&quot; &#125;# 与commit id 绑定s.source = &#123; :git =&gt; &quot;https://github.com/TeaseTian/HTQRCode.git&quot;, :commit =&gt; &quot;68defea&quot; &#125; tag =&gt; s.version 表示将这个 Pod 版本与 Git 仓库中相同版本的 comit 绑定 注意 如果仓库中对应的tag是 “v1.0.0”\b 这样以字母开头的，可以在 #&#123;s.version&#125; 前面加上对应的字母。commit =&gt; “68defea” 表示将这个 Pod 版本与 Git 仓库中某个 commit 绑定 验证 1pod spec lint AXKit.podspec 3. 上传到远程仓库修改 .podspec 时指定的版本号，如 0.0.1。那么远程仓库中必须始终存在这个版本的 branch 或 tag 才能够下载。建议使用 tag。s.source 中的 tag 需要与远程仓库中的 tag 对应起来。 12s.version = &quot;0.0.1&quot;s.source = &#123; :git =&gt; &quot;https://github.com/xaoxuu/AXKit.git&quot;, :tag =&gt; &quot;v#&#123;s.version&#125;&quot; &#125; 这里指向的是 &quot;v0.0.1&quot; 这个分支，因为分支我们用完之后习惯把它删掉，所以这里也可以指向 tag，也就是说打一个 &quot;v0.0.1&quot; 的 tag 并推送到远程就可以了。 12git tag v0.0.1git push --tags 这样做的好处就是删掉当前分支不影响 CocoaPods 中指向的仓库源码。 4. 发布到 CocoaPods1pod trunk push AXKit.podspec n. 删除一个 podspec 版本删除的命令是： 1pod trunk delete 项目名 版本号 官方建议使用 deprecate 来弃用 1pod trunk deprecate 项目名 这两种方法执行完有很大几率会出现一串很长很长的错误，不要着急，这实际上这是一个 html。把它保存到一个 html 文件中，打开，是个404错误页，原因众所周知。 删除之后立即搜索还是能搜到的，因为有一定的延迟，可能要半个小时才能更新。 pod trunk 命令在终端输入 1pod trunk --help 可以查看帮助 使用脚本没必要每次都重复每个步骤，如果你已经发布过一个，可以省去注册的步骤，直接把已经发不过的 podspec 复制一份，改一下仓库模块名，验证通过就可以发布了。 我写了一个便于发布更新的脚本，把脚本放在与 podspec 同级目录下，当你更新了项目之后，如果需要更新到 cocoapods，可以执行此脚本。流程是： 1输入版本号 -&gt; commit、push tag -&gt; pod spec lint -&gt; 询问是否发布(y/n) -&gt; 发布(y) 脚本的项目https://github.com/xaoxuu/podspec.sh 应用上传失败原因可能有很多，有关于 Transporter 的问题可以尝试删除缓存： 删除缓存 重新下载缓存 这个缓存有 60MB （2020年7月份下载实测） 素材规格iPhone 各代屏幕尺寸与分辨率 iPhone 对角线 缩放 逻辑分辨率 物理分辨率 ppi 1、3G、3GS 3.5 @2x 320 x 480 320 x 480 163 4、4s 3.5 @2x 320 x 480 640 x 960 326 5、5s、SE 4 @2x 320 x 568 640 x 1136 326 6、6s、7、8、SE(2020) 4.7 @2x 375 x 667 750 x 1334 326 6 Plus、6s Plus、7 Plus、8 Plus 5.5 @3x 414 x 736 1242 x 2208 401 X、XS、11 Pro 5.8 @3x 375 x 812 1125 x 2436 458 XR、11 6.1 @2x 414 x 896 828 x 1792 326 XS Max、11 Pro Max 6.5 @3x 414 x 896 1242 x 2688 458 12 mini 5.4 @3x 375 x 812 1080 x 2340 476 12 6.1 @3x 390 x 844 1170 x 2532 460 12 Pro 6.1 @3x 390 x 844 1170 x 2532 460 12 Pro Max 6.7 @3x 428 x 926 1284 x 2778 458 iPad 各代屏幕尺寸与分辨率 iPad 对角线 缩放 逻辑分辨率 物理分辨率 ppi 1、2 9.7 @1x 768 x 1024 768 x 1024 132 mini 1 7.9 @1x 768 x 1024 768 x 1024 163 mini 2/3/4 7.9 @2x 768 x 1024 1536 x 2048 326 Air 1/2 9.7 @2x 768 x 1024 1536 x 2048 264 Pro (9.7) 9.7 @2x 768 x 1024 1536 x 2048 264 Pro (10.5) 10.5 @2x 834 x 1112 1668 x 2224 264 Pro (12.9) 10.5 @2x 1024 x 1366 2048 x 2732 264 Pro (11’ 2018) 11 @2x 834 x 1194 1668 x 2388 264 Pro (12.9’ 2018) 11 @2x 1024 x 1366 2048 x 2732 264 Logo &amp; 启动图UI 只需要提供一张 1024*1024 尺寸的图即可，开发使用 IconKit 工具可以直接生成开发需要的各种尺寸的图片及其 json 配置文件，直接拖进 Xcode 工程中就可以使用了。使用传统方式不同尺寸一张一张的切图不仅浪费 UI 的时间，开发也需要一张图一张图往对应位置拖，双方都很麻烦。 如果使用 LaunchImage 方式，需要切各个尺寸的图片，参考 iPhone 各代屏幕尺寸与分辨率 表，如果需要兼容 iPhone 4、4s 机型，则需要提供一共7种尺寸的图片，如果最低兼容 iPhone5 的话，就只需要提供6种尺寸的图片。 注意：iOS 并不需要 1920*1080 这种尺寸的图片。 icon 素材iOS 端的切图需要同时提供 @2x 和 @3x 两种尺寸的图片，例如某个名为 “imagename” 的图片需要提供两个文件分别命名为： 12imagename@2x.pngimagename@3x.png 素材名（imagename）命名可以根据公司或团队规范而异，但是两种尺寸的文件的素材名部分要保持一致，唯一的不同就是 @2x 和 @3x。"},{"path":"/notes/linuxnote/index.html","content":"基本命令关机和重启关机 shutdown -h now 立刻关机 shutdown -h 5 5分钟后关机 poweroff 立刻关机重启 shutdown -r now 立刻重启 shutdown -r 5 5分钟后重启 reboot 立刻重启 帮助命令–help命令 shutdown –help： ifconfig –help：查看网卡信息 man命令（命令说明书） man shutdown 注意：man shutdown打开命令说明书之后，使用按键q退出 目录操作命令目录切换 cd命令：cd 目录 cd / 切换到根目录cd /usr 切换到根目录下的usr目录cd ../ 切换到上一级目录 或者 cd ..cd ~ 切换到home目录cd - 切换到上次访问的目录 目录查看 ls [-al]命令：ls [-al] ls 查看当前目录下的所有目录和文件ls -a 查看当前目录下的所有目录和文件（包括隐藏的文件）ls -l 或 ll 列表查看当前目录下的所有目录和文件（列表查看，显示更多信息）ls /dir 查看指定目录下的所有目录和文件 如：ls /usr 目录操作【增，删，改，查】创建目录【增】 mkdir命令：mkdir 目录 mkdir aaa 在当前目录下创建一个名为aaa的目录mkdir /usr/aaa 在指定目录下创建一个名为aaa的目录 删除目录或文件【删】rm命令：rm [-rf] 目录 删除文件：rm 文件 删除当前目录下的文件rm -f 文件 删除当前目录的的文件（不询问） 删除目录：rm -r aaa 递归删除当前目录下的aaa目录rm -rf aaa 递归删除当前目录下的aaa目录（不询问） 全部删除：rm -rf * 将当前目录下的所有目录和文件全部删除rm -rf /* 【自杀命令！慎用！慎用！慎用！】将根目录下的所有文件全部删除 注意：rm不仅可以删除目录，也可以删除其他文件或压缩包，为了方便大家的记忆，无论删除任何目录或文件，都直接使用 rm -rf 目录/文件/压缩包 目录修改【改】mv 和 cp一、重命名目录 命令：mv 当前目录 新目录 例如：mv aaa bbb 将目录aaa改为bbb 注意：mv的语法不仅可以对目录进行重命名而且也可以对各种文件，压缩包等进行 重命名的操作 二、剪切目录 命令：mv 目录名称 目录的新位置 示例：将/usr/tmp目录下的aaa目录剪切到 /usr目录下面 mv /usr/tmp/aaa /usr 注意：mv语法不仅可以对目录进行剪切操作，对文件和压缩包等都可执行剪切操作 三、拷贝目录 命令：cp -r 目录名称 目录拷贝的目标位置 -r代表递归 示例：将/usr/tmp目录下的aaa目录复制到 /usr目录下面 cp /usr/tmp/aaa /usr 注意：cp命令不仅可以拷贝目录还可以拷贝文件，压缩包等，拷贝文件和压缩包时不 用写-r递归 搜索目录【查】find命令：find 目录 参数 文件名称示例：find /usr/tmp -name ‘a*’ 查找/usr/tmp目录下的所有以a开头的目录或文件 文件操作命令文件操作【增，删，改，查】新建文件【增】touch命令：touch 文件名示例：在当前目录创建一个名为aa.txt的文件 touch aa.txt 删除文件 【删】 rm命令：rm -rf 文件名 修改文件【改】 vi或vim【vi编辑器的3种模式】 基本上vi可以分为三种状态，分别是命令模式（command mode）、插入模式（Insert mode）和底行模式（last line mode），各模式的功能区分如下： 命令行模式command mode） 控制屏幕光标的移动，字符、字或行的删除，查找，移动复制某区段及进入Insert mode下，或者到 last line mode。 命令行模式下的常用命令： 【1】控制光标移动：↑，↓，j 【2】删除当前行：dd 【3】查找：/字符 【4】进入编辑模式：i o a 【5】进入底行模式：: 编辑模式（Insert mode） 只有在Insert mode下，才可以做文字输入，按「ESC」键可回到命令行模式。 编辑模式下常用命令： 【1】ESC 退出编辑模式到命令行模式； 底行模式（last line mode） 将文件保存或退出vi，也可以设置编辑环境，如寻找字符串、列出行号……等。 底行模式下常用命令： 【1】退出编辑： :q 【2】强制退出： :q! 【3】保存并退出： :wq 打开文件 命令：vi 文件名示例：打开当前目录下的aa.txt文件 vi aa.txt 或者 vim aa.txt 注意：使用vi编辑器打开文件后，并不能编辑，因为此时处于命令模式，点击键盘i/a/o进入编辑模式。 编辑文件 使用vi编辑器打开文件后点击按键：i ，a或者o即可进入编辑模式。 i:在光标所在字符前开始插入a:在光标所在字符后开始插入o:在光标所在行的下面另起一新行插入 保存或者取消编辑 保存文件： 第一步：ESC 进入命令行模式第二步：: 进入底行模式第三步：wq 保存并退出编辑 取消编辑： 第一步：ESC 进入命令行模式第二步：: 进入底行模式第三步：q! 撤销本次修改并退出编辑 文件的查看【查】文件的查看命令：cat/more/less/tail cat：看最后一屏 示例：使用cat查看/etc/sudo.conf文件，只能显示最后一屏内容cat sudo.conf more：百分比显示 示例：使用more查看/etc/sudo.conf文件，可以显示百分比，回车可以向下一行，空格可以向下一页，q可以退出查看more sudo.conf less：翻页查看 示例：使用less查看/etc/sudo.conf文件，可以使用键盘上的PgUp和PgDn向上 和向下翻页，q结束查看less sudo.conf tail：指定行数或者动态查看 示例：使用tail -10 查看/etc/sudo.conf文件的后10行，Ctrl+C结束tail -10 sudo.conf 权限修改rwx：r代表可读，w代表可写，x代表该文件是一个可执行文件，如果rwx任意位置变为-则代表不可读或不可写或不可执行文件。 示例：给aaa.txt文件权限改为可执行文件权限，aaa.txt文件的权限是-rw——- 第一位：-就代表是文件，d代表是文件夹第一段（3位）：代表拥有者的权限第二段（3位）：代表拥有者所在的组，组员的权限第三段（最后3位）：代表的是其他用户的权限 421 421 421 rw- — — 命令：chmod +x aaa.txt或者采用8421法命令：chmod 100 aaa.txt四、压缩文件操作 打包和压缩Windows的压缩文件的扩展名 .zip/.rarlinux中的打包文件：aa.tarlinux中的压缩文件：bb.gzlinux中打包并压缩的文件：.tar.gz Linux中的打包文件一般是以.tar结尾的，压缩的命令一般是以.gz结尾的。而一般情况下打包和压缩是一起进行的，打包并压缩后的文件的后缀名一般.tar.gz。 命令：tar -zcvf 打包压缩后的文件名 要打包的文件其中：z：调用gzip压缩命令进行压缩 c：打包文件 v：显示运行过程 f：指定文件名 示例：打包并压缩/usr/tmp 下的所有文件 压缩后的压缩包指定名称为xxx.tartar -zcvf ab.tar aa.txt bb.txt或：tar -zcvf ab.tar * 解压命令：tar [-zxvf] 压缩文件其中：x：代表解压示例：将/usr/tmp 下的ab.tar解压到当前目录下 示例：将/usr/tmp 下的ab.tar解压到根目录/usr下tar -xvf ab.tar -C /usr——C代表指定解压的位置 查找命令grepgrep命令是一种强大的文本搜索工具 使用实例： ps -ef | grep sshd 查找指定ssh服务进程ps -ef | grep sshd | grep -v grep 查找指定服务进程，排除gerp身ps -ef | grep sshd -c 查找指定进程个数 findfind命令在目录结构中搜索文件，并对搜索结果执行指定的操作。 find 默认搜索当前目录及其子目录，并且不过滤任何结果（也就是返回所有文件），将它们全都显示在屏幕上。 使用实例： find . -name “.log” -ls 在当前目录查找以.log结尾的文件，并显示详细信息。find /root/ -perm 600 查找/root/目录下权限为600的文件find . -type f -name “.log” 查找当目录，以.log结尾的普通文件find . -type d | sort 查找当前所有目录并排序find . -size +100M 查找当前目录大于100M的文件5.3 locatelocate 让使用者可以很快速的搜寻某个路径。默认每天自动更新一次，所以使用locate 命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库。如果数据库中没有查询的数据，则会报出locate: can not stat () `/var/lib/mlocate/mlocate.db’: No such file or directory该错误！updatedb即可！ yum -y install mlocate 如果是精简版CentOS系统需要安装locate命令 使用实例： updatedblocate /etc/sh 搜索etc目录下所有以sh开头的文件locate pwd 查找和pwd相关的所有文件 whereiswhereis命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。这些文件的属性应属于原始代码，二进制文件，或是帮助文件。 使用实例： whereis ls 将和ls文件相关的文件都查找出来 whichwhich命令的作用是在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 使用实例： which pwd 查找pwd命令所在路径which java 查找path中java的路径 su、sudosusu用于用户之间的切换。但是切换前的用户依然保持登录状态。如果是root 向普通或虚拟用户切换不需要密码，反之普通用户切换到其它任何用户都需要密码验证。 su test:切换到test用户，但是路径还是/root目录su - test : 切换到test用户，路径变成了/home/testsu : 切换到root用户，但是路径还是原来的路径su - : 切换到root用户，并且路径是/rootsu不足：如果某个用户需要使用root权限、则必须要把root密码告诉此用户。 退出返回之前的用户：exit sudosudo是为所有想使用root权限的普通用户设计的。可以让普通用户具有临时使用root权限的权利。只需输入自己账户的密码即可。 进入sudo配置文件命令： vi /etc/sudoer或者visudo案例：允许hadoop用户以root身份执行各种应用命令，需要输入hadoop用户的密码。hadoop ALL=(ALL) ALL 案例：只允许hadoop用户以root身份执行ls 、cat命令，并且执行时候免输入密码。配置文件中：hadoop ALL=NOPASSWD: /bin/ls, /bin/cat 系统服务service iptables status –查看iptables服务的状态service iptables start –开启iptables服务service iptables stop –停止iptables服务service iptables restart –重启iptables服务 chkconfig iptables off –关闭iptables服务的开机自启动chkconfig iptables on –开启iptables服务的开机自启动 网络管理主机名配置[root@node1 ~]# vi /etc/sysconfig/networkNETWORKING=yesHOSTNAME=node1 IP 地址配置[root@node1 ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0 域名映射/etc/hosts文件用于在通过主机名进行访问时做ip地址解析之用。所以，你想访问一个什么样的主机名，就需要把这个主机名和它对应的ip地址。 [root@node1 ~]# vi /etc/hosts 在最后加上 192.168.52.201 node1192.168.52.202 node2192.168.52.203 node3 定时任务指令crontab 配置crontab是Unix和Linux用于设置定时任务的指令。通过crontab命令，可以在固定间隔时间,执行指定的系统指令或shell脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。 crontab安装： yum install crontabs服务操作说明： service crond start ## 启动服务service crond stop ## 关闭服务service crond restart ## 重启服务 命令格式crontab [-u user] file crontab [-u user] [ -e | -l | -r ] 参数说明： -u user：用来设定某个用户的crontab服务 file：file是命令文件的名字,表示将file做为crontab的任务列表文件 并载入crontab。 -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前 用户的crontab文件。 -l：显示某个用户的crontab文件内容。如果不指定用户，则表示显示当前 用户的crontab文件内容。 -r：删除定时任务配置，从/var/spool/cron目录中删除某个用户的crontab 文件，如果不指定用户，则默认删除当前用户的crontab文件。 命令示例： crontab file [-u user] ## 用指定的文件替代目前的crontabcrontab -l [-u user] ## 列出用户目前的crontabcrontab -e [-u user] ## 编辑用户目前的crontab 配置说明、实例命令：* * * * * command 解释：分 时 日 月 周 命令 第1列表示分钟1～59 每分钟用*或者 */1表示 第2列表示小时0～23（0表示0点） 第3列表示日期1～31 第4列表示月份1～12 第5列标识号星期0～6（0表示星期天） 第6列要运行的命令 配置实例： 先打开定时任务所在的文件：crontab -e 每分钟执行一次date命令*/1 * * * * date &gt;&gt; /root/date.txt 每晚的21:30重启apache。30 21 * * * service httpd restart 每月1、10、22日的4 : 45重启apache。45 4 1,10,22 * * service httpd restart 每周六、周日的1 : 10重启apache。10 1 * * 6,0 service httpd restart 每天18 : 00至23 : 00之间每隔30分钟重启apache。0,30 18-23 * * * service httpd restart晚上11点到早上7点之间，每隔一小时重启apache 23-7/1 * * * service httpd restart其他命令 查看当前目录：pwd命令：pwd 查看当前目录路径 查看进程：ps -ef命令：ps -ef 查看所有正在运行的进程 结束进程：kill命令：kill pid 或者 kill -9 pid(强制杀死进程) pid:进程号 网络通信命令：ifconfig：查看网卡信息 命令：ifconfig 或 ifconfig | more ping：查看与某台机器的连接情况 命令：ping ip netstat -an：查看当前系统端口 命令：netstat -an 搜索指定端口命令：netstat -an | grep 8080 配置网络命令：setup 重启网络命令：service network restart 切换用户命令：su - 用户名 关闭防火墙命令：chkconfig iptables off 或者： iptables -L; iptables -F; service iptables stop 修改文件权限命令：chmod 777 清屏命令：ctrl + l vi模式下快捷键esc后: 保存并退出快捷键：shift+z+z 光标跳到最后一行快捷键：shift+g 删除一行：dd 复制一行内容：y+y 粘贴复制的内容：p Linux项目部署安装jdk1.8先卸载open-jdk java -versionrpm -qa | grep java rpm -e –nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64rpm -e –nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64 开始安装：mkdir /usr/local/src/javarz 上传jdk tar包tar -zxvf jdk-8u181-linux-x64.tar.gz yum install glibc.i686 配置环境变量： vi /etc/profile 在末尾行添加 #set java environment JAVA_HOME=/usr/local/src/jdk8/jdk1.8.0_181 CLASSPATH=.:$JAVA_HOME/lib.tools.jar PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME CLASSPATH PATH 保存退出source /etc/profile 使更改的配置立即生效java -version 查看JDK版本信息，如果显示出1.8证明成功 安装MySQL5.6上传MySQL5.6的tar包创建目录：mkdir /usr/local/src/mysql5.6 上传：MySQL-5.6.34-1.rhel5.x86_64.rpm-bundle.tar 到上面的目录中 安装第一步：解压 命令：tar -xvf MySQL-5.6.34-1.rhel5.x86_64.rpm-bundle.tar 第二步：检测是否已经安装了mysql 命令：rpm -qa | grep mysql 如果已经安装了，将其卸载，如： rpm -e --nodeps mysql-libs-5.1.71-1.el6.x86_64 第三步：安装MySQL的服务端 命令：rpm -ivh MySQL-server-5.6.34-1.rhel5.x86_64.rpm 第四步：安装MySQL的客户端 命令：rpm -ivh MySQL-client-5.6.34-1.rhel5.x86_64.rpm 第五步：查看MySQL服务运行状态 命令：service mysql status 第六步：启动MySQL服务 命令：service mysql start 第七步：使用root账号登录mysql 在安装mysql server时有句提示： 注意：这个密码是不安全的，所有需要修改初始密码。 使用密码登录mysql账号：mysql -uroot -p修改root密码：SET PASSWORD = PASSWORD(‘root’); 开机自动启动设置加入到系统服务： chkconfig –add mysql 自动启动： chkconfig mysql on 查询列表： chkconfig 说明：都没关闭（off）时是没有自动启动。 开启远程访问登录： mysql -uroot –proot 设置远程访问（使用root密码）： grant all privileges on . to ‘root’ @’%’ identified by ‘root’; flush privileges; 退出mysql，在centos环境下打开3306防火墙 /sbin/iptables -I INPUT -p tcp –dport 3306 -j ACCEPT /etc/rc.d/init.d/iptables save /etc/init.d/iptables status 安装tomcat部署项目准备工作：将web项目打成war包，改名为ROOT.war 创建ucenter用户一般情况下，发布应用程序都不是使用root用户的，需要创建一个普通用户来发布程序； 创建ucenter用户： useradd -d /ucenter ucenter 设置密码： passwd ucenter （密码 ucenter） 切换用户： su - ucenter 安装Tomcattomcat只要解压就可以使用。 1、创建web目录mkdir /ucenter/web 2、上传apache-tomcat-7.0.57.tar.gz 3、解压：tar -xvf apache-tomcat-7.0.57.tar.gz 4、重命名：mv apache-tomcat-7.0.57 itcast-usermanage 5、启动tomcat： cd itcast-usermanage/bin/ ./startup.sh 或者 sh startup.sh 6、查看日志： tail -f ../logs/catalina.out 7、查看效果 http://192.168.0.160:8080/ 发现无法访问： 8、防火墙打开 8080 端口 /sbin/iptables -I INPUT -p tcp –dport 8080 -j ACCEPT /etc/rc.d/init.d/iptables save 9、安装成功 部署用户管理项目1、上传usermanage.sql和ROOT.war到/ucenter/web 2、执行数据库脚本 cat user_manager.sql | mysql -uroot -p123456 3、部署web程序 3.1 删除webapps下的所有文件 cd /ucenter/web/usermanage/webapps rm -rf * 3.2 拷贝ROOT.war到webapps cp /ucenter/web/ROOT.war . 3.3 重新启动tomcat cd ../bin/ sh startup.sh &amp;&amp; tail -f ../logs/catalina.out 3.4 启动浏览器测试 注意事项：Centos环境下部署项目中文乱码问题解决方案 今天在一台新的CentOS机器上使用c3p0连接池操作mysql数据库出现中文乱码问题，具体表现为：查询时无中文乱码问题，写数据时中文乱码，查看了机器上数据库字符集也是UTF8，应该不会出现中文乱码才对，最后在c3p0配置文件中 jdbcUrl后加上：?useUnicode=true&amp;characterEncoding=UTF8 中文就不会乱码了。 【C3P0配置文件】 com.mysql.jdbc.Driver jdbc:mysql://localhost:3306/user_manager_yun6?useUnicode=true&amp;characterEncoding=UTF8 root root 2 5 1 5 11.4 Linux下使用FastDFS 相关的安装包我打包到云盘上了，链接：https://pan.baidu.com/s/13NDYYil4mgLhkb5CYsc2Ww 提取码：66tn 单节点FastDFS 整个安装过程非常复杂，很容易出错，建议进行多次备份。 我们这里不打算安装多台虚拟机，因此会把tracker和storage都安装在一起。 安装gccGCC用来对C语言代码进行编译运行，使用yum命令安装： yum -y install gcc后面会用到解压命令（unzip），所以这里可以用yum把unzip 也装一下 yum install -y unzip zip 安装libeventyum -y install libevent 安装libfastcommon-master解压刚刚上传的libfastcommon-master.zipunzip libfastcommon-master.zip 进入解压完成的目录cd libfastcommon-master 编译并且安装：./make.sh./make.sh install 安装fastdfstar -zxvf FastDFS_v5.08.tar.gzcd FastDFS./make.sh./make.sh install如果安装成功，会看到/etc/init.d/下看到提供的脚本文件： ll /etc/init.d/ | grep fdfs fdfs_trackerd 是tracker启动脚本 fdfs_storaged 是storage启动脚本 能够在 /etc/fdfs/ 目录下看到默认的配置文件模板： ll /etc/fdfs/ tarcker.conf.sample 是tracker的配置文件模板 storage.conf.sample 是storage的配置文件模板 client.conf.sample 是客户端的配置文件模板 配置并启动tracker服务1）首先将模板文件复制 cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf2）修改复制后的配置文件： vim /etc/fdfs/tracker.conf 修改的内容如下： base_path=/项目名/tracker # 存储日志和数据的根目录3）新建目录： mkdir -p /项目名/tracker注意：关闭防火墙： chkconfig iptables off4）启动和停止 service fdfs_trackerd start # 启动fdfs_trackerd服务，停止用stop检查FastDFS Tracker Server是否启动成功： ps -ef | grep fdfs_trackerd设置tracker服务开机启动: chkconfig fdfs_trackerd on11.4.6 配置并启动storage服务1）首先将模板文件复制 cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf2）修改复制后的配置文件： vim /etc/fdfs/storage.conf 修改的内容如下: base_path=/项目名/storage # 数据和日志文件存储根目录 store_path0=/项目名/storage # 第一个存储目录 tracker_server=192.168.56.101:22122 # tracker服务器IP和端口3）新建目录： mkdir -p /项目名/storage注意关闭防火墙： chkconfig iptables off 4）启动和停止 service fdfs_storaged start # 启动fdfs_storaged服务，停止用stop设置storage服务开机启动： chkconfig fdfs_storaged onps -ef | grep fdfs 安装fastdfs-nginx-module解压tar -zxvf fastdfs-nginx-module_v1.16.tar.gz 修改config1）进入src目录 cd fastdfs-nginx-module/src/2）编辑config vim config使用以下底行命令： :%s+/usr/local/+/usr/+g将所有的/usr/local替换为 /usr，这个才是正确的目录: 配置nginx与FastDFS关联配置文件复制 fastdfs-nginx-module 源码中的配置文件到/etc/fdfs 目录， 并修改 cp /usr/local/项目名/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/ vi /etc/fdfs/mod_fastdfs.conf修改以下配置： connect_timeout=10 # 客户端访问文件连接超时时长（单位：秒） tracker_server=192.168.56.101:22122 # tracker服务IP和端口 url_have_group_name=true # 访问链接前缀加上组名 store_path0=/leyou/storage # 文件存储路径复制 FastDFS 的部分配置文件到/etc/fdfs 目录 cd /usr/local/项目名/FastDFS/conf/cp http.conf mime.types /etc/fdfs/ 安装Nginx的插件如果没有安装过nginx1、安装nginx的依赖库 yum -y install gcc pcre pcre-devel zlib zlib-devel openssl openssl-devel2、解压安装包 tar -zxvf nginx-1.10.0.tar.gz 3、配置nginx安装包，并指定fastdfs-nginx-model cd nginx-1.10.0 ./configure –prefix=/opt/nginx –sbin-path=/usr/bin/nginx –add-module=/usr/local/leyou/fastdfs-nginx-module/src注意：在执行./configure配置nginx参数的时候，需要将fastdfs-nginx-moudle源码作为模块编译进去。 4、编译并安装 make &amp;&amp; make install11.6.2 如果已经安装过nginx1、 进入nginx目录： cd /usr/local/项目名/nginx-1.10.0/2、 配置FastDFS 模块 ./configure –prefix=/opt/nginx –sbin-path=/usr/bin/nginx –add-module=/usr/local/项目名/fastdfs-nginx-module/src注意：这次配置时，要添加fastdfs-nginx-moudle模块 3、编译，注意，这次不要安装（install） make4、替换nginx二进制文件: 备份： mv /usr/bin/nginx /usr/bin/nginx-bak用新编译的nginx启动文件替代原来的： cp objs/nginx /usr/bin/ 启动nginx配置nginx整合fastdfs-module模块 我们需要修改nginx配置文件，在/opt/nginx/config/nginx.conf文件中： vim /opt/nginx/conf/nginx.conf将文件中，原来的server 80{ …} 部分代码替换为如下代码： server { listen 80; server_name image.项目名.com; # 监听域名中带有group的，交给FastDFS模块处理 location ~/group([0-9])/ { ngx_fastdfs_module; } location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; }}启动nginx： nginx # 启动nginx nginx -s stop # 停止nginx nginx -s reload # 重新载入配置文件可通过ps -ef | grep nginx查看nginx是否已启动成功 设置nginx开机启动创建一个开机启动的脚本： vim /etc/init.d/nginx添加以下内容： #!/bin/sh# nginx - this script starts and stops the nginx daemonchkconfig: - 85 15description: NGINX is an HTTP(S) server, HTTP(S) reverse \\proxy and IMAP/POP3 proxy serverprocessname: nginxconfig: /etc/nginx/nginx.confconfig: /etc/sysconfig/nginxpidfile: /var/run/nginx.pidSource function library.. /etc/rc.d/init.d/functions Source networking configuration.. /etc/sysconfig/network Check that networking is up.[ “$NETWORKING” = “no” ] &amp;&amp; exit 0 nginx=”/usr/bin/nginx”prog=$(basename $nginx) NGINX_CONF_FILE=”/opt/nginx/conf/nginx.conf” [ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginx lockfile=/var/lock/subsys/nginx make_dirs() { make required directories user=$nginx -V 2&gt;&amp;1 | grep &quot;configure arguments:.*--user=&quot; | sed &#39;s/[^*]*--user=\\([^ ]*\\).*/\\1/g&#39; - if [ -n “$user” ]; then if [ -z “grep $user /etc/passwd“ ]; then useradd -M -s /bin/nologin $user fi options=$nginx -V 2&gt;&amp;1 | grep &#39;configure arguments:&#39; for opt in $options; do if [ echo $opt | grep &#39;.*-temp-path&#39; ]; then value=echo $opt | cut -d &quot;=&quot; -f 2 if [ ! -d “$value” ]; then # echo “creating” $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done fi} start() { [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $”Starting $prog: “ daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval} stop() { echo -n $”Stopping $prog: “ killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval} restart() { configtest || return $? stop sleep 1 start} reload() { configtest || return $? echo -n $”Reloading $prog: “ killproc $nginx -HUP RETVAL=$? echo} force_reload() { restart} configtest() { $nginx -t -c $NGINX_CONF_FILE} rh_status() { status $prog} rh_status_q() { rh_status &gt;/dev/null 2&gt;&amp;1} case “$1” in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $”Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}” exit 2esac修改文件权限，并加入服务列表 修改权限chmod 777 /etc/init.d/nginx 添加到服务列表chkconfig –add /etc/init.d/nginx设置开机启动 chkconfig nginx on 安装Elasticsearch需要虚拟机JDK1.8及以上 新建一个用户leyou出于安全考虑，elasticsearch默认不允许以root账号运行。 创建用户： useradd leyou设置密码： passwd leyou切换用户： su - leyou 上传安装包,并解压我们将安装包上传到：/home/leyou目录 解压缩： tar -zxvf elasticsearch-6.2.4.tar.gz我们把目录重命名： mv elasticsearch-6.3.0/ elasticsearch 进入，查看目录结构： 修改配置我们进入config目录：cd config 需要修改的配置文件有两个： 1、jvm.options Elasticsearch基于Lucene的，而Lucene底层是java实现，因此我们需要配置jvm参数。 编辑jvm.options： vim jvm.options默认配置如下： -Xms1g-Xmx1g 内存占用太多了，我们调小一些： -Xms512m-Xmx512m 2、elasticsearch.yml vim elasticsearch.yml修改数据和日志目录： path.data: /home/leyou/elasticsearch/data # 数据目录位置path.logs: /home/leyou/elasticsearch/logs # 日志目录位置我们把data和logs目录修改指向了elasticsearch的安装目录。但是这两个目录并不存在，因此我们需要创建出来。 进入elasticsearch的根目录，然后创建： mkdir datamkdir logs 修改绑定的ip： network.host: 0.0.0.0 # 绑定到0.0.0.0，允许任何ip来访问默认只允许本机访问，修改为0.0.0.0后则可以远程访问 运行进入elasticsearch/bin目录，可以看到下面的执行文件： 然后输入命令： ./elasticsearch或者后台运行： ./elasticsearch -d11.7.5 错误1：内核过低 修改elasticsearch.yml文件，在最下面添加如下配置： 然后重启 bootstrap.system_call_filter: false11.7.6 错误2：文件权限不足 我们用的是leyou用户，而不是root，所以文件权限不足。 首先用root用户登录。直接输入exit命令 然后修改配置文件: vim /etc/security/limits.conf添加下面的内容： soft nofile 65536 hard nofile 131072 soft nproc 4096 hard nproc 4096 11.7.7 错误3：线程数不够[1]: max number of threads [1024] for user [leyou] is too low, increase to at least [4096] 继续修改配置： vim /etc/security/limits.d/90-nproc.conf修改下面的内容： soft nproc 1024改为 soft nproc 4096 11.7.8 错误4：进程虚拟内存[3]: max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] vm.max_map_count：限制一个进程可以拥有的VMA(虚拟内存区域)的数量，继续修改配置文件， ： vim /etc/sysctl.conf添加下面内容： vm.max_map_count=655360然后执行命令： sysctl -p 重启终端窗口所有错误修改完毕，一定要重启你的 Xshell终端，否则配置无效。 安装RabbitMQcd /usr/local/myapp mkdir rabbitmq cd rabbitmq 安装Erlang1、在线安装 yum install esl-erlang_17.3-1centos6_amd64.rpm yum install esl-erlang-compat-R14B-1.el6.noarch.rpm2、离线安装 依次执行命令： 1）rpm -ivh esl-erlang-17.3-1.x86_64.rpm –force –nodeps 2）rpm -ivh esl-erlang_17.3-1centos6_amd64.rpm –force –nodeps 3）rpm -ivh esl-erlang-compat-R14B-1.el6.noarch.rpm –force –nodeps 11.8.2 安装RabbitMQ 安装： rpm -ivh rabbitmq-server-3.4.1-1.noarch.rpm 设置配置文件cp /usr/share/doc/rabbitmq-server-3.4.1/rabbitmq.config.example/etc/rabbitmq/rabbitmq.config开启用户远程访问 vi /etc/rabbitmq/rabbitmq.config 注意要去掉后面的逗号。 启动、停止service rabbitmq-server start service rabbitmq-server stop service rabbitmq-server restart11.8.5 开启web界面管理工具rabbitmq-plugins enable rabbitmq_management service rabbitmq-server restart 设置开机启动chkconfig rabbitmq-server on 防火墙开放15672端口/sbin/iptables -I INPUT -p tcp –dport 15672 -j ACCEPT /etc/rc.d/init.d/iptables save redis安装和配置安装解压 tar -xvf redis-4.0.9.tar.gz编译安装 mv redis-4.0.9 redis cd redis make &amp;&amp; make install 11.9.2 配置修改安装目录下的redis.conf文件 vim redis.conf修改以下配置： #bind 127.0.0.1 # 将这行代码注释，监听所有的ip地址，外网可以访问protected-mode no # 把yes改成no，允许外网访问daemonize yes # 把no改成yes，后台运行 启动或停止redis提供了服务端命令和客户端命令： redis-server 服务端命令，可以包含以下参数： start 启动 stop 停止 redis-cli 客户端控制台，包含参数： -h xxx 指定服务端地址，缺省值是127.0.0.1 -p xxx 指定服务端端口，缺省值是6379 设置开机启动 输入命令，新建文件 vim /etc/init.d/redis输入下面内容： #!/bin/sh chkconfig: 2345 90 10description: Redis is a persistent key-value databasePATH=/usr/local/bin:/sbin:/usr/bin:/bin REDISPORT=6379EXEC=/usr/local/bin/redis-serverREDIS_CLI=/usr/local/bin/redis-cli PIDFILE=/var/run/redis.pid CONF=”/usr/local/leyou/redis/redis.conf” case “$1” in start) if [ -f $PIDFILE ] then echo “$PIDFILE exists, process is already running or crashed” else echo “Starting Redis server…” $EXEC $CONF fi if [ “$?”=”0” ] then echo “Redis is running…” fi ;; stop) if [ ! -f $PIDFILE ] then echo “$PIDFILE does not exist, process is not running” else PID=$(cat $PIDFILE) echo “Stopping …” $REDIS_CLI -p $REDISPORT SHUTDOWN while [ -x ${PIDFILE} ] do echo “Waiting for Redis to shutdown …” sleep 1 done echo “Redis stopped” fi ;; restart|force-reload) ${0} stop ${0} start ;; *) echo “Usage: /etc/init.d/redis {start|stop|restart|force-reload}” &gt;&amp;2 exit 1esac然后保存退出 注意：以下信息需要根据安装目录进行调整： EXEC=/usr/local/bin/redis-server # 执行脚本的地址 REDIS_CLI=/usr/local/bin/redis-cli # 客户端执行脚本的地址 PIDFILE=/var/run/redis.pid # 进程id文件地址 CONF=”/usr/local/src/redis-3.0.2/redis.conf” #配置文件地址 2）设置权限 chmod 755 /etc/init.d/redis3）启动测试 /etc/init.d/redis start启动成功会提示如下信息： Starting Redis server…Redis is running… 4）设置开机自启动 chkconfig –add /etc/init.d/redischkconfig redis on"},{"title":"Mac 相关问题","path":"/notes/mac/index.html","content":"{ % folding 提示 “安装包已损坏” 怎么办？ % } { % copy sudo spctl –master-disable % } { % endfolding % } { % folding child:codeblock 清理 Mac 的 DNS 缓存 % } 123sudo killall -HUP mDNSRespondersudo killall mDNSResponderHelpersudo dscacheutil -flushcache { % endfolding % } { % folding TNT 团队的应用无法使用怎么办？ % } TNT 的证书签署的软件在 2019年7月12日 后都不能运行了，临时的解决办法，就是自己签名。 1. 安装 Xcode 安装 Xcode，你可以在 App Store 中下载安装，并且至少运行一次。 2. 安装 Command Line Tools 工具 打开终端工具输入如下命令： { % copy xcode-select –install % } 弹出后选择继续安装。 3. 为应用签名 打开终端工具输入并执行如下命令： 1codesign --force --deep --sign - /Applications/name.app 注意后面的文件路径，你可以打开访达找到应用程序，找到要签名的软件，直接拖入「终端」界面，即可自动生成路径。 { % endfolding % } { % folding 显示隐藏文件 % } { % tabs active:1 align:left % } { % copy defaults write com.apple.finder _FXShowPosixPathInTitle -bool TRUE; killall Finder % } { % copy defaults delete com.apple.finder _FXShowPosixPathInTitle; killall Finder % } { % endtabs % } { % endfolding % } { % folding 外置磁盘路径 % } 1/volume/磁盘路径/~~~ 例如一个名称为 “Files” 的磁盘里的文件夹 “Projects” 路径是: 1/Volumes/Files/Projects/ { % endfolding % } { % folding 使用终端将 json 文件转为 plist 文件 % } 1plutil -convert xml1 data.json -o data.plist 其中 data.json、data.plist 分别对应转换前后的文件路径。 { % endfolding % } { % folding sudo 依然没有权限的解决办法 % } { % tabs active:1 % } { % copy csrutil status % } 如果输出以下信息，说明 SIP 开启，需要暂时将 SIP 关闭。 { % codeblock % }System Integrity Protection status: enabled.{ % endcodeblock % } 重启 Mac，按住 { % kbd command % } + { % kbd R % } 直到出现开机 logo，此时会进入 Recovery 模式，选择「实用工具」-&gt;「Terminal」并输入以下命令： { % copy csrutil disable % } 然后重新启动电脑即可关闭 SIP。 重启 Mac，按住 { % kbd command % } + { % kbd R % } 直到出现开机 logo，此时会进入 Recovery 模式，选择「实用工具」-&gt;「Terminal」并输入以下命令： { % copy csrutil enable % } 然后重新启动电脑即可开启 SIP。 { % endtabs % } { % endfolding % } { % folding 搭载 Intel 芯片的 Mac 启动组合键 % } Command (⌘)-R：从内建的 macOS 恢复系统启动。或者，您也可以使用 Option-Command-R 或 Shift-Option-Command-R 以通过互联网从 macOS 恢复功能启动。macOS 恢复功能可以安装不同版本的 macOS，具体取决于您在电脑启动时使用的组合键。如果您的 Mac 使用了固件密码，系统将提示您输入这个密码。 Option (⌥) 或 Alt：启动进入“启动管理器”，您可以从中选取其他可用的启动磁盘或宗卷。如果您的 Mac 使用了固件密码，系统将提示您输入这个密码。 Option-Command-P-R：重置 NVRAM 或 PRAM。如果您的 Mac 使用了固件密码，电脑会忽略这个组合键或从 macOS 恢复功能启动。 Shift (⇧) ：以安全模式启动。如果使用了固件密码，这个组合键将被停用。 D：启动进入“Apple 诊断”实用工具。也可以使用 Option-D 通过互联网启动进入这个实用工具。如果使用了固件密码，这个组合键将被停用。 N：从 NetBoot 服务器启动，前提是您的 Mac 支持网络启动宗卷。要使用服务器上默认的引导映像，请按住 Option-N。如果使用了固件密码，这个组合键将被停用。 Command-S：以单用户模式启动。如果运行的是 macOS Mojave 或更高版本，或者使用了固件密码，这个组合键会被停用。 T：以目标磁盘模式启动。如果使用了固件密码，这个组合键将被停用。 Command-V：以详细模式启动。如果使用了固件密码，这个组合键将被停用。 推出键 (⏏)、F12、鼠标按钮或触控板按钮：推出可移动介质，例如光盘。如果使用了固件密码，这个组合键将被停用。 { % endfolding % }"},{"title":"Node.js 相关问题","path":"/notes/nodejs/index.html","content":"查看当前的源：{ % copy npm config get registry % } 官方源：{ % copy npm set registry https://registry.npmjs.org/ % } 淘宝源：{ % copy npm set registry https://registry.npm.taobao.org/ % }"},{"title":"服务器相关问题","path":"/notes/server/index.html","content":"GitHub Action + Hexo 部署到服务器在本地电脑生成 ssh key{ % copy ssh-keygen -t rsa % } 创建 git 用户{ % copy adduser git % } 设置 ssh把本机的 id_isa.pub 内容复制到这里： 1/home/git/.ssh/authorized_keys 如果通过 ssh 登录仍需要密码的解决方法找到并修改 /etc/ssh/sshd_config 文件： 12345678910111213141516#禁用root账户登录，如果是用root用户登录请开启PermitRootLogin yes# 是否让 sshd 去检查用户家目录或相关档案的权限数据，# 这是为了担心使用者将某些重要档案的权限设错，可能会导致一些问题所致。# 例如使用者的 ~.ssh/ 权限设错时，某些特殊情况下会不许用户登入StrictModes no# 是否允许用户自行使用成对的密钥系统进行登入行为，仅针对 version 2。# 至于自制的公钥数据就放置于用户家目录下的 .ssh/authorized_keys 内RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys# 有了证书登录了，就禁用密码登录。PasswordAuthentication no 然后重启 sshd 服务 { % copy /bin/systemctl restart sshd.service % } 网站路径创建网站，以 /www/wwwroot/xaoxuu.github.io 为例，/www/wwwroot/xaoxuu.github.io 的权限要改成 777 并且所有者为 www 才可以访问。 GitHub Action1234567891011121314151617181920212223242526272829303132333435363738394041424344name: auto deploy # workflow nameon: [push] # 触发事件jobs: build: # job1 id runs-on: ubuntu-latest # 运行环境为最新版 Ubuntu name: auto deploy steps: - name: Checkout # step1 获取源码 uses: actions/checkout@v1 # 使用 actions/checkout@v1 with: # 条件 submodules: true # Checkout private submodules(themes or something else). 当有子模块时切换分支？ - name: Setup Node.js 10.x uses: actions/setup-node@master with: node-version: &quot;10.x&quot; - name: Generate Public Files run: | npm i npm install hexo-cli -g hexo clean &amp;&amp; hexo generate # Deploy to GitHub Pages - name: Deploy to GitHub Pages uses: peaceiris/actions-gh-pages@v3 with: deploy_key: $&#123;&#123; secrets.DEPLOY_KEY &#125;&#125; external_repository: xaoxuu/xaoxuu.github.io publish_branch: gh-pages publish_dir: ./public commit_message: $&#123;&#123; github.event.head_commit.message &#125;&#125; user_name: &#x27;github-actions[bot]&#x27; user_email: &#x27;github-actions[bot]@users.noreply.github.com&#x27; # Deploy to Server - name: Deploy to Server uses: easingthemes/ssh-deploy@v2 env: SSH_PRIVATE_KEY: $&#123;&#123; secrets.SERVER_SSH_KEY &#125;&#125; ARGS: &quot;-rltgoDzvO --delete&quot; SOURCE: public/ REMOTE_HOST: $&#123;&#123; secrets.REMOTE_HOST &#125;&#125; REMOTE_USER: $&#123;&#123; secrets.REMOTE_USER &#125;&#125; TARGET: $&#123;&#123; secrets.TARGET &#125;&#125; 在 Settings -&gt; Secrets 中填写对应的值： 1234SERVER_SSH_KEY: 第一步本机生成的 id_isa 文件内容REMOTE_HOST: 服务器地址REMOTE_USER: 用户名，例如 &quot;git&quot;TARGET: 生成的文件路径，例如 &quot;/www/wwwroot/xaoxuu.github.io/&quot; 设置 webhookpost-receive123#!/bin/bashWEBROOT=/www/wwwroot/xaoxuu.github.iogit --work-tree=$WEBROOT checkout -f master 把上述的 post-receive 文件放在这里： 1/home/git/xxx.git/hooks/post-receive /www/wwwroot/xaoxuu.github.io 的权限要改成 777 才行 { % link https://zhuanlan.zhihu.com/p/58654392 Hexo 从 GitHub 到阿里云 % } GitLab{ % link http://42.192.89.158:8099 GitLab % } 把上述的 post-receive 文件放在这里： 1/var/opt/gitlab/git-data/repositories/root/xxx.git/custom_hooks/post-receive GitLab 的 ssh 能记住密钥， hook 也正常，缺点就是每个月多花10块钱满足 GitLab 最低配置要求。 404打开 nginx 配置文件，拉到最后，看到： 1include /www/server/panel/vhost/nginx/*.conf; 然后根据这个路径找到自定义的配置文件： 1/www/server/panel/vhost/nginx/xaoxuu.com.conf 在其中添加如下代码就可以了： 12345678910server&#123; ... fastcgi_intercept_errors on; error_page 404 /404.html; location = /404.html &#123; root /www/wwwroot/xaoxuu.github.io; &#125; ...&#125;"},{"title":"认识 Git","path":"/wiki/git/index.html","content":"什么是 Git ？Git 是目前世界上最先进的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。 Git 与 SVN 区别点 Git 是分布式的，SVN 不是。这是 Git 和其它非分布式的版本控制系统如 SVN，CVS 等最核心的区别。 Git 把内容按元数据方式存储，而 SVN 是按文件。 Git 分支和 SVN 的分支不同：分支在 SVN 中一点都不特别，其实它就是版本库中的另外一个目录。 Git 没有一个全局的版本号，而 SVN 有。目前为止这是跟 SVN 相比 Git 缺少的最大的一个特征。 Git 的内容完整性要优于 SVN。Git 的内容存储使用的是 SHA-1 哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏。 图片来源于 RUNOOB Git 工作区、暂存区和版本库 工作区：就是你在电脑里能看到的目录。 暂存区：英文叫stage, 或index。一般存放在 “.git目录下” 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。 版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。"}]